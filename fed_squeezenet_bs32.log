Files already downloaded and verified
Files already downloaded and verified
Training Epoch: 1 [32/50000]	Loss: 4.6666	LR: 0.300000
Training Epoch: 1 [32/50000]	Loss: 4.5459	LR: 0.300000
Training Epoch: 1 [32/50000]	Loss: 4.6970	LR: 0.300000
Training Epoch: 1 [32/50000]	Loss: 4.6085	LR: 0.300000
Training Epoch: 1 [32/50000]	Loss: 4.6408	LR: 0.300000
Training Epoch: 1 [32/50000]	Loss: 4.6118	LR: 0.300000
Training Epoch: 1 [32/50000]	Loss: 4.5937	LR: 0.300000
Training Epoch: 1 [32/50000]	Loss: 4.6673	LR: 0.300000
Training Epoch: 1 [32/50000]	Loss: 4.6949	LR: 0.300000
Training Epoch: 1 [32/50000]	Loss: 4.6000	LR: 0.300000
Evaluating Network.....
Test set: Epoch: 1, Average loss: 0.1442, Top1Accuracy: 0.0100, Top3Accuracy: 0.0300, Top5Accuracy: 0.0500, Time consumed:1.78s

Training Epoch: 2 [32/50000]	Loss: 4.5871	LR: 0.292080
Training Epoch: 2 [32/50000]	Loss: 4.6203	LR: 0.292080
Training Epoch: 2 [32/50000]	Loss: 4.5992	LR: 0.292080
Training Epoch: 2 [32/50000]	Loss: 4.5912	LR: 0.292080
Training Epoch: 2 [32/50000]	Loss: 4.5852	LR: 0.292080
Training Epoch: 2 [32/50000]	Loss: 4.5775	LR: 0.292080
Training Epoch: 2 [32/50000]	Loss: 4.5886	LR: 0.292080
Training Epoch: 2 [32/50000]	Loss: 4.5851	LR: 0.292080
Training Epoch: 2 [32/50000]	Loss: 4.6006	LR: 0.292080
Training Epoch: 2 [32/50000]	Loss: 4.5827	LR: 0.292080
Evaluating Network.....
Test set: Epoch: 2, Average loss: 0.1445, Top1Accuracy: 0.0100, Top3Accuracy: 0.0300, Top5Accuracy: 0.0500, Time consumed:1.70s

Training Epoch: 3 [32/50000]	Loss: 4.5642	LR: 0.284369
Training Epoch: 3 [32/50000]	Loss: 4.4562	LR: 0.284369
Training Epoch: 3 [32/50000]	Loss: 4.5052	LR: 0.284369
Training Epoch: 3 [32/50000]	Loss: 4.5324	LR: 0.284369
Training Epoch: 3 [32/50000]	Loss: 4.5551	LR: 0.284369
Training Epoch: 3 [32/50000]	Loss: 4.5704	LR: 0.284369
Training Epoch: 3 [32/50000]	Loss: 4.4923	LR: 0.284369
Training Epoch: 3 [32/50000]	Loss: 4.5648	LR: 0.284369
Training Epoch: 3 [32/50000]	Loss: 4.4848	LR: 0.284369
Training Epoch: 3 [32/50000]	Loss: 4.5195	LR: 0.284369
Evaluating Network.....
Test set: Epoch: 3, Average loss: 0.1455, Top1Accuracy: 0.0101, Top3Accuracy: 0.0300, Top5Accuracy: 0.0500, Time consumed:1.78s

Training Epoch: 4 [32/50000]	Loss: 4.2219	LR: 0.276862
Training Epoch: 4 [32/50000]	Loss: 4.4317	LR: 0.276862
Training Epoch: 4 [32/50000]	Loss: 3.9916	LR: 0.276862
Training Epoch: 4 [32/50000]	Loss: 4.1319	LR: 0.276862
Training Epoch: 4 [32/50000]	Loss: 4.1759	LR: 0.276862
Training Epoch: 4 [32/50000]	Loss: 4.2400	LR: 0.276862
Training Epoch: 4 [32/50000]	Loss: 4.2166	LR: 0.276862
Training Epoch: 4 [32/50000]	Loss: 4.3314	LR: 0.276862
Training Epoch: 4 [32/50000]	Loss: 4.2433	LR: 0.276862
Training Epoch: 4 [32/50000]	Loss: 4.2512	LR: 0.276862
Evaluating Network.....
Test set: Epoch: 4, Average loss: 0.1386, Top1Accuracy: 0.0265, Top3Accuracy: 0.0718, Top5Accuracy: 0.1150, Time consumed:1.77s

Training Epoch: 5 [32/50000]	Loss: 4.0319	LR: 0.269553
Training Epoch: 5 [32/50000]	Loss: 3.9760	LR: 0.269553
Training Epoch: 5 [32/50000]	Loss: 4.0981	LR: 0.269553
Training Epoch: 5 [32/50000]	Loss: 4.1406	LR: 0.269553
Training Epoch: 5 [32/50000]	Loss: 4.3201	LR: 0.269553
Training Epoch: 5 [32/50000]	Loss: 4.0230	LR: 0.269553
Training Epoch: 5 [32/50000]	Loss: 4.0420	LR: 0.269553
Training Epoch: 5 [32/50000]	Loss: 4.2495	LR: 0.269553
Training Epoch: 5 [32/50000]	Loss: 3.9448	LR: 0.269553
Training Epoch: 5 [32/50000]	Loss: 4.0677	LR: 0.269553
Evaluating Network.....
Test set: Epoch: 5, Average loss: 0.1332, Top1Accuracy: 0.0387, Top3Accuracy: 0.1025, Top5Accuracy: 0.1678, Time consumed:1.71s

Training Epoch: 6 [32/50000]	Loss: 4.1489	LR: 0.262436
Training Epoch: 6 [32/50000]	Loss: 4.1189	LR: 0.262436
Training Epoch: 6 [32/50000]	Loss: 4.1503	LR: 0.262436
Training Epoch: 6 [32/50000]	Loss: 4.2766	LR: 0.262436
Training Epoch: 6 [32/50000]	Loss: 3.8933	LR: 0.262436
Training Epoch: 6 [32/50000]	Loss: 4.0843	LR: 0.262436
Training Epoch: 6 [32/50000]	Loss: 4.0741	LR: 0.262436
Training Epoch: 6 [32/50000]	Loss: 4.0298	LR: 0.262436
Training Epoch: 6 [32/50000]	Loss: 4.3509	LR: 0.262436
Training Epoch: 6 [32/50000]	Loss: 4.1096	LR: 0.262436
Evaluating Network.....
Test set: Epoch: 6, Average loss: 0.1283, Top1Accuracy: 0.0629, Top3Accuracy: 0.1534, Top5Accuracy: 0.2298, Time consumed:1.72s

Training Epoch: 7 [32/50000]	Loss: 3.8890	LR: 0.255508
Training Epoch: 7 [32/50000]	Loss: 3.9506	LR: 0.255508
Training Epoch: 7 [32/50000]	Loss: 4.1211	LR: 0.255508
Training Epoch: 7 [32/50000]	Loss: 4.0868	LR: 0.255508
Training Epoch: 7 [32/50000]	Loss: 4.1391	LR: 0.255508
Training Epoch: 7 [32/50000]	Loss: 3.9147	LR: 0.255508
Training Epoch: 7 [32/50000]	Loss: 3.9394	LR: 0.255508
Training Epoch: 7 [32/50000]	Loss: 3.9118	LR: 0.255508
Training Epoch: 7 [32/50000]	Loss: 4.0235	LR: 0.255508
Training Epoch: 7 [32/50000]	Loss: 4.2236	LR: 0.255508
Evaluating Network.....
Test set: Epoch: 7, Average loss: 0.1280, Top1Accuracy: 0.0668, Top3Accuracy: 0.1601, Top5Accuracy: 0.2313, Time consumed:1.75s

Training Epoch: 8 [32/50000]	Loss: 3.9296	LR: 0.248763
Training Epoch: 8 [32/50000]	Loss: 4.3290	LR: 0.248763
Training Epoch: 8 [32/50000]	Loss: 3.8825	LR: 0.248763
Training Epoch: 8 [32/50000]	Loss: 3.8457	LR: 0.248763
Training Epoch: 8 [32/50000]	Loss: 4.0377	LR: 0.248763
Training Epoch: 8 [32/50000]	Loss: 3.8631	LR: 0.248763
Training Epoch: 8 [32/50000]	Loss: 4.0066	LR: 0.248763
Training Epoch: 8 [32/50000]	Loss: 4.0527	LR: 0.248763
Training Epoch: 8 [32/50000]	Loss: 4.1053	LR: 0.248763
Training Epoch: 8 [32/50000]	Loss: 3.9348	LR: 0.248763
Evaluating Network.....
Test set: Epoch: 8, Average loss: 0.1254, Top1Accuracy: 0.0737, Top3Accuracy: 0.1748, Top5Accuracy: 0.2519, Time consumed:1.98s

Training Epoch: 9 [32/50000]	Loss: 3.8785	LR: 0.242195
Training Epoch: 9 [32/50000]	Loss: 3.9192	LR: 0.242195
Training Epoch: 9 [32/50000]	Loss: 3.8127	LR: 0.242195
Training Epoch: 9 [32/50000]	Loss: 3.8859	LR: 0.242195
Training Epoch: 9 [32/50000]	Loss: 4.0295	LR: 0.242195
Training Epoch: 9 [32/50000]	Loss: 4.0626	LR: 0.242195
Training Epoch: 9 [32/50000]	Loss: 4.0849	LR: 0.242195
Training Epoch: 9 [32/50000]	Loss: 4.1483	LR: 0.242195
Training Epoch: 9 [32/50000]	Loss: 3.6800	LR: 0.242195
Training Epoch: 9 [32/50000]	Loss: 3.8111	LR: 0.242195
Evaluating Network.....
Test set: Epoch: 9, Average loss: 0.1243, Top1Accuracy: 0.0786, Top3Accuracy: 0.1890, Top5Accuracy: 0.2745, Time consumed:1.79s

Training Epoch: 10 [32/50000]	Loss: 3.7269	LR: 0.235801
Training Epoch: 10 [32/50000]	Loss: 3.9689	LR: 0.235801
Training Epoch: 10 [32/50000]	Loss: 3.9344	LR: 0.235801
Training Epoch: 10 [32/50000]	Loss: 3.9669	LR: 0.235801
Training Epoch: 10 [32/50000]	Loss: 4.0205	LR: 0.235801
Training Epoch: 10 [32/50000]	Loss: 4.1258	LR: 0.235801
Training Epoch: 10 [32/50000]	Loss: 4.0129	LR: 0.235801
Training Epoch: 10 [32/50000]	Loss: 3.7971	LR: 0.235801
Training Epoch: 10 [32/50000]	Loss: 3.8882	LR: 0.235801
Training Epoch: 10 [32/50000]	Loss: 3.8374	LR: 0.235801
Evaluating Network.....
Test set: Epoch: 10, Average loss: 0.1209, Top1Accuracy: 0.0968, Top3Accuracy: 0.2230, Top5Accuracy: 0.3118, Time consumed:1.74s

Training Epoch: 11 [32/50000]	Loss: 3.7706	LR: 0.229576
Training Epoch: 11 [32/50000]	Loss: 3.4933	LR: 0.229576
Training Epoch: 11 [32/50000]	Loss: 3.7345	LR: 0.229576
Training Epoch: 11 [32/50000]	Loss: 3.8693	LR: 0.229576
Training Epoch: 11 [32/50000]	Loss: 3.6791	LR: 0.229576
Training Epoch: 11 [32/50000]	Loss: 3.9698	LR: 0.229576
Training Epoch: 11 [32/50000]	Loss: 4.2341	LR: 0.229576
Training Epoch: 11 [32/50000]	Loss: 3.6534	LR: 0.229576
Training Epoch: 11 [32/50000]	Loss: 3.7177	LR: 0.229576
Training Epoch: 11 [32/50000]	Loss: 4.0174	LR: 0.229576
Evaluating Network.....
Test set: Epoch: 11, Average loss: 0.1231, Top1Accuracy: 0.0810, Top3Accuracy: 0.1981, Top5Accuracy: 0.2804, Time consumed:1.83s

Training Epoch: 12 [32/50000]	Loss: 4.0695	LR: 0.223515
Training Epoch: 12 [32/50000]	Loss: 3.8526	LR: 0.223515
Training Epoch: 12 [32/50000]	Loss: 3.9934	LR: 0.223515
Training Epoch: 12 [32/50000]	Loss: 3.8258	LR: 0.223515
Training Epoch: 12 [32/50000]	Loss: 3.7716	LR: 0.223515
Training Epoch: 12 [32/50000]	Loss: 3.8033	LR: 0.223515
Training Epoch: 12 [32/50000]	Loss: 3.9607	LR: 0.223515
Training Epoch: 12 [32/50000]	Loss: 3.5958	LR: 0.223515
Training Epoch: 12 [32/50000]	Loss: 3.7706	LR: 0.223515
Training Epoch: 12 [32/50000]	Loss: 3.8608	LR: 0.223515
Evaluating Network.....
Test set: Epoch: 12, Average loss: 0.1196, Top1Accuracy: 0.1035, Top3Accuracy: 0.2338, Top5Accuracy: 0.3185, Time consumed:1.92s

Training Epoch: 13 [32/50000]	Loss: 3.6638	LR: 0.217615
Training Epoch: 13 [32/50000]	Loss: 3.5017	LR: 0.217615
Training Epoch: 13 [32/50000]	Loss: 4.0491	LR: 0.217615
Training Epoch: 13 [32/50000]	Loss: 3.9665	LR: 0.217615
Training Epoch: 13 [32/50000]	Loss: 3.2709	LR: 0.217615
Training Epoch: 13 [32/50000]	Loss: 3.6445	LR: 0.217615
Training Epoch: 13 [32/50000]	Loss: 3.7512	LR: 0.217615
Training Epoch: 13 [32/50000]	Loss: 3.5538	LR: 0.217615
Training Epoch: 13 [32/50000]	Loss: 3.6999	LR: 0.217615
Training Epoch: 13 [32/50000]	Loss: 3.7680	LR: 0.217615
Evaluating Network.....
Test set: Epoch: 13, Average loss: 0.1182, Top1Accuracy: 0.1118, Top3Accuracy: 0.2411, Top5Accuracy: 0.3314, Time consumed:2.01s

Training Epoch: 14 [32/50000]	Loss: 3.8073	LR: 0.211870
Training Epoch: 14 [32/50000]	Loss: 3.9855	LR: 0.211870
Training Epoch: 14 [32/50000]	Loss: 3.5595	LR: 0.211870
Training Epoch: 14 [32/50000]	Loss: 4.0008	LR: 0.211870
Training Epoch: 14 [32/50000]	Loss: 3.4458	LR: 0.211870
Training Epoch: 14 [32/50000]	Loss: 3.6561	LR: 0.211870
Training Epoch: 14 [32/50000]	Loss: 3.2869	LR: 0.211870
Training Epoch: 14 [32/50000]	Loss: 3.5063	LR: 0.211870
Training Epoch: 14 [32/50000]	Loss: 3.6506	LR: 0.211870
Training Epoch: 14 [32/50000]	Loss: 3.3472	LR: 0.211870
Evaluating Network.....
Test set: Epoch: 14, Average loss: 0.1178, Top1Accuracy: 0.1186, Top3Accuracy: 0.2502, Top5Accuracy: 0.3401, Time consumed:1.80s

Training Epoch: 15 [32/50000]	Loss: 3.7635	LR: 0.206276
Training Epoch: 15 [32/50000]	Loss: 3.8960	LR: 0.206276
Training Epoch: 15 [32/50000]	Loss: 3.7537	LR: 0.206276
Training Epoch: 15 [32/50000]	Loss: 3.6417	LR: 0.206276
Training Epoch: 15 [32/50000]	Loss: 3.6632	LR: 0.206276
Training Epoch: 15 [32/50000]	Loss: 3.7920	LR: 0.206276
Training Epoch: 15 [32/50000]	Loss: 3.7508	LR: 0.206276
Training Epoch: 15 [32/50000]	Loss: 3.3878	LR: 0.206276
Training Epoch: 15 [32/50000]	Loss: 3.4725	LR: 0.206276
Training Epoch: 15 [32/50000]	Loss: 3.5783	LR: 0.206276
Evaluating Network.....
Test set: Epoch: 15, Average loss: 0.1153, Top1Accuracy: 0.1274, Top3Accuracy: 0.2686, Top5Accuracy: 0.3579, Time consumed:1.82s

Training Epoch: 16 [32/50000]	Loss: 3.8620	LR: 0.200831
Training Epoch: 16 [32/50000]	Loss: 3.6375	LR: 0.200831
Training Epoch: 16 [32/50000]	Loss: 3.8266	LR: 0.200831
Training Epoch: 16 [32/50000]	Loss: 3.3987	LR: 0.200831
Training Epoch: 16 [32/50000]	Loss: 3.9169	LR: 0.200831
Training Epoch: 16 [32/50000]	Loss: 3.3793	LR: 0.200831
Training Epoch: 16 [32/50000]	Loss: 3.2407	LR: 0.200831
Training Epoch: 16 [32/50000]	Loss: 3.6536	LR: 0.200831
Training Epoch: 16 [32/50000]	Loss: 3.4503	LR: 0.200831
Training Epoch: 16 [32/50000]	Loss: 3.5736	LR: 0.200831
Evaluating Network.....
Test set: Epoch: 16, Average loss: 0.1123, Top1Accuracy: 0.1470, Top3Accuracy: 0.2990, Top5Accuracy: 0.3946, Time consumed:1.75s

Training Epoch: 17 [32/50000]	Loss: 3.5442	LR: 0.195529
Training Epoch: 17 [32/50000]	Loss: 3.5939	LR: 0.195529
Training Epoch: 17 [32/50000]	Loss: 3.3950	LR: 0.195529
Training Epoch: 17 [32/50000]	Loss: 3.5169	LR: 0.195529
Training Epoch: 17 [32/50000]	Loss: 3.6545	LR: 0.195529
Training Epoch: 17 [32/50000]	Loss: 3.9288	LR: 0.195529
Training Epoch: 17 [32/50000]	Loss: 3.6288	LR: 0.195529
Training Epoch: 17 [32/50000]	Loss: 3.8786	LR: 0.195529
Training Epoch: 17 [32/50000]	Loss: 3.5111	LR: 0.195529
Training Epoch: 17 [32/50000]	Loss: 3.5793	LR: 0.195529
Evaluating Network.....
Test set: Epoch: 17, Average loss: 0.1106, Top1Accuracy: 0.1509, Top3Accuracy: 0.3066, Top5Accuracy: 0.4042, Time consumed:1.84s

Training Epoch: 18 [32/50000]	Loss: 4.1098	LR: 0.190367
Training Epoch: 18 [32/50000]	Loss: 3.3089	LR: 0.190367
Training Epoch: 18 [32/50000]	Loss: 3.6737	LR: 0.190367
Training Epoch: 18 [32/50000]	Loss: 3.6409	LR: 0.190367
Training Epoch: 18 [32/50000]	Loss: 3.6220	LR: 0.190367
Training Epoch: 18 [32/50000]	Loss: 3.3503	LR: 0.190367
Training Epoch: 18 [32/50000]	Loss: 3.7316	LR: 0.190367
Training Epoch: 18 [32/50000]	Loss: 3.6541	LR: 0.190367
Training Epoch: 18 [32/50000]	Loss: 3.8497	LR: 0.190367
Training Epoch: 18 [32/50000]	Loss: 3.4129	LR: 0.190367
Evaluating Network.....
Test set: Epoch: 18, Average loss: 0.1120, Top1Accuracy: 0.1438, Top3Accuracy: 0.3003, Top5Accuracy: 0.3946, Time consumed:1.89s

Training Epoch: 19 [32/50000]	Loss: 3.4486	LR: 0.185341
Training Epoch: 19 [32/50000]	Loss: 3.0314	LR: 0.185341
Training Epoch: 19 [32/50000]	Loss: 3.6910	LR: 0.185341
Training Epoch: 19 [32/50000]	Loss: 3.3701	LR: 0.185341
Training Epoch: 19 [32/50000]	Loss: 3.3404	LR: 0.185341
Training Epoch: 19 [32/50000]	Loss: 3.4129	LR: 0.185341
Training Epoch: 19 [32/50000]	Loss: 3.2663	LR: 0.185341
Training Epoch: 19 [32/50000]	Loss: 3.5881	LR: 0.185341
Training Epoch: 19 [32/50000]	Loss: 3.4227	LR: 0.185341
Training Epoch: 19 [32/50000]	Loss: 3.5719	LR: 0.185341
Evaluating Network.....
Test set: Epoch: 19, Average loss: 0.1068, Top1Accuracy: 0.1803, Top3Accuracy: 0.3505, Top5Accuracy: 0.4460, Time consumed:1.80s

Training Epoch: 20 [32/50000]	Loss: 3.6067	LR: 0.180448
Training Epoch: 20 [32/50000]	Loss: 3.5174	LR: 0.180448
Training Epoch: 20 [32/50000]	Loss: 3.5597	LR: 0.180448
Training Epoch: 20 [32/50000]	Loss: 3.1970	LR: 0.180448
Training Epoch: 20 [32/50000]	Loss: 3.7995	LR: 0.180448
Training Epoch: 20 [32/50000]	Loss: 3.4088	LR: 0.180448
Training Epoch: 20 [32/50000]	Loss: 3.3068	LR: 0.180448
Training Epoch: 20 [32/50000]	Loss: 3.6150	LR: 0.180448
Training Epoch: 20 [32/50000]	Loss: 3.0088	LR: 0.180448
Training Epoch: 20 [32/50000]	Loss: 3.1242	LR: 0.180448
Evaluating Network.....
Test set: Epoch: 20, Average loss: 0.1079, Top1Accuracy: 0.1631, Top3Accuracy: 0.3341, Top5Accuracy: 0.4366, Time consumed:1.73s

Training Epoch: 21 [32/50000]	Loss: 3.4686	LR: 0.175684
Training Epoch: 21 [32/50000]	Loss: 3.4910	LR: 0.175684
Training Epoch: 21 [32/50000]	Loss: 3.5506	LR: 0.175684
Training Epoch: 21 [32/50000]	Loss: 3.9817	LR: 0.175684
Training Epoch: 21 [32/50000]	Loss: 3.3906	LR: 0.175684
Training Epoch: 21 [32/50000]	Loss: 3.3381	LR: 0.175684
Training Epoch: 21 [32/50000]	Loss: 3.4789	LR: 0.175684
Training Epoch: 21 [32/50000]	Loss: 3.2591	LR: 0.175684
Training Epoch: 21 [32/50000]	Loss: 3.2449	LR: 0.175684
Training Epoch: 21 [32/50000]	Loss: 3.7205	LR: 0.175684
Evaluating Network.....
Test set: Epoch: 21, Average loss: 0.1057, Top1Accuracy: 0.1853, Top3Accuracy: 0.3575, Top5Accuracy: 0.4561, Time consumed:1.73s

Training Epoch: 22 [32/50000]	Loss: 3.1393	LR: 0.171046
Training Epoch: 22 [32/50000]	Loss: 3.3705	LR: 0.171046
Training Epoch: 22 [32/50000]	Loss: 3.5188	LR: 0.171046
Training Epoch: 22 [32/50000]	Loss: 3.4757	LR: 0.171046
Training Epoch: 22 [32/50000]	Loss: 3.1302	LR: 0.171046
Training Epoch: 22 [32/50000]	Loss: 3.6276	LR: 0.171046
Training Epoch: 22 [32/50000]	Loss: 3.3435	LR: 0.171046
Training Epoch: 22 [32/50000]	Loss: 2.7861	LR: 0.171046
Training Epoch: 22 [32/50000]	Loss: 3.3340	LR: 0.171046
Training Epoch: 22 [32/50000]	Loss: 3.3372	LR: 0.171046
Evaluating Network.....
Test set: Epoch: 22, Average loss: 0.1068, Top1Accuracy: 0.1788, Top3Accuracy: 0.3463, Top5Accuracy: 0.4465, Time consumed:1.76s

Training Epoch: 23 [32/50000]	Loss: 3.3290	LR: 0.166530
Training Epoch: 23 [32/50000]	Loss: 3.1989	LR: 0.166530
Training Epoch: 23 [32/50000]	Loss: 3.3367	LR: 0.166530
Training Epoch: 23 [32/50000]	Loss: 3.4996	LR: 0.166530
Training Epoch: 23 [32/50000]	Loss: 3.2364	LR: 0.166530
Training Epoch: 23 [32/50000]	Loss: 3.3956	LR: 0.166530
Training Epoch: 23 [32/50000]	Loss: 3.7127	LR: 0.166530
Training Epoch: 23 [32/50000]	Loss: 3.0916	LR: 0.166530
Training Epoch: 23 [32/50000]	Loss: 3.4770	LR: 0.166530
Training Epoch: 23 [32/50000]	Loss: 3.2327	LR: 0.166530
Evaluating Network.....
Test set: Epoch: 23, Average loss: 0.1031, Top1Accuracy: 0.1995, Top3Accuracy: 0.3760, Top5Accuracy: 0.4734, Time consumed:1.80s

Training Epoch: 24 [32/50000]	Loss: 3.5769	LR: 0.162134
Training Epoch: 24 [32/50000]	Loss: 3.0720	LR: 0.162134
Training Epoch: 24 [32/50000]	Loss: 3.2975	LR: 0.162134
Training Epoch: 24 [32/50000]	Loss: 3.3239	LR: 0.162134
Training Epoch: 24 [32/50000]	Loss: 3.5024	LR: 0.162134
Training Epoch: 24 [32/50000]	Loss: 3.0978	LR: 0.162134
Training Epoch: 24 [32/50000]	Loss: 3.4835	LR: 0.162134
Training Epoch: 24 [32/50000]	Loss: 3.3614	LR: 0.162134
Training Epoch: 24 [32/50000]	Loss: 3.1726	LR: 0.162134
Training Epoch: 24 [32/50000]	Loss: 2.9082	LR: 0.162134
Evaluating Network.....
Test set: Epoch: 24, Average loss: 0.1028, Top1Accuracy: 0.2019, Top3Accuracy: 0.3773, Top5Accuracy: 0.4873, Time consumed:1.81s

Training Epoch: 25 [32/50000]	Loss: 3.4046	LR: 0.157854
Training Epoch: 25 [32/50000]	Loss: 3.4503	LR: 0.157854
Training Epoch: 25 [32/50000]	Loss: 3.6120	LR: 0.157854
Training Epoch: 25 [32/50000]	Loss: 3.3455	LR: 0.157854
Training Epoch: 25 [32/50000]	Loss: 3.3957	LR: 0.157854
Training Epoch: 25 [32/50000]	Loss: 3.4266	LR: 0.157854
Training Epoch: 25 [32/50000]	Loss: 3.3857	LR: 0.157854
Training Epoch: 25 [32/50000]	Loss: 3.2412	LR: 0.157854
Training Epoch: 25 [32/50000]	Loss: 3.4165	LR: 0.157854
Training Epoch: 25 [32/50000]	Loss: 3.2777	LR: 0.157854
Evaluating Network.....
Test set: Epoch: 25, Average loss: 0.1047, Top1Accuracy: 0.1932, Top3Accuracy: 0.3675, Top5Accuracy: 0.4659, Time consumed:1.76s

Training Epoch: 26 [32/50000]	Loss: 3.6867	LR: 0.153686
Training Epoch: 26 [32/50000]	Loss: 3.3161	LR: 0.153686
Training Epoch: 26 [32/50000]	Loss: 3.3269	LR: 0.153686
Training Epoch: 26 [32/50000]	Loss: 3.5038	LR: 0.153686
Training Epoch: 26 [32/50000]	Loss: 3.1581	LR: 0.153686
Training Epoch: 26 [32/50000]	Loss: 3.2031	LR: 0.153686
Training Epoch: 26 [32/50000]	Loss: 3.6047	LR: 0.153686
Training Epoch: 26 [32/50000]	Loss: 3.0947	LR: 0.153686
Training Epoch: 26 [32/50000]	Loss: 3.1090	LR: 0.153686
Training Epoch: 26 [32/50000]	Loss: 3.0986	LR: 0.153686
Evaluating Network.....
Test set: Epoch: 26, Average loss: 0.1023, Top1Accuracy: 0.2027, Top3Accuracy: 0.3806, Top5Accuracy: 0.4811, Time consumed:1.79s

Training Epoch: 27 [32/50000]	Loss: 3.4561	LR: 0.149629
Training Epoch: 27 [32/50000]	Loss: 2.8043	LR: 0.149629
Training Epoch: 27 [32/50000]	Loss: 3.0518	LR: 0.149629
Training Epoch: 27 [32/50000]	Loss: 3.3944	LR: 0.149629
Training Epoch: 27 [32/50000]	Loss: 3.1583	LR: 0.149629
Training Epoch: 27 [32/50000]	Loss: 3.3665	LR: 0.149629
Training Epoch: 27 [32/50000]	Loss: 2.8108	LR: 0.149629
Training Epoch: 27 [32/50000]	Loss: 3.3401	LR: 0.149629
Training Epoch: 27 [32/50000]	Loss: 3.4613	LR: 0.149629
Training Epoch: 27 [32/50000]	Loss: 3.1882	LR: 0.149629
Evaluating Network.....
Test set: Epoch: 27, Average loss: 0.1011, Top1Accuracy: 0.2128, Top3Accuracy: 0.3920, Top5Accuracy: 0.4975, Time consumed:1.78s

Training Epoch: 28 [32/50000]	Loss: 3.7704	LR: 0.145679
Training Epoch: 28 [32/50000]	Loss: 3.3070	LR: 0.145679
Training Epoch: 28 [32/50000]	Loss: 3.5718	LR: 0.145679
Training Epoch: 28 [32/50000]	Loss: 3.2612	LR: 0.145679
Training Epoch: 28 [32/50000]	Loss: 3.1953	LR: 0.145679
Training Epoch: 28 [32/50000]	Loss: 3.5736	LR: 0.145679
Training Epoch: 28 [32/50000]	Loss: 2.8253	LR: 0.145679
Training Epoch: 28 [32/50000]	Loss: 3.0641	LR: 0.145679
Training Epoch: 28 [32/50000]	Loss: 3.2289	LR: 0.145679
Training Epoch: 28 [32/50000]	Loss: 3.2760	LR: 0.145679
Evaluating Network.....
Test set: Epoch: 28, Average loss: 0.1003, Top1Accuracy: 0.2203, Top3Accuracy: 0.4039, Top5Accuracy: 0.5004, Time consumed:1.76s

Training Epoch: 29 [32/50000]	Loss: 2.9403	LR: 0.141833
Training Epoch: 29 [32/50000]	Loss: 3.2008	LR: 0.141833
Training Epoch: 29 [32/50000]	Loss: 2.9924	LR: 0.141833
Training Epoch: 29 [32/50000]	Loss: 2.6040	LR: 0.141833
Training Epoch: 29 [32/50000]	Loss: 3.3179	LR: 0.141833
Training Epoch: 29 [32/50000]	Loss: 3.0651	LR: 0.141833
Training Epoch: 29 [32/50000]	Loss: 3.7962	LR: 0.141833
Training Epoch: 29 [32/50000]	Loss: 3.4732	LR: 0.141833
Training Epoch: 29 [32/50000]	Loss: 3.1656	LR: 0.141833
Training Epoch: 29 [32/50000]	Loss: 2.8890	LR: 0.141833
Evaluating Network.....
Test set: Epoch: 29, Average loss: 0.1005, Top1Accuracy: 0.2186, Top3Accuracy: 0.4005, Top5Accuracy: 0.4979, Time consumed:1.84s

Training Epoch: 30 [32/50000]	Loss: 2.9544	LR: 0.138089
Training Epoch: 30 [32/50000]	Loss: 3.0485	LR: 0.138089
Training Epoch: 30 [32/50000]	Loss: 2.8819	LR: 0.138089
Training Epoch: 30 [32/50000]	Loss: 3.2440	LR: 0.138089
Training Epoch: 30 [32/50000]	Loss: 3.2773	LR: 0.138089
Training Epoch: 30 [32/50000]	Loss: 2.9287	LR: 0.138089
Training Epoch: 30 [32/50000]	Loss: 2.8963	LR: 0.138089
Training Epoch: 30 [32/50000]	Loss: 3.0570	LR: 0.138089
Training Epoch: 30 [32/50000]	Loss: 3.5314	LR: 0.138089
Training Epoch: 30 [32/50000]	Loss: 3.0378	LR: 0.138089
Evaluating Network.....
Test set: Epoch: 30, Average loss: 0.0967, Top1Accuracy: 0.2385, Top3Accuracy: 0.4300, Top5Accuracy: 0.5296, Time consumed:1.77s

Training Epoch: 31 [32/50000]	Loss: 2.9588	LR: 0.134443
Training Epoch: 31 [32/50000]	Loss: 2.9427	LR: 0.134443
Training Epoch: 31 [32/50000]	Loss: 3.3818	LR: 0.134443
Training Epoch: 31 [32/50000]	Loss: 3.3417	LR: 0.134443
Training Epoch: 31 [32/50000]	Loss: 3.3496	LR: 0.134443
Training Epoch: 31 [32/50000]	Loss: 2.8985	LR: 0.134443
Training Epoch: 31 [32/50000]	Loss: 3.6272	LR: 0.134443
Training Epoch: 31 [32/50000]	Loss: 3.0272	LR: 0.134443
Training Epoch: 31 [32/50000]	Loss: 3.1701	LR: 0.134443
Training Epoch: 31 [32/50000]	Loss: 3.0851	LR: 0.134443
Evaluating Network.....
Test set: Epoch: 31, Average loss: 0.0971, Top1Accuracy: 0.2377, Top3Accuracy: 0.4279, Top5Accuracy: 0.5287, Time consumed:1.86s

Training Epoch: 32 [32/50000]	Loss: 3.7719	LR: 0.130894
Training Epoch: 32 [32/50000]	Loss: 3.5527	LR: 0.130894
Training Epoch: 32 [32/50000]	Loss: 3.0740	LR: 0.130894
Training Epoch: 32 [32/50000]	Loss: 3.0021	LR: 0.130894
Training Epoch: 32 [32/50000]	Loss: 2.7851	LR: 0.130894
Training Epoch: 32 [32/50000]	Loss: 2.7723	LR: 0.130894
Training Epoch: 32 [32/50000]	Loss: 3.0809	LR: 0.130894
Training Epoch: 32 [32/50000]	Loss: 2.8438	LR: 0.130894
Training Epoch: 32 [32/50000]	Loss: 3.1794	LR: 0.130894
Training Epoch: 32 [32/50000]	Loss: 3.3302	LR: 0.130894
Evaluating Network.....
Test set: Epoch: 32, Average loss: 0.0957, Top1Accuracy: 0.2438, Top3Accuracy: 0.4396, Top5Accuracy: 0.5432, Time consumed:1.77s

Training Epoch: 33 [32/50000]	Loss: 2.8944	LR: 0.127438
Training Epoch: 33 [32/50000]	Loss: 2.6454	LR: 0.127438
Training Epoch: 33 [32/50000]	Loss: 3.1122	LR: 0.127438
Training Epoch: 33 [32/50000]	Loss: 2.9646	LR: 0.127438
Training Epoch: 33 [32/50000]	Loss: 2.7613	LR: 0.127438
Training Epoch: 33 [32/50000]	Loss: 3.0605	LR: 0.127438
Training Epoch: 33 [32/50000]	Loss: 3.0384	LR: 0.127438
Training Epoch: 33 [32/50000]	Loss: 2.9215	LR: 0.127438
Training Epoch: 33 [32/50000]	Loss: 3.0296	LR: 0.127438
Training Epoch: 33 [32/50000]	Loss: 2.9454	LR: 0.127438
Evaluating Network.....
Test set: Epoch: 33, Average loss: 0.0948, Top1Accuracy: 0.2497, Top3Accuracy: 0.4453, Top5Accuracy: 0.5502, Time consumed:1.81s

Training Epoch: 34 [32/50000]	Loss: 2.8966	LR: 0.124074
Training Epoch: 34 [32/50000]	Loss: 3.1615	LR: 0.124074
Training Epoch: 34 [32/50000]	Loss: 3.1851	LR: 0.124074
Training Epoch: 34 [32/50000]	Loss: 3.2290	LR: 0.124074
Training Epoch: 34 [32/50000]	Loss: 2.8657	LR: 0.124074
Training Epoch: 34 [32/50000]	Loss: 2.6701	LR: 0.124074
Training Epoch: 34 [32/50000]	Loss: 2.9858	LR: 0.124074
Training Epoch: 34 [32/50000]	Loss: 2.7991	LR: 0.124074
Training Epoch: 34 [32/50000]	Loss: 3.8361	LR: 0.124074
Training Epoch: 34 [32/50000]	Loss: 3.2122	LR: 0.124074
Evaluating Network.....
Test set: Epoch: 34, Average loss: 0.0940, Top1Accuracy: 0.2602, Top3Accuracy: 0.4526, Top5Accuracy: 0.5534, Time consumed:1.80s

Training Epoch: 35 [32/50000]	Loss: 2.7594	LR: 0.120798
Training Epoch: 35 [32/50000]	Loss: 3.6028	LR: 0.120798
Training Epoch: 35 [32/50000]	Loss: 2.6780	LR: 0.120798
Training Epoch: 35 [32/50000]	Loss: 2.8219	LR: 0.120798
Training Epoch: 35 [32/50000]	Loss: 2.9898	LR: 0.120798
Training Epoch: 35 [32/50000]	Loss: 3.2283	LR: 0.120798
Training Epoch: 35 [32/50000]	Loss: 2.7681	LR: 0.120798
Training Epoch: 35 [32/50000]	Loss: 3.2208	LR: 0.120798
Training Epoch: 35 [32/50000]	Loss: 2.8977	LR: 0.120798
Training Epoch: 35 [32/50000]	Loss: 3.0069	LR: 0.120798
Evaluating Network.....
Test set: Epoch: 35, Average loss: 0.0941, Top1Accuracy: 0.2548, Top3Accuracy: 0.4524, Top5Accuracy: 0.5550, Time consumed:1.78s

Training Epoch: 36 [32/50000]	Loss: 2.9418	LR: 0.117609
Training Epoch: 36 [32/50000]	Loss: 2.9765	LR: 0.117609
Training Epoch: 36 [32/50000]	Loss: 2.7052	LR: 0.117609
Training Epoch: 36 [32/50000]	Loss: 3.4315	LR: 0.117609
Training Epoch: 36 [32/50000]	Loss: 2.6710	LR: 0.117609
Training Epoch: 36 [32/50000]	Loss: 2.7734	LR: 0.117609
Training Epoch: 36 [32/50000]	Loss: 2.4852	LR: 0.117609
Training Epoch: 36 [32/50000]	Loss: 2.7950	LR: 0.117609
Training Epoch: 36 [32/50000]	Loss: 2.8877	LR: 0.117609
Training Epoch: 36 [32/50000]	Loss: 2.9707	LR: 0.117609
Evaluating Network.....
Test set: Epoch: 36, Average loss: 0.0926, Top1Accuracy: 0.2671, Top3Accuracy: 0.4601, Top5Accuracy: 0.5607, Time consumed:1.96s

Training Epoch: 37 [32/50000]	Loss: 2.6566	LR: 0.114504
Training Epoch: 37 [32/50000]	Loss: 2.7492	LR: 0.114504
Training Epoch: 37 [32/50000]	Loss: 2.5743	LR: 0.114504
Training Epoch: 37 [32/50000]	Loss: 2.8107	LR: 0.114504
Training Epoch: 37 [32/50000]	Loss: 2.7501	LR: 0.114504
Training Epoch: 37 [32/50000]	Loss: 3.2765	LR: 0.114504
Training Epoch: 37 [32/50000]	Loss: 2.6813	LR: 0.114504
Training Epoch: 37 [32/50000]	Loss: 3.0328	LR: 0.114504
Training Epoch: 37 [32/50000]	Loss: 2.9484	LR: 0.114504
Training Epoch: 37 [32/50000]	Loss: 2.8875	LR: 0.114504
Evaluating Network.....
Test set: Epoch: 37, Average loss: 0.0916, Top1Accuracy: 0.2713, Top3Accuracy: 0.4740, Top5Accuracy: 0.5739, Time consumed:1.78s

Training Epoch: 38 [32/50000]	Loss: 2.9704	LR: 0.111481
Training Epoch: 38 [32/50000]	Loss: 3.1750	LR: 0.111481
Training Epoch: 38 [32/50000]	Loss: 2.8658	LR: 0.111481
Training Epoch: 38 [32/50000]	Loss: 2.6697	LR: 0.111481
Training Epoch: 38 [32/50000]	Loss: 2.5072	LR: 0.111481
Training Epoch: 38 [32/50000]	Loss: 2.9242	LR: 0.111481
Training Epoch: 38 [32/50000]	Loss: 3.0118	LR: 0.111481
Training Epoch: 38 [32/50000]	Loss: 2.8207	LR: 0.111481
Training Epoch: 38 [32/50000]	Loss: 3.3934	LR: 0.111481
Training Epoch: 38 [32/50000]	Loss: 2.9143	LR: 0.111481
Evaluating Network.....
Test set: Epoch: 38, Average loss: 0.0910, Top1Accuracy: 0.2779, Top3Accuracy: 0.4727, Top5Accuracy: 0.5743, Time consumed:1.74s

Training Epoch: 39 [32/50000]	Loss: 2.5005	LR: 0.108538
Training Epoch: 39 [32/50000]	Loss: 2.6762	LR: 0.108538
Training Epoch: 39 [32/50000]	Loss: 2.9435	LR: 0.108538
Training Epoch: 39 [32/50000]	Loss: 2.8167	LR: 0.108538
Training Epoch: 39 [32/50000]	Loss: 3.2658	LR: 0.108538
Training Epoch: 39 [32/50000]	Loss: 2.9894	LR: 0.108538
Training Epoch: 39 [32/50000]	Loss: 3.1491	LR: 0.108538
Training Epoch: 39 [32/50000]	Loss: 2.8187	LR: 0.108538
Training Epoch: 39 [32/50000]	Loss: 2.8009	LR: 0.108538
Training Epoch: 39 [32/50000]	Loss: 2.7727	LR: 0.108538
Evaluating Network.....
Test set: Epoch: 39, Average loss: 0.0894, Top1Accuracy: 0.2874, Top3Accuracy: 0.4860, Top5Accuracy: 0.5871, Time consumed:1.75s

Training Epoch: 40 [32/50000]	Loss: 2.8689	LR: 0.105673
Training Epoch: 40 [32/50000]	Loss: 3.1441	LR: 0.105673
Training Epoch: 40 [32/50000]	Loss: 3.4894	LR: 0.105673
Training Epoch: 40 [32/50000]	Loss: 2.8400	LR: 0.105673
Training Epoch: 40 [32/50000]	Loss: 2.8382	LR: 0.105673
Training Epoch: 40 [32/50000]	Loss: 2.4896	LR: 0.105673
Training Epoch: 40 [32/50000]	Loss: 2.8218	LR: 0.105673
Training Epoch: 40 [32/50000]	Loss: 2.8036	LR: 0.105673
Training Epoch: 40 [32/50000]	Loss: 2.5811	LR: 0.105673
Training Epoch: 40 [32/50000]	Loss: 2.8487	LR: 0.105673
Evaluating Network.....
Test set: Epoch: 40, Average loss: 0.0896, Top1Accuracy: 0.2830, Top3Accuracy: 0.4823, Top5Accuracy: 0.5850, Time consumed:1.76s

Training Epoch: 41 [32/50000]	Loss: 3.4318	LR: 0.102883
Training Epoch: 41 [32/50000]	Loss: 3.1019	LR: 0.102883
Training Epoch: 41 [32/50000]	Loss: 3.3067	LR: 0.102883
Training Epoch: 41 [32/50000]	Loss: 2.5597	LR: 0.102883
Training Epoch: 41 [32/50000]	Loss: 2.6818	LR: 0.102883
Training Epoch: 41 [32/50000]	Loss: 3.0335	LR: 0.102883
Training Epoch: 41 [32/50000]	Loss: 3.3499	LR: 0.102883
Training Epoch: 41 [32/50000]	Loss: 2.9105	LR: 0.102883
Training Epoch: 41 [32/50000]	Loss: 2.7987	LR: 0.102883
Training Epoch: 41 [32/50000]	Loss: 2.6677	LR: 0.102883
Evaluating Network.....
Test set: Epoch: 41, Average loss: 0.0884, Top1Accuracy: 0.2923, Top3Accuracy: 0.4921, Top5Accuracy: 0.5939, Time consumed:1.79s

Training Epoch: 42 [32/50000]	Loss: 2.9418	LR: 0.100167
Training Epoch: 42 [32/50000]	Loss: 2.7163	LR: 0.100167
Training Epoch: 42 [32/50000]	Loss: 2.9242	LR: 0.100167
Training Epoch: 42 [32/50000]	Loss: 3.2487	LR: 0.100167
Training Epoch: 42 [32/50000]	Loss: 3.0223	LR: 0.100167
Training Epoch: 42 [32/50000]	Loss: 2.9354	LR: 0.100167
Training Epoch: 42 [32/50000]	Loss: 2.7101	LR: 0.100167
Training Epoch: 42 [32/50000]	Loss: 2.7777	LR: 0.100167
Training Epoch: 42 [32/50000]	Loss: 2.8431	LR: 0.100167
Training Epoch: 42 [32/50000]	Loss: 3.1308	LR: 0.100167
Evaluating Network.....
Test set: Epoch: 42, Average loss: 0.0878, Top1Accuracy: 0.2959, Top3Accuracy: 0.5024, Top5Accuracy: 0.6005, Time consumed:1.74s

Training Epoch: 43 [32/50000]	Loss: 3.2379	LR: 0.097523
Training Epoch: 43 [32/50000]	Loss: 2.7498	LR: 0.097523
Training Epoch: 43 [32/50000]	Loss: 2.3233	LR: 0.097523
Training Epoch: 43 [32/50000]	Loss: 3.2435	LR: 0.097523
Training Epoch: 43 [32/50000]	Loss: 2.7423	LR: 0.097523
Training Epoch: 43 [32/50000]	Loss: 2.7863	LR: 0.097523
Training Epoch: 43 [32/50000]	Loss: 2.7060	LR: 0.097523
Training Epoch: 43 [32/50000]	Loss: 2.4208	LR: 0.097523
Training Epoch: 43 [32/50000]	Loss: 3.0540	LR: 0.097523
Training Epoch: 43 [32/50000]	Loss: 2.8844	LR: 0.097523
Evaluating Network.....
Test set: Epoch: 43, Average loss: 0.0870, Top1Accuracy: 0.3019, Top3Accuracy: 0.5030, Top5Accuracy: 0.6055, Time consumed:1.69s

Training Epoch: 44 [32/50000]	Loss: 3.1598	LR: 0.094948
Training Epoch: 44 [32/50000]	Loss: 3.3226	LR: 0.094948
Training Epoch: 44 [32/50000]	Loss: 2.6879	LR: 0.094948
Training Epoch: 44 [32/50000]	Loss: 2.8596	LR: 0.094948
Training Epoch: 44 [32/50000]	Loss: 3.2086	LR: 0.094948
Training Epoch: 44 [32/50000]	Loss: 2.9958	LR: 0.094948
Training Epoch: 44 [32/50000]	Loss: 2.7938	LR: 0.094948
Training Epoch: 44 [32/50000]	Loss: 2.6607	LR: 0.094948
Training Epoch: 44 [32/50000]	Loss: 2.5341	LR: 0.094948
Training Epoch: 44 [32/50000]	Loss: 3.0103	LR: 0.094948
Evaluating Network.....
Test set: Epoch: 44, Average loss: 0.0859, Top1Accuracy: 0.3075, Top3Accuracy: 0.5170, Top5Accuracy: 0.6186, Time consumed:1.75s

Training Epoch: 45 [32/50000]	Loss: 3.4940	LR: 0.092441
Training Epoch: 45 [32/50000]	Loss: 2.8976	LR: 0.092441
Training Epoch: 45 [32/50000]	Loss: 2.6902	LR: 0.092441
Training Epoch: 45 [32/50000]	Loss: 2.1548	LR: 0.092441
Training Epoch: 45 [32/50000]	Loss: 2.5334	LR: 0.092441
Training Epoch: 45 [32/50000]	Loss: 2.7362	LR: 0.092441
Training Epoch: 45 [32/50000]	Loss: 3.0125	LR: 0.092441
Training Epoch: 45 [32/50000]	Loss: 2.8503	LR: 0.092441
Training Epoch: 45 [32/50000]	Loss: 2.8150	LR: 0.092441
Training Epoch: 45 [32/50000]	Loss: 2.4505	LR: 0.092441
Evaluating Network.....
Test set: Epoch: 45, Average loss: 0.0860, Top1Accuracy: 0.3097, Top3Accuracy: 0.5167, Top5Accuracy: 0.6132, Time consumed:1.84s

Training Epoch: 46 [32/50000]	Loss: 2.9187	LR: 0.090001
Training Epoch: 46 [32/50000]	Loss: 2.5368	LR: 0.090001
Training Epoch: 46 [32/50000]	Loss: 2.6111	LR: 0.090001
Training Epoch: 46 [32/50000]	Loss: 3.0637	LR: 0.090001
Training Epoch: 46 [32/50000]	Loss: 2.5505	LR: 0.090001
Training Epoch: 46 [32/50000]	Loss: 2.6982	LR: 0.090001
Training Epoch: 46 [32/50000]	Loss: 2.4872	LR: 0.090001
Training Epoch: 46 [32/50000]	Loss: 2.7766	LR: 0.090001
Training Epoch: 46 [32/50000]	Loss: 2.5719	LR: 0.090001
Training Epoch: 46 [32/50000]	Loss: 2.6730	LR: 0.090001
Evaluating Network.....
Test set: Epoch: 46, Average loss: 0.0849, Top1Accuracy: 0.3143, Top3Accuracy: 0.5177, Top5Accuracy: 0.6213, Time consumed:1.79s

Training Epoch: 47 [32/50000]	Loss: 2.6483	LR: 0.087625
Training Epoch: 47 [32/50000]	Loss: 3.0083	LR: 0.087625
Training Epoch: 47 [32/50000]	Loss: 3.0514	LR: 0.087625
Training Epoch: 47 [32/50000]	Loss: 2.6726	LR: 0.087625
Training Epoch: 47 [32/50000]	Loss: 2.1871	LR: 0.087625
Training Epoch: 47 [32/50000]	Loss: 2.5262	LR: 0.087625
Training Epoch: 47 [32/50000]	Loss: 2.5847	LR: 0.087625
Training Epoch: 47 [32/50000]	Loss: 3.2057	LR: 0.087625
Training Epoch: 47 [32/50000]	Loss: 2.6123	LR: 0.087625
Training Epoch: 47 [32/50000]	Loss: 2.7096	LR: 0.087625
Evaluating Network.....
Test set: Epoch: 47, Average loss: 0.0840, Top1Accuracy: 0.3219, Top3Accuracy: 0.5271, Top5Accuracy: 0.6264, Time consumed:1.70s

Training Epoch: 48 [32/50000]	Loss: 2.9333	LR: 0.085312
Training Epoch: 48 [32/50000]	Loss: 3.1695	LR: 0.085312
Training Epoch: 48 [32/50000]	Loss: 2.7888	LR: 0.085312
Training Epoch: 48 [32/50000]	Loss: 2.0452	LR: 0.085312
Training Epoch: 48 [32/50000]	Loss: 2.6696	LR: 0.085312
Training Epoch: 48 [32/50000]	Loss: 2.8174	LR: 0.085312
Training Epoch: 48 [32/50000]	Loss: 3.0258	LR: 0.085312
Training Epoch: 48 [32/50000]	Loss: 2.7791	LR: 0.085312
Training Epoch: 48 [32/50000]	Loss: 2.5445	LR: 0.085312
Training Epoch: 48 [32/50000]	Loss: 2.6129	LR: 0.085312
Evaluating Network.....
Test set: Epoch: 48, Average loss: 0.0833, Top1Accuracy: 0.3249, Top3Accuracy: 0.5322, Top5Accuracy: 0.6313, Time consumed:1.70s

Training Epoch: 49 [32/50000]	Loss: 2.7209	LR: 0.083059
Training Epoch: 49 [32/50000]	Loss: 2.3681	LR: 0.083059
Training Epoch: 49 [32/50000]	Loss: 2.7142	LR: 0.083059
Training Epoch: 49 [32/50000]	Loss: 2.3727	LR: 0.083059
Training Epoch: 49 [32/50000]	Loss: 2.6741	LR: 0.083059
Training Epoch: 49 [32/50000]	Loss: 2.5674	LR: 0.083059
Training Epoch: 49 [32/50000]	Loss: 2.8240	LR: 0.083059
Training Epoch: 49 [32/50000]	Loss: 2.2341	LR: 0.083059
Training Epoch: 49 [32/50000]	Loss: 2.5744	LR: 0.083059
Training Epoch: 49 [32/50000]	Loss: 2.6516	LR: 0.083059
Evaluating Network.....
Test set: Epoch: 49, Average loss: 0.0840, Top1Accuracy: 0.3179, Top3Accuracy: 0.5255, Top5Accuracy: 0.6224, Time consumed:1.79s

Training Epoch: 50 [32/50000]	Loss: 2.5256	LR: 0.080867
Training Epoch: 50 [32/50000]	Loss: 2.5701	LR: 0.080867
Training Epoch: 50 [32/50000]	Loss: 2.5542	LR: 0.080867
Training Epoch: 50 [32/50000]	Loss: 2.5529	LR: 0.080867
Training Epoch: 50 [32/50000]	Loss: 2.8212	LR: 0.080867
Training Epoch: 50 [32/50000]	Loss: 2.3117	LR: 0.080867
Training Epoch: 50 [32/50000]	Loss: 2.6972	LR: 0.080867
Training Epoch: 50 [32/50000]	Loss: 2.5156	LR: 0.080867
Training Epoch: 50 [32/50000]	Loss: 2.4317	LR: 0.080867
Training Epoch: 50 [32/50000]	Loss: 2.4712	LR: 0.080867
Evaluating Network.....
Test set: Epoch: 50, Average loss: 0.0828, Top1Accuracy: 0.3244, Top3Accuracy: 0.5337, Top5Accuracy: 0.6353, Time consumed:1.93s

Training Epoch: 51 [32/50000]	Loss: 2.4765	LR: 0.078732
Training Epoch: 51 [32/50000]	Loss: 2.9472	LR: 0.078732
Training Epoch: 51 [32/50000]	Loss: 2.6147	LR: 0.078732
Training Epoch: 51 [32/50000]	Loss: 2.1553	LR: 0.078732
Training Epoch: 51 [32/50000]	Loss: 2.7451	LR: 0.078732
Training Epoch: 51 [32/50000]	Loss: 2.6737	LR: 0.078732
Training Epoch: 51 [32/50000]	Loss: 2.5310	LR: 0.078732
Training Epoch: 51 [32/50000]	Loss: 2.4681	LR: 0.078732
Training Epoch: 51 [32/50000]	Loss: 2.9958	LR: 0.078732
Training Epoch: 51 [32/50000]	Loss: 2.5962	LR: 0.078732
Evaluating Network.....
Test set: Epoch: 51, Average loss: 0.0821, Top1Accuracy: 0.3326, Top3Accuracy: 0.5405, Top5Accuracy: 0.6435, Time consumed:1.80s

Training Epoch: 52 [32/50000]	Loss: 2.4625	LR: 0.076653
Training Epoch: 52 [32/50000]	Loss: 2.5591	LR: 0.076653
Training Epoch: 52 [32/50000]	Loss: 2.6837	LR: 0.076653
Training Epoch: 52 [32/50000]	Loss: 2.9729	LR: 0.076653
Training Epoch: 52 [32/50000]	Loss: 2.4073	LR: 0.076653
Training Epoch: 52 [32/50000]	Loss: 2.3525	LR: 0.076653
Training Epoch: 52 [32/50000]	Loss: 2.5113	LR: 0.076653
Training Epoch: 52 [32/50000]	Loss: 2.7057	LR: 0.076653
Training Epoch: 52 [32/50000]	Loss: 3.1264	LR: 0.076653
Training Epoch: 52 [32/50000]	Loss: 2.4841	LR: 0.076653
Evaluating Network.....
Test set: Epoch: 52, Average loss: 0.0816, Top1Accuracy: 0.3360, Top3Accuracy: 0.5460, Top5Accuracy: 0.6490, Time consumed:1.82s

Training Epoch: 53 [32/50000]	Loss: 2.4070	LR: 0.074630
Training Epoch: 53 [32/50000]	Loss: 2.5202	LR: 0.074630
Training Epoch: 53 [32/50000]	Loss: 2.4876	LR: 0.074630
Training Epoch: 53 [32/50000]	Loss: 2.4419	LR: 0.074630
Training Epoch: 53 [32/50000]	Loss: 2.3886	LR: 0.074630
Training Epoch: 53 [32/50000]	Loss: 2.8348	LR: 0.074630
Training Epoch: 53 [32/50000]	Loss: 2.6885	LR: 0.074630
Training Epoch: 53 [32/50000]	Loss: 2.3999	LR: 0.074630
Training Epoch: 53 [32/50000]	Loss: 2.3455	LR: 0.074630
Training Epoch: 53 [32/50000]	Loss: 2.8594	LR: 0.074630
Evaluating Network.....
Test set: Epoch: 53, Average loss: 0.0811, Top1Accuracy: 0.3382, Top3Accuracy: 0.5484, Top5Accuracy: 0.6491, Time consumed:1.80s

Training Epoch: 54 [32/50000]	Loss: 2.5861	LR: 0.072659
Training Epoch: 54 [32/50000]	Loss: 2.8193	LR: 0.072659
Training Epoch: 54 [32/50000]	Loss: 3.1456	LR: 0.072659
Training Epoch: 54 [32/50000]	Loss: 2.7696	LR: 0.072659
Training Epoch: 54 [32/50000]	Loss: 2.8960	LR: 0.072659
Training Epoch: 54 [32/50000]	Loss: 2.5274	LR: 0.072659
Training Epoch: 54 [32/50000]	Loss: 2.6173	LR: 0.072659
Training Epoch: 54 [32/50000]	Loss: 2.4830	LR: 0.072659
Training Epoch: 54 [32/50000]	Loss: 3.1586	LR: 0.072659
Training Epoch: 54 [32/50000]	Loss: 2.9662	LR: 0.072659
Evaluating Network.....
Test set: Epoch: 54, Average loss: 0.0805, Top1Accuracy: 0.3440, Top3Accuracy: 0.5535, Top5Accuracy: 0.6508, Time consumed:1.77s

Training Epoch: 55 [32/50000]	Loss: 2.5444	LR: 0.070741
Training Epoch: 55 [32/50000]	Loss: 2.3598	LR: 0.070741
Training Epoch: 55 [32/50000]	Loss: 2.4856	LR: 0.070741
Training Epoch: 55 [32/50000]	Loss: 2.8265	LR: 0.070741
Training Epoch: 55 [32/50000]	Loss: 2.6275	LR: 0.070741
Training Epoch: 55 [32/50000]	Loss: 3.1178	LR: 0.070741
Training Epoch: 55 [32/50000]	Loss: 2.5622	LR: 0.070741
Training Epoch: 55 [32/50000]	Loss: 3.0215	LR: 0.070741
Training Epoch: 55 [32/50000]	Loss: 2.3535	LR: 0.070741
Training Epoch: 55 [32/50000]	Loss: 2.7840	LR: 0.070741
Evaluating Network.....
Test set: Epoch: 55, Average loss: 0.0796, Top1Accuracy: 0.3470, Top3Accuracy: 0.5543, Top5Accuracy: 0.6569, Time consumed:2.01s

Training Epoch: 56 [32/50000]	Loss: 2.6887	LR: 0.068874
Training Epoch: 56 [32/50000]	Loss: 2.3622	LR: 0.068874
Training Epoch: 56 [32/50000]	Loss: 2.7026	LR: 0.068874
Training Epoch: 56 [32/50000]	Loss: 2.2608	LR: 0.068874
Training Epoch: 56 [32/50000]	Loss: 2.4536	LR: 0.068874
Training Epoch: 56 [32/50000]	Loss: 2.9260	LR: 0.068874
Training Epoch: 56 [32/50000]	Loss: 2.3028	LR: 0.068874
Training Epoch: 56 [32/50000]	Loss: 2.9074	LR: 0.068874
Training Epoch: 56 [32/50000]	Loss: 2.8270	LR: 0.068874
Training Epoch: 56 [32/50000]	Loss: 2.7593	LR: 0.068874
Evaluating Network.....
Test set: Epoch: 56, Average loss: 0.0789, Top1Accuracy: 0.3564, Top3Accuracy: 0.5671, Top5Accuracy: 0.6681, Time consumed:1.83s

Training Epoch: 57 [32/50000]	Loss: 2.3774	LR: 0.067055
Training Epoch: 57 [32/50000]	Loss: 2.6683	LR: 0.067055
Training Epoch: 57 [32/50000]	Loss: 2.3685	LR: 0.067055
Training Epoch: 57 [32/50000]	Loss: 2.4261	LR: 0.067055
Training Epoch: 57 [32/50000]	Loss: 2.7502	LR: 0.067055
Training Epoch: 57 [32/50000]	Loss: 2.9421	LR: 0.067055
Training Epoch: 57 [32/50000]	Loss: 2.7495	LR: 0.067055
Training Epoch: 57 [32/50000]	Loss: 2.5058	LR: 0.067055
Training Epoch: 57 [32/50000]	Loss: 2.4058	LR: 0.067055
Training Epoch: 57 [32/50000]	Loss: 2.9416	LR: 0.067055
Evaluating Network.....
Test set: Epoch: 57, Average loss: 0.0789, Top1Accuracy: 0.3536, Top3Accuracy: 0.5634, Top5Accuracy: 0.6631, Time consumed:1.77s

Training Epoch: 58 [32/50000]	Loss: 2.5827	LR: 0.065285
Training Epoch: 58 [32/50000]	Loss: 2.4470	LR: 0.065285
Training Epoch: 58 [32/50000]	Loss: 2.6328	LR: 0.065285
Training Epoch: 58 [32/50000]	Loss: 2.5062	LR: 0.065285
Training Epoch: 58 [32/50000]	Loss: 2.2424	LR: 0.065285
Training Epoch: 58 [32/50000]	Loss: 2.8389	LR: 0.065285
Training Epoch: 58 [32/50000]	Loss: 2.3372	LR: 0.065285
Training Epoch: 58 [32/50000]	Loss: 2.7973	LR: 0.065285
Training Epoch: 58 [32/50000]	Loss: 2.2200	LR: 0.065285
Training Epoch: 58 [32/50000]	Loss: 2.3935	LR: 0.065285
Evaluating Network.....
Test set: Epoch: 58, Average loss: 0.0779, Top1Accuracy: 0.3636, Top3Accuracy: 0.5690, Top5Accuracy: 0.6681, Time consumed:1.79s

Training Epoch: 59 [32/50000]	Loss: 2.2166	LR: 0.063561
Training Epoch: 59 [32/50000]	Loss: 2.2532	LR: 0.063561
Training Epoch: 59 [32/50000]	Loss: 2.2454	LR: 0.063561
Training Epoch: 59 [32/50000]	Loss: 2.7768	LR: 0.063561
Training Epoch: 59 [32/50000]	Loss: 2.4807	LR: 0.063561
Training Epoch: 59 [32/50000]	Loss: 2.1074	LR: 0.063561
Training Epoch: 59 [32/50000]	Loss: 2.6292	LR: 0.063561
Training Epoch: 59 [32/50000]	Loss: 1.9718	LR: 0.063561
Training Epoch: 59 [32/50000]	Loss: 2.4933	LR: 0.063561
Training Epoch: 59 [32/50000]	Loss: 2.2997	LR: 0.063561
Evaluating Network.....
Test set: Epoch: 59, Average loss: 0.0782, Top1Accuracy: 0.3582, Top3Accuracy: 0.5678, Top5Accuracy: 0.6697, Time consumed:1.99s

Training Epoch: 60 [32/50000]	Loss: 2.0275	LR: 0.061883
Training Epoch: 60 [32/50000]	Loss: 2.1786	LR: 0.061883
Training Epoch: 60 [32/50000]	Loss: 2.4249	LR: 0.061883
Training Epoch: 60 [32/50000]	Loss: 2.6293	LR: 0.061883
Training Epoch: 60 [32/50000]	Loss: 2.3360	LR: 0.061883
Training Epoch: 60 [32/50000]	Loss: 2.7756	LR: 0.061883
Training Epoch: 60 [32/50000]	Loss: 2.5817	LR: 0.061883
Training Epoch: 60 [32/50000]	Loss: 2.2782	LR: 0.061883
Training Epoch: 60 [32/50000]	Loss: 2.1999	LR: 0.061883
Training Epoch: 60 [32/50000]	Loss: 2.8750	LR: 0.061883
Evaluating Network.....
Test set: Epoch: 60, Average loss: 0.0774, Top1Accuracy: 0.3624, Top3Accuracy: 0.5756, Top5Accuracy: 0.6741, Time consumed:1.78s

Training Epoch: 61 [32/50000]	Loss: 2.7012	LR: 0.060250
Training Epoch: 61 [32/50000]	Loss: 2.5926	LR: 0.060250
Training Epoch: 61 [32/50000]	Loss: 1.8958	LR: 0.060250
Training Epoch: 61 [32/50000]	Loss: 2.1298	LR: 0.060250
Training Epoch: 61 [32/50000]	Loss: 3.0802	LR: 0.060250
Training Epoch: 61 [32/50000]	Loss: 2.4963	LR: 0.060250
Training Epoch: 61 [32/50000]	Loss: 2.1889	LR: 0.060250
Training Epoch: 61 [32/50000]	Loss: 3.2231	LR: 0.060250
Training Epoch: 61 [32/50000]	Loss: 2.6081	LR: 0.060250
Training Epoch: 61 [32/50000]	Loss: 2.3257	LR: 0.060250
Evaluating Network.....
Test set: Epoch: 61, Average loss: 0.0763, Top1Accuracy: 0.3686, Top3Accuracy: 0.5802, Top5Accuracy: 0.6817, Time consumed:1.79s

Training Epoch: 62 [32/50000]	Loss: 2.4738	LR: 0.058659
Training Epoch: 62 [32/50000]	Loss: 2.3893	LR: 0.058659
Training Epoch: 62 [32/50000]	Loss: 2.5219	LR: 0.058659
Training Epoch: 62 [32/50000]	Loss: 2.4163	LR: 0.058659
Training Epoch: 62 [32/50000]	Loss: 2.3802	LR: 0.058659
Training Epoch: 62 [32/50000]	Loss: 1.9954	LR: 0.058659
Training Epoch: 62 [32/50000]	Loss: 3.2790	LR: 0.058659
Training Epoch: 62 [32/50000]	Loss: 2.6747	LR: 0.058659
Training Epoch: 62 [32/50000]	Loss: 2.4903	LR: 0.058659
Training Epoch: 62 [32/50000]	Loss: 2.2177	LR: 0.058659
Evaluating Network.....
Test set: Epoch: 62, Average loss: 0.0759, Top1Accuracy: 0.3746, Top3Accuracy: 0.5901, Top5Accuracy: 0.6835, Time consumed:1.73s

Training Epoch: 63 [32/50000]	Loss: 2.5794	LR: 0.057111
Training Epoch: 63 [32/50000]	Loss: 2.8860	LR: 0.057111
Training Epoch: 63 [32/50000]	Loss: 2.3070	LR: 0.057111
Training Epoch: 63 [32/50000]	Loss: 2.6582	LR: 0.057111
Training Epoch: 63 [32/50000]	Loss: 2.4049	LR: 0.057111
Training Epoch: 63 [32/50000]	Loss: 2.4299	LR: 0.057111
Training Epoch: 63 [32/50000]	Loss: 2.6300	LR: 0.057111
Training Epoch: 63 [32/50000]	Loss: 2.5051	LR: 0.057111
Training Epoch: 63 [32/50000]	Loss: 2.1911	LR: 0.057111
Training Epoch: 63 [32/50000]	Loss: 2.3834	LR: 0.057111
Evaluating Network.....
Test set: Epoch: 63, Average loss: 0.0754, Top1Accuracy: 0.3778, Top3Accuracy: 0.5918, Top5Accuracy: 0.6865, Time consumed:1.81s

Training Epoch: 64 [32/50000]	Loss: 2.6979	LR: 0.055603
Training Epoch: 64 [32/50000]	Loss: 2.8720	LR: 0.055603
Training Epoch: 64 [32/50000]	Loss: 2.2149	LR: 0.055603
Training Epoch: 64 [32/50000]	Loss: 2.7901	LR: 0.055603
Training Epoch: 64 [32/50000]	Loss: 2.6030	LR: 0.055603
Training Epoch: 64 [32/50000]	Loss: 2.8178	LR: 0.055603
Training Epoch: 64 [32/50000]	Loss: 2.8102	LR: 0.055603
Training Epoch: 64 [32/50000]	Loss: 2.6256	LR: 0.055603
Training Epoch: 64 [32/50000]	Loss: 2.5784	LR: 0.055603
Training Epoch: 64 [32/50000]	Loss: 3.0290	LR: 0.055603
Evaluating Network.....
Test set: Epoch: 64, Average loss: 0.0761, Top1Accuracy: 0.3675, Top3Accuracy: 0.5825, Top5Accuracy: 0.6830, Time consumed:1.71s

Training Epoch: 65 [32/50000]	Loss: 2.6209	LR: 0.054135
Training Epoch: 65 [32/50000]	Loss: 2.3607	LR: 0.054135
Training Epoch: 65 [32/50000]	Loss: 2.2050	LR: 0.054135
Training Epoch: 65 [32/50000]	Loss: 2.4561	LR: 0.054135
Training Epoch: 65 [32/50000]	Loss: 2.4120	LR: 0.054135
Training Epoch: 65 [32/50000]	Loss: 2.2829	LR: 0.054135
Training Epoch: 65 [32/50000]	Loss: 2.6187	LR: 0.054135
Training Epoch: 65 [32/50000]	Loss: 2.5346	LR: 0.054135
Training Epoch: 65 [32/50000]	Loss: 2.4909	LR: 0.054135
Training Epoch: 65 [32/50000]	Loss: 2.4861	LR: 0.054135
Evaluating Network.....
Test set: Epoch: 65, Average loss: 0.0757, Top1Accuracy: 0.3751, Top3Accuracy: 0.5845, Top5Accuracy: 0.6805, Time consumed:1.84s

Training Epoch: 66 [32/50000]	Loss: 2.3975	LR: 0.052706
Training Epoch: 66 [32/50000]	Loss: 2.4674	LR: 0.052706
Training Epoch: 66 [32/50000]	Loss: 2.5434	LR: 0.052706
Training Epoch: 66 [32/50000]	Loss: 2.4871	LR: 0.052706
Training Epoch: 66 [32/50000]	Loss: 2.3310	LR: 0.052706
Training Epoch: 66 [32/50000]	Loss: 2.5664	LR: 0.052706
Training Epoch: 66 [32/50000]	Loss: 2.2445	LR: 0.052706
Training Epoch: 66 [32/50000]	Loss: 2.5047	LR: 0.052706
Training Epoch: 66 [32/50000]	Loss: 2.4946	LR: 0.052706
Training Epoch: 66 [32/50000]	Loss: 2.2148	LR: 0.052706
Evaluating Network.....
Test set: Epoch: 66, Average loss: 0.0753, Top1Accuracy: 0.3771, Top3Accuracy: 0.5888, Top5Accuracy: 0.6868, Time consumed:1.82s

Training Epoch: 67 [32/50000]	Loss: 2.3531	LR: 0.051314
Training Epoch: 67 [32/50000]	Loss: 2.2830	LR: 0.051314
Training Epoch: 67 [32/50000]	Loss: 1.9883	LR: 0.051314
Training Epoch: 67 [32/50000]	Loss: 2.3355	LR: 0.051314
Training Epoch: 67 [32/50000]	Loss: 2.3456	LR: 0.051314
Training Epoch: 67 [32/50000]	Loss: 2.6489	LR: 0.051314
Training Epoch: 67 [32/50000]	Loss: 2.3659	LR: 0.051314
Training Epoch: 67 [32/50000]	Loss: 2.4532	LR: 0.051314
Training Epoch: 67 [32/50000]	Loss: 2.6713	LR: 0.051314
Training Epoch: 67 [32/50000]	Loss: 2.6147	LR: 0.051314
Evaluating Network.....
Test set: Epoch: 67, Average loss: 0.0747, Top1Accuracy: 0.3838, Top3Accuracy: 0.5928, Top5Accuracy: 0.6910, Time consumed:1.78s

Training Epoch: 68 [32/50000]	Loss: 2.3809	LR: 0.049960
Training Epoch: 68 [32/50000]	Loss: 2.8598	LR: 0.049960
Training Epoch: 68 [32/50000]	Loss: 2.2740	LR: 0.049960
Training Epoch: 68 [32/50000]	Loss: 2.1590	LR: 0.049960
Training Epoch: 68 [32/50000]	Loss: 2.4155	LR: 0.049960
Training Epoch: 68 [32/50000]	Loss: 2.5297	LR: 0.049960
Training Epoch: 68 [32/50000]	Loss: 2.1638	LR: 0.049960
Training Epoch: 68 [32/50000]	Loss: 2.6070	LR: 0.049960
Training Epoch: 68 [32/50000]	Loss: 2.4050	LR: 0.049960
Training Epoch: 68 [32/50000]	Loss: 2.8171	LR: 0.049960
Evaluating Network.....
Test set: Epoch: 68, Average loss: 0.0745, Top1Accuracy: 0.3816, Top3Accuracy: 0.5954, Top5Accuracy: 0.6919, Time consumed:1.77s

Training Epoch: 69 [32/50000]	Loss: 3.0615	LR: 0.048641
Training Epoch: 69 [32/50000]	Loss: 2.5405	LR: 0.048641
Training Epoch: 69 [32/50000]	Loss: 2.4441	LR: 0.048641
Training Epoch: 69 [32/50000]	Loss: 2.2813	LR: 0.048641
Training Epoch: 69 [32/50000]	Loss: 2.2307	LR: 0.048641
Training Epoch: 69 [32/50000]	Loss: 2.1721	LR: 0.048641
Training Epoch: 69 [32/50000]	Loss: 2.4775	LR: 0.048641
Training Epoch: 69 [32/50000]	Loss: 2.1789	LR: 0.048641
Training Epoch: 69 [32/50000]	Loss: 1.9123	LR: 0.048641
Training Epoch: 69 [32/50000]	Loss: 2.2635	LR: 0.048641
Evaluating Network.....
Test set: Epoch: 69, Average loss: 0.0736, Top1Accuracy: 0.3909, Top3Accuracy: 0.6043, Top5Accuracy: 0.6975, Time consumed:1.78s

Training Epoch: 70 [32/50000]	Loss: 1.9121	LR: 0.047357
Training Epoch: 70 [32/50000]	Loss: 2.6990	LR: 0.047357
Training Epoch: 70 [32/50000]	Loss: 2.4957	LR: 0.047357
Training Epoch: 70 [32/50000]	Loss: 2.8755	LR: 0.047357
Training Epoch: 70 [32/50000]	Loss: 2.5928	LR: 0.047357
Training Epoch: 70 [32/50000]	Loss: 2.4030	LR: 0.047357
Training Epoch: 70 [32/50000]	Loss: 2.8313	LR: 0.047357
Training Epoch: 70 [32/50000]	Loss: 2.3627	LR: 0.047357
Training Epoch: 70 [32/50000]	Loss: 2.3305	LR: 0.047357
Training Epoch: 70 [32/50000]	Loss: 2.4423	LR: 0.047357
Evaluating Network.....
Test set: Epoch: 70, Average loss: 0.0727, Top1Accuracy: 0.3936, Top3Accuracy: 0.6052, Top5Accuracy: 0.7069, Time consumed:1.77s

Training Epoch: 71 [32/50000]	Loss: 2.6522	LR: 0.046106
Training Epoch: 71 [32/50000]	Loss: 2.2104	LR: 0.046106
Training Epoch: 71 [32/50000]	Loss: 2.2946	LR: 0.046106
Training Epoch: 71 [32/50000]	Loss: 2.2453	LR: 0.046106
Training Epoch: 71 [32/50000]	Loss: 2.6264	LR: 0.046106
Training Epoch: 71 [32/50000]	Loss: 2.4413	LR: 0.046106
Training Epoch: 71 [32/50000]	Loss: 2.2468	LR: 0.046106
Training Epoch: 71 [32/50000]	Loss: 2.1017	LR: 0.046106
Training Epoch: 71 [32/50000]	Loss: 2.2394	LR: 0.046106
Training Epoch: 71 [32/50000]	Loss: 2.6320	LR: 0.046106
Evaluating Network.....
Test set: Epoch: 71, Average loss: 0.0726, Top1Accuracy: 0.3954, Top3Accuracy: 0.6087, Top5Accuracy: 0.7075, Time consumed:1.78s

Training Epoch: 72 [32/50000]	Loss: 2.7033	LR: 0.044889
Training Epoch: 72 [32/50000]	Loss: 2.2956	LR: 0.044889
Training Epoch: 72 [32/50000]	Loss: 2.7870	LR: 0.044889
Training Epoch: 72 [32/50000]	Loss: 2.4401	LR: 0.044889
Training Epoch: 72 [32/50000]	Loss: 2.4728	LR: 0.044889
Training Epoch: 72 [32/50000]	Loss: 2.5656	LR: 0.044889
Training Epoch: 72 [32/50000]	Loss: 2.4695	LR: 0.044889
Training Epoch: 72 [32/50000]	Loss: 2.7391	LR: 0.044889
Training Epoch: 72 [32/50000]	Loss: 2.1432	LR: 0.044889
Training Epoch: 72 [32/50000]	Loss: 2.2308	LR: 0.044889
Evaluating Network.....
Test set: Epoch: 72, Average loss: 0.0718, Top1Accuracy: 0.4001, Top3Accuracy: 0.6134, Top5Accuracy: 0.7120, Time consumed:1.79s

Training Epoch: 73 [32/50000]	Loss: 2.3188	LR: 0.043704
Training Epoch: 73 [32/50000]	Loss: 2.3741	LR: 0.043704
Training Epoch: 73 [32/50000]	Loss: 2.2924	LR: 0.043704
Training Epoch: 73 [32/50000]	Loss: 2.4373	LR: 0.043704
Training Epoch: 73 [32/50000]	Loss: 2.6717	LR: 0.043704
Training Epoch: 73 [32/50000]	Loss: 2.2189	LR: 0.043704
Training Epoch: 73 [32/50000]	Loss: 1.8605	LR: 0.043704
Training Epoch: 73 [32/50000]	Loss: 2.5473	LR: 0.043704
Training Epoch: 73 [32/50000]	Loss: 2.5058	LR: 0.043704
Training Epoch: 73 [32/50000]	Loss: 2.3883	LR: 0.043704
Evaluating Network.....
Test set: Epoch: 73, Average loss: 0.0720, Top1Accuracy: 0.4013, Top3Accuracy: 0.6157, Top5Accuracy: 0.7087, Time consumed:1.84s

Training Epoch: 74 [32/50000]	Loss: 2.4427	LR: 0.042550
Training Epoch: 74 [32/50000]	Loss: 2.2155	LR: 0.042550
Training Epoch: 74 [32/50000]	Loss: 2.3205	LR: 0.042550
Training Epoch: 74 [32/50000]	Loss: 2.3644	LR: 0.042550
Training Epoch: 74 [32/50000]	Loss: 2.7582	LR: 0.042550
Training Epoch: 74 [32/50000]	Loss: 2.2079	LR: 0.042550
Training Epoch: 74 [32/50000]	Loss: 1.8165	LR: 0.042550
Training Epoch: 74 [32/50000]	Loss: 2.2571	LR: 0.042550
Training Epoch: 74 [32/50000]	Loss: 2.0995	LR: 0.042550
Training Epoch: 74 [32/50000]	Loss: 2.2791	LR: 0.042550
Evaluating Network.....
Test set: Epoch: 74, Average loss: 0.0723, Top1Accuracy: 0.3995, Top3Accuracy: 0.6093, Top5Accuracy: 0.7027, Time consumed:1.82s

Training Epoch: 75 [32/50000]	Loss: 2.6215	LR: 0.041427
Training Epoch: 75 [32/50000]	Loss: 2.3465	LR: 0.041427
Training Epoch: 75 [32/50000]	Loss: 2.4175	LR: 0.041427
Training Epoch: 75 [32/50000]	Loss: 2.3826	LR: 0.041427
Training Epoch: 75 [32/50000]	Loss: 2.7058	LR: 0.041427
Training Epoch: 75 [32/50000]	Loss: 1.8754	LR: 0.041427
Training Epoch: 75 [32/50000]	Loss: 2.4520	LR: 0.041427
Training Epoch: 75 [32/50000]	Loss: 2.4172	LR: 0.041427
Training Epoch: 75 [32/50000]	Loss: 2.2794	LR: 0.041427
Training Epoch: 75 [32/50000]	Loss: 2.5085	LR: 0.041427
Evaluating Network.....
Test set: Epoch: 75, Average loss: 0.0715, Top1Accuracy: 0.4059, Top3Accuracy: 0.6232, Top5Accuracy: 0.7113, Time consumed:1.82s

Training Epoch: 76 [32/50000]	Loss: 2.1978	LR: 0.040333
Training Epoch: 76 [32/50000]	Loss: 1.7928	LR: 0.040333
Training Epoch: 76 [32/50000]	Loss: 1.7823	LR: 0.040333
Training Epoch: 76 [32/50000]	Loss: 2.4340	LR: 0.040333
Training Epoch: 76 [32/50000]	Loss: 2.0762	LR: 0.040333
Training Epoch: 76 [32/50000]	Loss: 2.3737	LR: 0.040333
Training Epoch: 76 [32/50000]	Loss: 2.3201	LR: 0.040333
Training Epoch: 76 [32/50000]	Loss: 2.7111	LR: 0.040333
Training Epoch: 76 [32/50000]	Loss: 1.9476	LR: 0.040333
Training Epoch: 76 [32/50000]	Loss: 2.0407	LR: 0.040333
Evaluating Network.....
Test set: Epoch: 76, Average loss: 0.0706, Top1Accuracy: 0.4126, Top3Accuracy: 0.6244, Top5Accuracy: 0.7155, Time consumed:1.76s

Training Epoch: 77 [32/50000]	Loss: 2.3724	LR: 0.039268
Training Epoch: 77 [32/50000]	Loss: 2.5316	LR: 0.039268
Training Epoch: 77 [32/50000]	Loss: 2.4128	LR: 0.039268
Training Epoch: 77 [32/50000]	Loss: 2.1545	LR: 0.039268
Training Epoch: 77 [32/50000]	Loss: 2.4499	LR: 0.039268
Training Epoch: 77 [32/50000]	Loss: 2.0256	LR: 0.039268
Training Epoch: 77 [32/50000]	Loss: 2.4124	LR: 0.039268
Training Epoch: 77 [32/50000]	Loss: 2.3465	LR: 0.039268
Training Epoch: 77 [32/50000]	Loss: 2.4810	LR: 0.039268
Training Epoch: 77 [32/50000]	Loss: 2.2443	LR: 0.039268
Evaluating Network.....
Test set: Epoch: 77, Average loss: 0.0709, Top1Accuracy: 0.4102, Top3Accuracy: 0.6212, Top5Accuracy: 0.7158, Time consumed:1.79s

Training Epoch: 78 [32/50000]	Loss: 2.2595	LR: 0.038232
Training Epoch: 78 [32/50000]	Loss: 2.3983	LR: 0.038232
Training Epoch: 78 [32/50000]	Loss: 2.0889	LR: 0.038232
Training Epoch: 78 [32/50000]	Loss: 2.3282	LR: 0.038232
Training Epoch: 78 [32/50000]	Loss: 1.9745	LR: 0.038232
Training Epoch: 78 [32/50000]	Loss: 1.7670	LR: 0.038232
Training Epoch: 78 [32/50000]	Loss: 3.0690	LR: 0.038232
Training Epoch: 78 [32/50000]	Loss: 2.0206	LR: 0.038232
Training Epoch: 78 [32/50000]	Loss: 2.2671	LR: 0.038232
Training Epoch: 78 [32/50000]	Loss: 2.1730	LR: 0.038232
Evaluating Network.....
Test set: Epoch: 78, Average loss: 0.0695, Top1Accuracy: 0.4154, Top3Accuracy: 0.6321, Top5Accuracy: 0.7262, Time consumed:1.82s

Training Epoch: 79 [32/50000]	Loss: 2.3885	LR: 0.037222
Training Epoch: 79 [32/50000]	Loss: 2.3250	LR: 0.037222
Training Epoch: 79 [32/50000]	Loss: 2.2552	LR: 0.037222
Training Epoch: 79 [32/50000]	Loss: 2.1043	LR: 0.037222
Training Epoch: 79 [32/50000]	Loss: 2.3010	LR: 0.037222
Training Epoch: 79 [32/50000]	Loss: 2.1983	LR: 0.037222
Training Epoch: 79 [32/50000]	Loss: 2.2898	LR: 0.037222
Training Epoch: 79 [32/50000]	Loss: 2.4721	LR: 0.037222
Training Epoch: 79 [32/50000]	Loss: 1.9185	LR: 0.037222
Training Epoch: 79 [32/50000]	Loss: 2.1253	LR: 0.037222
Evaluating Network.....
Test set: Epoch: 79, Average loss: 0.0689, Top1Accuracy: 0.4181, Top3Accuracy: 0.6308, Top5Accuracy: 0.7309, Time consumed:1.83s

Training Epoch: 80 [32/50000]	Loss: 2.7305	LR: 0.036240
Training Epoch: 80 [32/50000]	Loss: 1.8227	LR: 0.036240
Training Epoch: 80 [32/50000]	Loss: 1.9048	LR: 0.036240
Training Epoch: 80 [32/50000]	Loss: 1.8743	LR: 0.036240
Training Epoch: 80 [32/50000]	Loss: 2.2492	LR: 0.036240
Training Epoch: 80 [32/50000]	Loss: 2.6390	LR: 0.036240
Training Epoch: 80 [32/50000]	Loss: 1.8860	LR: 0.036240
Training Epoch: 80 [32/50000]	Loss: 2.7276	LR: 0.036240
Training Epoch: 80 [32/50000]	Loss: 2.2989	LR: 0.036240
Training Epoch: 80 [32/50000]	Loss: 2.1343	LR: 0.036240
Evaluating Network.....
Test set: Epoch: 80, Average loss: 0.0703, Top1Accuracy: 0.4110, Top3Accuracy: 0.6243, Top5Accuracy: 0.7198, Time consumed:1.79s

Training Epoch: 81 [32/50000]	Loss: 2.0245	LR: 0.035283
Training Epoch: 81 [32/50000]	Loss: 2.3895	LR: 0.035283
Training Epoch: 81 [32/50000]	Loss: 2.7310	LR: 0.035283
Training Epoch: 81 [32/50000]	Loss: 2.4830	LR: 0.035283
Training Epoch: 81 [32/50000]	Loss: 2.1599	LR: 0.035283
Training Epoch: 81 [32/50000]	Loss: 2.1010	LR: 0.035283
Training Epoch: 81 [32/50000]	Loss: 2.5871	LR: 0.035283
Training Epoch: 81 [32/50000]	Loss: 1.5804	LR: 0.035283
Training Epoch: 81 [32/50000]	Loss: 1.9668	LR: 0.035283
Training Epoch: 81 [32/50000]	Loss: 2.1226	LR: 0.035283
Evaluating Network.....
Test set: Epoch: 81, Average loss: 0.0693, Top1Accuracy: 0.4149, Top3Accuracy: 0.6343, Top5Accuracy: 0.7288, Time consumed:1.85s

Training Epoch: 82 [32/50000]	Loss: 2.4599	LR: 0.034352
Training Epoch: 82 [32/50000]	Loss: 1.9445	LR: 0.034352
Training Epoch: 82 [32/50000]	Loss: 2.6154	LR: 0.034352
Training Epoch: 82 [32/50000]	Loss: 2.3461	LR: 0.034352
Training Epoch: 82 [32/50000]	Loss: 2.4229	LR: 0.034352
Training Epoch: 82 [32/50000]	Loss: 2.2667	LR: 0.034352
Training Epoch: 82 [32/50000]	Loss: 1.8176	LR: 0.034352
Training Epoch: 82 [32/50000]	Loss: 2.4636	LR: 0.034352
Training Epoch: 82 [32/50000]	Loss: 2.7192	LR: 0.034352
Training Epoch: 82 [32/50000]	Loss: 2.8374	LR: 0.034352
Evaluating Network.....
Test set: Epoch: 82, Average loss: 0.0692, Top1Accuracy: 0.4198, Top3Accuracy: 0.6332, Top5Accuracy: 0.7260, Time consumed:1.81s

Training Epoch: 83 [32/50000]	Loss: 1.9650	LR: 0.033445
Training Epoch: 83 [32/50000]	Loss: 1.9201	LR: 0.033445
Training Epoch: 83 [32/50000]	Loss: 2.1229	LR: 0.033445
Training Epoch: 83 [32/50000]	Loss: 2.3179	LR: 0.033445
Training Epoch: 83 [32/50000]	Loss: 2.4418	LR: 0.033445
Training Epoch: 83 [32/50000]	Loss: 1.5931	LR: 0.033445
Training Epoch: 83 [32/50000]	Loss: 2.1626	LR: 0.033445
Training Epoch: 83 [32/50000]	Loss: 2.1356	LR: 0.033445
Training Epoch: 83 [32/50000]	Loss: 1.9577	LR: 0.033445
Training Epoch: 83 [32/50000]	Loss: 2.4881	LR: 0.033445
Evaluating Network.....
Test set: Epoch: 83, Average loss: 0.0675, Top1Accuracy: 0.4330, Top3Accuracy: 0.6454, Top5Accuracy: 0.7402, Time consumed:1.76s

Training Epoch: 84 [32/50000]	Loss: 2.5365	LR: 0.032562
Training Epoch: 84 [32/50000]	Loss: 2.4097	LR: 0.032562
Training Epoch: 84 [32/50000]	Loss: 1.6205	LR: 0.032562
Training Epoch: 84 [32/50000]	Loss: 2.4475	LR: 0.032562
Training Epoch: 84 [32/50000]	Loss: 2.2944	LR: 0.032562
Training Epoch: 84 [32/50000]	Loss: 2.0527	LR: 0.032562
Training Epoch: 84 [32/50000]	Loss: 2.5175	LR: 0.032562
Training Epoch: 84 [32/50000]	Loss: 1.8849	LR: 0.032562
Training Epoch: 84 [32/50000]	Loss: 1.7842	LR: 0.032562
Training Epoch: 84 [32/50000]	Loss: 1.8927	LR: 0.032562
Evaluating Network.....
Test set: Epoch: 84, Average loss: 0.0689, Top1Accuracy: 0.4202, Top3Accuracy: 0.6371, Top5Accuracy: 0.7288, Time consumed:1.76s

Training Epoch: 85 [32/50000]	Loss: 2.0671	LR: 0.031702
Training Epoch: 85 [32/50000]	Loss: 2.0899	LR: 0.031702
Training Epoch: 85 [32/50000]	Loss: 2.4396	LR: 0.031702
Training Epoch: 85 [32/50000]	Loss: 2.6989	LR: 0.031702
Training Epoch: 85 [32/50000]	Loss: 2.3994	LR: 0.031702
Training Epoch: 85 [32/50000]	Loss: 2.2817	LR: 0.031702
Training Epoch: 85 [32/50000]	Loss: 1.9438	LR: 0.031702
Training Epoch: 85 [32/50000]	Loss: 2.1589	LR: 0.031702
Training Epoch: 85 [32/50000]	Loss: 2.3008	LR: 0.031702
Training Epoch: 85 [32/50000]	Loss: 2.1211	LR: 0.031702
Evaluating Network.....
Test set: Epoch: 85, Average loss: 0.0676, Top1Accuracy: 0.4288, Top3Accuracy: 0.6442, Top5Accuracy: 0.7408, Time consumed:1.75s

Training Epoch: 86 [32/50000]	Loss: 2.2483	LR: 0.030865
Training Epoch: 86 [32/50000]	Loss: 2.1123	LR: 0.030865
Training Epoch: 86 [32/50000]	Loss: 1.7511	LR: 0.030865
Training Epoch: 86 [32/50000]	Loss: 2.1958	LR: 0.030865
Training Epoch: 86 [32/50000]	Loss: 2.1099	LR: 0.030865
Training Epoch: 86 [32/50000]	Loss: 2.5891	LR: 0.030865
Training Epoch: 86 [32/50000]	Loss: 1.9546	LR: 0.030865
Training Epoch: 86 [32/50000]	Loss: 2.3319	LR: 0.030865
Training Epoch: 86 [32/50000]	Loss: 2.4892	LR: 0.030865
Training Epoch: 86 [32/50000]	Loss: 2.5032	LR: 0.030865
Evaluating Network.....
Test set: Epoch: 86, Average loss: 0.0668, Top1Accuracy: 0.4335, Top3Accuracy: 0.6515, Top5Accuracy: 0.7438, Time consumed:1.89s

Training Epoch: 87 [32/50000]	Loss: 2.2441	LR: 0.030050
Training Epoch: 87 [32/50000]	Loss: 2.3140	LR: 0.030050
Training Epoch: 87 [32/50000]	Loss: 2.1054	LR: 0.030050
Training Epoch: 87 [32/50000]	Loss: 2.0636	LR: 0.030050
Training Epoch: 87 [32/50000]	Loss: 1.8804	LR: 0.030050
Training Epoch: 87 [32/50000]	Loss: 2.5536	LR: 0.030050
Training Epoch: 87 [32/50000]	Loss: 2.3911	LR: 0.030050
Training Epoch: 87 [32/50000]	Loss: 1.9697	LR: 0.030050
Training Epoch: 87 [32/50000]	Loss: 2.2952	LR: 0.030050
Training Epoch: 87 [32/50000]	Loss: 2.0795	LR: 0.030050
Evaluating Network.....
Test set: Epoch: 87, Average loss: 0.0666, Top1Accuracy: 0.4356, Top3Accuracy: 0.6533, Top5Accuracy: 0.7474, Time consumed:1.76s

Training Epoch: 88 [32/50000]	Loss: 2.4675	LR: 0.029257
Training Epoch: 88 [32/50000]	Loss: 2.0526	LR: 0.029257
Training Epoch: 88 [32/50000]	Loss: 1.9284	LR: 0.029257
Training Epoch: 88 [32/50000]	Loss: 1.8283	LR: 0.029257
Training Epoch: 88 [32/50000]	Loss: 2.3521	LR: 0.029257
Training Epoch: 88 [32/50000]	Loss: 2.3411	LR: 0.029257
Training Epoch: 88 [32/50000]	Loss: 2.1451	LR: 0.029257
Training Epoch: 88 [32/50000]	Loss: 1.7679	LR: 0.029257
Training Epoch: 88 [32/50000]	Loss: 1.6940	LR: 0.029257
Training Epoch: 88 [32/50000]	Loss: 2.0712	LR: 0.029257
Evaluating Network.....
Test set: Epoch: 88, Average loss: 0.0666, Top1Accuracy: 0.4394, Top3Accuracy: 0.6543, Top5Accuracy: 0.7450, Time consumed:1.81s

Training Epoch: 89 [32/50000]	Loss: 1.9812	LR: 0.028485
Training Epoch: 89 [32/50000]	Loss: 2.3157	LR: 0.028485
Training Epoch: 89 [32/50000]	Loss: 2.6372	LR: 0.028485
Training Epoch: 89 [32/50000]	Loss: 1.7993	LR: 0.028485
Training Epoch: 89 [32/50000]	Loss: 1.8841	LR: 0.028485
Training Epoch: 89 [32/50000]	Loss: 2.1395	LR: 0.028485
Training Epoch: 89 [32/50000]	Loss: 2.2726	LR: 0.028485
Training Epoch: 89 [32/50000]	Loss: 2.1574	LR: 0.028485
Training Epoch: 89 [32/50000]	Loss: 1.8008	LR: 0.028485
Training Epoch: 89 [32/50000]	Loss: 2.0305	LR: 0.028485
Evaluating Network.....
Test set: Epoch: 89, Average loss: 0.0651, Top1Accuracy: 0.4465, Top3Accuracy: 0.6682, Top5Accuracy: 0.7565, Time consumed:1.78s

Training Epoch: 90 [32/50000]	Loss: 1.8941	LR: 0.027733
Training Epoch: 90 [32/50000]	Loss: 2.0500	LR: 0.027733
Training Epoch: 90 [32/50000]	Loss: 1.5972	LR: 0.027733
Training Epoch: 90 [32/50000]	Loss: 1.6486	LR: 0.027733
Training Epoch: 90 [32/50000]	Loss: 2.1006	LR: 0.027733
Training Epoch: 90 [32/50000]	Loss: 1.7848	LR: 0.027733
Training Epoch: 90 [32/50000]	Loss: 1.9702	LR: 0.027733
Training Epoch: 90 [32/50000]	Loss: 2.6539	LR: 0.027733
Training Epoch: 90 [32/50000]	Loss: 2.4239	LR: 0.027733
Training Epoch: 90 [32/50000]	Loss: 1.9854	LR: 0.027733
Evaluating Network.....
Test set: Epoch: 90, Average loss: 0.0661, Top1Accuracy: 0.4447, Top3Accuracy: 0.6565, Top5Accuracy: 0.7466, Time consumed:1.69s

Training Epoch: 91 [32/50000]	Loss: 2.2611	LR: 0.027001
Training Epoch: 91 [32/50000]	Loss: 2.3803	LR: 0.027001
Training Epoch: 91 [32/50000]	Loss: 2.1825	LR: 0.027001
Training Epoch: 91 [32/50000]	Loss: 2.1402	LR: 0.027001
Training Epoch: 91 [32/50000]	Loss: 2.1991	LR: 0.027001
Training Epoch: 91 [32/50000]	Loss: 1.8986	LR: 0.027001
Training Epoch: 91 [32/50000]	Loss: 2.5011	LR: 0.027001
Training Epoch: 91 [32/50000]	Loss: 1.4890	LR: 0.027001
Training Epoch: 91 [32/50000]	Loss: 2.4645	LR: 0.027001
Training Epoch: 91 [32/50000]	Loss: 2.7751	LR: 0.027001
Evaluating Network.....
Test set: Epoch: 91, Average loss: 0.0656, Top1Accuracy: 0.4414, Top3Accuracy: 0.6589, Top5Accuracy: 0.7533, Time consumed:1.72s

Training Epoch: 92 [32/50000]	Loss: 1.4595	LR: 0.026288
Training Epoch: 92 [32/50000]	Loss: 2.1745	LR: 0.026288
Training Epoch: 92 [32/50000]	Loss: 2.1590	LR: 0.026288
Training Epoch: 92 [32/50000]	Loss: 2.0952	LR: 0.026288
Training Epoch: 92 [32/50000]	Loss: 2.3131	LR: 0.026288
Training Epoch: 92 [32/50000]	Loss: 2.3518	LR: 0.026288
Training Epoch: 92 [32/50000]	Loss: 1.8898	LR: 0.026288
Training Epoch: 92 [32/50000]	Loss: 2.0948	LR: 0.026288
Training Epoch: 92 [32/50000]	Loss: 2.7360	LR: 0.026288
Training Epoch: 92 [32/50000]	Loss: 1.8021	LR: 0.026288
Evaluating Network.....
Test set: Epoch: 92, Average loss: 0.0640, Top1Accuracy: 0.4564, Top3Accuracy: 0.6738, Top5Accuracy: 0.7630, Time consumed:1.78s

Training Epoch: 93 [32/50000]	Loss: 2.0419	LR: 0.025594
Training Epoch: 93 [32/50000]	Loss: 2.1854	LR: 0.025594
Training Epoch: 93 [32/50000]	Loss: 2.3461	LR: 0.025594
Training Epoch: 93 [32/50000]	Loss: 2.3532	LR: 0.025594
Training Epoch: 93 [32/50000]	Loss: 2.5075	LR: 0.025594
Training Epoch: 93 [32/50000]	Loss: 1.9432	LR: 0.025594
Training Epoch: 93 [32/50000]	Loss: 2.0557	LR: 0.025594
Training Epoch: 93 [32/50000]	Loss: 1.7050	LR: 0.025594
Training Epoch: 93 [32/50000]	Loss: 2.2199	LR: 0.025594
Training Epoch: 93 [32/50000]	Loss: 1.9973	LR: 0.025594
Evaluating Network.....
Test set: Epoch: 93, Average loss: 0.0640, Top1Accuracy: 0.4566, Top3Accuracy: 0.6724, Top5Accuracy: 0.7583, Time consumed:1.78s

Training Epoch: 94 [32/50000]	Loss: 2.0995	LR: 0.024918
Training Epoch: 94 [32/50000]	Loss: 1.9191	LR: 0.024918
Training Epoch: 94 [32/50000]	Loss: 2.1751	LR: 0.024918
Training Epoch: 94 [32/50000]	Loss: 1.9147	LR: 0.024918
Training Epoch: 94 [32/50000]	Loss: 1.9088	LR: 0.024918
Training Epoch: 94 [32/50000]	Loss: 2.2113	LR: 0.024918
Training Epoch: 94 [32/50000]	Loss: 2.1216	LR: 0.024918
Training Epoch: 94 [32/50000]	Loss: 2.1803	LR: 0.024918
Training Epoch: 94 [32/50000]	Loss: 1.9533	LR: 0.024918
Training Epoch: 94 [32/50000]	Loss: 1.7870	LR: 0.024918
Evaluating Network.....
Test set: Epoch: 94, Average loss: 0.0639, Top1Accuracy: 0.4568, Top3Accuracy: 0.6750, Top5Accuracy: 0.7611, Time consumed:1.75s

Training Epoch: 95 [32/50000]	Loss: 2.1185	LR: 0.024260
Training Epoch: 95 [32/50000]	Loss: 2.2981	LR: 0.024260
Training Epoch: 95 [32/50000]	Loss: 2.0155	LR: 0.024260
Training Epoch: 95 [32/50000]	Loss: 1.7052	LR: 0.024260
Training Epoch: 95 [32/50000]	Loss: 2.0685	LR: 0.024260
Training Epoch: 95 [32/50000]	Loss: 2.0205	LR: 0.024260
Training Epoch: 95 [32/50000]	Loss: 1.8601	LR: 0.024260
Training Epoch: 95 [32/50000]	Loss: 1.9163	LR: 0.024260
Training Epoch: 95 [32/50000]	Loss: 2.1388	LR: 0.024260
Training Epoch: 95 [32/50000]	Loss: 2.2503	LR: 0.024260
Evaluating Network.....
Test set: Epoch: 95, Average loss: 0.0630, Top1Accuracy: 0.4643, Top3Accuracy: 0.6780, Top5Accuracy: 0.7697, Time consumed:1.73s

Training Epoch: 96 [32/50000]	Loss: 2.0906	LR: 0.023620
Training Epoch: 96 [32/50000]	Loss: 1.7296	LR: 0.023620
Training Epoch: 96 [32/50000]	Loss: 2.4617	LR: 0.023620
Training Epoch: 96 [32/50000]	Loss: 1.7878	LR: 0.023620
Training Epoch: 96 [32/50000]	Loss: 2.4094	LR: 0.023620
Training Epoch: 96 [32/50000]	Loss: 2.0574	LR: 0.023620
Training Epoch: 96 [32/50000]	Loss: 2.4593	LR: 0.023620
Training Epoch: 96 [32/50000]	Loss: 2.6112	LR: 0.023620
Training Epoch: 96 [32/50000]	Loss: 2.2715	LR: 0.023620
Training Epoch: 96 [32/50000]	Loss: 2.2494	LR: 0.023620
Evaluating Network.....
Test set: Epoch: 96, Average loss: 0.0639, Top1Accuracy: 0.4547, Top3Accuracy: 0.6750, Top5Accuracy: 0.7621, Time consumed:1.79s

Training Epoch: 97 [32/50000]	Loss: 2.1532	LR: 0.022996
Training Epoch: 97 [32/50000]	Loss: 1.6489	LR: 0.022996
Training Epoch: 97 [32/50000]	Loss: 2.3193	LR: 0.022996
Training Epoch: 97 [32/50000]	Loss: 2.1980	LR: 0.022996
Training Epoch: 97 [32/50000]	Loss: 2.3116	LR: 0.022996
Training Epoch: 97 [32/50000]	Loss: 1.8405	LR: 0.022996
Training Epoch: 97 [32/50000]	Loss: 2.4054	LR: 0.022996
Training Epoch: 97 [32/50000]	Loss: 1.7004	LR: 0.022996
Training Epoch: 97 [32/50000]	Loss: 2.0687	LR: 0.022996
Training Epoch: 97 [32/50000]	Loss: 1.7649	LR: 0.022996
Evaluating Network.....
Test set: Epoch: 97, Average loss: 0.0636, Top1Accuracy: 0.4593, Top3Accuracy: 0.6728, Top5Accuracy: 0.7649, Time consumed:1.71s

Training Epoch: 98 [32/50000]	Loss: 1.5979	LR: 0.022389
Training Epoch: 98 [32/50000]	Loss: 2.3722	LR: 0.022389
Training Epoch: 98 [32/50000]	Loss: 1.7379	LR: 0.022389
Training Epoch: 98 [32/50000]	Loss: 2.3848	LR: 0.022389
Training Epoch: 98 [32/50000]	Loss: 2.0239	LR: 0.022389
Training Epoch: 98 [32/50000]	Loss: 1.9398	LR: 0.022389
Training Epoch: 98 [32/50000]	Loss: 2.1765	LR: 0.022389
Training Epoch: 98 [32/50000]	Loss: 1.7682	LR: 0.022389
Training Epoch: 98 [32/50000]	Loss: 2.0750	LR: 0.022389
Training Epoch: 98 [32/50000]	Loss: 2.4314	LR: 0.022389
Evaluating Network.....
Test set: Epoch: 98, Average loss: 0.0625, Top1Accuracy: 0.4658, Top3Accuracy: 0.6817, Top5Accuracy: 0.7692, Time consumed:1.72s

Training Epoch: 99 [32/50000]	Loss: 2.7250	LR: 0.021798
Training Epoch: 99 [32/50000]	Loss: 1.7901	LR: 0.021798
Training Epoch: 99 [32/50000]	Loss: 2.6887	LR: 0.021798
Training Epoch: 99 [32/50000]	Loss: 1.8991	LR: 0.021798
Training Epoch: 99 [32/50000]	Loss: 2.2793	LR: 0.021798
Training Epoch: 99 [32/50000]	Loss: 2.2391	LR: 0.021798
Training Epoch: 99 [32/50000]	Loss: 2.3526	LR: 0.021798
Training Epoch: 99 [32/50000]	Loss: 2.0554	LR: 0.021798
Training Epoch: 99 [32/50000]	Loss: 1.9792	LR: 0.021798
Training Epoch: 99 [32/50000]	Loss: 1.8404	LR: 0.021798
Evaluating Network.....
Test set: Epoch: 99, Average loss: 0.0637, Top1Accuracy: 0.4569, Top3Accuracy: 0.6724, Top5Accuracy: 0.7661, Time consumed:1.78s

Training Epoch: 100 [32/50000]	Loss: 2.2041	LR: 0.021223
Training Epoch: 100 [32/50000]	Loss: 2.5735	LR: 0.021223
Training Epoch: 100 [32/50000]	Loss: 1.4841	LR: 0.021223
Training Epoch: 100 [32/50000]	Loss: 1.9340	LR: 0.021223
Training Epoch: 100 [32/50000]	Loss: 1.8374	LR: 0.021223
Training Epoch: 100 [32/50000]	Loss: 2.1534	LR: 0.021223
Training Epoch: 100 [32/50000]	Loss: 2.1850	LR: 0.021223
Training Epoch: 100 [32/50000]	Loss: 2.0339	LR: 0.021223
Training Epoch: 100 [32/50000]	Loss: 2.2882	LR: 0.021223
Training Epoch: 100 [32/50000]	Loss: 2.0124	LR: 0.021223
Evaluating Network.....
Test set: Epoch: 100, Average loss: 0.0634, Top1Accuracy: 0.4642, Top3Accuracy: 0.6732, Top5Accuracy: 0.7665, Time consumed:1.77s

Training Epoch: 101 [32/50000]	Loss: 2.1985	LR: 0.020662
Training Epoch: 101 [32/50000]	Loss: 2.4286	LR: 0.020662
Training Epoch: 101 [32/50000]	Loss: 2.4809	LR: 0.020662
Training Epoch: 101 [32/50000]	Loss: 2.0229	LR: 0.020662
Training Epoch: 101 [32/50000]	Loss: 1.8219	LR: 0.020662
Training Epoch: 101 [32/50000]	Loss: 2.0197	LR: 0.020662
Training Epoch: 101 [32/50000]	Loss: 1.6085	LR: 0.020662
Training Epoch: 101 [32/50000]	Loss: 2.2526	LR: 0.020662
Training Epoch: 101 [32/50000]	Loss: 2.1089	LR: 0.020662
Training Epoch: 101 [32/50000]	Loss: 1.9405	LR: 0.020662
Evaluating Network.....
Test set: Epoch: 101, Average loss: 0.0627, Top1Accuracy: 0.4653, Top3Accuracy: 0.6797, Top5Accuracy: 0.7687, Time consumed:1.78s

Training Epoch: 102 [32/50000]	Loss: 2.3731	LR: 0.020117
Training Epoch: 102 [32/50000]	Loss: 1.8022	LR: 0.020117
Training Epoch: 102 [32/50000]	Loss: 1.8621	LR: 0.020117
Training Epoch: 102 [32/50000]	Loss: 2.0429	LR: 0.020117
Training Epoch: 102 [32/50000]	Loss: 2.0519	LR: 0.020117
Training Epoch: 102 [32/50000]	Loss: 1.8760	LR: 0.020117
Training Epoch: 102 [32/50000]	Loss: 2.3632	LR: 0.020117
Training Epoch: 102 [32/50000]	Loss: 2.5403	LR: 0.020117
Training Epoch: 102 [32/50000]	Loss: 2.1673	LR: 0.020117
Training Epoch: 102 [32/50000]	Loss: 1.8562	LR: 0.020117
Evaluating Network.....
Test set: Epoch: 102, Average loss: 0.0619, Top1Accuracy: 0.4727, Top3Accuracy: 0.6848, Top5Accuracy: 0.7737, Time consumed:1.77s

Training Epoch: 103 [32/50000]	Loss: 2.0818	LR: 0.019586
Training Epoch: 103 [32/50000]	Loss: 1.6863	LR: 0.019586
Training Epoch: 103 [32/50000]	Loss: 2.1029	LR: 0.019586
Training Epoch: 103 [32/50000]	Loss: 1.7856	LR: 0.019586
Training Epoch: 103 [32/50000]	Loss: 2.0426	LR: 0.019586
Training Epoch: 103 [32/50000]	Loss: 1.8343	LR: 0.019586
Training Epoch: 103 [32/50000]	Loss: 2.0871	LR: 0.019586
Training Epoch: 103 [32/50000]	Loss: 1.4667	LR: 0.019586
Training Epoch: 103 [32/50000]	Loss: 1.9804	LR: 0.019586
Training Epoch: 103 [32/50000]	Loss: 1.6302	LR: 0.019586
Evaluating Network.....
Test set: Epoch: 103, Average loss: 0.0621, Top1Accuracy: 0.4663, Top3Accuracy: 0.6840, Top5Accuracy: 0.7735, Time consumed:1.90s

Training Epoch: 104 [32/50000]	Loss: 1.7569	LR: 0.019069
Training Epoch: 104 [32/50000]	Loss: 2.4498	LR: 0.019069
Training Epoch: 104 [32/50000]	Loss: 1.6664	LR: 0.019069
Training Epoch: 104 [32/50000]	Loss: 2.0022	LR: 0.019069
Training Epoch: 104 [32/50000]	Loss: 1.8629	LR: 0.019069
Training Epoch: 104 [32/50000]	Loss: 1.9153	LR: 0.019069
Training Epoch: 104 [32/50000]	Loss: 2.1168	LR: 0.019069
Training Epoch: 104 [32/50000]	Loss: 1.9589	LR: 0.019069
Training Epoch: 104 [32/50000]	Loss: 1.7890	LR: 0.019069
Training Epoch: 104 [32/50000]	Loss: 1.9610	LR: 0.019069
Evaluating Network.....
Test set: Epoch: 104, Average loss: 0.0618, Top1Accuracy: 0.4710, Top3Accuracy: 0.6877, Top5Accuracy: 0.7760, Time consumed:1.83s

Training Epoch: 105 [32/50000]	Loss: 1.9097	LR: 0.018565
Training Epoch: 105 [32/50000]	Loss: 2.0544	LR: 0.018565
Training Epoch: 105 [32/50000]	Loss: 1.9727	LR: 0.018565
Training Epoch: 105 [32/50000]	Loss: 2.3189	LR: 0.018565
Training Epoch: 105 [32/50000]	Loss: 1.8017	LR: 0.018565
Training Epoch: 105 [32/50000]	Loss: 1.9630	LR: 0.018565
Training Epoch: 105 [32/50000]	Loss: 2.1845	LR: 0.018565
Training Epoch: 105 [32/50000]	Loss: 1.7315	LR: 0.018565
Training Epoch: 105 [32/50000]	Loss: 1.4040	LR: 0.018565
Training Epoch: 105 [32/50000]	Loss: 1.6361	LR: 0.018565
Evaluating Network.....
Test set: Epoch: 105, Average loss: 0.0628, Top1Accuracy: 0.4687, Top3Accuracy: 0.6786, Top5Accuracy: 0.7694, Time consumed:1.85s

Training Epoch: 106 [32/50000]	Loss: 1.9017	LR: 0.018075
Training Epoch: 106 [32/50000]	Loss: 1.8873	LR: 0.018075
Training Epoch: 106 [32/50000]	Loss: 1.5801	LR: 0.018075
Training Epoch: 106 [32/50000]	Loss: 2.1469	LR: 0.018075
Training Epoch: 106 [32/50000]	Loss: 2.3253	LR: 0.018075
Training Epoch: 106 [32/50000]	Loss: 1.8218	LR: 0.018075
Training Epoch: 106 [32/50000]	Loss: 1.6839	LR: 0.018075
Training Epoch: 106 [32/50000]	Loss: 1.8835	LR: 0.018075
Training Epoch: 106 [32/50000]	Loss: 1.8042	LR: 0.018075
Training Epoch: 106 [32/50000]	Loss: 1.8008	LR: 0.018075
Evaluating Network.....
Test set: Epoch: 106, Average loss: 0.0615, Top1Accuracy: 0.4714, Top3Accuracy: 0.6914, Top5Accuracy: 0.7755, Time consumed:1.75s

Training Epoch: 107 [32/50000]	Loss: 1.8334	LR: 0.017598
Training Epoch: 107 [32/50000]	Loss: 1.5851	LR: 0.017598
Training Epoch: 107 [32/50000]	Loss: 2.3410	LR: 0.017598
Training Epoch: 107 [32/50000]	Loss: 2.1154	LR: 0.017598
Training Epoch: 107 [32/50000]	Loss: 1.6395	LR: 0.017598
Training Epoch: 107 [32/50000]	Loss: 2.2271	LR: 0.017598
Training Epoch: 107 [32/50000]	Loss: 2.3769	LR: 0.017598
Training Epoch: 107 [32/50000]	Loss: 2.1969	LR: 0.017598
Training Epoch: 107 [32/50000]	Loss: 2.1059	LR: 0.017598
Training Epoch: 107 [32/50000]	Loss: 1.7297	LR: 0.017598
Evaluating Network.....
Test set: Epoch: 107, Average loss: 0.0606, Top1Accuracy: 0.4825, Top3Accuracy: 0.6953, Top5Accuracy: 0.7779, Time consumed:1.82s

Training Epoch: 108 [32/50000]	Loss: 1.6885	LR: 0.017133
Training Epoch: 108 [32/50000]	Loss: 2.4749	LR: 0.017133
Training Epoch: 108 [32/50000]	Loss: 2.3411	LR: 0.017133
Training Epoch: 108 [32/50000]	Loss: 2.0154	LR: 0.017133
Training Epoch: 108 [32/50000]	Loss: 1.8700	LR: 0.017133
Training Epoch: 108 [32/50000]	Loss: 1.9737	LR: 0.017133
Training Epoch: 108 [32/50000]	Loss: 1.9512	LR: 0.017133
Training Epoch: 108 [32/50000]	Loss: 1.9159	LR: 0.017133
Training Epoch: 108 [32/50000]	Loss: 1.8806	LR: 0.017133
Training Epoch: 108 [32/50000]	Loss: 1.5895	LR: 0.017133
Evaluating Network.....
Test set: Epoch: 108, Average loss: 0.0603, Top1Accuracy: 0.4813, Top3Accuracy: 0.6964, Top5Accuracy: 0.7834, Time consumed:1.84s

Training Epoch: 109 [32/50000]	Loss: 1.5297	LR: 0.016681
Training Epoch: 109 [32/50000]	Loss: 1.9643	LR: 0.016681
Training Epoch: 109 [32/50000]	Loss: 2.0682	LR: 0.016681
Training Epoch: 109 [32/50000]	Loss: 1.6630	LR: 0.016681
Training Epoch: 109 [32/50000]	Loss: 1.9265	LR: 0.016681
Training Epoch: 109 [32/50000]	Loss: 2.7405	LR: 0.016681
Training Epoch: 109 [32/50000]	Loss: 2.0971	LR: 0.016681
Training Epoch: 109 [32/50000]	Loss: 2.0889	LR: 0.016681
Training Epoch: 109 [32/50000]	Loss: 1.9645	LR: 0.016681
Training Epoch: 109 [32/50000]	Loss: 1.3770	LR: 0.016681
Evaluating Network.....
Test set: Epoch: 109, Average loss: 0.0611, Top1Accuracy: 0.4788, Top3Accuracy: 0.6902, Top5Accuracy: 0.7791, Time consumed:1.78s

Training Epoch: 110 [32/50000]	Loss: 1.8750	LR: 0.016241
Training Epoch: 110 [32/50000]	Loss: 1.9110	LR: 0.016241
Training Epoch: 110 [32/50000]	Loss: 1.7352	LR: 0.016241
Training Epoch: 110 [32/50000]	Loss: 1.5313	LR: 0.016241
Training Epoch: 110 [32/50000]	Loss: 2.4459	LR: 0.016241
Training Epoch: 110 [32/50000]	Loss: 1.9820	LR: 0.016241
Training Epoch: 110 [32/50000]	Loss: 1.6370	LR: 0.016241
Training Epoch: 110 [32/50000]	Loss: 1.8769	LR: 0.016241
Training Epoch: 110 [32/50000]	Loss: 1.3680	LR: 0.016241
Training Epoch: 110 [32/50000]	Loss: 1.6119	LR: 0.016241
Evaluating Network.....
Test set: Epoch: 110, Average loss: 0.0595, Top1Accuracy: 0.4890, Top3Accuracy: 0.7047, Top5Accuracy: 0.7874, Time consumed:1.82s

Training Epoch: 111 [32/50000]	Loss: 1.8943	LR: 0.015812
Training Epoch: 111 [32/50000]	Loss: 1.8216	LR: 0.015812
Training Epoch: 111 [32/50000]	Loss: 1.6425	LR: 0.015812
Training Epoch: 111 [32/50000]	Loss: 1.9555	LR: 0.015812
Training Epoch: 111 [32/50000]	Loss: 2.0941	LR: 0.015812
Training Epoch: 111 [32/50000]	Loss: 1.8549	LR: 0.015812
Training Epoch: 111 [32/50000]	Loss: 1.6170	LR: 0.015812
Training Epoch: 111 [32/50000]	Loss: 1.8855	LR: 0.015812
Training Epoch: 111 [32/50000]	Loss: 2.0110	LR: 0.015812
Training Epoch: 111 [32/50000]	Loss: 2.3486	LR: 0.015812
Evaluating Network.....
Test set: Epoch: 111, Average loss: 0.0598, Top1Accuracy: 0.4836, Top3Accuracy: 0.7002, Top5Accuracy: 0.7888, Time consumed:1.71s

Training Epoch: 112 [32/50000]	Loss: 2.0643	LR: 0.015394
Training Epoch: 112 [32/50000]	Loss: 1.2283	LR: 0.015394
Training Epoch: 112 [32/50000]	Loss: 1.8751	LR: 0.015394
Training Epoch: 112 [32/50000]	Loss: 1.9677	LR: 0.015394
Training Epoch: 112 [32/50000]	Loss: 2.1856	LR: 0.015394
Training Epoch: 112 [32/50000]	Loss: 1.8159	LR: 0.015394
Training Epoch: 112 [32/50000]	Loss: 1.9101	LR: 0.015394
Training Epoch: 112 [32/50000]	Loss: 2.1722	LR: 0.015394
Training Epoch: 112 [32/50000]	Loss: 2.1399	LR: 0.015394
Training Epoch: 112 [32/50000]	Loss: 1.9754	LR: 0.015394
Evaluating Network.....
Test set: Epoch: 112, Average loss: 0.0594, Top1Accuracy: 0.4928, Top3Accuracy: 0.7037, Top5Accuracy: 0.7890, Time consumed:1.81s

Training Epoch: 113 [32/50000]	Loss: 1.7468	LR: 0.014988
Training Epoch: 113 [32/50000]	Loss: 1.8249	LR: 0.014988
Training Epoch: 113 [32/50000]	Loss: 1.4205	LR: 0.014988
Training Epoch: 113 [32/50000]	Loss: 2.2650	LR: 0.014988
Training Epoch: 113 [32/50000]	Loss: 1.7310	LR: 0.014988
Training Epoch: 113 [32/50000]	Loss: 1.9842	LR: 0.014988
Training Epoch: 113 [32/50000]	Loss: 1.7230	LR: 0.014988
Training Epoch: 113 [32/50000]	Loss: 1.7638	LR: 0.014988
Training Epoch: 113 [32/50000]	Loss: 2.1864	LR: 0.014988
Training Epoch: 113 [32/50000]	Loss: 2.0100	LR: 0.014988
Evaluating Network.....
Test set: Epoch: 113, Average loss: 0.0593, Top1Accuracy: 0.4911, Top3Accuracy: 0.7053, Top5Accuracy: 0.7905, Time consumed:1.82s

Training Epoch: 114 [32/50000]	Loss: 1.9269	LR: 0.014592
Training Epoch: 114 [32/50000]	Loss: 1.8680	LR: 0.014592
Training Epoch: 114 [32/50000]	Loss: 2.0117	LR: 0.014592
Training Epoch: 114 [32/50000]	Loss: 1.1011	LR: 0.014592
Training Epoch: 114 [32/50000]	Loss: 1.5264	LR: 0.014592
Training Epoch: 114 [32/50000]	Loss: 2.2687	LR: 0.014592
Training Epoch: 114 [32/50000]	Loss: 2.3911	LR: 0.014592
Training Epoch: 114 [32/50000]	Loss: 1.8582	LR: 0.014592
Training Epoch: 114 [32/50000]	Loss: 2.1127	LR: 0.014592
Training Epoch: 114 [32/50000]	Loss: 1.5941	LR: 0.014592
Evaluating Network.....
Test set: Epoch: 114, Average loss: 0.0597, Top1Accuracy: 0.4861, Top3Accuracy: 0.7043, Top5Accuracy: 0.7892, Time consumed:1.82s

Training Epoch: 115 [32/50000]	Loss: 1.8082	LR: 0.014207
Training Epoch: 115 [32/50000]	Loss: 1.8423	LR: 0.014207
Training Epoch: 115 [32/50000]	Loss: 1.7165	LR: 0.014207
Training Epoch: 115 [32/50000]	Loss: 1.4122	LR: 0.014207
Training Epoch: 115 [32/50000]	Loss: 1.6007	LR: 0.014207
Training Epoch: 115 [32/50000]	Loss: 1.7190	LR: 0.014207
Training Epoch: 115 [32/50000]	Loss: 1.7991	LR: 0.014207
Training Epoch: 115 [32/50000]	Loss: 1.4159	LR: 0.014207
Training Epoch: 115 [32/50000]	Loss: 1.8295	LR: 0.014207
Training Epoch: 115 [32/50000]	Loss: 1.5480	LR: 0.014207
Evaluating Network.....
Test set: Epoch: 115, Average loss: 0.0588, Top1Accuracy: 0.4979, Top3Accuracy: 0.7095, Top5Accuracy: 0.7912, Time consumed:1.83s

Training Epoch: 116 [32/50000]	Loss: 1.6932	LR: 0.013832
Training Epoch: 116 [32/50000]	Loss: 2.0039	LR: 0.013832
Training Epoch: 116 [32/50000]	Loss: 2.0211	LR: 0.013832
Training Epoch: 116 [32/50000]	Loss: 1.5956	LR: 0.013832
Training Epoch: 116 [32/50000]	Loss: 1.8571	LR: 0.013832
Training Epoch: 116 [32/50000]	Loss: 2.1260	LR: 0.013832
Training Epoch: 116 [32/50000]	Loss: 1.8101	LR: 0.013832
Training Epoch: 116 [32/50000]	Loss: 1.4550	LR: 0.013832
Training Epoch: 116 [32/50000]	Loss: 2.0947	LR: 0.013832
Training Epoch: 116 [32/50000]	Loss: 1.8910	LR: 0.013832
Evaluating Network.....
Test set: Epoch: 116, Average loss: 0.0594, Top1Accuracy: 0.4884, Top3Accuracy: 0.7009, Top5Accuracy: 0.7872, Time consumed:1.79s

Training Epoch: 117 [32/50000]	Loss: 1.8502	LR: 0.013467
Training Epoch: 117 [32/50000]	Loss: 2.4622	LR: 0.013467
Training Epoch: 117 [32/50000]	Loss: 1.5851	LR: 0.013467
Training Epoch: 117 [32/50000]	Loss: 1.7299	LR: 0.013467
Training Epoch: 117 [32/50000]	Loss: 1.8693	LR: 0.013467
Training Epoch: 117 [32/50000]	Loss: 2.1574	LR: 0.013467
Training Epoch: 117 [32/50000]	Loss: 1.7304	LR: 0.013467
Training Epoch: 117 [32/50000]	Loss: 2.4073	LR: 0.013467
Training Epoch: 117 [32/50000]	Loss: 2.0516	LR: 0.013467
Training Epoch: 117 [32/50000]	Loss: 1.6678	LR: 0.013467
Evaluating Network.....
Test set: Epoch: 117, Average loss: 0.0589, Top1Accuracy: 0.4933, Top3Accuracy: 0.7089, Top5Accuracy: 0.7909, Time consumed:1.74s

Training Epoch: 118 [32/50000]	Loss: 1.7713	LR: 0.013111
Training Epoch: 118 [32/50000]	Loss: 1.8880	LR: 0.013111
Training Epoch: 118 [32/50000]	Loss: 1.9047	LR: 0.013111
Training Epoch: 118 [32/50000]	Loss: 1.5205	LR: 0.013111
Training Epoch: 118 [32/50000]	Loss: 1.5780	LR: 0.013111
Training Epoch: 118 [32/50000]	Loss: 1.5557	LR: 0.013111
Training Epoch: 118 [32/50000]	Loss: 1.8791	LR: 0.013111
Training Epoch: 118 [32/50000]	Loss: 1.8260	LR: 0.013111
Training Epoch: 118 [32/50000]	Loss: 1.4887	LR: 0.013111
Training Epoch: 118 [32/50000]	Loss: 2.1881	LR: 0.013111
Evaluating Network.....
Test set: Epoch: 118, Average loss: 0.0580, Top1Accuracy: 0.5003, Top3Accuracy: 0.7138, Top5Accuracy: 0.8005, Time consumed:1.77s

Training Epoch: 119 [32/50000]	Loss: 1.8737	LR: 0.012765
Training Epoch: 119 [32/50000]	Loss: 2.0453	LR: 0.012765
Training Epoch: 119 [32/50000]	Loss: 1.9589	LR: 0.012765
Training Epoch: 119 [32/50000]	Loss: 1.5367	LR: 0.012765
Training Epoch: 119 [32/50000]	Loss: 1.7984	LR: 0.012765
Training Epoch: 119 [32/50000]	Loss: 1.6814	LR: 0.012765
Training Epoch: 119 [32/50000]	Loss: 1.6725	LR: 0.012765
Training Epoch: 119 [32/50000]	Loss: 1.7400	LR: 0.012765
Training Epoch: 119 [32/50000]	Loss: 1.8524	LR: 0.012765
Training Epoch: 119 [32/50000]	Loss: 1.5858	LR: 0.012765
Evaluating Network.....
Test set: Epoch: 119, Average loss: 0.0583, Top1Accuracy: 0.4984, Top3Accuracy: 0.7135, Top5Accuracy: 0.7943, Time consumed:1.75s

Training Epoch: 120 [32/50000]	Loss: 2.2375	LR: 0.012428
Training Epoch: 120 [32/50000]	Loss: 2.0373	LR: 0.012428
Training Epoch: 120 [32/50000]	Loss: 1.3870	LR: 0.012428
Training Epoch: 120 [32/50000]	Loss: 1.6724	LR: 0.012428
Training Epoch: 120 [32/50000]	Loss: 1.4251	LR: 0.012428
Training Epoch: 120 [32/50000]	Loss: 1.8879	LR: 0.012428
Training Epoch: 120 [32/50000]	Loss: 1.5412	LR: 0.012428
Training Epoch: 120 [32/50000]	Loss: 1.5963	LR: 0.012428
Training Epoch: 120 [32/50000]	Loss: 1.9038	LR: 0.012428
Training Epoch: 120 [32/50000]	Loss: 1.7706	LR: 0.012428
Evaluating Network.....
Test set: Epoch: 120, Average loss: 0.0581, Top1Accuracy: 0.5043, Top3Accuracy: 0.7135, Top5Accuracy: 0.7954, Time consumed:1.83s

Training Epoch: 121 [32/50000]	Loss: 1.7424	LR: 0.012100
Training Epoch: 121 [32/50000]	Loss: 2.1594	LR: 0.012100
Training Epoch: 121 [32/50000]	Loss: 2.1653	LR: 0.012100
Training Epoch: 121 [32/50000]	Loss: 1.9396	LR: 0.012100
Training Epoch: 121 [32/50000]	Loss: 2.1305	LR: 0.012100
Training Epoch: 121 [32/50000]	Loss: 1.9076	LR: 0.012100
Training Epoch: 121 [32/50000]	Loss: 1.6686	LR: 0.012100
Training Epoch: 121 [32/50000]	Loss: 1.9015	LR: 0.012100
Training Epoch: 121 [32/50000]	Loss: 1.8498	LR: 0.012100
Training Epoch: 121 [32/50000]	Loss: 2.0667	LR: 0.012100
Evaluating Network.....
Test set: Epoch: 121, Average loss: 0.0582, Top1Accuracy: 0.4987, Top3Accuracy: 0.7107, Top5Accuracy: 0.7935, Time consumed:1.76s

Training Epoch: 122 [32/50000]	Loss: 1.9657	LR: 0.011781
Training Epoch: 122 [32/50000]	Loss: 1.4366	LR: 0.011781
Training Epoch: 122 [32/50000]	Loss: 1.6145	LR: 0.011781
Training Epoch: 122 [32/50000]	Loss: 1.7841	LR: 0.011781
Training Epoch: 122 [32/50000]	Loss: 1.8992	LR: 0.011781
Training Epoch: 122 [32/50000]	Loss: 1.2950	LR: 0.011781
Training Epoch: 122 [32/50000]	Loss: 1.6968	LR: 0.011781
Training Epoch: 122 [32/50000]	Loss: 1.7884	LR: 0.011781
Training Epoch: 122 [32/50000]	Loss: 1.7449	LR: 0.011781
Training Epoch: 122 [32/50000]	Loss: 1.8628	LR: 0.011781
Evaluating Network.....
Test set: Epoch: 122, Average loss: 0.0572, Top1Accuracy: 0.5088, Top3Accuracy: 0.7202, Top5Accuracy: 0.8024, Time consumed:1.83s

Training Epoch: 123 [32/50000]	Loss: 1.7278	LR: 0.011470
Training Epoch: 123 [32/50000]	Loss: 1.7918	LR: 0.011470
Training Epoch: 123 [32/50000]	Loss: 1.5970	LR: 0.011470
Training Epoch: 123 [32/50000]	Loss: 1.8739	LR: 0.011470
Training Epoch: 123 [32/50000]	Loss: 2.0479	LR: 0.011470
Training Epoch: 123 [32/50000]	Loss: 1.5129	LR: 0.011470
Training Epoch: 123 [32/50000]	Loss: 1.7651	LR: 0.011470
Training Epoch: 123 [32/50000]	Loss: 1.8249	LR: 0.011470
Training Epoch: 123 [32/50000]	Loss: 1.9412	LR: 0.011470
Training Epoch: 123 [32/50000]	Loss: 2.0103	LR: 0.011470
Evaluating Network.....
Test set: Epoch: 123, Average loss: 0.0572, Top1Accuracy: 0.5050, Top3Accuracy: 0.7263, Top5Accuracy: 0.8011, Time consumed:1.81s

Training Epoch: 124 [32/50000]	Loss: 1.6986	LR: 0.011167
Training Epoch: 124 [32/50000]	Loss: 1.8991	LR: 0.011167
Training Epoch: 124 [32/50000]	Loss: 1.4971	LR: 0.011167
Training Epoch: 124 [32/50000]	Loss: 1.9364	LR: 0.011167
Training Epoch: 124 [32/50000]	Loss: 1.9462	LR: 0.011167
Training Epoch: 124 [32/50000]	Loss: 1.6379	LR: 0.011167
Training Epoch: 124 [32/50000]	Loss: 2.2896	LR: 0.011167
Training Epoch: 124 [32/50000]	Loss: 1.7620	LR: 0.011167
Training Epoch: 124 [32/50000]	Loss: 1.5331	LR: 0.011167
Training Epoch: 124 [32/50000]	Loss: 1.5548	LR: 0.011167
Evaluating Network.....
Test set: Epoch: 124, Average loss: 0.0568, Top1Accuracy: 0.5067, Top3Accuracy: 0.7215, Top5Accuracy: 0.8038, Time consumed:1.79s

Training Epoch: 125 [32/50000]	Loss: 1.6756	LR: 0.010872
Training Epoch: 125 [32/50000]	Loss: 1.6754	LR: 0.010872
Training Epoch: 125 [32/50000]	Loss: 2.1709	LR: 0.010872
Training Epoch: 125 [32/50000]	Loss: 1.8717	LR: 0.010872
Training Epoch: 125 [32/50000]	Loss: 1.9484	LR: 0.010872
Training Epoch: 125 [32/50000]	Loss: 1.4169	LR: 0.010872
Training Epoch: 125 [32/50000]	Loss: 1.8814	LR: 0.010872
Training Epoch: 125 [32/50000]	Loss: 1.9951	LR: 0.010872
Training Epoch: 125 [32/50000]	Loss: 2.2757	LR: 0.010872
Training Epoch: 125 [32/50000]	Loss: 1.8335	LR: 0.010872
Evaluating Network.....
Test set: Epoch: 125, Average loss: 0.0570, Top1Accuracy: 0.5040, Top3Accuracy: 0.7211, Top5Accuracy: 0.8042, Time consumed:1.80s

Training Epoch: 126 [32/50000]	Loss: 1.6069	LR: 0.010585
Training Epoch: 126 [32/50000]	Loss: 1.9636	LR: 0.010585
Training Epoch: 126 [32/50000]	Loss: 1.2595	LR: 0.010585
Training Epoch: 126 [32/50000]	Loss: 1.6183	LR: 0.010585
Training Epoch: 126 [32/50000]	Loss: 1.9935	LR: 0.010585
Training Epoch: 126 [32/50000]	Loss: 2.0361	LR: 0.010585
Training Epoch: 126 [32/50000]	Loss: 1.2915	LR: 0.010585
Training Epoch: 126 [32/50000]	Loss: 1.7202	LR: 0.010585
Training Epoch: 126 [32/50000]	Loss: 1.5963	LR: 0.010585
Training Epoch: 126 [32/50000]	Loss: 1.9797	LR: 0.010585
Evaluating Network.....
Test set: Epoch: 126, Average loss: 0.0575, Top1Accuracy: 0.5052, Top3Accuracy: 0.7210, Top5Accuracy: 0.8020, Time consumed:1.79s

Training Epoch: 127 [32/50000]	Loss: 2.3097	LR: 0.010306
Training Epoch: 127 [32/50000]	Loss: 1.9272	LR: 0.010306
Training Epoch: 127 [32/50000]	Loss: 1.4862	LR: 0.010306
Training Epoch: 127 [32/50000]	Loss: 1.4158	LR: 0.010306
Training Epoch: 127 [32/50000]	Loss: 1.9334	LR: 0.010306
Training Epoch: 127 [32/50000]	Loss: 1.7162	LR: 0.010306
Training Epoch: 127 [32/50000]	Loss: 1.6852	LR: 0.010306
Training Epoch: 127 [32/50000]	Loss: 1.3681	LR: 0.010306
Training Epoch: 127 [32/50000]	Loss: 2.0691	LR: 0.010306
Training Epoch: 127 [32/50000]	Loss: 1.5903	LR: 0.010306
Evaluating Network.....
Test set: Epoch: 127, Average loss: 0.0562, Top1Accuracy: 0.5139, Top3Accuracy: 0.7265, Top5Accuracy: 0.8088, Time consumed:1.81s

Training Epoch: 128 [32/50000]	Loss: 2.1041	LR: 0.010034
Training Epoch: 128 [32/50000]	Loss: 1.3569	LR: 0.010034
Training Epoch: 128 [32/50000]	Loss: 2.0850	LR: 0.010034
Training Epoch: 128 [32/50000]	Loss: 1.6368	LR: 0.010034
Training Epoch: 128 [32/50000]	Loss: 1.7903	LR: 0.010034
Training Epoch: 128 [32/50000]	Loss: 1.8651	LR: 0.010034
Training Epoch: 128 [32/50000]	Loss: 1.4581	LR: 0.010034
Training Epoch: 128 [32/50000]	Loss: 1.8113	LR: 0.010034
Training Epoch: 128 [32/50000]	Loss: 1.6065	LR: 0.010034
Training Epoch: 128 [32/50000]	Loss: 1.8359	LR: 0.010034
Evaluating Network.....
Test set: Epoch: 128, Average loss: 0.0569, Top1Accuracy: 0.5110, Top3Accuracy: 0.7227, Top5Accuracy: 0.8043, Time consumed:1.78s

Training Epoch: 129 [32/50000]	Loss: 1.2378	LR: 0.009769
Training Epoch: 129 [32/50000]	Loss: 1.9669	LR: 0.009769
Training Epoch: 129 [32/50000]	Loss: 1.8686	LR: 0.009769
Training Epoch: 129 [32/50000]	Loss: 1.8778	LR: 0.009769
Training Epoch: 129 [32/50000]	Loss: 1.9023	LR: 0.009769
Training Epoch: 129 [32/50000]	Loss: 2.0498	LR: 0.009769
Training Epoch: 129 [32/50000]	Loss: 1.6061	LR: 0.009769
Training Epoch: 129 [32/50000]	Loss: 2.4890	LR: 0.009769
Training Epoch: 129 [32/50000]	Loss: 1.1121	LR: 0.009769
Training Epoch: 129 [32/50000]	Loss: 2.0765	LR: 0.009769
Evaluating Network.....
Test set: Epoch: 129, Average loss: 0.0565, Top1Accuracy: 0.5106, Top3Accuracy: 0.7277, Top5Accuracy: 0.8061, Time consumed:1.82s

Training Epoch: 130 [32/50000]	Loss: 2.0478	LR: 0.009511
Training Epoch: 130 [32/50000]	Loss: 1.7754	LR: 0.009511
Training Epoch: 130 [32/50000]	Loss: 2.1072	LR: 0.009511
Training Epoch: 130 [32/50000]	Loss: 2.1130	LR: 0.009511
Training Epoch: 130 [32/50000]	Loss: 1.4899	LR: 0.009511
Training Epoch: 130 [32/50000]	Loss: 1.7838	LR: 0.009511
Training Epoch: 130 [32/50000]	Loss: 1.5087	LR: 0.009511
Training Epoch: 130 [32/50000]	Loss: 1.6081	LR: 0.009511
Training Epoch: 130 [32/50000]	Loss: 2.1323	LR: 0.009511
Training Epoch: 130 [32/50000]	Loss: 1.8910	LR: 0.009511
Evaluating Network.....
Test set: Epoch: 130, Average loss: 0.0558, Top1Accuracy: 0.5180, Top3Accuracy: 0.7289, Top5Accuracy: 0.8103, Time consumed:1.84s

Training Epoch: 131 [32/50000]	Loss: 1.6559	LR: 0.009260
Training Epoch: 131 [32/50000]	Loss: 1.4796	LR: 0.009260
Training Epoch: 131 [32/50000]	Loss: 1.5376	LR: 0.009260
Training Epoch: 131 [32/50000]	Loss: 1.9039	LR: 0.009260
Training Epoch: 131 [32/50000]	Loss: 1.3625	LR: 0.009260
Training Epoch: 131 [32/50000]	Loss: 1.0989	LR: 0.009260
Training Epoch: 131 [32/50000]	Loss: 1.7379	LR: 0.009260
Training Epoch: 131 [32/50000]	Loss: 1.2946	LR: 0.009260
Training Epoch: 131 [32/50000]	Loss: 1.4939	LR: 0.009260
Training Epoch: 131 [32/50000]	Loss: 1.3591	LR: 0.009260
Evaluating Network.....
Test set: Epoch: 131, Average loss: 0.0561, Top1Accuracy: 0.5153, Top3Accuracy: 0.7257, Top5Accuracy: 0.8087, Time consumed:1.82s

Training Epoch: 132 [32/50000]	Loss: 1.6423	LR: 0.009015
Training Epoch: 132 [32/50000]	Loss: 1.4675	LR: 0.009015
Training Epoch: 132 [32/50000]	Loss: 1.8178	LR: 0.009015
Training Epoch: 132 [32/50000]	Loss: 1.8016	LR: 0.009015
Training Epoch: 132 [32/50000]	Loss: 1.7838	LR: 0.009015
Training Epoch: 132 [32/50000]	Loss: 2.2475	LR: 0.009015
Training Epoch: 132 [32/50000]	Loss: 1.6507	LR: 0.009015
Training Epoch: 132 [32/50000]	Loss: 1.7706	LR: 0.009015
Training Epoch: 132 [32/50000]	Loss: 1.6885	LR: 0.009015
Training Epoch: 132 [32/50000]	Loss: 1.5807	LR: 0.009015
Evaluating Network.....
Test set: Epoch: 132, Average loss: 0.0556, Top1Accuracy: 0.5174, Top3Accuracy: 0.7310, Top5Accuracy: 0.8112, Time consumed:1.83s

Training Epoch: 133 [32/50000]	Loss: 1.8669	LR: 0.008777
Training Epoch: 133 [32/50000]	Loss: 1.8920	LR: 0.008777
Training Epoch: 133 [32/50000]	Loss: 1.6564	LR: 0.008777
Training Epoch: 133 [32/50000]	Loss: 1.6566	LR: 0.008777
Training Epoch: 133 [32/50000]	Loss: 1.6821	LR: 0.008777
Training Epoch: 133 [32/50000]	Loss: 1.8790	LR: 0.008777
Training Epoch: 133 [32/50000]	Loss: 1.7802	LR: 0.008777
Training Epoch: 133 [32/50000]	Loss: 1.7765	LR: 0.008777
Training Epoch: 133 [32/50000]	Loss: 1.7828	LR: 0.008777
Training Epoch: 133 [32/50000]	Loss: 1.7555	LR: 0.008777
Evaluating Network.....
Test set: Epoch: 133, Average loss: 0.0551, Top1Accuracy: 0.5215, Top3Accuracy: 0.7349, Top5Accuracy: 0.8158, Time consumed:1.80s

Training Epoch: 134 [32/50000]	Loss: 1.6777	LR: 0.008545
Training Epoch: 134 [32/50000]	Loss: 1.8005	LR: 0.008545
Training Epoch: 134 [32/50000]	Loss: 1.4662	LR: 0.008545
Training Epoch: 134 [32/50000]	Loss: 2.0790	LR: 0.008545
Training Epoch: 134 [32/50000]	Loss: 1.6627	LR: 0.008545
Training Epoch: 134 [32/50000]	Loss: 1.7971	LR: 0.008545
Training Epoch: 134 [32/50000]	Loss: 1.8443	LR: 0.008545
Training Epoch: 134 [32/50000]	Loss: 1.6862	LR: 0.008545
Training Epoch: 134 [32/50000]	Loss: 1.8987	LR: 0.008545
Training Epoch: 134 [32/50000]	Loss: 1.4397	LR: 0.008545
Evaluating Network.....
Test set: Epoch: 134, Average loss: 0.0556, Top1Accuracy: 0.5164, Top3Accuracy: 0.7305, Top5Accuracy: 0.8113, Time consumed:1.82s

Training Epoch: 135 [32/50000]	Loss: 1.8808	LR: 0.008320
Training Epoch: 135 [32/50000]	Loss: 1.7628	LR: 0.008320
Training Epoch: 135 [32/50000]	Loss: 1.7575	LR: 0.008320
Training Epoch: 135 [32/50000]	Loss: 1.8716	LR: 0.008320
Training Epoch: 135 [32/50000]	Loss: 2.2175	LR: 0.008320
Training Epoch: 135 [32/50000]	Loss: 1.7706	LR: 0.008320
Training Epoch: 135 [32/50000]	Loss: 1.7981	LR: 0.008320
Training Epoch: 135 [32/50000]	Loss: 1.7895	LR: 0.008320
Training Epoch: 135 [32/50000]	Loss: 1.8417	LR: 0.008320
Training Epoch: 135 [32/50000]	Loss: 2.1052	LR: 0.008320
Evaluating Network.....
Test set: Epoch: 135, Average loss: 0.0553, Top1Accuracy: 0.5187, Top3Accuracy: 0.7318, Top5Accuracy: 0.8109, Time consumed:1.77s

Training Epoch: 136 [32/50000]	Loss: 1.5105	LR: 0.008100
Training Epoch: 136 [32/50000]	Loss: 1.8036	LR: 0.008100
Training Epoch: 136 [32/50000]	Loss: 1.8326	LR: 0.008100
Training Epoch: 136 [32/50000]	Loss: 1.5237	LR: 0.008100
Training Epoch: 136 [32/50000]	Loss: 1.4832	LR: 0.008100
Training Epoch: 136 [32/50000]	Loss: 1.0878	LR: 0.008100
Training Epoch: 136 [32/50000]	Loss: 1.7324	LR: 0.008100
Training Epoch: 136 [32/50000]	Loss: 1.6265	LR: 0.008100
Training Epoch: 136 [32/50000]	Loss: 1.8270	LR: 0.008100
Training Epoch: 136 [32/50000]	Loss: 1.7638	LR: 0.008100
Evaluating Network.....
Test set: Epoch: 136, Average loss: 0.0550, Top1Accuracy: 0.5211, Top3Accuracy: 0.7339, Top5Accuracy: 0.8157, Time consumed:1.79s

Training Epoch: 137 [32/50000]	Loss: 1.5553	LR: 0.007886
Training Epoch: 137 [32/50000]	Loss: 2.0773	LR: 0.007886
Training Epoch: 137 [32/50000]	Loss: 1.8485	LR: 0.007886
Training Epoch: 137 [32/50000]	Loss: 1.6750	LR: 0.007886
Training Epoch: 137 [32/50000]	Loss: 1.9133	LR: 0.007886
Training Epoch: 137 [32/50000]	Loss: 1.5180	LR: 0.007886
Training Epoch: 137 [32/50000]	Loss: 1.8570	LR: 0.007886
Training Epoch: 137 [32/50000]	Loss: 1.9091	LR: 0.007886
Training Epoch: 137 [32/50000]	Loss: 1.5729	LR: 0.007886
Training Epoch: 137 [32/50000]	Loss: 1.4641	LR: 0.007886
Evaluating Network.....
Test set: Epoch: 137, Average loss: 0.0554, Top1Accuracy: 0.5213, Top3Accuracy: 0.7318, Top5Accuracy: 0.8105, Time consumed:1.85s

Training Epoch: 138 [32/50000]	Loss: 1.5687	LR: 0.007678
Training Epoch: 138 [32/50000]	Loss: 1.4751	LR: 0.007678
Training Epoch: 138 [32/50000]	Loss: 1.8514	LR: 0.007678
Training Epoch: 138 [32/50000]	Loss: 2.0076	LR: 0.007678
Training Epoch: 138 [32/50000]	Loss: 1.4643	LR: 0.007678
Training Epoch: 138 [32/50000]	Loss: 1.9901	LR: 0.007678
Training Epoch: 138 [32/50000]	Loss: 2.1460	LR: 0.007678
Training Epoch: 138 [32/50000]	Loss: 1.8420	LR: 0.007678
Training Epoch: 138 [32/50000]	Loss: 1.8103	LR: 0.007678
Training Epoch: 138 [32/50000]	Loss: 1.9451	LR: 0.007678
Evaluating Network.....
Test set: Epoch: 138, Average loss: 0.0552, Top1Accuracy: 0.5229, Top3Accuracy: 0.7351, Top5Accuracy: 0.8115, Time consumed:1.81s

Training Epoch: 139 [32/50000]	Loss: 1.5087	LR: 0.007475
Training Epoch: 139 [32/50000]	Loss: 1.9563	LR: 0.007475
Training Epoch: 139 [32/50000]	Loss: 1.3297	LR: 0.007475
Training Epoch: 139 [32/50000]	Loss: 1.9024	LR: 0.007475
Training Epoch: 139 [32/50000]	Loss: 1.6525	LR: 0.007475
Training Epoch: 139 [32/50000]	Loss: 1.3559	LR: 0.007475
Training Epoch: 139 [32/50000]	Loss: 1.6803	LR: 0.007475
Training Epoch: 139 [32/50000]	Loss: 1.4994	LR: 0.007475
Training Epoch: 139 [32/50000]	Loss: 1.3849	LR: 0.007475
Training Epoch: 139 [32/50000]	Loss: 1.5109	LR: 0.007475
Evaluating Network.....
Test set: Epoch: 139, Average loss: 0.0547, Top1Accuracy: 0.5259, Top3Accuracy: 0.7360, Top5Accuracy: 0.8143, Time consumed:1.81s

Training Epoch: 140 [32/50000]	Loss: 1.9555	LR: 0.007278
Training Epoch: 140 [32/50000]	Loss: 1.7755	LR: 0.007278
Training Epoch: 140 [32/50000]	Loss: 1.3788	LR: 0.007278
Training Epoch: 140 [32/50000]	Loss: 1.7775	LR: 0.007278
Training Epoch: 140 [32/50000]	Loss: 1.5506	LR: 0.007278
Training Epoch: 140 [32/50000]	Loss: 2.0388	LR: 0.007278
Training Epoch: 140 [32/50000]	Loss: 2.0386	LR: 0.007278
Training Epoch: 140 [32/50000]	Loss: 1.6050	LR: 0.007278
Training Epoch: 140 [32/50000]	Loss: 1.5332	LR: 0.007278
Training Epoch: 140 [32/50000]	Loss: 1.4113	LR: 0.007278
Evaluating Network.....
Test set: Epoch: 140, Average loss: 0.0540, Top1Accuracy: 0.5298, Top3Accuracy: 0.7441, Top5Accuracy: 0.8185, Time consumed:1.78s

Training Epoch: 141 [32/50000]	Loss: 1.5347	LR: 0.007086
Training Epoch: 141 [32/50000]	Loss: 1.9293	LR: 0.007086
Training Epoch: 141 [32/50000]	Loss: 1.8621	LR: 0.007086
Training Epoch: 141 [32/50000]	Loss: 1.6970	LR: 0.007086
Training Epoch: 141 [32/50000]	Loss: 1.2134	LR: 0.007086
Training Epoch: 141 [32/50000]	Loss: 1.3628	LR: 0.007086
Training Epoch: 141 [32/50000]	Loss: 1.9417	LR: 0.007086
Training Epoch: 141 [32/50000]	Loss: 1.4780	LR: 0.007086
Training Epoch: 141 [32/50000]	Loss: 1.5375	LR: 0.007086
Training Epoch: 141 [32/50000]	Loss: 2.0583	LR: 0.007086
Evaluating Network.....
Test set: Epoch: 141, Average loss: 0.0545, Top1Accuracy: 0.5271, Top3Accuracy: 0.7398, Top5Accuracy: 0.8168, Time consumed:1.80s

Training Epoch: 142 [32/50000]	Loss: 1.4305	LR: 0.006899
Training Epoch: 142 [32/50000]	Loss: 1.4526	LR: 0.006899
Training Epoch: 142 [32/50000]	Loss: 1.4870	LR: 0.006899
Training Epoch: 142 [32/50000]	Loss: 1.7217	LR: 0.006899
Training Epoch: 142 [32/50000]	Loss: 1.9546	LR: 0.006899
Training Epoch: 142 [32/50000]	Loss: 1.6167	LR: 0.006899
Training Epoch: 142 [32/50000]	Loss: 2.0979	LR: 0.006899
Training Epoch: 142 [32/50000]	Loss: 1.9674	LR: 0.006899
Training Epoch: 142 [32/50000]	Loss: 1.6433	LR: 0.006899
Training Epoch: 142 [32/50000]	Loss: 1.4508	LR: 0.006899
Evaluating Network.....
Test set: Epoch: 142, Average loss: 0.0551, Top1Accuracy: 0.5201, Top3Accuracy: 0.7348, Top5Accuracy: 0.8162, Time consumed:1.78s

Training Epoch: 143 [32/50000]	Loss: 1.5171	LR: 0.006717
Training Epoch: 143 [32/50000]	Loss: 1.8239	LR: 0.006717
Training Epoch: 143 [32/50000]	Loss: 2.1718	LR: 0.006717
Training Epoch: 143 [32/50000]	Loss: 1.7332	LR: 0.006717
Training Epoch: 143 [32/50000]	Loss: 1.5520	LR: 0.006717
Training Epoch: 143 [32/50000]	Loss: 2.1251	LR: 0.006717
Training Epoch: 143 [32/50000]	Loss: 1.7832	LR: 0.006717
Training Epoch: 143 [32/50000]	Loss: 1.7147	LR: 0.006717
Training Epoch: 143 [32/50000]	Loss: 1.8213	LR: 0.006717
Training Epoch: 143 [32/50000]	Loss: 1.8613	LR: 0.006717
Evaluating Network.....
Test set: Epoch: 143, Average loss: 0.0543, Top1Accuracy: 0.5293, Top3Accuracy: 0.7379, Top5Accuracy: 0.8165, Time consumed:1.78s

Training Epoch: 144 [32/50000]	Loss: 1.4837	LR: 0.006539
Training Epoch: 144 [32/50000]	Loss: 1.7959	LR: 0.006539
Training Epoch: 144 [32/50000]	Loss: 1.9389	LR: 0.006539
Training Epoch: 144 [32/50000]	Loss: 1.5262	LR: 0.006539
Training Epoch: 144 [32/50000]	Loss: 1.9966	LR: 0.006539
Training Epoch: 144 [32/50000]	Loss: 1.8430	LR: 0.006539
Training Epoch: 144 [32/50000]	Loss: 1.7531	LR: 0.006539
Training Epoch: 144 [32/50000]	Loss: 1.6694	LR: 0.006539
Training Epoch: 144 [32/50000]	Loss: 1.4024	LR: 0.006539
Training Epoch: 144 [32/50000]	Loss: 1.7851	LR: 0.006539
Evaluating Network.....
Test set: Epoch: 144, Average loss: 0.0537, Top1Accuracy: 0.5321, Top3Accuracy: 0.7436, Top5Accuracy: 0.8212, Time consumed:1.80s

Training Epoch: 145 [32/50000]	Loss: 2.2985	LR: 0.006367
Training Epoch: 145 [32/50000]	Loss: 1.6058	LR: 0.006367
Training Epoch: 145 [32/50000]	Loss: 1.5241	LR: 0.006367
Training Epoch: 145 [32/50000]	Loss: 1.7986	LR: 0.006367
Training Epoch: 145 [32/50000]	Loss: 1.9215	LR: 0.006367
Training Epoch: 145 [32/50000]	Loss: 1.5822	LR: 0.006367
Training Epoch: 145 [32/50000]	Loss: 1.3703	LR: 0.006367
Training Epoch: 145 [32/50000]	Loss: 1.7805	LR: 0.006367
Training Epoch: 145 [32/50000]	Loss: 1.2508	LR: 0.006367
Training Epoch: 145 [32/50000]	Loss: 1.3645	LR: 0.006367
Evaluating Network.....
Test set: Epoch: 145, Average loss: 0.0541, Top1Accuracy: 0.5328, Top3Accuracy: 0.7415, Top5Accuracy: 0.8182, Time consumed:1.81s

Training Epoch: 146 [32/50000]	Loss: 1.9400	LR: 0.006199
Training Epoch: 146 [32/50000]	Loss: 1.7596	LR: 0.006199
Training Epoch: 146 [32/50000]	Loss: 1.6833	LR: 0.006199
Training Epoch: 146 [32/50000]	Loss: 1.9600	LR: 0.006199
Training Epoch: 146 [32/50000]	Loss: 1.4147	LR: 0.006199
Training Epoch: 146 [32/50000]	Loss: 2.0722	LR: 0.006199
Training Epoch: 146 [32/50000]	Loss: 1.8095	LR: 0.006199
Training Epoch: 146 [32/50000]	Loss: 1.6176	LR: 0.006199
Training Epoch: 146 [32/50000]	Loss: 1.4017	LR: 0.006199
Training Epoch: 146 [32/50000]	Loss: 1.7163	LR: 0.006199
Evaluating Network.....
Test set: Epoch: 146, Average loss: 0.0533, Top1Accuracy: 0.5317, Top3Accuracy: 0.7490, Top5Accuracy: 0.8233, Time consumed:1.83s

Training Epoch: 147 [32/50000]	Loss: 1.4557	LR: 0.006035
Training Epoch: 147 [32/50000]	Loss: 1.2655	LR: 0.006035
Training Epoch: 147 [32/50000]	Loss: 1.6633	LR: 0.006035
Training Epoch: 147 [32/50000]	Loss: 1.6092	LR: 0.006035
Training Epoch: 147 [32/50000]	Loss: 1.5741	LR: 0.006035
Training Epoch: 147 [32/50000]	Loss: 1.4961	LR: 0.006035
Training Epoch: 147 [32/50000]	Loss: 1.7043	LR: 0.006035
Training Epoch: 147 [32/50000]	Loss: 1.8450	LR: 0.006035
Training Epoch: 147 [32/50000]	Loss: 2.2393	LR: 0.006035
Training Epoch: 147 [32/50000]	Loss: 1.5490	LR: 0.006035
Evaluating Network.....
Test set: Epoch: 147, Average loss: 0.0535, Top1Accuracy: 0.5324, Top3Accuracy: 0.7451, Top5Accuracy: 0.8221, Time consumed:1.78s

Training Epoch: 148 [32/50000]	Loss: 1.6154	LR: 0.005876
Training Epoch: 148 [32/50000]	Loss: 1.9770	LR: 0.005876
Training Epoch: 148 [32/50000]	Loss: 1.7611	LR: 0.005876
Training Epoch: 148 [32/50000]	Loss: 1.5691	LR: 0.005876
Training Epoch: 148 [32/50000]	Loss: 1.3974	LR: 0.005876
Training Epoch: 148 [32/50000]	Loss: 1.7093	LR: 0.005876
Training Epoch: 148 [32/50000]	Loss: 1.7633	LR: 0.005876
Training Epoch: 148 [32/50000]	Loss: 1.0891	LR: 0.005876
Training Epoch: 148 [32/50000]	Loss: 1.7214	LR: 0.005876
Training Epoch: 148 [32/50000]	Loss: 1.8170	LR: 0.005876
Evaluating Network.....
Test set: Epoch: 148, Average loss: 0.0530, Top1Accuracy: 0.5372, Top3Accuracy: 0.7469, Top5Accuracy: 0.8238, Time consumed:1.81s

Training Epoch: 149 [32/50000]	Loss: 1.4336	LR: 0.005721
Training Epoch: 149 [32/50000]	Loss: 1.8503	LR: 0.005721
Training Epoch: 149 [32/50000]	Loss: 0.9017	LR: 0.005721
Training Epoch: 149 [32/50000]	Loss: 1.9354	LR: 0.005721
Training Epoch: 149 [32/50000]	Loss: 1.6090	LR: 0.005721
Training Epoch: 149 [32/50000]	Loss: 1.5704	LR: 0.005721
Training Epoch: 149 [32/50000]	Loss: 2.1084	LR: 0.005721
Training Epoch: 149 [32/50000]	Loss: 1.5510	LR: 0.005721
Training Epoch: 149 [32/50000]	Loss: 1.8598	LR: 0.005721
Training Epoch: 149 [32/50000]	Loss: 1.8637	LR: 0.005721
Evaluating Network.....
Test set: Epoch: 149, Average loss: 0.0532, Top1Accuracy: 0.5365, Top3Accuracy: 0.7460, Top5Accuracy: 0.8216, Time consumed:1.76s

Training Epoch: 150 [32/50000]	Loss: 1.7237	LR: 0.005570
Training Epoch: 150 [32/50000]	Loss: 1.7736	LR: 0.005570
Training Epoch: 150 [32/50000]	Loss: 1.6397	LR: 0.005570
Training Epoch: 150 [32/50000]	Loss: 1.4396	LR: 0.005570
Training Epoch: 150 [32/50000]	Loss: 1.7938	LR: 0.005570
Training Epoch: 150 [32/50000]	Loss: 1.7051	LR: 0.005570
Training Epoch: 150 [32/50000]	Loss: 2.0383	LR: 0.005570
Training Epoch: 150 [32/50000]	Loss: 1.6135	LR: 0.005570
Training Epoch: 150 [32/50000]	Loss: 1.5113	LR: 0.005570
Training Epoch: 150 [32/50000]	Loss: 1.7982	LR: 0.005570
Evaluating Network.....
Test set: Epoch: 150, Average loss: 0.0528, Top1Accuracy: 0.5402, Top3Accuracy: 0.7505, Top5Accuracy: 0.8233, Time consumed:1.74s

Training Epoch: 151 [32/50000]	Loss: 1.7821	LR: 0.005423
Training Epoch: 151 [32/50000]	Loss: 1.5866	LR: 0.005423
Training Epoch: 151 [32/50000]	Loss: 1.3261	LR: 0.005423
Training Epoch: 151 [32/50000]	Loss: 1.8876	LR: 0.005423
Training Epoch: 151 [32/50000]	Loss: 2.1387	LR: 0.005423
Training Epoch: 151 [32/50000]	Loss: 1.8698	LR: 0.005423
Training Epoch: 151 [32/50000]	Loss: 1.8540	LR: 0.005423
Training Epoch: 151 [32/50000]	Loss: 1.1777	LR: 0.005423
Training Epoch: 151 [32/50000]	Loss: 1.5547	LR: 0.005423
Training Epoch: 151 [32/50000]	Loss: 1.3336	LR: 0.005423
Evaluating Network.....
Test set: Epoch: 151, Average loss: 0.0530, Top1Accuracy: 0.5389, Top3Accuracy: 0.7489, Top5Accuracy: 0.8249, Time consumed:1.79s

Training Epoch: 152 [32/50000]	Loss: 1.8577	LR: 0.005279
Training Epoch: 152 [32/50000]	Loss: 2.1388	LR: 0.005279
Training Epoch: 152 [32/50000]	Loss: 1.5569	LR: 0.005279
Training Epoch: 152 [32/50000]	Loss: 1.6841	LR: 0.005279
Training Epoch: 152 [32/50000]	Loss: 1.4695	LR: 0.005279
Training Epoch: 152 [32/50000]	Loss: 1.4540	LR: 0.005279
Training Epoch: 152 [32/50000]	Loss: 1.8956	LR: 0.005279
Training Epoch: 152 [32/50000]	Loss: 1.9970	LR: 0.005279
Training Epoch: 152 [32/50000]	Loss: 1.3116	LR: 0.005279
Training Epoch: 152 [32/50000]	Loss: 1.4793	LR: 0.005279
Evaluating Network.....
Test set: Epoch: 152, Average loss: 0.0525, Top1Accuracy: 0.5419, Top3Accuracy: 0.7534, Top5Accuracy: 0.8290, Time consumed:1.75s

Training Epoch: 153 [32/50000]	Loss: 1.4748	LR: 0.005140
Training Epoch: 153 [32/50000]	Loss: 1.4747	LR: 0.005140
Training Epoch: 153 [32/50000]	Loss: 1.4578	LR: 0.005140
Training Epoch: 153 [32/50000]	Loss: 1.9165	LR: 0.005140
Training Epoch: 153 [32/50000]	Loss: 1.8711	LR: 0.005140
Training Epoch: 153 [32/50000]	Loss: 1.5617	LR: 0.005140
Training Epoch: 153 [32/50000]	Loss: 1.1241	LR: 0.005140
Training Epoch: 153 [32/50000]	Loss: 1.2366	LR: 0.005140
Training Epoch: 153 [32/50000]	Loss: 2.0657	LR: 0.005140
Training Epoch: 153 [32/50000]	Loss: 1.5108	LR: 0.005140
Evaluating Network.....
Test set: Epoch: 153, Average loss: 0.0525, Top1Accuracy: 0.5412, Top3Accuracy: 0.7525, Top5Accuracy: 0.8284, Time consumed:1.84s

Training Epoch: 154 [32/50000]	Loss: 1.7777	LR: 0.005004
Training Epoch: 154 [32/50000]	Loss: 2.1159	LR: 0.005004
Training Epoch: 154 [32/50000]	Loss: 2.0511	LR: 0.005004
Training Epoch: 154 [32/50000]	Loss: 1.2499	LR: 0.005004
Training Epoch: 154 [32/50000]	Loss: 1.6523	LR: 0.005004
Training Epoch: 154 [32/50000]	Loss: 2.2747	LR: 0.005004
Training Epoch: 154 [32/50000]	Loss: 1.8363	LR: 0.005004
Training Epoch: 154 [32/50000]	Loss: 1.5389	LR: 0.005004
Training Epoch: 154 [32/50000]	Loss: 1.7434	LR: 0.005004
Training Epoch: 154 [32/50000]	Loss: 1.7082	LR: 0.005004
Evaluating Network.....
Test set: Epoch: 154, Average loss: 0.0527, Top1Accuracy: 0.5403, Top3Accuracy: 0.7535, Top5Accuracy: 0.8285, Time consumed:1.75s

Training Epoch: 155 [32/50000]	Loss: 1.2986	LR: 0.004872
Training Epoch: 155 [32/50000]	Loss: 1.6632	LR: 0.004872
Training Epoch: 155 [32/50000]	Loss: 1.5992	LR: 0.004872
Training Epoch: 155 [32/50000]	Loss: 2.1520	LR: 0.004872
Training Epoch: 155 [32/50000]	Loss: 1.4248	LR: 0.004872
Training Epoch: 155 [32/50000]	Loss: 1.4410	LR: 0.004872
Training Epoch: 155 [32/50000]	Loss: 1.9615	LR: 0.004872
Training Epoch: 155 [32/50000]	Loss: 1.6893	LR: 0.004872
Training Epoch: 155 [32/50000]	Loss: 2.1245	LR: 0.004872
Training Epoch: 155 [32/50000]	Loss: 1.6211	LR: 0.004872
Evaluating Network.....
Test set: Epoch: 155, Average loss: 0.0519, Top1Accuracy: 0.5453, Top3Accuracy: 0.7581, Top5Accuracy: 0.8285, Time consumed:1.77s

Training Epoch: 156 [32/50000]	Loss: 1.8914	LR: 0.004744
Training Epoch: 156 [32/50000]	Loss: 1.5290	LR: 0.004744
Training Epoch: 156 [32/50000]	Loss: 1.5303	LR: 0.004744
Training Epoch: 156 [32/50000]	Loss: 1.6233	LR: 0.004744
Training Epoch: 156 [32/50000]	Loss: 1.7448	LR: 0.004744
Training Epoch: 156 [32/50000]	Loss: 1.4112	LR: 0.004744
Training Epoch: 156 [32/50000]	Loss: 1.5454	LR: 0.004744
Training Epoch: 156 [32/50000]	Loss: 1.9929	LR: 0.004744
Training Epoch: 156 [32/50000]	Loss: 1.5745	LR: 0.004744
Training Epoch: 156 [32/50000]	Loss: 1.5062	LR: 0.004744
Evaluating Network.....
Test set: Epoch: 156, Average loss: 0.0521, Top1Accuracy: 0.5439, Top3Accuracy: 0.7561, Top5Accuracy: 0.8285, Time consumed:1.76s

Training Epoch: 157 [32/50000]	Loss: 1.7562	LR: 0.004618
Training Epoch: 157 [32/50000]	Loss: 1.4178	LR: 0.004618
Training Epoch: 157 [32/50000]	Loss: 1.6030	LR: 0.004618
Training Epoch: 157 [32/50000]	Loss: 1.7696	LR: 0.004618
Training Epoch: 157 [32/50000]	Loss: 1.7763	LR: 0.004618
Training Epoch: 157 [32/50000]	Loss: 1.4425	LR: 0.004618
Training Epoch: 157 [32/50000]	Loss: 1.0201	LR: 0.004618
Training Epoch: 157 [32/50000]	Loss: 1.4723	LR: 0.004618
Training Epoch: 157 [32/50000]	Loss: 1.6978	LR: 0.004618
Training Epoch: 157 [32/50000]	Loss: 1.5100	LR: 0.004618
Evaluating Network.....
Test set: Epoch: 157, Average loss: 0.0516, Top1Accuracy: 0.5474, Top3Accuracy: 0.7591, Top5Accuracy: 0.8316, Time consumed:1.80s

Training Epoch: 158 [32/50000]	Loss: 1.4881	LR: 0.004496
Training Epoch: 158 [32/50000]	Loss: 1.0593	LR: 0.004496
Training Epoch: 158 [32/50000]	Loss: 1.9395	LR: 0.004496
Training Epoch: 158 [32/50000]	Loss: 1.2310	LR: 0.004496
Training Epoch: 158 [32/50000]	Loss: 1.5045	LR: 0.004496
Training Epoch: 158 [32/50000]	Loss: 2.1004	LR: 0.004496
Training Epoch: 158 [32/50000]	Loss: 2.1462	LR: 0.004496
Training Epoch: 158 [32/50000]	Loss: 1.4894	LR: 0.004496
Training Epoch: 158 [32/50000]	Loss: 1.4255	LR: 0.004496
Training Epoch: 158 [32/50000]	Loss: 1.4399	LR: 0.004496
Evaluating Network.....
Test set: Epoch: 158, Average loss: 0.0518, Top1Accuracy: 0.5467, Top3Accuracy: 0.7613, Top5Accuracy: 0.8302, Time consumed:1.81s

Training Epoch: 159 [32/50000]	Loss: 1.6974	LR: 0.004378
Training Epoch: 159 [32/50000]	Loss: 2.2083	LR: 0.004378
Training Epoch: 159 [32/50000]	Loss: 1.7879	LR: 0.004378
Training Epoch: 159 [32/50000]	Loss: 1.4533	LR: 0.004378
Training Epoch: 159 [32/50000]	Loss: 1.8055	LR: 0.004378
Training Epoch: 159 [32/50000]	Loss: 1.3152	LR: 0.004378
Training Epoch: 159 [32/50000]	Loss: 1.2950	LR: 0.004378
Training Epoch: 159 [32/50000]	Loss: 1.2703	LR: 0.004378
Training Epoch: 159 [32/50000]	Loss: 1.5893	LR: 0.004378
Training Epoch: 159 [32/50000]	Loss: 1.3916	LR: 0.004378
Evaluating Network.....
Test set: Epoch: 159, Average loss: 0.0515, Top1Accuracy: 0.5488, Top3Accuracy: 0.7605, Top5Accuracy: 0.8330, Time consumed:1.78s

Training Epoch: 160 [32/50000]	Loss: 1.3903	LR: 0.004262
Training Epoch: 160 [32/50000]	Loss: 1.5055	LR: 0.004262
Training Epoch: 160 [32/50000]	Loss: 2.1031	LR: 0.004262
Training Epoch: 160 [32/50000]	Loss: 1.2864	LR: 0.004262
Training Epoch: 160 [32/50000]	Loss: 1.6119	LR: 0.004262
Training Epoch: 160 [32/50000]	Loss: 1.3129	LR: 0.004262
Training Epoch: 160 [32/50000]	Loss: 1.2218	LR: 0.004262
Training Epoch: 160 [32/50000]	Loss: 1.4387	LR: 0.004262
Training Epoch: 160 [32/50000]	Loss: 1.5278	LR: 0.004262
Training Epoch: 160 [32/50000]	Loss: 1.2262	LR: 0.004262
Evaluating Network.....
Test set: Epoch: 160, Average loss: 0.0515, Top1Accuracy: 0.5481, Top3Accuracy: 0.7573, Top5Accuracy: 0.8314, Time consumed:1.81s

Training Epoch: 161 [32/50000]	Loss: 1.4041	LR: 0.004150
Training Epoch: 161 [32/50000]	Loss: 1.2919	LR: 0.004150
Training Epoch: 161 [32/50000]	Loss: 1.4369	LR: 0.004150
Training Epoch: 161 [32/50000]	Loss: 1.9290	LR: 0.004150
Training Epoch: 161 [32/50000]	Loss: 1.6629	LR: 0.004150
Training Epoch: 161 [32/50000]	Loss: 1.4943	LR: 0.004150
Training Epoch: 161 [32/50000]	Loss: 2.0986	LR: 0.004150
Training Epoch: 161 [32/50000]	Loss: 1.5770	LR: 0.004150
Training Epoch: 161 [32/50000]	Loss: 1.6288	LR: 0.004150
Training Epoch: 161 [32/50000]	Loss: 1.5960	LR: 0.004150
Evaluating Network.....
Test set: Epoch: 161, Average loss: 0.0515, Top1Accuracy: 0.5477, Top3Accuracy: 0.7566, Top5Accuracy: 0.8334, Time consumed:1.77s

Training Epoch: 162 [32/50000]	Loss: 1.4550	LR: 0.004040
Training Epoch: 162 [32/50000]	Loss: 1.6041	LR: 0.004040
Training Epoch: 162 [32/50000]	Loss: 1.7973	LR: 0.004040
Training Epoch: 162 [32/50000]	Loss: 1.5798	LR: 0.004040
Training Epoch: 162 [32/50000]	Loss: 1.5607	LR: 0.004040
Training Epoch: 162 [32/50000]	Loss: 1.6585	LR: 0.004040
Training Epoch: 162 [32/50000]	Loss: 1.5783	LR: 0.004040
Training Epoch: 162 [32/50000]	Loss: 1.9915	LR: 0.004040
Training Epoch: 162 [32/50000]	Loss: 1.5234	LR: 0.004040
Training Epoch: 162 [32/50000]	Loss: 1.3533	LR: 0.004040
Evaluating Network.....
Test set: Epoch: 162, Average loss: 0.0514, Top1Accuracy: 0.5495, Top3Accuracy: 0.7597, Top5Accuracy: 0.8322, Time consumed:1.75s

Training Epoch: 163 [32/50000]	Loss: 1.5235	LR: 0.003933
Training Epoch: 163 [32/50000]	Loss: 1.6636	LR: 0.003933
Training Epoch: 163 [32/50000]	Loss: 1.3647	LR: 0.003933
Training Epoch: 163 [32/50000]	Loss: 1.5442	LR: 0.003933
Training Epoch: 163 [32/50000]	Loss: 1.6955	LR: 0.003933
Training Epoch: 163 [32/50000]	Loss: 1.9999	LR: 0.003933
Training Epoch: 163 [32/50000]	Loss: 1.7310	LR: 0.003933
Training Epoch: 163 [32/50000]	Loss: 1.8393	LR: 0.003933
Training Epoch: 163 [32/50000]	Loss: 1.1461	LR: 0.003933
Training Epoch: 163 [32/50000]	Loss: 1.8254	LR: 0.003933
Evaluating Network.....
Test set: Epoch: 163, Average loss: 0.0509, Top1Accuracy: 0.5523, Top3Accuracy: 0.7639, Top5Accuracy: 0.8323, Time consumed:1.84s

Training Epoch: 164 [32/50000]	Loss: 1.7670	LR: 0.003830
Training Epoch: 164 [32/50000]	Loss: 1.1788	LR: 0.003830
Training Epoch: 164 [32/50000]	Loss: 1.1161	LR: 0.003830
Training Epoch: 164 [32/50000]	Loss: 1.1212	LR: 0.003830
Training Epoch: 164 [32/50000]	Loss: 1.5068	LR: 0.003830
Training Epoch: 164 [32/50000]	Loss: 0.9607	LR: 0.003830
Training Epoch: 164 [32/50000]	Loss: 1.4793	LR: 0.003830
Training Epoch: 164 [32/50000]	Loss: 1.5185	LR: 0.003830
Training Epoch: 164 [32/50000]	Loss: 2.0561	LR: 0.003830
Training Epoch: 164 [32/50000]	Loss: 1.5782	LR: 0.003830
Evaluating Network.....
Test set: Epoch: 164, Average loss: 0.0507, Top1Accuracy: 0.5498, Top3Accuracy: 0.7657, Top5Accuracy: 0.8355, Time consumed:1.79s

Training Epoch: 165 [32/50000]	Loss: 1.2809	LR: 0.003728
Training Epoch: 165 [32/50000]	Loss: 1.4521	LR: 0.003728
Training Epoch: 165 [32/50000]	Loss: 1.3775	LR: 0.003728
Training Epoch: 165 [32/50000]	Loss: 1.3236	LR: 0.003728
Training Epoch: 165 [32/50000]	Loss: 1.1224	LR: 0.003728
Training Epoch: 165 [32/50000]	Loss: 1.4178	LR: 0.003728
Training Epoch: 165 [32/50000]	Loss: 1.9187	LR: 0.003728
Training Epoch: 165 [32/50000]	Loss: 1.6078	LR: 0.003728
Training Epoch: 165 [32/50000]	Loss: 1.7178	LR: 0.003728
Training Epoch: 165 [32/50000]	Loss: 1.5992	LR: 0.003728
Evaluating Network.....
Test set: Epoch: 165, Average loss: 0.0504, Top1Accuracy: 0.5582, Top3Accuracy: 0.7653, Top5Accuracy: 0.8381, Time consumed:1.77s

Training Epoch: 166 [32/50000]	Loss: 1.4441	LR: 0.003630
Training Epoch: 166 [32/50000]	Loss: 1.4980	LR: 0.003630
Training Epoch: 166 [32/50000]	Loss: 1.3705	LR: 0.003630
Training Epoch: 166 [32/50000]	Loss: 1.2411	LR: 0.003630
Training Epoch: 166 [32/50000]	Loss: 1.5843	LR: 0.003630
Training Epoch: 166 [32/50000]	Loss: 1.1189	LR: 0.003630
Training Epoch: 166 [32/50000]	Loss: 1.7135	LR: 0.003630
Training Epoch: 166 [32/50000]	Loss: 1.0707	LR: 0.003630
Training Epoch: 166 [32/50000]	Loss: 1.6027	LR: 0.003630
Training Epoch: 166 [32/50000]	Loss: 1.2330	LR: 0.003630
Evaluating Network.....
Test set: Epoch: 166, Average loss: 0.0508, Top1Accuracy: 0.5546, Top3Accuracy: 0.7652, Top5Accuracy: 0.8372, Time consumed:1.93s

Training Epoch: 167 [32/50000]	Loss: 2.1211	LR: 0.003534
Training Epoch: 167 [32/50000]	Loss: 1.4935	LR: 0.003534
Training Epoch: 167 [32/50000]	Loss: 1.1215	LR: 0.003534
Training Epoch: 167 [32/50000]	Loss: 1.5729	LR: 0.003534
Training Epoch: 167 [32/50000]	Loss: 1.4511	LR: 0.003534
Training Epoch: 167 [32/50000]	Loss: 1.3917	LR: 0.003534
Training Epoch: 167 [32/50000]	Loss: 1.5303	LR: 0.003534
Training Epoch: 167 [32/50000]	Loss: 1.5735	LR: 0.003534
Training Epoch: 167 [32/50000]	Loss: 1.7345	LR: 0.003534
Training Epoch: 167 [32/50000]	Loss: 1.5799	LR: 0.003534
Evaluating Network.....
Test set: Epoch: 167, Average loss: 0.0504, Top1Accuracy: 0.5555, Top3Accuracy: 0.7678, Top5Accuracy: 0.8385, Time consumed:1.80s

Training Epoch: 168 [32/50000]	Loss: 1.3506	LR: 0.003441
Training Epoch: 168 [32/50000]	Loss: 1.7588	LR: 0.003441
Training Epoch: 168 [32/50000]	Loss: 1.3325	LR: 0.003441
Training Epoch: 168 [32/50000]	Loss: 1.3562	LR: 0.003441
Training Epoch: 168 [32/50000]	Loss: 1.1664	LR: 0.003441
Training Epoch: 168 [32/50000]	Loss: 1.3965	LR: 0.003441
Training Epoch: 168 [32/50000]	Loss: 1.8099	LR: 0.003441
Training Epoch: 168 [32/50000]	Loss: 1.1300	LR: 0.003441
Training Epoch: 168 [32/50000]	Loss: 1.3330	LR: 0.003441
Training Epoch: 168 [32/50000]	Loss: 1.2394	LR: 0.003441
Evaluating Network.....
Test set: Epoch: 168, Average loss: 0.0506, Top1Accuracy: 0.5583, Top3Accuracy: 0.7659, Top5Accuracy: 0.8372, Time consumed:1.75s

Training Epoch: 169 [32/50000]	Loss: 1.5360	LR: 0.003350
Training Epoch: 169 [32/50000]	Loss: 1.6210	LR: 0.003350
Training Epoch: 169 [32/50000]	Loss: 1.3009	LR: 0.003350
Training Epoch: 169 [32/50000]	Loss: 1.4510	LR: 0.003350
Training Epoch: 169 [32/50000]	Loss: 1.6610	LR: 0.003350
Training Epoch: 169 [32/50000]	Loss: 1.4577	LR: 0.003350
Training Epoch: 169 [32/50000]	Loss: 1.9386	LR: 0.003350
Training Epoch: 169 [32/50000]	Loss: 1.1549	LR: 0.003350
Training Epoch: 169 [32/50000]	Loss: 2.0898	LR: 0.003350
Training Epoch: 169 [32/50000]	Loss: 1.3045	LR: 0.003350
Evaluating Network.....
Test set: Epoch: 169, Average loss: 0.0507, Top1Accuracy: 0.5522, Top3Accuracy: 0.7667, Top5Accuracy: 0.8374, Time consumed:1.82s

Training Epoch: 170 [32/50000]	Loss: 1.4205	LR: 0.003262
Training Epoch: 170 [32/50000]	Loss: 1.6777	LR: 0.003262
Training Epoch: 170 [32/50000]	Loss: 1.6274	LR: 0.003262
Training Epoch: 170 [32/50000]	Loss: 1.2757	LR: 0.003262
Training Epoch: 170 [32/50000]	Loss: 1.6314	LR: 0.003262
Training Epoch: 170 [32/50000]	Loss: 1.7494	LR: 0.003262
Training Epoch: 170 [32/50000]	Loss: 1.4259	LR: 0.003262
Training Epoch: 170 [32/50000]	Loss: 1.2610	LR: 0.003262
Training Epoch: 170 [32/50000]	Loss: 1.1738	LR: 0.003262
Training Epoch: 170 [32/50000]	Loss: 2.0155	LR: 0.003262
Evaluating Network.....
Test set: Epoch: 170, Average loss: 0.0504, Top1Accuracy: 0.5543, Top3Accuracy: 0.7697, Top5Accuracy: 0.8416, Time consumed:1.72s

Training Epoch: 171 [32/50000]	Loss: 1.5307	LR: 0.003176
Training Epoch: 171 [32/50000]	Loss: 1.3678	LR: 0.003176
Training Epoch: 171 [32/50000]	Loss: 1.0269	LR: 0.003176
Training Epoch: 171 [32/50000]	Loss: 1.6755	LR: 0.003176
Training Epoch: 171 [32/50000]	Loss: 1.2868	LR: 0.003176
Training Epoch: 171 [32/50000]	Loss: 1.0770	LR: 0.003176
Training Epoch: 171 [32/50000]	Loss: 1.7645	LR: 0.003176
Training Epoch: 171 [32/50000]	Loss: 1.2577	LR: 0.003176
Training Epoch: 171 [32/50000]	Loss: 1.6655	LR: 0.003176
Training Epoch: 171 [32/50000]	Loss: 1.5234	LR: 0.003176
Evaluating Network.....
Test set: Epoch: 171, Average loss: 0.0503, Top1Accuracy: 0.5560, Top3Accuracy: 0.7675, Top5Accuracy: 0.8400, Time consumed:1.75s

Training Epoch: 172 [32/50000]	Loss: 2.4208	LR: 0.003092
Training Epoch: 172 [32/50000]	Loss: 1.0054	LR: 0.003092
Training Epoch: 172 [32/50000]	Loss: 1.1025	LR: 0.003092
Training Epoch: 172 [32/50000]	Loss: 1.3366	LR: 0.003092
Training Epoch: 172 [32/50000]	Loss: 1.8205	LR: 0.003092
Training Epoch: 172 [32/50000]	Loss: 1.2965	LR: 0.003092
Training Epoch: 172 [32/50000]	Loss: 1.2615	LR: 0.003092
Training Epoch: 172 [32/50000]	Loss: 1.3472	LR: 0.003092
Training Epoch: 172 [32/50000]	Loss: 1.5788	LR: 0.003092
Training Epoch: 172 [32/50000]	Loss: 1.8956	LR: 0.003092
Evaluating Network.....
Test set: Epoch: 172, Average loss: 0.0503, Top1Accuracy: 0.5566, Top3Accuracy: 0.7689, Top5Accuracy: 0.8409, Time consumed:1.79s

Training Epoch: 173 [32/50000]	Loss: 1.7600	LR: 0.003010
Training Epoch: 173 [32/50000]	Loss: 1.4120	LR: 0.003010
Training Epoch: 173 [32/50000]	Loss: 1.8166	LR: 0.003010
Training Epoch: 173 [32/50000]	Loss: 1.8670	LR: 0.003010
Training Epoch: 173 [32/50000]	Loss: 1.2676	LR: 0.003010
Training Epoch: 173 [32/50000]	Loss: 1.1901	LR: 0.003010
Training Epoch: 173 [32/50000]	Loss: 1.0744	LR: 0.003010
Training Epoch: 173 [32/50000]	Loss: 1.9329	LR: 0.003010
Training Epoch: 173 [32/50000]	Loss: 1.9589	LR: 0.003010
Training Epoch: 173 [32/50000]	Loss: 1.5650	LR: 0.003010
Evaluating Network.....
Test set: Epoch: 173, Average loss: 0.0500, Top1Accuracy: 0.5614, Top3Accuracy: 0.7709, Top5Accuracy: 0.8396, Time consumed:1.88s

Training Epoch: 174 [32/50000]	Loss: 1.3918	LR: 0.002931
Training Epoch: 174 [32/50000]	Loss: 1.3064	LR: 0.002931
Training Epoch: 174 [32/50000]	Loss: 1.6096	LR: 0.002931
Training Epoch: 174 [32/50000]	Loss: 1.3504	LR: 0.002931
Training Epoch: 174 [32/50000]	Loss: 1.5230	LR: 0.002931
Training Epoch: 174 [32/50000]	Loss: 1.3853	LR: 0.002931
Training Epoch: 174 [32/50000]	Loss: 1.8733	LR: 0.002931
Training Epoch: 174 [32/50000]	Loss: 1.7644	LR: 0.002931
Training Epoch: 174 [32/50000]	Loss: 1.2002	LR: 0.002931
Training Epoch: 174 [32/50000]	Loss: 1.0913	LR: 0.002931
Evaluating Network.....
Test set: Epoch: 174, Average loss: 0.0498, Top1Accuracy: 0.5621, Top3Accuracy: 0.7719, Top5Accuracy: 0.8420, Time consumed:1.76s

Training Epoch: 175 [32/50000]	Loss: 1.6470	LR: 0.002853
Training Epoch: 175 [32/50000]	Loss: 1.2980	LR: 0.002853
Training Epoch: 175 [32/50000]	Loss: 1.9604	LR: 0.002853
Training Epoch: 175 [32/50000]	Loss: 1.7145	LR: 0.002853
Training Epoch: 175 [32/50000]	Loss: 1.1000	LR: 0.002853
Training Epoch: 175 [32/50000]	Loss: 2.1323	LR: 0.002853
Training Epoch: 175 [32/50000]	Loss: 1.7649	LR: 0.002853
Training Epoch: 175 [32/50000]	Loss: 1.2999	LR: 0.002853
Training Epoch: 175 [32/50000]	Loss: 1.1774	LR: 0.002853
Training Epoch: 175 [32/50000]	Loss: 1.5052	LR: 0.002853
Evaluating Network.....
Test set: Epoch: 175, Average loss: 0.0497, Top1Accuracy: 0.5614, Top3Accuracy: 0.7712, Top5Accuracy: 0.8445, Time consumed:1.82s

Training Epoch: 176 [32/50000]	Loss: 1.6389	LR: 0.002778
Training Epoch: 176 [32/50000]	Loss: 1.1927	LR: 0.002778
Training Epoch: 176 [32/50000]	Loss: 1.1533	LR: 0.002778
Training Epoch: 176 [32/50000]	Loss: 0.9240	LR: 0.002778
Training Epoch: 176 [32/50000]	Loss: 1.1258	LR: 0.002778
Training Epoch: 176 [32/50000]	Loss: 1.6275	LR: 0.002778
Training Epoch: 176 [32/50000]	Loss: 1.7151	LR: 0.002778
Training Epoch: 176 [32/50000]	Loss: 1.9517	LR: 0.002778
Training Epoch: 176 [32/50000]	Loss: 1.7523	LR: 0.002778
Training Epoch: 176 [32/50000]	Loss: 1.9630	LR: 0.002778
Evaluating Network.....
Test set: Epoch: 176, Average loss: 0.0498, Top1Accuracy: 0.5616, Top3Accuracy: 0.7695, Top5Accuracy: 0.8418, Time consumed:1.78s

Training Epoch: 177 [32/50000]	Loss: 1.4116	LR: 0.002705
Training Epoch: 177 [32/50000]	Loss: 2.0028	LR: 0.002705
Training Epoch: 177 [32/50000]	Loss: 1.8109	LR: 0.002705
Training Epoch: 177 [32/50000]	Loss: 2.1240	LR: 0.002705
Training Epoch: 177 [32/50000]	Loss: 1.6251	LR: 0.002705
Training Epoch: 177 [32/50000]	Loss: 2.0767	LR: 0.002705
Training Epoch: 177 [32/50000]	Loss: 1.4500	LR: 0.002705
Training Epoch: 177 [32/50000]	Loss: 1.7137	LR: 0.002705
Training Epoch: 177 [32/50000]	Loss: 1.2624	LR: 0.002705
Training Epoch: 177 [32/50000]	Loss: 1.2670	LR: 0.002705
Evaluating Network.....
Test set: Epoch: 177, Average loss: 0.0499, Top1Accuracy: 0.5579, Top3Accuracy: 0.7666, Top5Accuracy: 0.8403, Time consumed:1.76s

Training Epoch: 178 [32/50000]	Loss: 1.3905	LR: 0.002633
Training Epoch: 178 [32/50000]	Loss: 1.3216	LR: 0.002633
Training Epoch: 178 [32/50000]	Loss: 1.6158	LR: 0.002633
Training Epoch: 178 [32/50000]	Loss: 1.4521	LR: 0.002633
Training Epoch: 178 [32/50000]	Loss: 2.1422	LR: 0.002633
Training Epoch: 178 [32/50000]	Loss: 1.0177	LR: 0.002633
Training Epoch: 178 [32/50000]	Loss: 1.7545	LR: 0.002633
Training Epoch: 178 [32/50000]	Loss: 1.8327	LR: 0.002633
Training Epoch: 178 [32/50000]	Loss: 1.1948	LR: 0.002633
Training Epoch: 178 [32/50000]	Loss: 1.1938	LR: 0.002633
Evaluating Network.....
Test set: Epoch: 178, Average loss: 0.0496, Top1Accuracy: 0.5613, Top3Accuracy: 0.7732, Top5Accuracy: 0.8446, Time consumed:1.78s

Training Epoch: 179 [32/50000]	Loss: 1.4406	LR: 0.002564
Training Epoch: 179 [32/50000]	Loss: 1.7097	LR: 0.002564
Training Epoch: 179 [32/50000]	Loss: 1.7996	LR: 0.002564
Training Epoch: 179 [32/50000]	Loss: 1.4204	LR: 0.002564
Training Epoch: 179 [32/50000]	Loss: 1.3735	LR: 0.002564
Training Epoch: 179 [32/50000]	Loss: 1.7428	LR: 0.002564
Training Epoch: 179 [32/50000]	Loss: 1.3378	LR: 0.002564
Training Epoch: 179 [32/50000]	Loss: 1.3800	LR: 0.002564
Training Epoch: 179 [32/50000]	Loss: 1.3070	LR: 0.002564
Training Epoch: 179 [32/50000]	Loss: 1.7479	LR: 0.002564
Evaluating Network.....
Test set: Epoch: 179, Average loss: 0.0495, Top1Accuracy: 0.5638, Top3Accuracy: 0.7744, Top5Accuracy: 0.8432, Time consumed:1.82s

Training Epoch: 180 [32/50000]	Loss: 2.3804	LR: 0.002496
Training Epoch: 180 [32/50000]	Loss: 1.4558	LR: 0.002496
Training Epoch: 180 [32/50000]	Loss: 1.8072	LR: 0.002496
Training Epoch: 180 [32/50000]	Loss: 1.1336	LR: 0.002496
Training Epoch: 180 [32/50000]	Loss: 1.2844	LR: 0.002496
Training Epoch: 180 [32/50000]	Loss: 1.3765	LR: 0.002496
Training Epoch: 180 [32/50000]	Loss: 1.3280	LR: 0.002496
Training Epoch: 180 [32/50000]	Loss: 1.4427	LR: 0.002496
Training Epoch: 180 [32/50000]	Loss: 1.9859	LR: 0.002496
Training Epoch: 180 [32/50000]	Loss: 1.6602	LR: 0.002496
Evaluating Network.....
Test set: Epoch: 180, Average loss: 0.0497, Top1Accuracy: 0.5623, Top3Accuracy: 0.7719, Top5Accuracy: 0.8419, Time consumed:1.79s

Training Epoch: 181 [32/50000]	Loss: 1.4017	LR: 0.002430
Training Epoch: 181 [32/50000]	Loss: 1.2747	LR: 0.002430
Training Epoch: 181 [32/50000]	Loss: 1.4157	LR: 0.002430
Training Epoch: 181 [32/50000]	Loss: 1.3184	LR: 0.002430
Training Epoch: 181 [32/50000]	Loss: 1.2930	LR: 0.002430
Training Epoch: 181 [32/50000]	Loss: 1.2984	LR: 0.002430
Training Epoch: 181 [32/50000]	Loss: 1.5854	LR: 0.002430
Training Epoch: 181 [32/50000]	Loss: 1.6233	LR: 0.002430
Training Epoch: 181 [32/50000]	Loss: 1.4379	LR: 0.002430
Training Epoch: 181 [32/50000]	Loss: 2.2591	LR: 0.002430
Evaluating Network.....
Test set: Epoch: 181, Average loss: 0.0494, Top1Accuracy: 0.5653, Top3Accuracy: 0.7747, Top5Accuracy: 0.8430, Time consumed:1.86s

Training Epoch: 182 [32/50000]	Loss: 1.3274	LR: 0.002366
Training Epoch: 182 [32/50000]	Loss: 1.1575	LR: 0.002366
Training Epoch: 182 [32/50000]	Loss: 0.9735	LR: 0.002366
Training Epoch: 182 [32/50000]	Loss: 1.3744	LR: 0.002366
Training Epoch: 182 [32/50000]	Loss: 1.4350	LR: 0.002366
Training Epoch: 182 [32/50000]	Loss: 1.1671	LR: 0.002366
Training Epoch: 182 [32/50000]	Loss: 1.3854	LR: 0.002366
Training Epoch: 182 [32/50000]	Loss: 1.1206	LR: 0.002366
Training Epoch: 182 [32/50000]	Loss: 1.5291	LR: 0.002366
Training Epoch: 182 [32/50000]	Loss: 1.8769	LR: 0.002366
Evaluating Network.....
Test set: Epoch: 182, Average loss: 0.0494, Top1Accuracy: 0.5661, Top3Accuracy: 0.7711, Top5Accuracy: 0.8438, Time consumed:1.78s

Training Epoch: 183 [32/50000]	Loss: 1.4483	LR: 0.002303
Training Epoch: 183 [32/50000]	Loss: 1.4770	LR: 0.002303
Training Epoch: 183 [32/50000]	Loss: 1.5886	LR: 0.002303
Training Epoch: 183 [32/50000]	Loss: 1.1712	LR: 0.002303
Training Epoch: 183 [32/50000]	Loss: 1.5787	LR: 0.002303
Training Epoch: 183 [32/50000]	Loss: 1.2334	LR: 0.002303
Training Epoch: 183 [32/50000]	Loss: 1.5179	LR: 0.002303
Training Epoch: 183 [32/50000]	Loss: 1.5677	LR: 0.002303
Training Epoch: 183 [32/50000]	Loss: 2.1160	LR: 0.002303
Training Epoch: 183 [32/50000]	Loss: 1.4263	LR: 0.002303
Evaluating Network.....
Test set: Epoch: 183, Average loss: 0.0493, Top1Accuracy: 0.5657, Top3Accuracy: 0.7755, Top5Accuracy: 0.8461, Time consumed:1.94s

Training Epoch: 184 [32/50000]	Loss: 1.7215	LR: 0.002243
Training Epoch: 184 [32/50000]	Loss: 1.7639	LR: 0.002243
Training Epoch: 184 [32/50000]	Loss: 1.4314	LR: 0.002243
Training Epoch: 184 [32/50000]	Loss: 1.4696	LR: 0.002243
Training Epoch: 184 [32/50000]	Loss: 1.0667	LR: 0.002243
Training Epoch: 184 [32/50000]	Loss: 1.5997	LR: 0.002243
Training Epoch: 184 [32/50000]	Loss: 1.7207	LR: 0.002243
Training Epoch: 184 [32/50000]	Loss: 1.3778	LR: 0.002243
Training Epoch: 184 [32/50000]	Loss: 1.3383	LR: 0.002243
Training Epoch: 184 [32/50000]	Loss: 1.3333	LR: 0.002243
Evaluating Network.....
Test set: Epoch: 184, Average loss: 0.0490, Top1Accuracy: 0.5680, Top3Accuracy: 0.7749, Top5Accuracy: 0.8461, Time consumed:1.78s

Training Epoch: 185 [32/50000]	Loss: 1.6206	LR: 0.002183
Training Epoch: 185 [32/50000]	Loss: 1.1070	LR: 0.002183
Training Epoch: 185 [32/50000]	Loss: 1.3311	LR: 0.002183
Training Epoch: 185 [32/50000]	Loss: 1.2582	LR: 0.002183
Training Epoch: 185 [32/50000]	Loss: 1.6945	LR: 0.002183
Training Epoch: 185 [32/50000]	Loss: 1.3488	LR: 0.002183
Training Epoch: 185 [32/50000]	Loss: 1.5115	LR: 0.002183
Training Epoch: 185 [32/50000]	Loss: 1.9529	LR: 0.002183
Training Epoch: 185 [32/50000]	Loss: 1.6213	LR: 0.002183
Training Epoch: 185 [32/50000]	Loss: 1.7793	LR: 0.002183
Evaluating Network.....
Test set: Epoch: 185, Average loss: 0.0492, Top1Accuracy: 0.5665, Top3Accuracy: 0.7735, Top5Accuracy: 0.8476, Time consumed:1.74s

Training Epoch: 186 [32/50000]	Loss: 1.3759	LR: 0.002126
Training Epoch: 186 [32/50000]	Loss: 1.4158	LR: 0.002126
Training Epoch: 186 [32/50000]	Loss: 1.5301	LR: 0.002126
Training Epoch: 186 [32/50000]	Loss: 1.5178	LR: 0.002126
Training Epoch: 186 [32/50000]	Loss: 1.4192	LR: 0.002126
Training Epoch: 186 [32/50000]	Loss: 1.1191	LR: 0.002126
Training Epoch: 186 [32/50000]	Loss: 2.1598	LR: 0.002126
Training Epoch: 186 [32/50000]	Loss: 1.0296	LR: 0.002126
Training Epoch: 186 [32/50000]	Loss: 1.2357	LR: 0.002126
Training Epoch: 186 [32/50000]	Loss: 1.8990	LR: 0.002126
Evaluating Network.....
Test set: Epoch: 186, Average loss: 0.0492, Top1Accuracy: 0.5669, Top3Accuracy: 0.7748, Top5Accuracy: 0.8444, Time consumed:1.80s

Training Epoch: 187 [32/50000]	Loss: 1.4677	LR: 0.002070
Training Epoch: 187 [32/50000]	Loss: 1.3988	LR: 0.002070
Training Epoch: 187 [32/50000]	Loss: 1.4009	LR: 0.002070
Training Epoch: 187 [32/50000]	Loss: 1.6037	LR: 0.002070
Training Epoch: 187 [32/50000]	Loss: 1.7323	LR: 0.002070
Training Epoch: 187 [32/50000]	Loss: 1.3648	LR: 0.002070
Training Epoch: 187 [32/50000]	Loss: 1.6097	LR: 0.002070
Training Epoch: 187 [32/50000]	Loss: 1.2346	LR: 0.002070
Training Epoch: 187 [32/50000]	Loss: 1.0240	LR: 0.002070
Training Epoch: 187 [32/50000]	Loss: 1.3040	LR: 0.002070
Evaluating Network.....
Test set: Epoch: 187, Average loss: 0.0489, Top1Accuracy: 0.5667, Top3Accuracy: 0.7755, Top5Accuracy: 0.8475, Time consumed:1.92s

Training Epoch: 188 [32/50000]	Loss: 1.4739	LR: 0.002015
Training Epoch: 188 [32/50000]	Loss: 1.2920	LR: 0.002015
Training Epoch: 188 [32/50000]	Loss: 1.6862	LR: 0.002015
Training Epoch: 188 [32/50000]	Loss: 1.9377	LR: 0.002015
Training Epoch: 188 [32/50000]	Loss: 1.1918	LR: 0.002015
Training Epoch: 188 [32/50000]	Loss: 1.3181	LR: 0.002015
Training Epoch: 188 [32/50000]	Loss: 1.9934	LR: 0.002015
Training Epoch: 188 [32/50000]	Loss: 1.1192	LR: 0.002015
Training Epoch: 188 [32/50000]	Loss: 1.6089	LR: 0.002015
Training Epoch: 188 [32/50000]	Loss: 1.8839	LR: 0.002015
Evaluating Network.....
Test set: Epoch: 188, Average loss: 0.0488, Top1Accuracy: 0.5703, Top3Accuracy: 0.7801, Top5Accuracy: 0.8483, Time consumed:1.82s

Training Epoch: 189 [32/50000]	Loss: 1.5617	LR: 0.001962
Training Epoch: 189 [32/50000]	Loss: 1.4383	LR: 0.001962
Training Epoch: 189 [32/50000]	Loss: 1.3083	LR: 0.001962
Training Epoch: 189 [32/50000]	Loss: 1.6802	LR: 0.001962
Training Epoch: 189 [32/50000]	Loss: 1.6110	LR: 0.001962
Training Epoch: 189 [32/50000]	Loss: 2.1301	LR: 0.001962
Training Epoch: 189 [32/50000]	Loss: 1.4783	LR: 0.001962
Training Epoch: 189 [32/50000]	Loss: 1.2385	LR: 0.001962
Training Epoch: 189 [32/50000]	Loss: 1.2940	LR: 0.001962
Training Epoch: 189 [32/50000]	Loss: 1.2753	LR: 0.001962
Evaluating Network.....
Test set: Epoch: 189, Average loss: 0.0490, Top1Accuracy: 0.5678, Top3Accuracy: 0.7743, Top5Accuracy: 0.8462, Time consumed:1.83s

Training Epoch: 190 [32/50000]	Loss: 1.1858	LR: 0.001910
Training Epoch: 190 [32/50000]	Loss: 1.3837	LR: 0.001910
Training Epoch: 190 [32/50000]	Loss: 1.4411	LR: 0.001910
Training Epoch: 190 [32/50000]	Loss: 1.6361	LR: 0.001910
Training Epoch: 190 [32/50000]	Loss: 1.4846	LR: 0.001910
Training Epoch: 190 [32/50000]	Loss: 1.4448	LR: 0.001910
Training Epoch: 190 [32/50000]	Loss: 1.2343	LR: 0.001910
Training Epoch: 190 [32/50000]	Loss: 1.4097	LR: 0.001910
Training Epoch: 190 [32/50000]	Loss: 1.7646	LR: 0.001910
Training Epoch: 190 [32/50000]	Loss: 1.2798	LR: 0.001910
Evaluating Network.....
Test set: Epoch: 190, Average loss: 0.0488, Top1Accuracy: 0.5714, Top3Accuracy: 0.7771, Top5Accuracy: 0.8469, Time consumed:1.79s

Training Epoch: 191 [32/50000]	Loss: 1.9596	LR: 0.001860
Training Epoch: 191 [32/50000]	Loss: 1.1372	LR: 0.001860
Training Epoch: 191 [32/50000]	Loss: 1.7276	LR: 0.001860
Training Epoch: 191 [32/50000]	Loss: 1.3414	LR: 0.001860
Training Epoch: 191 [32/50000]	Loss: 1.5453	LR: 0.001860
Training Epoch: 191 [32/50000]	Loss: 1.5422	LR: 0.001860
Training Epoch: 191 [32/50000]	Loss: 0.8370	LR: 0.001860
Training Epoch: 191 [32/50000]	Loss: 1.7419	LR: 0.001860
Training Epoch: 191 [32/50000]	Loss: 1.1300	LR: 0.001860
Training Epoch: 191 [32/50000]	Loss: 1.4333	LR: 0.001860
Evaluating Network.....
Test set: Epoch: 191, Average loss: 0.0488, Top1Accuracy: 0.5679, Top3Accuracy: 0.7756, Top5Accuracy: 0.8475, Time consumed:1.81s

Training Epoch: 192 [32/50000]	Loss: 1.5817	LR: 0.001811
Training Epoch: 192 [32/50000]	Loss: 1.4077	LR: 0.001811
Training Epoch: 192 [32/50000]	Loss: 1.2895	LR: 0.001811
Training Epoch: 192 [32/50000]	Loss: 1.5002	LR: 0.001811
Training Epoch: 192 [32/50000]	Loss: 1.2587	LR: 0.001811
Training Epoch: 192 [32/50000]	Loss: 1.1035	LR: 0.001811
Training Epoch: 192 [32/50000]	Loss: 1.2371	LR: 0.001811
Training Epoch: 192 [32/50000]	Loss: 1.2826	LR: 0.001811
Training Epoch: 192 [32/50000]	Loss: 1.3157	LR: 0.001811
Training Epoch: 192 [32/50000]	Loss: 1.4179	LR: 0.001811
Evaluating Network.....
Test set: Epoch: 192, Average loss: 0.0488, Top1Accuracy: 0.5698, Top3Accuracy: 0.7771, Top5Accuracy: 0.8483, Time consumed:1.79s

Training Epoch: 193 [32/50000]	Loss: 1.1297	LR: 0.001763
Training Epoch: 193 [32/50000]	Loss: 1.8963	LR: 0.001763
Training Epoch: 193 [32/50000]	Loss: 1.7117	LR: 0.001763
Training Epoch: 193 [32/50000]	Loss: 1.4015	LR: 0.001763
Training Epoch: 193 [32/50000]	Loss: 0.7858	LR: 0.001763
Training Epoch: 193 [32/50000]	Loss: 1.3098	LR: 0.001763
Training Epoch: 193 [32/50000]	Loss: 1.1154	LR: 0.001763
Training Epoch: 193 [32/50000]	Loss: 1.3829	LR: 0.001763
Training Epoch: 193 [32/50000]	Loss: 1.4295	LR: 0.001763
Training Epoch: 193 [32/50000]	Loss: 1.7968	LR: 0.001763
Evaluating Network.....
Test set: Epoch: 193, Average loss: 0.0486, Top1Accuracy: 0.5711, Top3Accuracy: 0.7789, Top5Accuracy: 0.8486, Time consumed:1.76s

Training Epoch: 194 [32/50000]	Loss: 1.2617	LR: 0.001716
Training Epoch: 194 [32/50000]	Loss: 1.5632	LR: 0.001716
Training Epoch: 194 [32/50000]	Loss: 1.3073	LR: 0.001716
Training Epoch: 194 [32/50000]	Loss: 1.2858	LR: 0.001716
Training Epoch: 194 [32/50000]	Loss: 1.3474	LR: 0.001716
Training Epoch: 194 [32/50000]	Loss: 1.2857	LR: 0.001716
Training Epoch: 194 [32/50000]	Loss: 1.0763	LR: 0.001716
Training Epoch: 194 [32/50000]	Loss: 1.3256	LR: 0.001716
Training Epoch: 194 [32/50000]	Loss: 1.3382	LR: 0.001716
Training Epoch: 194 [32/50000]	Loss: 1.7842	LR: 0.001716
Evaluating Network.....
Test set: Epoch: 194, Average loss: 0.0485, Top1Accuracy: 0.5718, Top3Accuracy: 0.7777, Top5Accuracy: 0.8504, Time consumed:1.79s

Training Epoch: 195 [32/50000]	Loss: 1.1869	LR: 0.001671
Training Epoch: 195 [32/50000]	Loss: 1.5655	LR: 0.001671
Training Epoch: 195 [32/50000]	Loss: 1.5827	LR: 0.001671
Training Epoch: 195 [32/50000]	Loss: 1.4053	LR: 0.001671
Training Epoch: 195 [32/50000]	Loss: 1.3990	LR: 0.001671
Training Epoch: 195 [32/50000]	Loss: 1.6083	LR: 0.001671
Training Epoch: 195 [32/50000]	Loss: 1.6974	LR: 0.001671
Training Epoch: 195 [32/50000]	Loss: 1.2668	LR: 0.001671
Training Epoch: 195 [32/50000]	Loss: 1.4555	LR: 0.001671
Training Epoch: 195 [32/50000]	Loss: 1.6039	LR: 0.001671
Evaluating Network.....
Test set: Epoch: 195, Average loss: 0.0486, Top1Accuracy: 0.5726, Top3Accuracy: 0.7760, Top5Accuracy: 0.8488, Time consumed:1.77s

Training Epoch: 196 [32/50000]	Loss: 1.3217	LR: 0.001627
Training Epoch: 196 [32/50000]	Loss: 1.3420	LR: 0.001627
Training Epoch: 196 [32/50000]	Loss: 1.5229	LR: 0.001627
Training Epoch: 196 [32/50000]	Loss: 1.3355	LR: 0.001627
Training Epoch: 196 [32/50000]	Loss: 1.3700	LR: 0.001627
Training Epoch: 196 [32/50000]	Loss: 1.0347	LR: 0.001627
Training Epoch: 196 [32/50000]	Loss: 1.0380	LR: 0.001627
Training Epoch: 196 [32/50000]	Loss: 1.4078	LR: 0.001627
Training Epoch: 196 [32/50000]	Loss: 1.3585	LR: 0.001627
Training Epoch: 196 [32/50000]	Loss: 0.9624	LR: 0.001627
Evaluating Network.....
Test set: Epoch: 196, Average loss: 0.0485, Top1Accuracy: 0.5704, Top3Accuracy: 0.7766, Top5Accuracy: 0.8493, Time consumed:1.80s

Training Epoch: 197 [32/50000]	Loss: 1.0438	LR: 0.001584
Training Epoch: 197 [32/50000]	Loss: 1.3909	LR: 0.001584
Training Epoch: 197 [32/50000]	Loss: 1.2463	LR: 0.001584
Training Epoch: 197 [32/50000]	Loss: 1.4907	LR: 0.001584
Training Epoch: 197 [32/50000]	Loss: 2.0287	LR: 0.001584
Training Epoch: 197 [32/50000]	Loss: 1.1881	LR: 0.001584
Training Epoch: 197 [32/50000]	Loss: 1.4084	LR: 0.001584
Training Epoch: 197 [32/50000]	Loss: 1.6205	LR: 0.001584
Training Epoch: 197 [32/50000]	Loss: 1.2482	LR: 0.001584
Training Epoch: 197 [32/50000]	Loss: 1.6528	LR: 0.001584
Evaluating Network.....
Test set: Epoch: 197, Average loss: 0.0482, Top1Accuracy: 0.5731, Top3Accuracy: 0.7819, Top5Accuracy: 0.8513, Time consumed:1.75s

Training Epoch: 198 [32/50000]	Loss: 0.9742	LR: 0.001542
Training Epoch: 198 [32/50000]	Loss: 1.2641	LR: 0.001542
Training Epoch: 198 [32/50000]	Loss: 1.5040	LR: 0.001542
Training Epoch: 198 [32/50000]	Loss: 1.4977	LR: 0.001542
Training Epoch: 198 [32/50000]	Loss: 1.4727	LR: 0.001542
Training Epoch: 198 [32/50000]	Loss: 1.3456	LR: 0.001542
Training Epoch: 198 [32/50000]	Loss: 1.3915	LR: 0.001542
Training Epoch: 198 [32/50000]	Loss: 1.4508	LR: 0.001542
Training Epoch: 198 [32/50000]	Loss: 1.5434	LR: 0.001542
Training Epoch: 198 [32/50000]	Loss: 1.5603	LR: 0.001542
Evaluating Network.....
Test set: Epoch: 198, Average loss: 0.0484, Top1Accuracy: 0.5743, Top3Accuracy: 0.7771, Top5Accuracy: 0.8487, Time consumed:1.74s

Training Epoch: 199 [32/50000]	Loss: 1.6080	LR: 0.001501
Training Epoch: 199 [32/50000]	Loss: 1.2351	LR: 0.001501
Training Epoch: 199 [32/50000]	Loss: 2.0601	LR: 0.001501
Training Epoch: 199 [32/50000]	Loss: 1.7271	LR: 0.001501
Training Epoch: 199 [32/50000]	Loss: 1.5234	LR: 0.001501
Training Epoch: 199 [32/50000]	Loss: 1.3985	LR: 0.001501
Training Epoch: 199 [32/50000]	Loss: 1.3923	LR: 0.001501
Training Epoch: 199 [32/50000]	Loss: 1.2904	LR: 0.001501
Training Epoch: 199 [32/50000]	Loss: 1.8419	LR: 0.001501
Training Epoch: 199 [32/50000]	Loss: 1.2709	LR: 0.001501
Evaluating Network.....
Test set: Epoch: 199, Average loss: 0.0485, Top1Accuracy: 0.5743, Top3Accuracy: 0.7771, Top5Accuracy: 0.8491, Time consumed:1.76s

Training Epoch: 200 [32/50000]	Loss: 0.9482	LR: 0.001462
Training Epoch: 200 [32/50000]	Loss: 1.7190	LR: 0.001462
Training Epoch: 200 [32/50000]	Loss: 1.4421	LR: 0.001462
Training Epoch: 200 [32/50000]	Loss: 1.2330	LR: 0.001462
Training Epoch: 200 [32/50000]	Loss: 1.2504	LR: 0.001462
Training Epoch: 200 [32/50000]	Loss: 1.1126	LR: 0.001462
Training Epoch: 200 [32/50000]	Loss: 1.1956	LR: 0.001462
Training Epoch: 200 [32/50000]	Loss: 1.2294	LR: 0.001462
Training Epoch: 200 [32/50000]	Loss: 2.2768	LR: 0.001462
Training Epoch: 200 [32/50000]	Loss: 1.6928	LR: 0.001462
Evaluating Network.....
Test set: Epoch: 200, Average loss: 0.0482, Top1Accuracy: 0.5740, Top3Accuracy: 0.7774, Top5Accuracy: 0.8514, Time consumed:1.80s

Training Epoch: 201 [32/50000]	Loss: 1.7908	LR: 0.001423
Training Epoch: 201 [32/50000]	Loss: 1.6940	LR: 0.001423
Training Epoch: 201 [32/50000]	Loss: 1.3286	LR: 0.001423
Training Epoch: 201 [32/50000]	Loss: 1.5510	LR: 0.001423
Training Epoch: 201 [32/50000]	Loss: 1.7824	LR: 0.001423
Training Epoch: 201 [32/50000]	Loss: 1.1994	LR: 0.001423
Training Epoch: 201 [32/50000]	Loss: 1.5229	LR: 0.001423
Training Epoch: 201 [32/50000]	Loss: 1.1766	LR: 0.001423
Training Epoch: 201 [32/50000]	Loss: 1.2545	LR: 0.001423
Training Epoch: 201 [32/50000]	Loss: 1.9139	LR: 0.001423
Evaluating Network.....
Test set: Epoch: 201, Average loss: 0.0484, Top1Accuracy: 0.5746, Top3Accuracy: 0.7763, Top5Accuracy: 0.8497, Time consumed:1.82s

Training Epoch: 202 [32/50000]	Loss: 1.7014	LR: 0.001386
Training Epoch: 202 [32/50000]	Loss: 1.6538	LR: 0.001386
Training Epoch: 202 [32/50000]	Loss: 1.4307	LR: 0.001386
Training Epoch: 202 [32/50000]	Loss: 1.2416	LR: 0.001386
Training Epoch: 202 [32/50000]	Loss: 1.5045	LR: 0.001386
Training Epoch: 202 [32/50000]	Loss: 1.1946	LR: 0.001386
Training Epoch: 202 [32/50000]	Loss: 1.3324	LR: 0.001386
Training Epoch: 202 [32/50000]	Loss: 1.1549	LR: 0.001386
Training Epoch: 202 [32/50000]	Loss: 1.6032	LR: 0.001386
Training Epoch: 202 [32/50000]	Loss: 1.0699	LR: 0.001386
Evaluating Network.....
Test set: Epoch: 202, Average loss: 0.0480, Top1Accuracy: 0.5779, Top3Accuracy: 0.7790, Top5Accuracy: 0.8523, Time consumed:1.78s

Training Epoch: 203 [32/50000]	Loss: 0.9855	LR: 0.001349
Training Epoch: 203 [32/50000]	Loss: 1.4068	LR: 0.001349
Training Epoch: 203 [32/50000]	Loss: 1.3694	LR: 0.001349
Training Epoch: 203 [32/50000]	Loss: 1.2113	LR: 0.001349
Training Epoch: 203 [32/50000]	Loss: 1.6444	LR: 0.001349
Training Epoch: 203 [32/50000]	Loss: 1.1502	LR: 0.001349
Training Epoch: 203 [32/50000]	Loss: 1.3095	LR: 0.001349
Training Epoch: 203 [32/50000]	Loss: 1.2705	LR: 0.001349
Training Epoch: 203 [32/50000]	Loss: 1.7629	LR: 0.001349
Training Epoch: 203 [32/50000]	Loss: 1.3850	LR: 0.001349
Evaluating Network.....
Test set: Epoch: 203, Average loss: 0.0482, Top1Accuracy: 0.5755, Top3Accuracy: 0.7799, Top5Accuracy: 0.8506, Time consumed:1.71s

Training Epoch: 204 [32/50000]	Loss: 1.2304	LR: 0.001313
Training Epoch: 204 [32/50000]	Loss: 1.4768	LR: 0.001313
Training Epoch: 204 [32/50000]	Loss: 1.4653	LR: 0.001313
Training Epoch: 204 [32/50000]	Loss: 1.0069	LR: 0.001313
Training Epoch: 204 [32/50000]	Loss: 1.7706	LR: 0.001313
Training Epoch: 204 [32/50000]	Loss: 1.0307	LR: 0.001313
Training Epoch: 204 [32/50000]	Loss: 1.3589	LR: 0.001313
Training Epoch: 204 [32/50000]	Loss: 1.3233	LR: 0.001313
Training Epoch: 204 [32/50000]	Loss: 2.2041	LR: 0.001313
Training Epoch: 204 [32/50000]	Loss: 1.8232	LR: 0.001313
Evaluating Network.....
Test set: Epoch: 204, Average loss: 0.0479, Top1Accuracy: 0.5768, Top3Accuracy: 0.7806, Top5Accuracy: 0.8525, Time consumed:1.80s

Training Epoch: 205 [32/50000]	Loss: 0.9640	LR: 0.001279
Training Epoch: 205 [32/50000]	Loss: 1.6959	LR: 0.001279
Training Epoch: 205 [32/50000]	Loss: 1.3614	LR: 0.001279
Training Epoch: 205 [32/50000]	Loss: 1.8550	LR: 0.001279
Training Epoch: 205 [32/50000]	Loss: 1.0035	LR: 0.001279
Training Epoch: 205 [32/50000]	Loss: 1.9787	LR: 0.001279
Training Epoch: 205 [32/50000]	Loss: 1.3125	LR: 0.001279
Training Epoch: 205 [32/50000]	Loss: 1.0871	LR: 0.001279
Training Epoch: 205 [32/50000]	Loss: 1.4008	LR: 0.001279
Training Epoch: 205 [32/50000]	Loss: 1.0049	LR: 0.001279
Evaluating Network.....
Test set: Epoch: 205, Average loss: 0.0479, Top1Accuracy: 0.5797, Top3Accuracy: 0.7814, Top5Accuracy: 0.8539, Time consumed:1.80s

Training Epoch: 206 [32/50000]	Loss: 1.9680	LR: 0.001245
Training Epoch: 206 [32/50000]	Loss: 1.9224	LR: 0.001245
Training Epoch: 206 [32/50000]	Loss: 1.0637	LR: 0.001245
Training Epoch: 206 [32/50000]	Loss: 1.4858	LR: 0.001245
Training Epoch: 206 [32/50000]	Loss: 1.5991	LR: 0.001245
Training Epoch: 206 [32/50000]	Loss: 1.4768	LR: 0.001245
Training Epoch: 206 [32/50000]	Loss: 1.2549	LR: 0.001245
Training Epoch: 206 [32/50000]	Loss: 1.3000	LR: 0.001245
Training Epoch: 206 [32/50000]	Loss: 1.3626	LR: 0.001245
Training Epoch: 206 [32/50000]	Loss: 1.1830	LR: 0.001245
Evaluating Network.....
Test set: Epoch: 206, Average loss: 0.0479, Top1Accuracy: 0.5758, Top3Accuracy: 0.7797, Top5Accuracy: 0.8516, Time consumed:1.77s

Training Epoch: 207 [32/50000]	Loss: 1.5882	LR: 0.001212
Training Epoch: 207 [32/50000]	Loss: 1.4245	LR: 0.001212
Training Epoch: 207 [32/50000]	Loss: 1.6836	LR: 0.001212
Training Epoch: 207 [32/50000]	Loss: 1.2112	LR: 0.001212
Training Epoch: 207 [32/50000]	Loss: 1.2315	LR: 0.001212
Training Epoch: 207 [32/50000]	Loss: 1.3360	LR: 0.001212
Training Epoch: 207 [32/50000]	Loss: 1.2047	LR: 0.001212
Training Epoch: 207 [32/50000]	Loss: 1.3068	LR: 0.001212
Training Epoch: 207 [32/50000]	Loss: 1.3867	LR: 0.001212
Training Epoch: 207 [32/50000]	Loss: 1.2625	LR: 0.001212
Evaluating Network.....
Test set: Epoch: 207, Average loss: 0.0480, Top1Accuracy: 0.5749, Top3Accuracy: 0.7807, Top5Accuracy: 0.8531, Time consumed:1.77s

Training Epoch: 208 [32/50000]	Loss: 1.1154	LR: 0.001180
Training Epoch: 208 [32/50000]	Loss: 1.2379	LR: 0.001180
Training Epoch: 208 [32/50000]	Loss: 1.6852	LR: 0.001180
Training Epoch: 208 [32/50000]	Loss: 1.2463	LR: 0.001180
Training Epoch: 208 [32/50000]	Loss: 0.9272	LR: 0.001180
Training Epoch: 208 [32/50000]	Loss: 1.5320	LR: 0.001180
Training Epoch: 208 [32/50000]	Loss: 1.7568	LR: 0.001180
Training Epoch: 208 [32/50000]	Loss: 1.5603	LR: 0.001180
Training Epoch: 208 [32/50000]	Loss: 1.7433	LR: 0.001180
Training Epoch: 208 [32/50000]	Loss: 1.5026	LR: 0.001180
Evaluating Network.....
Test set: Epoch: 208, Average loss: 0.0480, Top1Accuracy: 0.5780, Top3Accuracy: 0.7807, Top5Accuracy: 0.8534, Time consumed:1.81s

Training Epoch: 209 [32/50000]	Loss: 1.5712	LR: 0.001149
Training Epoch: 209 [32/50000]	Loss: 1.4213	LR: 0.001149
Training Epoch: 209 [32/50000]	Loss: 1.4471	LR: 0.001149
Training Epoch: 209 [32/50000]	Loss: 0.9075	LR: 0.001149
Training Epoch: 209 [32/50000]	Loss: 1.7869	LR: 0.001149
Training Epoch: 209 [32/50000]	Loss: 1.7351	LR: 0.001149
Training Epoch: 209 [32/50000]	Loss: 1.3351	LR: 0.001149
Training Epoch: 209 [32/50000]	Loss: 1.2980	LR: 0.001149
Training Epoch: 209 [32/50000]	Loss: 1.3102	LR: 0.001149
Training Epoch: 209 [32/50000]	Loss: 1.5996	LR: 0.001149
Evaluating Network.....
Test set: Epoch: 209, Average loss: 0.0479, Top1Accuracy: 0.5781, Top3Accuracy: 0.7804, Top5Accuracy: 0.8515, Time consumed:1.84s

Training Epoch: 210 [32/50000]	Loss: 1.7039	LR: 0.001119
Training Epoch: 210 [32/50000]	Loss: 1.5495	LR: 0.001119
Training Epoch: 210 [32/50000]	Loss: 1.7755	LR: 0.001119
Training Epoch: 210 [32/50000]	Loss: 1.1754	LR: 0.001119
Training Epoch: 210 [32/50000]	Loss: 1.4416	LR: 0.001119
Training Epoch: 210 [32/50000]	Loss: 1.5104	LR: 0.001119
Training Epoch: 210 [32/50000]	Loss: 1.1308	LR: 0.001119
Training Epoch: 210 [32/50000]	Loss: 1.3970	LR: 0.001119
Training Epoch: 210 [32/50000]	Loss: 1.2475	LR: 0.001119
Training Epoch: 210 [32/50000]	Loss: 1.4788	LR: 0.001119
Evaluating Network.....
Test set: Epoch: 210, Average loss: 0.0477, Top1Accuracy: 0.5777, Top3Accuracy: 0.7812, Top5Accuracy: 0.8549, Time consumed:1.85s

Training Epoch: 211 [32/50000]	Loss: 1.4925	LR: 0.001089
Training Epoch: 211 [32/50000]	Loss: 1.3813	LR: 0.001089
Training Epoch: 211 [32/50000]	Loss: 1.1644	LR: 0.001089
Training Epoch: 211 [32/50000]	Loss: 1.2592	LR: 0.001089
Training Epoch: 211 [32/50000]	Loss: 1.0158	LR: 0.001089
Training Epoch: 211 [32/50000]	Loss: 1.4030	LR: 0.001089
Training Epoch: 211 [32/50000]	Loss: 1.3628	LR: 0.001089
Training Epoch: 211 [32/50000]	Loss: 1.5889	LR: 0.001089
Training Epoch: 211 [32/50000]	Loss: 1.6369	LR: 0.001089
Training Epoch: 211 [32/50000]	Loss: 1.0217	LR: 0.001089
Evaluating Network.....
Test set: Epoch: 211, Average loss: 0.0478, Top1Accuracy: 0.5770, Top3Accuracy: 0.7824, Top5Accuracy: 0.8523, Time consumed:1.79s

Training Epoch: 212 [32/50000]	Loss: 1.3200	LR: 0.001060
Training Epoch: 212 [32/50000]	Loss: 1.1574	LR: 0.001060
Training Epoch: 212 [32/50000]	Loss: 1.1715	LR: 0.001060
Training Epoch: 212 [32/50000]	Loss: 1.9487	LR: 0.001060
Training Epoch: 212 [32/50000]	Loss: 1.0401	LR: 0.001060
Training Epoch: 212 [32/50000]	Loss: 1.6388	LR: 0.001060
Training Epoch: 212 [32/50000]	Loss: 1.2464	LR: 0.001060
Training Epoch: 212 [32/50000]	Loss: 1.7601	LR: 0.001060
Training Epoch: 212 [32/50000]	Loss: 1.2648	LR: 0.001060
Training Epoch: 212 [32/50000]	Loss: 1.3750	LR: 0.001060
Evaluating Network.....
Test set: Epoch: 212, Average loss: 0.0476, Top1Accuracy: 0.5809, Top3Accuracy: 0.7807, Top5Accuracy: 0.8522, Time consumed:1.81s

Training Epoch: 213 [32/50000]	Loss: 1.4290	LR: 0.001032
Training Epoch: 213 [32/50000]	Loss: 1.3022	LR: 0.001032
Training Epoch: 213 [32/50000]	Loss: 1.7976	LR: 0.001032
Training Epoch: 213 [32/50000]	Loss: 1.5072	LR: 0.001032
Training Epoch: 213 [32/50000]	Loss: 1.1081	LR: 0.001032
Training Epoch: 213 [32/50000]	Loss: 2.0212	LR: 0.001032
Training Epoch: 213 [32/50000]	Loss: 1.1566	LR: 0.001032
Training Epoch: 213 [32/50000]	Loss: 1.0277	LR: 0.001032
Training Epoch: 213 [32/50000]	Loss: 1.4265	LR: 0.001032
Training Epoch: 213 [32/50000]	Loss: 1.5359	LR: 0.001032
Evaluating Network.....
Test set: Epoch: 213, Average loss: 0.0477, Top1Accuracy: 0.5810, Top3Accuracy: 0.7823, Top5Accuracy: 0.8550, Time consumed:1.79s

Training Epoch: 214 [32/50000]	Loss: 1.4113	LR: 0.001005
Training Epoch: 214 [32/50000]	Loss: 1.6529	LR: 0.001005
Training Epoch: 214 [32/50000]	Loss: 1.5274	LR: 0.001005
Training Epoch: 214 [32/50000]	Loss: 1.4089	LR: 0.001005
Training Epoch: 214 [32/50000]	Loss: 0.7718	LR: 0.001005
Training Epoch: 214 [32/50000]	Loss: 1.5227	LR: 0.001005
Training Epoch: 214 [32/50000]	Loss: 1.7021	LR: 0.001005
Training Epoch: 214 [32/50000]	Loss: 0.6411	LR: 0.001005
Training Epoch: 214 [32/50000]	Loss: 0.8763	LR: 0.001005
Training Epoch: 214 [32/50000]	Loss: 1.9218	LR: 0.001005
Evaluating Network.....
Test set: Epoch: 214, Average loss: 0.0477, Top1Accuracy: 0.5796, Top3Accuracy: 0.7820, Top5Accuracy: 0.8521, Time consumed:1.81s

Training Epoch: 215 [32/50000]	Loss: 1.2615	LR: 0.000979
Training Epoch: 215 [32/50000]	Loss: 1.5118	LR: 0.000979
Training Epoch: 215 [32/50000]	Loss: 1.7768	LR: 0.000979
Training Epoch: 215 [32/50000]	Loss: 1.1836	LR: 0.000979
Training Epoch: 215 [32/50000]	Loss: 1.4685	LR: 0.000979
Training Epoch: 215 [32/50000]	Loss: 1.6027	LR: 0.000979
Training Epoch: 215 [32/50000]	Loss: 1.4598	LR: 0.000979
Training Epoch: 215 [32/50000]	Loss: 1.0973	LR: 0.000979
Training Epoch: 215 [32/50000]	Loss: 1.2428	LR: 0.000979
Training Epoch: 215 [32/50000]	Loss: 1.4666	LR: 0.000979
Evaluating Network.....
Test set: Epoch: 215, Average loss: 0.0477, Top1Accuracy: 0.5770, Top3Accuracy: 0.7805, Top5Accuracy: 0.8543, Time consumed:1.77s

Training Epoch: 216 [32/50000]	Loss: 1.7043	LR: 0.000953
Training Epoch: 216 [32/50000]	Loss: 1.2297	LR: 0.000953
Training Epoch: 216 [32/50000]	Loss: 1.4229	LR: 0.000953
Training Epoch: 216 [32/50000]	Loss: 1.4669	LR: 0.000953
Training Epoch: 216 [32/50000]	Loss: 0.9298	LR: 0.000953
Training Epoch: 216 [32/50000]	Loss: 0.8674	LR: 0.000953
Training Epoch: 216 [32/50000]	Loss: 1.2840	LR: 0.000953
Training Epoch: 216 [32/50000]	Loss: 0.9959	LR: 0.000953
Training Epoch: 216 [32/50000]	Loss: 1.7655	LR: 0.000953
Training Epoch: 216 [32/50000]	Loss: 1.7014	LR: 0.000953
Evaluating Network.....
Test set: Epoch: 216, Average loss: 0.0477, Top1Accuracy: 0.5804, Top3Accuracy: 0.7815, Top5Accuracy: 0.8556, Time consumed:1.79s

Training Epoch: 217 [32/50000]	Loss: 1.3122	LR: 0.000928
Training Epoch: 217 [32/50000]	Loss: 1.3494	LR: 0.000928
Training Epoch: 217 [32/50000]	Loss: 0.9861	LR: 0.000928
Training Epoch: 217 [32/50000]	Loss: 1.3087	LR: 0.000928
Training Epoch: 217 [32/50000]	Loss: 1.3742	LR: 0.000928
Training Epoch: 217 [32/50000]	Loss: 1.3759	LR: 0.000928
Training Epoch: 217 [32/50000]	Loss: 1.2537	LR: 0.000928
Training Epoch: 217 [32/50000]	Loss: 1.5224	LR: 0.000928
Training Epoch: 217 [32/50000]	Loss: 1.5782	LR: 0.000928
Training Epoch: 217 [32/50000]	Loss: 1.4879	LR: 0.000928
Evaluating Network.....
Test set: Epoch: 217, Average loss: 0.0476, Top1Accuracy: 0.5789, Top3Accuracy: 0.7806, Top5Accuracy: 0.8531, Time consumed:1.83s

Training Epoch: 218 [32/50000]	Loss: 1.4268	LR: 0.000903
Training Epoch: 218 [32/50000]	Loss: 1.2701	LR: 0.000903
Training Epoch: 218 [32/50000]	Loss: 1.1898	LR: 0.000903
Training Epoch: 218 [32/50000]	Loss: 1.4764	LR: 0.000903
Training Epoch: 218 [32/50000]	Loss: 1.5336	LR: 0.000903
Training Epoch: 218 [32/50000]	Loss: 1.4546	LR: 0.000903
Training Epoch: 218 [32/50000]	Loss: 1.5913	LR: 0.000903
Training Epoch: 218 [32/50000]	Loss: 1.4401	LR: 0.000903
Training Epoch: 218 [32/50000]	Loss: 1.8042	LR: 0.000903
Training Epoch: 218 [32/50000]	Loss: 1.3547	LR: 0.000903
Evaluating Network.....
Test set: Epoch: 218, Average loss: 0.0473, Top1Accuracy: 0.5818, Top3Accuracy: 0.7856, Top5Accuracy: 0.8564, Time consumed:1.78s

Training Epoch: 219 [32/50000]	Loss: 1.0763	LR: 0.000879
Training Epoch: 219 [32/50000]	Loss: 1.1124	LR: 0.000879
Training Epoch: 219 [32/50000]	Loss: 1.2050	LR: 0.000879
Training Epoch: 219 [32/50000]	Loss: 1.3291	LR: 0.000879
Training Epoch: 219 [32/50000]	Loss: 1.5814	LR: 0.000879
Training Epoch: 219 [32/50000]	Loss: 1.3615	LR: 0.000879
Training Epoch: 219 [32/50000]	Loss: 1.5904	LR: 0.000879
Training Epoch: 219 [32/50000]	Loss: 1.6951	LR: 0.000879
Training Epoch: 219 [32/50000]	Loss: 2.0225	LR: 0.000879
Training Epoch: 219 [32/50000]	Loss: 1.0460	LR: 0.000879
Evaluating Network.....
Test set: Epoch: 219, Average loss: 0.0475, Top1Accuracy: 0.5801, Top3Accuracy: 0.7857, Top5Accuracy: 0.8534, Time consumed:1.78s

Training Epoch: 220 [32/50000]	Loss: 1.2732	LR: 0.000856
Training Epoch: 220 [32/50000]	Loss: 1.2639	LR: 0.000856
Training Epoch: 220 [32/50000]	Loss: 1.3341	LR: 0.000856
Training Epoch: 220 [32/50000]	Loss: 1.2225	LR: 0.000856
Training Epoch: 220 [32/50000]	Loss: 1.4015	LR: 0.000856
Training Epoch: 220 [32/50000]	Loss: 0.9455	LR: 0.000856
Training Epoch: 220 [32/50000]	Loss: 1.3570	LR: 0.000856
Training Epoch: 220 [32/50000]	Loss: 1.4751	LR: 0.000856
Training Epoch: 220 [32/50000]	Loss: 1.2165	LR: 0.000856
Training Epoch: 220 [32/50000]	Loss: 1.3965	LR: 0.000856
Evaluating Network.....
Test set: Epoch: 220, Average loss: 0.0474, Top1Accuracy: 0.5824, Top3Accuracy: 0.7860, Top5Accuracy: 0.8546, Time consumed:1.82s

Training Epoch: 221 [32/50000]	Loss: 1.6803	LR: 0.000833
Training Epoch: 221 [32/50000]	Loss: 1.5450	LR: 0.000833
Training Epoch: 221 [32/50000]	Loss: 1.4627	LR: 0.000833
Training Epoch: 221 [32/50000]	Loss: 1.4153	LR: 0.000833
Training Epoch: 221 [32/50000]	Loss: 1.7109	LR: 0.000833
Training Epoch: 221 [32/50000]	Loss: 1.5626	LR: 0.000833
Training Epoch: 221 [32/50000]	Loss: 0.9287	LR: 0.000833
Training Epoch: 221 [32/50000]	Loss: 1.1174	LR: 0.000833
Training Epoch: 221 [32/50000]	Loss: 1.4193	LR: 0.000833
Training Epoch: 221 [32/50000]	Loss: 1.1606	LR: 0.000833
Evaluating Network.....
Test set: Epoch: 221, Average loss: 0.0474, Top1Accuracy: 0.5821, Top3Accuracy: 0.7849, Top5Accuracy: 0.8551, Time consumed:1.82s

Training Epoch: 222 [32/50000]	Loss: 1.2668	LR: 0.000811
Training Epoch: 222 [32/50000]	Loss: 1.5129	LR: 0.000811
Training Epoch: 222 [32/50000]	Loss: 1.7566	LR: 0.000811
Training Epoch: 222 [32/50000]	Loss: 1.4367	LR: 0.000811
Training Epoch: 222 [32/50000]	Loss: 1.1847	LR: 0.000811
Training Epoch: 222 [32/50000]	Loss: 1.1922	LR: 0.000811
Training Epoch: 222 [32/50000]	Loss: 1.3239	LR: 0.000811
Training Epoch: 222 [32/50000]	Loss: 1.3515	LR: 0.000811
Training Epoch: 222 [32/50000]	Loss: 1.2725	LR: 0.000811
Training Epoch: 222 [32/50000]	Loss: 1.6278	LR: 0.000811
Evaluating Network.....
Test set: Epoch: 222, Average loss: 0.0474, Top1Accuracy: 0.5812, Top3Accuracy: 0.7842, Top5Accuracy: 0.8566, Time consumed:1.81s

Training Epoch: 223 [32/50000]	Loss: 1.2853	LR: 0.000790
Training Epoch: 223 [32/50000]	Loss: 1.4378	LR: 0.000790
Training Epoch: 223 [32/50000]	Loss: 1.1885	LR: 0.000790
Training Epoch: 223 [32/50000]	Loss: 1.1858	LR: 0.000790
Training Epoch: 223 [32/50000]	Loss: 1.7031	LR: 0.000790
Training Epoch: 223 [32/50000]	Loss: 1.2763	LR: 0.000790
Training Epoch: 223 [32/50000]	Loss: 1.0467	LR: 0.000790
Training Epoch: 223 [32/50000]	Loss: 2.0548	LR: 0.000790
Training Epoch: 223 [32/50000]	Loss: 1.4609	LR: 0.000790
Training Epoch: 223 [32/50000]	Loss: 1.4773	LR: 0.000790
Evaluating Network.....
Test set: Epoch: 223, Average loss: 0.0474, Top1Accuracy: 0.5804, Top3Accuracy: 0.7852, Top5Accuracy: 0.8554, Time consumed:1.78s

Training Epoch: 224 [32/50000]	Loss: 1.3290	LR: 0.000769
Training Epoch: 224 [32/50000]	Loss: 1.3033	LR: 0.000769
Training Epoch: 224 [32/50000]	Loss: 1.6375	LR: 0.000769
Training Epoch: 224 [32/50000]	Loss: 1.0377	LR: 0.000769
Training Epoch: 224 [32/50000]	Loss: 1.0878	LR: 0.000769
Training Epoch: 224 [32/50000]	Loss: 1.5398	LR: 0.000769
Training Epoch: 224 [32/50000]	Loss: 1.5429	LR: 0.000769
Training Epoch: 224 [32/50000]	Loss: 1.3514	LR: 0.000769
Training Epoch: 224 [32/50000]	Loss: 1.2668	LR: 0.000769
Training Epoch: 224 [32/50000]	Loss: 1.4578	LR: 0.000769
Evaluating Network.....
Test set: Epoch: 224, Average loss: 0.0473, Top1Accuracy: 0.5823, Top3Accuracy: 0.7860, Top5Accuracy: 0.8560, Time consumed:1.81s

Training Epoch: 225 [32/50000]	Loss: 1.3366	LR: 0.000749
Training Epoch: 225 [32/50000]	Loss: 1.2581	LR: 0.000749
Training Epoch: 225 [32/50000]	Loss: 0.9488	LR: 0.000749
Training Epoch: 225 [32/50000]	Loss: 1.2840	LR: 0.000749
Training Epoch: 225 [32/50000]	Loss: 1.2171	LR: 0.000749
Training Epoch: 225 [32/50000]	Loss: 1.1060	LR: 0.000749
Training Epoch: 225 [32/50000]	Loss: 1.3798	LR: 0.000749
Training Epoch: 225 [32/50000]	Loss: 1.5773	LR: 0.000749
Training Epoch: 225 [32/50000]	Loss: 0.8598	LR: 0.000749
Training Epoch: 225 [32/50000]	Loss: 1.3057	LR: 0.000749
Evaluating Network.....
Test set: Epoch: 225, Average loss: 0.0472, Top1Accuracy: 0.5857, Top3Accuracy: 0.7871, Top5Accuracy: 0.8569, Time consumed:1.81s

Training Epoch: 226 [32/50000]	Loss: 1.1947	LR: 0.000729
Training Epoch: 226 [32/50000]	Loss: 1.6416	LR: 0.000729
Training Epoch: 226 [32/50000]	Loss: 0.8649	LR: 0.000729
Training Epoch: 226 [32/50000]	Loss: 1.1315	LR: 0.000729
Training Epoch: 226 [32/50000]	Loss: 1.2984	LR: 0.000729
Training Epoch: 226 [32/50000]	Loss: 1.4058	LR: 0.000729
Training Epoch: 226 [32/50000]	Loss: 1.3931	LR: 0.000729
Training Epoch: 226 [32/50000]	Loss: 1.3537	LR: 0.000729
Training Epoch: 226 [32/50000]	Loss: 0.9511	LR: 0.000729
Training Epoch: 226 [32/50000]	Loss: 1.6001	LR: 0.000729
Evaluating Network.....
Test set: Epoch: 226, Average loss: 0.0473, Top1Accuracy: 0.5845, Top3Accuracy: 0.7840, Top5Accuracy: 0.8543, Time consumed:1.94s

Training Epoch: 227 [32/50000]	Loss: 1.4179	LR: 0.000710
Training Epoch: 227 [32/50000]	Loss: 1.3788	LR: 0.000710
Training Epoch: 227 [32/50000]	Loss: 2.3051	LR: 0.000710
Training Epoch: 227 [32/50000]	Loss: 1.3026	LR: 0.000710
Training Epoch: 227 [32/50000]	Loss: 1.1771	LR: 0.000710
Training Epoch: 227 [32/50000]	Loss: 1.4502	LR: 0.000710
Training Epoch: 227 [32/50000]	Loss: 1.5272	LR: 0.000710
Training Epoch: 227 [32/50000]	Loss: 1.3860	LR: 0.000710
Training Epoch: 227 [32/50000]	Loss: 1.6777	LR: 0.000710
Training Epoch: 227 [32/50000]	Loss: 1.4500	LR: 0.000710
Evaluating Network.....
Test set: Epoch: 227, Average loss: 0.0473, Top1Accuracy: 0.5838, Top3Accuracy: 0.7851, Top5Accuracy: 0.8555, Time consumed:1.80s

Training Epoch: 228 [32/50000]	Loss: 1.8661	LR: 0.000691
Training Epoch: 228 [32/50000]	Loss: 1.5398	LR: 0.000691
Training Epoch: 228 [32/50000]	Loss: 1.3093	LR: 0.000691
Training Epoch: 228 [32/50000]	Loss: 1.4612	LR: 0.000691
Training Epoch: 228 [32/50000]	Loss: 1.2236	LR: 0.000691
Training Epoch: 228 [32/50000]	Loss: 1.3577	LR: 0.000691
Training Epoch: 228 [32/50000]	Loss: 1.3558	LR: 0.000691
Training Epoch: 228 [32/50000]	Loss: 1.1827	LR: 0.000691
Training Epoch: 228 [32/50000]	Loss: 1.6811	LR: 0.000691
Training Epoch: 228 [32/50000]	Loss: 1.7298	LR: 0.000691
Evaluating Network.....
Test set: Epoch: 228, Average loss: 0.0473, Top1Accuracy: 0.5813, Top3Accuracy: 0.7846, Top5Accuracy: 0.8568, Time consumed:1.80s

Training Epoch: 229 [32/50000]	Loss: 1.5062	LR: 0.000673
Training Epoch: 229 [32/50000]	Loss: 1.8482	LR: 0.000673
Training Epoch: 229 [32/50000]	Loss: 1.6065	LR: 0.000673
Training Epoch: 229 [32/50000]	Loss: 1.2243	LR: 0.000673
Training Epoch: 229 [32/50000]	Loss: 1.0228	LR: 0.000673
Training Epoch: 229 [32/50000]	Loss: 1.0923	LR: 0.000673
Training Epoch: 229 [32/50000]	Loss: 1.2692	LR: 0.000673
Training Epoch: 229 [32/50000]	Loss: 1.5689	LR: 0.000673
Training Epoch: 229 [32/50000]	Loss: 1.0098	LR: 0.000673
Training Epoch: 229 [32/50000]	Loss: 0.8234	LR: 0.000673
Evaluating Network.....
Test set: Epoch: 229, Average loss: 0.0471, Top1Accuracy: 0.5866, Top3Accuracy: 0.7842, Top5Accuracy: 0.8562, Time consumed:1.81s

Training Epoch: 230 [32/50000]	Loss: 1.0236	LR: 0.000655
Training Epoch: 230 [32/50000]	Loss: 1.4651	LR: 0.000655
Training Epoch: 230 [32/50000]	Loss: 1.8871	LR: 0.000655
Training Epoch: 230 [32/50000]	Loss: 1.6378	LR: 0.000655
Training Epoch: 230 [32/50000]	Loss: 1.4693	LR: 0.000655
Training Epoch: 230 [32/50000]	Loss: 1.2721	LR: 0.000655
Training Epoch: 230 [32/50000]	Loss: 1.1625	LR: 0.000655
Training Epoch: 230 [32/50000]	Loss: 1.0891	LR: 0.000655
Training Epoch: 230 [32/50000]	Loss: 1.5430	LR: 0.000655
Training Epoch: 230 [32/50000]	Loss: 0.6596	LR: 0.000655
Evaluating Network.....
Test set: Epoch: 230, Average loss: 0.0473, Top1Accuracy: 0.5833, Top3Accuracy: 0.7830, Top5Accuracy: 0.8558, Time consumed:1.76s

Training Epoch: 231 [32/50000]	Loss: 1.1475	LR: 0.000638
Training Epoch: 231 [32/50000]	Loss: 1.5296	LR: 0.000638
Training Epoch: 231 [32/50000]	Loss: 1.3656	LR: 0.000638
Training Epoch: 231 [32/50000]	Loss: 1.3844	LR: 0.000638
Training Epoch: 231 [32/50000]	Loss: 0.9924	LR: 0.000638
Training Epoch: 231 [32/50000]	Loss: 1.3516	LR: 0.000638
Training Epoch: 231 [32/50000]	Loss: 1.1316	LR: 0.000638
Training Epoch: 231 [32/50000]	Loss: 1.4017	LR: 0.000638
Training Epoch: 231 [32/50000]	Loss: 1.0686	LR: 0.000638
Training Epoch: 231 [32/50000]	Loss: 1.2757	LR: 0.000638
Evaluating Network.....
Test set: Epoch: 231, Average loss: 0.0472, Top1Accuracy: 0.5860, Top3Accuracy: 0.7851, Top5Accuracy: 0.8560, Time consumed:1.81s

Training Epoch: 232 [32/50000]	Loss: 1.5590	LR: 0.000621
Training Epoch: 232 [32/50000]	Loss: 1.1292	LR: 0.000621
Training Epoch: 232 [32/50000]	Loss: 1.7111	LR: 0.000621
Training Epoch: 232 [32/50000]	Loss: 1.4038	LR: 0.000621
Training Epoch: 232 [32/50000]	Loss: 2.1071	LR: 0.000621
Training Epoch: 232 [32/50000]	Loss: 1.2849	LR: 0.000621
Training Epoch: 232 [32/50000]	Loss: 0.9709	LR: 0.000621
Training Epoch: 232 [32/50000]	Loss: 1.4310	LR: 0.000621
Training Epoch: 232 [32/50000]	Loss: 1.5149	LR: 0.000621
Training Epoch: 232 [32/50000]	Loss: 1.1748	LR: 0.000621
Evaluating Network.....
Test set: Epoch: 232, Average loss: 0.0472, Top1Accuracy: 0.5837, Top3Accuracy: 0.7869, Top5Accuracy: 0.8569, Time consumed:1.78s

Training Epoch: 233 [32/50000]	Loss: 1.1642	LR: 0.000605
Training Epoch: 233 [32/50000]	Loss: 1.3097	LR: 0.000605
Training Epoch: 233 [32/50000]	Loss: 0.7225	LR: 0.000605
Training Epoch: 233 [32/50000]	Loss: 1.8224	LR: 0.000605
Training Epoch: 233 [32/50000]	Loss: 1.4959	LR: 0.000605
Training Epoch: 233 [32/50000]	Loss: 1.0425	LR: 0.000605
Training Epoch: 233 [32/50000]	Loss: 1.3989	LR: 0.000605
Training Epoch: 233 [32/50000]	Loss: 1.5054	LR: 0.000605
Training Epoch: 233 [32/50000]	Loss: 1.3911	LR: 0.000605
Training Epoch: 233 [32/50000]	Loss: 1.4335	LR: 0.000605
Evaluating Network.....
Test set: Epoch: 233, Average loss: 0.0471, Top1Accuracy: 0.5858, Top3Accuracy: 0.7855, Top5Accuracy: 0.8556, Time consumed:1.80s

Training Epoch: 234 [32/50000]	Loss: 1.2928	LR: 0.000589
Training Epoch: 234 [32/50000]	Loss: 1.2288	LR: 0.000589
Training Epoch: 234 [32/50000]	Loss: 0.9238	LR: 0.000589
Training Epoch: 234 [32/50000]	Loss: 1.6094	LR: 0.000589
Training Epoch: 234 [32/50000]	Loss: 1.3204	LR: 0.000589
Training Epoch: 234 [32/50000]	Loss: 1.5825	LR: 0.000589
Training Epoch: 234 [32/50000]	Loss: 1.2242	LR: 0.000589
Training Epoch: 234 [32/50000]	Loss: 1.5252	LR: 0.000589
Training Epoch: 234 [32/50000]	Loss: 1.5907	LR: 0.000589
Training Epoch: 234 [32/50000]	Loss: 1.7428	LR: 0.000589
Evaluating Network.....
Test set: Epoch: 234, Average loss: 0.0470, Top1Accuracy: 0.5853, Top3Accuracy: 0.7873, Top5Accuracy: 0.8577, Time consumed:1.79s

Training Epoch: 235 [32/50000]	Loss: 1.4020	LR: 0.000573
Training Epoch: 235 [32/50000]	Loss: 1.0679	LR: 0.000573
Training Epoch: 235 [32/50000]	Loss: 0.8785	LR: 0.000573
Training Epoch: 235 [32/50000]	Loss: 1.4315	LR: 0.000573
Training Epoch: 235 [32/50000]	Loss: 1.2531	LR: 0.000573
Training Epoch: 235 [32/50000]	Loss: 1.1104	LR: 0.000573
Training Epoch: 235 [32/50000]	Loss: 1.1101	LR: 0.000573
Training Epoch: 235 [32/50000]	Loss: 1.3777	LR: 0.000573
Training Epoch: 235 [32/50000]	Loss: 1.0746	LR: 0.000573
Training Epoch: 235 [32/50000]	Loss: 1.2130	LR: 0.000573
Evaluating Network.....
Test set: Epoch: 235, Average loss: 0.0471, Top1Accuracy: 0.5841, Top3Accuracy: 0.7867, Top5Accuracy: 0.8575, Time consumed:1.77s

Training Epoch: 236 [32/50000]	Loss: 1.5097	LR: 0.000558
Training Epoch: 236 [32/50000]	Loss: 1.4160	LR: 0.000558
Training Epoch: 236 [32/50000]	Loss: 1.0886	LR: 0.000558
Training Epoch: 236 [32/50000]	Loss: 1.5162	LR: 0.000558
Training Epoch: 236 [32/50000]	Loss: 1.1727	LR: 0.000558
Training Epoch: 236 [32/50000]	Loss: 1.4633	LR: 0.000558
Training Epoch: 236 [32/50000]	Loss: 1.3290	LR: 0.000558
Training Epoch: 236 [32/50000]	Loss: 1.7245	LR: 0.000558
Training Epoch: 236 [32/50000]	Loss: 1.4400	LR: 0.000558
Training Epoch: 236 [32/50000]	Loss: 1.8552	LR: 0.000558
Evaluating Network.....
Test set: Epoch: 236, Average loss: 0.0472, Top1Accuracy: 0.5876, Top3Accuracy: 0.7857, Top5Accuracy: 0.8578, Time consumed:1.79s

Training Epoch: 237 [32/50000]	Loss: 1.8315	LR: 0.000543
Training Epoch: 237 [32/50000]	Loss: 1.2521	LR: 0.000543
Training Epoch: 237 [32/50000]	Loss: 1.3851	LR: 0.000543
Training Epoch: 237 [32/50000]	Loss: 1.3118	LR: 0.000543
Training Epoch: 237 [32/50000]	Loss: 1.2833	LR: 0.000543
Training Epoch: 237 [32/50000]	Loss: 1.6882	LR: 0.000543
Training Epoch: 237 [32/50000]	Loss: 1.5033	LR: 0.000543
Training Epoch: 237 [32/50000]	Loss: 1.6182	LR: 0.000543
Training Epoch: 237 [32/50000]	Loss: 1.1724	LR: 0.000543
Training Epoch: 237 [32/50000]	Loss: 1.4553	LR: 0.000543
Evaluating Network.....
Test set: Epoch: 237, Average loss: 0.0471, Top1Accuracy: 0.5864, Top3Accuracy: 0.7868, Top5Accuracy: 0.8563, Time consumed:1.78s

Training Epoch: 238 [32/50000]	Loss: 1.3956	LR: 0.000529
Training Epoch: 238 [32/50000]	Loss: 1.3340	LR: 0.000529
Training Epoch: 238 [32/50000]	Loss: 1.3071	LR: 0.000529
Training Epoch: 238 [32/50000]	Loss: 0.9459	LR: 0.000529
Training Epoch: 238 [32/50000]	Loss: 1.2090	LR: 0.000529
Training Epoch: 238 [32/50000]	Loss: 1.1510	LR: 0.000529
Training Epoch: 238 [32/50000]	Loss: 1.2846	LR: 0.000529
Training Epoch: 238 [32/50000]	Loss: 1.6672	LR: 0.000529
Training Epoch: 238 [32/50000]	Loss: 1.7339	LR: 0.000529
Training Epoch: 238 [32/50000]	Loss: 1.3022	LR: 0.000529
Evaluating Network.....
Test set: Epoch: 238, Average loss: 0.0470, Top1Accuracy: 0.5855, Top3Accuracy: 0.7867, Top5Accuracy: 0.8572, Time consumed:1.78s

Training Epoch: 239 [32/50000]	Loss: 1.4636	LR: 0.000515
Training Epoch: 239 [32/50000]	Loss: 1.4866	LR: 0.000515
Training Epoch: 239 [32/50000]	Loss: 1.1939	LR: 0.000515
Training Epoch: 239 [32/50000]	Loss: 1.7793	LR: 0.000515
Training Epoch: 239 [32/50000]	Loss: 1.4887	LR: 0.000515
Training Epoch: 239 [32/50000]	Loss: 1.5131	LR: 0.000515
Training Epoch: 239 [32/50000]	Loss: 1.2016	LR: 0.000515
Training Epoch: 239 [32/50000]	Loss: 1.4914	LR: 0.000515
Training Epoch: 239 [32/50000]	Loss: 0.9876	LR: 0.000515
Training Epoch: 239 [32/50000]	Loss: 1.6275	LR: 0.000515
Evaluating Network.....
Test set: Epoch: 239, Average loss: 0.0471, Top1Accuracy: 0.5859, Top3Accuracy: 0.7854, Top5Accuracy: 0.8572, Time consumed:1.79s

Training Epoch: 240 [32/50000]	Loss: 1.5317	LR: 0.000501
Training Epoch: 240 [32/50000]	Loss: 1.8505	LR: 0.000501
Training Epoch: 240 [32/50000]	Loss: 1.3954	LR: 0.000501
Training Epoch: 240 [32/50000]	Loss: 1.6496	LR: 0.000501
Training Epoch: 240 [32/50000]	Loss: 1.2469	LR: 0.000501
Training Epoch: 240 [32/50000]	Loss: 1.4654	LR: 0.000501
Training Epoch: 240 [32/50000]	Loss: 1.5459	LR: 0.000501
Training Epoch: 240 [32/50000]	Loss: 1.1969	LR: 0.000501
Training Epoch: 240 [32/50000]	Loss: 1.5659	LR: 0.000501
Training Epoch: 240 [32/50000]	Loss: 1.2623	LR: 0.000501
Evaluating Network.....
Test set: Epoch: 240, Average loss: 0.0470, Top1Accuracy: 0.5866, Top3Accuracy: 0.7863, Top5Accuracy: 0.8574, Time consumed:1.78s

Training Epoch: 241 [32/50000]	Loss: 1.1711	LR: 0.000488
Training Epoch: 241 [32/50000]	Loss: 1.1919	LR: 0.000488
Training Epoch: 241 [32/50000]	Loss: 1.3603	LR: 0.000488
Training Epoch: 241 [32/50000]	Loss: 1.1598	LR: 0.000488
Training Epoch: 241 [32/50000]	Loss: 1.4469	LR: 0.000488
Training Epoch: 241 [32/50000]	Loss: 1.1739	LR: 0.000488
Training Epoch: 241 [32/50000]	Loss: 1.4272	LR: 0.000488
Training Epoch: 241 [32/50000]	Loss: 1.0892	LR: 0.000488
Training Epoch: 241 [32/50000]	Loss: 1.6452	LR: 0.000488
Training Epoch: 241 [32/50000]	Loss: 1.4886	LR: 0.000488
Evaluating Network.....
Test set: Epoch: 241, Average loss: 0.0470, Top1Accuracy: 0.5893, Top3Accuracy: 0.7867, Top5Accuracy: 0.8563, Time consumed:1.77s

Training Epoch: 242 [32/50000]	Loss: 1.7339	LR: 0.000475
Training Epoch: 242 [32/50000]	Loss: 1.4241	LR: 0.000475
Training Epoch: 242 [32/50000]	Loss: 1.4470	LR: 0.000475
Training Epoch: 242 [32/50000]	Loss: 1.1453	LR: 0.000475
Training Epoch: 242 [32/50000]	Loss: 0.8718	LR: 0.000475
Training Epoch: 242 [32/50000]	Loss: 1.8295	LR: 0.000475
Training Epoch: 242 [32/50000]	Loss: 1.2611	LR: 0.000475
Training Epoch: 242 [32/50000]	Loss: 1.2477	LR: 0.000475
Training Epoch: 242 [32/50000]	Loss: 1.6472	LR: 0.000475
Training Epoch: 242 [32/50000]	Loss: 1.5420	LR: 0.000475
Evaluating Network.....
Test set: Epoch: 242, Average loss: 0.0470, Top1Accuracy: 0.5891, Top3Accuracy: 0.7855, Top5Accuracy: 0.8572, Time consumed:1.77s

Training Epoch: 243 [32/50000]	Loss: 1.3038	LR: 0.000463
Training Epoch: 243 [32/50000]	Loss: 1.2463	LR: 0.000463
Training Epoch: 243 [32/50000]	Loss: 1.3626	LR: 0.000463
Training Epoch: 243 [32/50000]	Loss: 1.4826	LR: 0.000463
Training Epoch: 243 [32/50000]	Loss: 0.8284	LR: 0.000463
Training Epoch: 243 [32/50000]	Loss: 1.7845	LR: 0.000463
Training Epoch: 243 [32/50000]	Loss: 1.3261	LR: 0.000463
Training Epoch: 243 [32/50000]	Loss: 1.1726	LR: 0.000463
Training Epoch: 243 [32/50000]	Loss: 2.0608	LR: 0.000463
Training Epoch: 243 [32/50000]	Loss: 1.2774	LR: 0.000463
Evaluating Network.....
Test set: Epoch: 243, Average loss: 0.0469, Top1Accuracy: 0.5887, Top3Accuracy: 0.7868, Top5Accuracy: 0.8568, Time consumed:1.81s

Training Epoch: 244 [32/50000]	Loss: 1.1664	LR: 0.000450
Training Epoch: 244 [32/50000]	Loss: 1.4440	LR: 0.000450
Training Epoch: 244 [32/50000]	Loss: 1.8023	LR: 0.000450
Training Epoch: 244 [32/50000]	Loss: 1.2280	LR: 0.000450
Training Epoch: 244 [32/50000]	Loss: 1.3103	LR: 0.000450
Training Epoch: 244 [32/50000]	Loss: 1.6752	LR: 0.000450
Training Epoch: 244 [32/50000]	Loss: 1.2970	LR: 0.000450
Training Epoch: 244 [32/50000]	Loss: 1.1571	LR: 0.000450
Training Epoch: 244 [32/50000]	Loss: 1.5501	LR: 0.000450
Training Epoch: 244 [32/50000]	Loss: 1.4160	LR: 0.000450
Evaluating Network.....
Test set: Epoch: 244, Average loss: 0.0469, Top1Accuracy: 0.5874, Top3Accuracy: 0.7888, Top5Accuracy: 0.8581, Time consumed:1.80s

Training Epoch: 245 [32/50000]	Loss: 1.7060	LR: 0.000439
Training Epoch: 245 [32/50000]	Loss: 1.1308	LR: 0.000439
Training Epoch: 245 [32/50000]	Loss: 0.9557	LR: 0.000439
Training Epoch: 245 [32/50000]	Loss: 1.4542	LR: 0.000439
Training Epoch: 245 [32/50000]	Loss: 1.3412	LR: 0.000439
Training Epoch: 245 [32/50000]	Loss: 1.3300	LR: 0.000439
Training Epoch: 245 [32/50000]	Loss: 1.0787	LR: 0.000439
Training Epoch: 245 [32/50000]	Loss: 1.0427	LR: 0.000439
Training Epoch: 245 [32/50000]	Loss: 1.1990	LR: 0.000439
Training Epoch: 245 [32/50000]	Loss: 1.2737	LR: 0.000439
Evaluating Network.....
Test set: Epoch: 245, Average loss: 0.0471, Top1Accuracy: 0.5875, Top3Accuracy: 0.7855, Top5Accuracy: 0.8572, Time consumed:1.81s

Training Epoch: 246 [32/50000]	Loss: 1.9619	LR: 0.000427
Training Epoch: 246 [32/50000]	Loss: 1.1823	LR: 0.000427
Training Epoch: 246 [32/50000]	Loss: 1.5016	LR: 0.000427
Training Epoch: 246 [32/50000]	Loss: 1.6823	LR: 0.000427
Training Epoch: 246 [32/50000]	Loss: 1.2287	LR: 0.000427
Training Epoch: 246 [32/50000]	Loss: 1.3360	LR: 0.000427
Training Epoch: 246 [32/50000]	Loss: 1.2154	LR: 0.000427
Training Epoch: 246 [32/50000]	Loss: 1.3135	LR: 0.000427
Training Epoch: 246 [32/50000]	Loss: 1.8613	LR: 0.000427
Training Epoch: 246 [32/50000]	Loss: 1.6694	LR: 0.000427
Evaluating Network.....
Test set: Epoch: 246, Average loss: 0.0469, Top1Accuracy: 0.5880, Top3Accuracy: 0.7867, Top5Accuracy: 0.8583, Time consumed:1.81s

Training Epoch: 247 [32/50000]	Loss: 1.1412	LR: 0.000416
Training Epoch: 247 [32/50000]	Loss: 1.4220	LR: 0.000416
Training Epoch: 247 [32/50000]	Loss: 1.6633	LR: 0.000416
Training Epoch: 247 [32/50000]	Loss: 1.3397	LR: 0.000416
Training Epoch: 247 [32/50000]	Loss: 1.2474	LR: 0.000416
Training Epoch: 247 [32/50000]	Loss: 1.2742	LR: 0.000416
Training Epoch: 247 [32/50000]	Loss: 1.3771	LR: 0.000416
Training Epoch: 247 [32/50000]	Loss: 1.4570	LR: 0.000416
Training Epoch: 247 [32/50000]	Loss: 1.5846	LR: 0.000416
Training Epoch: 247 [32/50000]	Loss: 1.8508	LR: 0.000416
Evaluating Network.....
Test set: Epoch: 247, Average loss: 0.0469, Top1Accuracy: 0.5876, Top3Accuracy: 0.7860, Top5Accuracy: 0.8581, Time consumed:1.81s

Training Epoch: 248 [32/50000]	Loss: 1.4999	LR: 0.000405
Training Epoch: 248 [32/50000]	Loss: 1.3728	LR: 0.000405
Training Epoch: 248 [32/50000]	Loss: 1.1530	LR: 0.000405
Training Epoch: 248 [32/50000]	Loss: 1.4582	LR: 0.000405
Training Epoch: 248 [32/50000]	Loss: 1.5407	LR: 0.000405
Training Epoch: 248 [32/50000]	Loss: 1.8070	LR: 0.000405
Training Epoch: 248 [32/50000]	Loss: 1.3363	LR: 0.000405
Training Epoch: 248 [32/50000]	Loss: 1.6796	LR: 0.000405
Training Epoch: 248 [32/50000]	Loss: 1.3677	LR: 0.000405
Training Epoch: 248 [32/50000]	Loss: 0.7460	LR: 0.000405
Evaluating Network.....
Test set: Epoch: 248, Average loss: 0.0468, Top1Accuracy: 0.5893, Top3Accuracy: 0.7870, Top5Accuracy: 0.8587, Time consumed:1.80s

Training Epoch: 249 [32/50000]	Loss: 1.8095	LR: 0.000394
Training Epoch: 249 [32/50000]	Loss: 1.1547	LR: 0.000394
Training Epoch: 249 [32/50000]	Loss: 1.6991	LR: 0.000394
Training Epoch: 249 [32/50000]	Loss: 1.8074	LR: 0.000394
Training Epoch: 249 [32/50000]	Loss: 1.3426	LR: 0.000394
Training Epoch: 249 [32/50000]	Loss: 1.2217	LR: 0.000394
Training Epoch: 249 [32/50000]	Loss: 1.0130	LR: 0.000394
Training Epoch: 249 [32/50000]	Loss: 1.2411	LR: 0.000394
Training Epoch: 249 [32/50000]	Loss: 1.5793	LR: 0.000394
Training Epoch: 249 [32/50000]	Loss: 1.0714	LR: 0.000394
Evaluating Network.....
Test set: Epoch: 249, Average loss: 0.0469, Top1Accuracy: 0.5867, Top3Accuracy: 0.7875, Top5Accuracy: 0.8582, Time consumed:1.76s

Training Epoch: 250 [32/50000]	Loss: 1.1659	LR: 0.000384
Training Epoch: 250 [32/50000]	Loss: 1.1955	LR: 0.000384
Training Epoch: 250 [32/50000]	Loss: 1.6083	LR: 0.000384
Training Epoch: 250 [32/50000]	Loss: 1.5240	LR: 0.000384
Training Epoch: 250 [32/50000]	Loss: 1.2181	LR: 0.000384
Training Epoch: 250 [32/50000]	Loss: 1.2859	LR: 0.000384
Training Epoch: 250 [32/50000]	Loss: 1.5670	LR: 0.000384
Training Epoch: 250 [32/50000]	Loss: 1.5451	LR: 0.000384
Training Epoch: 250 [32/50000]	Loss: 1.6244	LR: 0.000384
Training Epoch: 250 [32/50000]	Loss: 1.6352	LR: 0.000384
Evaluating Network.....
Test set: Epoch: 250, Average loss: 0.0468, Top1Accuracy: 0.5884, Top3Accuracy: 0.7870, Top5Accuracy: 0.8590, Time consumed:1.80s

Training Epoch: 251 [32/50000]	Loss: 1.2298	LR: 0.000373
Training Epoch: 251 [32/50000]	Loss: 1.4308	LR: 0.000373
Training Epoch: 251 [32/50000]	Loss: 1.8266	LR: 0.000373
Training Epoch: 251 [32/50000]	Loss: 1.1408	LR: 0.000373
Training Epoch: 251 [32/50000]	Loss: 1.2158	LR: 0.000373
Training Epoch: 251 [32/50000]	Loss: 1.0566	LR: 0.000373
Training Epoch: 251 [32/50000]	Loss: 1.5214	LR: 0.000373
Training Epoch: 251 [32/50000]	Loss: 1.1311	LR: 0.000373
Training Epoch: 251 [32/50000]	Loss: 1.5034	LR: 0.000373
Training Epoch: 251 [32/50000]	Loss: 1.7112	LR: 0.000373
Evaluating Network.....
Test set: Epoch: 251, Average loss: 0.0467, Top1Accuracy: 0.5909, Top3Accuracy: 0.7876, Top5Accuracy: 0.8589, Time consumed:1.79s

Training Epoch: 252 [32/50000]	Loss: 1.3657	LR: 0.000364
Training Epoch: 252 [32/50000]	Loss: 1.2510	LR: 0.000364
Training Epoch: 252 [32/50000]	Loss: 1.0973	LR: 0.000364
Training Epoch: 252 [32/50000]	Loss: 0.9484	LR: 0.000364
Training Epoch: 252 [32/50000]	Loss: 1.2091	LR: 0.000364
Training Epoch: 252 [32/50000]	Loss: 1.4670	LR: 0.000364
Training Epoch: 252 [32/50000]	Loss: 1.3276	LR: 0.000364
Training Epoch: 252 [32/50000]	Loss: 1.5476	LR: 0.000364
Training Epoch: 252 [32/50000]	Loss: 1.0224	LR: 0.000364
Training Epoch: 252 [32/50000]	Loss: 1.3895	LR: 0.000364
Evaluating Network.....
Test set: Epoch: 252, Average loss: 0.0469, Top1Accuracy: 0.5875, Top3Accuracy: 0.7903, Top5Accuracy: 0.8589, Time consumed:1.79s

Training Epoch: 253 [32/50000]	Loss: 1.0488	LR: 0.000354
Training Epoch: 253 [32/50000]	Loss: 1.4867	LR: 0.000354
Training Epoch: 253 [32/50000]	Loss: 1.2010	LR: 0.000354
Training Epoch: 253 [32/50000]	Loss: 1.3967	LR: 0.000354
Training Epoch: 253 [32/50000]	Loss: 1.3626	LR: 0.000354
Training Epoch: 253 [32/50000]	Loss: 1.1849	LR: 0.000354
Training Epoch: 253 [32/50000]	Loss: 0.8310	LR: 0.000354
Training Epoch: 253 [32/50000]	Loss: 1.3619	LR: 0.000354
Training Epoch: 253 [32/50000]	Loss: 1.1294	LR: 0.000354
Training Epoch: 253 [32/50000]	Loss: 1.3386	LR: 0.000354
Evaluating Network.....
Test set: Epoch: 253, Average loss: 0.0467, Top1Accuracy: 0.5914, Top3Accuracy: 0.7879, Top5Accuracy: 0.8591, Time consumed:1.78s

Training Epoch: 254 [32/50000]	Loss: 1.7594	LR: 0.000345
Training Epoch: 254 [32/50000]	Loss: 1.0480	LR: 0.000345
Training Epoch: 254 [32/50000]	Loss: 1.1211	LR: 0.000345
Training Epoch: 254 [32/50000]	Loss: 1.2416	LR: 0.000345
Training Epoch: 254 [32/50000]	Loss: 1.5798	LR: 0.000345
Training Epoch: 254 [32/50000]	Loss: 1.5465	LR: 0.000345
Training Epoch: 254 [32/50000]	Loss: 1.2130	LR: 0.000345
Training Epoch: 254 [32/50000]	Loss: 1.3626	LR: 0.000345
Training Epoch: 254 [32/50000]	Loss: 1.2539	LR: 0.000345
Training Epoch: 254 [32/50000]	Loss: 1.5061	LR: 0.000345
Evaluating Network.....
Test set: Epoch: 254, Average loss: 0.0468, Top1Accuracy: 0.5897, Top3Accuracy: 0.7882, Top5Accuracy: 0.8591, Time consumed:1.79s

Training Epoch: 255 [32/50000]	Loss: 1.3388	LR: 0.000336
Training Epoch: 255 [32/50000]	Loss: 1.7034	LR: 0.000336
Training Epoch: 255 [32/50000]	Loss: 1.3682	LR: 0.000336
Training Epoch: 255 [32/50000]	Loss: 1.1474	LR: 0.000336
Training Epoch: 255 [32/50000]	Loss: 1.5685	LR: 0.000336
Training Epoch: 255 [32/50000]	Loss: 2.0521	LR: 0.000336
Training Epoch: 255 [32/50000]	Loss: 1.3573	LR: 0.000336
Training Epoch: 255 [32/50000]	Loss: 1.6761	LR: 0.000336
Training Epoch: 255 [32/50000]	Loss: 1.3878	LR: 0.000336
Training Epoch: 255 [32/50000]	Loss: 0.7138	LR: 0.000336
Evaluating Network.....
Test set: Epoch: 255, Average loss: 0.0467, Top1Accuracy: 0.5893, Top3Accuracy: 0.7879, Top5Accuracy: 0.8601, Time consumed:1.80s

Training Epoch: 256 [32/50000]	Loss: 1.2381	LR: 0.000327
Training Epoch: 256 [32/50000]	Loss: 1.5888	LR: 0.000327
Training Epoch: 256 [32/50000]	Loss: 1.4564	LR: 0.000327
Training Epoch: 256 [32/50000]	Loss: 1.3642	LR: 0.000327
Training Epoch: 256 [32/50000]	Loss: 1.6941	LR: 0.000327
Training Epoch: 256 [32/50000]	Loss: 1.6843	LR: 0.000327
Training Epoch: 256 [32/50000]	Loss: 1.1885	LR: 0.000327
Training Epoch: 256 [32/50000]	Loss: 1.1517	LR: 0.000327
Training Epoch: 256 [32/50000]	Loss: 1.3461	LR: 0.000327
Training Epoch: 256 [32/50000]	Loss: 1.2080	LR: 0.000327
Evaluating Network.....
Test set: Epoch: 256, Average loss: 0.0467, Top1Accuracy: 0.5900, Top3Accuracy: 0.7875, Top5Accuracy: 0.8600, Time consumed:1.79s

Training Epoch: 257 [32/50000]	Loss: 1.5711	LR: 0.000318
Training Epoch: 257 [32/50000]	Loss: 1.4803	LR: 0.000318
Training Epoch: 257 [32/50000]	Loss: 1.3269	LR: 0.000318
Training Epoch: 257 [32/50000]	Loss: 1.6403	LR: 0.000318
Training Epoch: 257 [32/50000]	Loss: 1.3080	LR: 0.000318
Training Epoch: 257 [32/50000]	Loss: 1.1654	LR: 0.000318
Training Epoch: 257 [32/50000]	Loss: 1.2865	LR: 0.000318
Training Epoch: 257 [32/50000]	Loss: 0.9829	LR: 0.000318
Training Epoch: 257 [32/50000]	Loss: 1.5955	LR: 0.000318
Training Epoch: 257 [32/50000]	Loss: 1.0223	LR: 0.000318
Evaluating Network.....
Test set: Epoch: 257, Average loss: 0.0467, Top1Accuracy: 0.5906, Top3Accuracy: 0.7884, Top5Accuracy: 0.8598, Time consumed:1.82s

Training Epoch: 258 [32/50000]	Loss: 1.0430	LR: 0.000310
Training Epoch: 258 [32/50000]	Loss: 1.2304	LR: 0.000310
Training Epoch: 258 [32/50000]	Loss: 1.5720	LR: 0.000310
Training Epoch: 258 [32/50000]	Loss: 1.8966	LR: 0.000310
Training Epoch: 258 [32/50000]	Loss: 1.0342	LR: 0.000310
Training Epoch: 258 [32/50000]	Loss: 1.1713	LR: 0.000310
Training Epoch: 258 [32/50000]	Loss: 1.6887	LR: 0.000310
Training Epoch: 258 [32/50000]	Loss: 1.1132	LR: 0.000310
Training Epoch: 258 [32/50000]	Loss: 1.4295	LR: 0.000310
Training Epoch: 258 [32/50000]	Loss: 1.6963	LR: 0.000310
Evaluating Network.....
Test set: Epoch: 258, Average loss: 0.0466, Top1Accuracy: 0.5897, Top3Accuracy: 0.7897, Top5Accuracy: 0.8600, Time consumed:1.80s

Training Epoch: 259 [32/50000]	Loss: 1.2956	LR: 0.000302
Training Epoch: 259 [32/50000]	Loss: 1.6285	LR: 0.000302
Training Epoch: 259 [32/50000]	Loss: 1.0416	LR: 0.000302
Training Epoch: 259 [32/50000]	Loss: 1.4372	LR: 0.000302
Training Epoch: 259 [32/50000]	Loss: 1.0130	LR: 0.000302
Training Epoch: 259 [32/50000]	Loss: 1.5811	LR: 0.000302
Training Epoch: 259 [32/50000]	Loss: 1.0556	LR: 0.000302
Training Epoch: 259 [32/50000]	Loss: 1.2467	LR: 0.000302
Training Epoch: 259 [32/50000]	Loss: 1.3759	LR: 0.000302
Training Epoch: 259 [32/50000]	Loss: 1.1463	LR: 0.000302
Evaluating Network.....
Test set: Epoch: 259, Average loss: 0.0467, Top1Accuracy: 0.5895, Top3Accuracy: 0.7887, Top5Accuracy: 0.8596, Time consumed:1.77s

Training Epoch: 260 [32/50000]	Loss: 1.3530	LR: 0.000294
Training Epoch: 260 [32/50000]	Loss: 1.2809	LR: 0.000294
Training Epoch: 260 [32/50000]	Loss: 1.1014	LR: 0.000294
Training Epoch: 260 [32/50000]	Loss: 1.2728	LR: 0.000294
Training Epoch: 260 [32/50000]	Loss: 1.4886	LR: 0.000294
Training Epoch: 260 [32/50000]	Loss: 1.4211	LR: 0.000294
Training Epoch: 260 [32/50000]	Loss: 0.9231	LR: 0.000294
Training Epoch: 260 [32/50000]	Loss: 1.2546	LR: 0.000294
Training Epoch: 260 [32/50000]	Loss: 1.0947	LR: 0.000294
Training Epoch: 260 [32/50000]	Loss: 1.5023	LR: 0.000294
Evaluating Network.....
Test set: Epoch: 260, Average loss: 0.0467, Top1Accuracy: 0.5892, Top3Accuracy: 0.7883, Top5Accuracy: 0.8594, Time consumed:1.83s

Training Epoch: 261 [32/50000]	Loss: 1.6298	LR: 0.000286
Training Epoch: 261 [32/50000]	Loss: 1.7332	LR: 0.000286
Training Epoch: 261 [32/50000]	Loss: 1.3858	LR: 0.000286
Training Epoch: 261 [32/50000]	Loss: 1.3171	LR: 0.000286
Training Epoch: 261 [32/50000]	Loss: 0.8892	LR: 0.000286
Training Epoch: 261 [32/50000]	Loss: 1.4527	LR: 0.000286
Training Epoch: 261 [32/50000]	Loss: 1.0285	LR: 0.000286
Training Epoch: 261 [32/50000]	Loss: 1.6055	LR: 0.000286
Training Epoch: 261 [32/50000]	Loss: 1.1748	LR: 0.000286
Training Epoch: 261 [32/50000]	Loss: 1.2142	LR: 0.000286
Evaluating Network.....
Test set: Epoch: 261, Average loss: 0.0466, Top1Accuracy: 0.5900, Top3Accuracy: 0.7889, Top5Accuracy: 0.8600, Time consumed:1.76s

Training Epoch: 262 [32/50000]	Loss: 1.5636	LR: 0.000278
Training Epoch: 262 [32/50000]	Loss: 1.5599	LR: 0.000278
Training Epoch: 262 [32/50000]	Loss: 1.7164	LR: 0.000278
Training Epoch: 262 [32/50000]	Loss: 1.6179	LR: 0.000278
Training Epoch: 262 [32/50000]	Loss: 1.2929	LR: 0.000278
Training Epoch: 262 [32/50000]	Loss: 1.3651	LR: 0.000278
Training Epoch: 262 [32/50000]	Loss: 1.3026	LR: 0.000278
Training Epoch: 262 [32/50000]	Loss: 1.4558	LR: 0.000278
Training Epoch: 262 [32/50000]	Loss: 1.0528	LR: 0.000278
Training Epoch: 262 [32/50000]	Loss: 1.7872	LR: 0.000278
Evaluating Network.....
Test set: Epoch: 262, Average loss: 0.0466, Top1Accuracy: 0.5900, Top3Accuracy: 0.7881, Top5Accuracy: 0.8605, Time consumed:1.78s

Training Epoch: 263 [32/50000]	Loss: 1.1875	LR: 0.000271
Training Epoch: 263 [32/50000]	Loss: 1.3046	LR: 0.000271
Training Epoch: 263 [32/50000]	Loss: 0.9360	LR: 0.000271
Training Epoch: 263 [32/50000]	Loss: 1.2470	LR: 0.000271
Training Epoch: 263 [32/50000]	Loss: 1.4788	LR: 0.000271
Training Epoch: 263 [32/50000]	Loss: 1.3456	LR: 0.000271
Training Epoch: 263 [32/50000]	Loss: 1.7772	LR: 0.000271
Training Epoch: 263 [32/50000]	Loss: 0.9906	LR: 0.000271
Training Epoch: 263 [32/50000]	Loss: 1.6978	LR: 0.000271
Training Epoch: 263 [32/50000]	Loss: 1.2459	LR: 0.000271
Evaluating Network.....
Test set: Epoch: 263, Average loss: 0.0467, Top1Accuracy: 0.5888, Top3Accuracy: 0.7881, Top5Accuracy: 0.8584, Time consumed:1.79s

Training Epoch: 264 [32/50000]	Loss: 1.2545	LR: 0.000264
Training Epoch: 264 [32/50000]	Loss: 1.0187	LR: 0.000264
Training Epoch: 264 [32/50000]	Loss: 1.1508	LR: 0.000264
Training Epoch: 264 [32/50000]	Loss: 1.4585	LR: 0.000264
Training Epoch: 264 [32/50000]	Loss: 1.5095	LR: 0.000264
Training Epoch: 264 [32/50000]	Loss: 1.4430	LR: 0.000264
Training Epoch: 264 [32/50000]	Loss: 1.2372	LR: 0.000264
Training Epoch: 264 [32/50000]	Loss: 1.3001	LR: 0.000264
Training Epoch: 264 [32/50000]	Loss: 1.5384	LR: 0.000264
Training Epoch: 264 [32/50000]	Loss: 1.1385	LR: 0.000264
Evaluating Network.....
Test set: Epoch: 264, Average loss: 0.0467, Top1Accuracy: 0.5895, Top3Accuracy: 0.7879, Top5Accuracy: 0.8589, Time consumed:1.80s

Training Epoch: 265 [32/50000]	Loss: 1.0257	LR: 0.000257
Training Epoch: 265 [32/50000]	Loss: 1.5235	LR: 0.000257
Training Epoch: 265 [32/50000]	Loss: 1.4263	LR: 0.000257
Training Epoch: 265 [32/50000]	Loss: 1.5391	LR: 0.000257
Training Epoch: 265 [32/50000]	Loss: 1.2819	LR: 0.000257
Training Epoch: 265 [32/50000]	Loss: 1.5059	LR: 0.000257
Training Epoch: 265 [32/50000]	Loss: 1.5104	LR: 0.000257
Training Epoch: 265 [32/50000]	Loss: 1.3435	LR: 0.000257
Training Epoch: 265 [32/50000]	Loss: 1.0889	LR: 0.000257
Training Epoch: 265 [32/50000]	Loss: 1.2129	LR: 0.000257
Evaluating Network.....
Test set: Epoch: 265, Average loss: 0.0466, Top1Accuracy: 0.5904, Top3Accuracy: 0.7886, Top5Accuracy: 0.8595, Time consumed:1.81s

Training Epoch: 266 [32/50000]	Loss: 1.0605	LR: 0.000250
Training Epoch: 266 [32/50000]	Loss: 1.0280	LR: 0.000250
Training Epoch: 266 [32/50000]	Loss: 1.4136	LR: 0.000250
Training Epoch: 266 [32/50000]	Loss: 1.6585	LR: 0.000250
Training Epoch: 266 [32/50000]	Loss: 1.4749	LR: 0.000250
Training Epoch: 266 [32/50000]	Loss: 1.4416	LR: 0.000250
Training Epoch: 266 [32/50000]	Loss: 1.1864	LR: 0.000250
Training Epoch: 266 [32/50000]	Loss: 0.8098	LR: 0.000250
Training Epoch: 266 [32/50000]	Loss: 1.1065	LR: 0.000250
Training Epoch: 266 [32/50000]	Loss: 1.2384	LR: 0.000250
Evaluating Network.....
Test set: Epoch: 266, Average loss: 0.0467, Top1Accuracy: 0.5903, Top3Accuracy: 0.7877, Top5Accuracy: 0.8585, Time consumed:1.79s

Training Epoch: 267 [32/50000]	Loss: 1.5749	LR: 0.000243
Training Epoch: 267 [32/50000]	Loss: 1.2697	LR: 0.000243
Training Epoch: 267 [32/50000]	Loss: 1.2258	LR: 0.000243
Training Epoch: 267 [32/50000]	Loss: 1.2021	LR: 0.000243
Training Epoch: 267 [32/50000]	Loss: 1.5709	LR: 0.000243
Training Epoch: 267 [32/50000]	Loss: 1.3535	LR: 0.000243
Training Epoch: 267 [32/50000]	Loss: 1.2311	LR: 0.000243
Training Epoch: 267 [32/50000]	Loss: 1.4250	LR: 0.000243
Training Epoch: 267 [32/50000]	Loss: 1.2348	LR: 0.000243
Training Epoch: 267 [32/50000]	Loss: 1.1989	LR: 0.000243
Evaluating Network.....
Test set: Epoch: 267, Average loss: 0.0466, Top1Accuracy: 0.5923, Top3Accuracy: 0.7872, Top5Accuracy: 0.8596, Time consumed:1.81s

Training Epoch: 268 [32/50000]	Loss: 1.4897	LR: 0.000237
Training Epoch: 268 [32/50000]	Loss: 0.8393	LR: 0.000237
Training Epoch: 268 [32/50000]	Loss: 1.9481	LR: 0.000237
Training Epoch: 268 [32/50000]	Loss: 0.9608	LR: 0.000237
Training Epoch: 268 [32/50000]	Loss: 1.0491	LR: 0.000237
Training Epoch: 268 [32/50000]	Loss: 1.3354	LR: 0.000237
Training Epoch: 268 [32/50000]	Loss: 1.6436	LR: 0.000237
Training Epoch: 268 [32/50000]	Loss: 1.1605	LR: 0.000237
Training Epoch: 268 [32/50000]	Loss: 0.9857	LR: 0.000237
Training Epoch: 268 [32/50000]	Loss: 1.2225	LR: 0.000237
Evaluating Network.....
Test set: Epoch: 268, Average loss: 0.0465, Top1Accuracy: 0.5901, Top3Accuracy: 0.7884, Top5Accuracy: 0.8605, Time consumed:1.76s

Training Epoch: 269 [32/50000]	Loss: 1.1808	LR: 0.000231
Training Epoch: 269 [32/50000]	Loss: 1.6641	LR: 0.000231
Training Epoch: 269 [32/50000]	Loss: 1.2309	LR: 0.000231
Training Epoch: 269 [32/50000]	Loss: 1.5167	LR: 0.000231
Training Epoch: 269 [32/50000]	Loss: 1.9822	LR: 0.000231
Training Epoch: 269 [32/50000]	Loss: 1.0223	LR: 0.000231
Training Epoch: 269 [32/50000]	Loss: 1.4896	LR: 0.000231
Training Epoch: 269 [32/50000]	Loss: 1.5560	LR: 0.000231
Training Epoch: 269 [32/50000]	Loss: 1.8538	LR: 0.000231
Training Epoch: 269 [32/50000]	Loss: 1.3113	LR: 0.000231
Evaluating Network.....
Test set: Epoch: 269, Average loss: 0.0467, Top1Accuracy: 0.5913, Top3Accuracy: 0.7870, Top5Accuracy: 0.8592, Time consumed:1.79s

Training Epoch: 270 [32/50000]	Loss: 1.4146	LR: 0.000225
Training Epoch: 270 [32/50000]	Loss: 1.1123	LR: 0.000225
Training Epoch: 270 [32/50000]	Loss: 1.5308	LR: 0.000225
Training Epoch: 270 [32/50000]	Loss: 1.3355	LR: 0.000225
Training Epoch: 270 [32/50000]	Loss: 1.2396	LR: 0.000225
Training Epoch: 270 [32/50000]	Loss: 1.0873	LR: 0.000225
Training Epoch: 270 [32/50000]	Loss: 1.0791	LR: 0.000225
Training Epoch: 270 [32/50000]	Loss: 1.0636	LR: 0.000225
Training Epoch: 270 [32/50000]	Loss: 1.3616	LR: 0.000225
Training Epoch: 270 [32/50000]	Loss: 1.7420	LR: 0.000225
Evaluating Network.....
Test set: Epoch: 270, Average loss: 0.0467, Top1Accuracy: 0.5909, Top3Accuracy: 0.7864, Top5Accuracy: 0.8598, Time consumed:1.79s

Training Epoch: 271 [32/50000]	Loss: 1.2379	LR: 0.000219
Training Epoch: 271 [32/50000]	Loss: 1.2865	LR: 0.000219
Training Epoch: 271 [32/50000]	Loss: 1.3026	LR: 0.000219
Training Epoch: 271 [32/50000]	Loss: 1.2065	LR: 0.000219
Training Epoch: 271 [32/50000]	Loss: 1.1674	LR: 0.000219
Training Epoch: 271 [32/50000]	Loss: 1.1953	LR: 0.000219
Training Epoch: 271 [32/50000]	Loss: 1.2724	LR: 0.000219
Training Epoch: 271 [32/50000]	Loss: 1.0944	LR: 0.000219
Training Epoch: 271 [32/50000]	Loss: 1.4497	LR: 0.000219
Training Epoch: 271 [32/50000]	Loss: 1.0944	LR: 0.000219
Evaluating Network.....
Test set: Epoch: 271, Average loss: 0.0466, Top1Accuracy: 0.5891, Top3Accuracy: 0.7888, Top5Accuracy: 0.8598, Time consumed:1.76s

Training Epoch: 272 [32/50000]	Loss: 1.4622	LR: 0.000213
Training Epoch: 272 [32/50000]	Loss: 1.2001	LR: 0.000213
Training Epoch: 272 [32/50000]	Loss: 1.8895	LR: 0.000213
Training Epoch: 272 [32/50000]	Loss: 1.7227	LR: 0.000213
Training Epoch: 272 [32/50000]	Loss: 1.3041	LR: 0.000213
Training Epoch: 272 [32/50000]	Loss: 1.2433	LR: 0.000213
Training Epoch: 272 [32/50000]	Loss: 1.3775	LR: 0.000213
Training Epoch: 272 [32/50000]	Loss: 1.2615	LR: 0.000213
Training Epoch: 272 [32/50000]	Loss: 1.1731	LR: 0.000213
Training Epoch: 272 [32/50000]	Loss: 1.5043	LR: 0.000213
Evaluating Network.....
Test set: Epoch: 272, Average loss: 0.0466, Top1Accuracy: 0.5909, Top3Accuracy: 0.7885, Top5Accuracy: 0.8596, Time consumed:1.78s

Training Epoch: 273 [32/50000]	Loss: 1.2880	LR: 0.000207
Training Epoch: 273 [32/50000]	Loss: 1.8254	LR: 0.000207
Training Epoch: 273 [32/50000]	Loss: 1.2718	LR: 0.000207
Training Epoch: 273 [32/50000]	Loss: 1.2659	LR: 0.000207
Training Epoch: 273 [32/50000]	Loss: 0.8876	LR: 0.000207
Training Epoch: 273 [32/50000]	Loss: 1.3378	LR: 0.000207
Training Epoch: 273 [32/50000]	Loss: 0.9813	LR: 0.000207
Training Epoch: 273 [32/50000]	Loss: 1.1533	LR: 0.000207
Training Epoch: 273 [32/50000]	Loss: 1.3020	LR: 0.000207
Training Epoch: 273 [32/50000]	Loss: 1.1501	LR: 0.000207
Evaluating Network.....
Test set: Epoch: 273, Average loss: 0.0466, Top1Accuracy: 0.5897, Top3Accuracy: 0.7883, Top5Accuracy: 0.8600, Time consumed:1.78s

Training Epoch: 274 [32/50000]	Loss: 1.6008	LR: 0.000202
Training Epoch: 274 [32/50000]	Loss: 1.0287	LR: 0.000202
Training Epoch: 274 [32/50000]	Loss: 1.6311	LR: 0.000202
Training Epoch: 274 [32/50000]	Loss: 1.5065	LR: 0.000202
Training Epoch: 274 [32/50000]	Loss: 1.3020	LR: 0.000202
Training Epoch: 274 [32/50000]	Loss: 1.3515	LR: 0.000202
Training Epoch: 274 [32/50000]	Loss: 1.3351	LR: 0.000202
Training Epoch: 274 [32/50000]	Loss: 1.3574	LR: 0.000202
Training Epoch: 274 [32/50000]	Loss: 1.0506	LR: 0.000202
Training Epoch: 274 [32/50000]	Loss: 2.0055	LR: 0.000202
Evaluating Network.....
Test set: Epoch: 274, Average loss: 0.0465, Top1Accuracy: 0.5914, Top3Accuracy: 0.7911, Top5Accuracy: 0.8605, Time consumed:1.77s

Training Epoch: 275 [32/50000]	Loss: 1.5483	LR: 0.000197
Training Epoch: 275 [32/50000]	Loss: 1.2708	LR: 0.000197
Training Epoch: 275 [32/50000]	Loss: 1.1766	LR: 0.000197
Training Epoch: 275 [32/50000]	Loss: 1.4722	LR: 0.000197
Training Epoch: 275 [32/50000]	Loss: 1.5682	LR: 0.000197
Training Epoch: 275 [32/50000]	Loss: 0.8129	LR: 0.000197
Training Epoch: 275 [32/50000]	Loss: 1.6143	LR: 0.000197
Training Epoch: 275 [32/50000]	Loss: 1.1666	LR: 0.000197
Training Epoch: 275 [32/50000]	Loss: 1.1315	LR: 0.000197
Training Epoch: 275 [32/50000]	Loss: 1.6244	LR: 0.000197
Evaluating Network.....
Test set: Epoch: 275, Average loss: 0.0465, Top1Accuracy: 0.5911, Top3Accuracy: 0.7897, Top5Accuracy: 0.8593, Time consumed:1.79s

Training Epoch: 276 [32/50000]	Loss: 1.7524	LR: 0.000191
Training Epoch: 276 [32/50000]	Loss: 1.5410	LR: 0.000191
Training Epoch: 276 [32/50000]	Loss: 1.6055	LR: 0.000191
Training Epoch: 276 [32/50000]	Loss: 1.8380	LR: 0.000191
Training Epoch: 276 [32/50000]	Loss: 1.0716	LR: 0.000191
Training Epoch: 276 [32/50000]	Loss: 1.1280	LR: 0.000191
Training Epoch: 276 [32/50000]	Loss: 1.0884	LR: 0.000191
Training Epoch: 276 [32/50000]	Loss: 1.5720	LR: 0.000191
Training Epoch: 276 [32/50000]	Loss: 1.0413	LR: 0.000191
Training Epoch: 276 [32/50000]	Loss: 1.4609	LR: 0.000191
Evaluating Network.....
Test set: Epoch: 276, Average loss: 0.0466, Top1Accuracy: 0.5905, Top3Accuracy: 0.7878, Top5Accuracy: 0.8609, Time consumed:1.80s

Training Epoch: 277 [32/50000]	Loss: 1.1839	LR: 0.000186
Training Epoch: 277 [32/50000]	Loss: 1.2855	LR: 0.000186
Training Epoch: 277 [32/50000]	Loss: 1.4899	LR: 0.000186
Training Epoch: 277 [32/50000]	Loss: 1.1953	LR: 0.000186
Training Epoch: 277 [32/50000]	Loss: 1.3529	LR: 0.000186
Training Epoch: 277 [32/50000]	Loss: 0.8337	LR: 0.000186
Training Epoch: 277 [32/50000]	Loss: 1.2456	LR: 0.000186
Training Epoch: 277 [32/50000]	Loss: 1.2077	LR: 0.000186
Training Epoch: 277 [32/50000]	Loss: 1.3148	LR: 0.000186
Training Epoch: 277 [32/50000]	Loss: 1.1219	LR: 0.000186
Evaluating Network.....
Test set: Epoch: 277, Average loss: 0.0465, Top1Accuracy: 0.5915, Top3Accuracy: 0.7887, Top5Accuracy: 0.8604, Time consumed:1.80s

Training Epoch: 278 [32/50000]	Loss: 1.4456	LR: 0.000181
Training Epoch: 278 [32/50000]	Loss: 1.5028	LR: 0.000181
Training Epoch: 278 [32/50000]	Loss: 1.4137	LR: 0.000181
Training Epoch: 278 [32/50000]	Loss: 1.2162	LR: 0.000181
Training Epoch: 278 [32/50000]	Loss: 1.0745	LR: 0.000181
Training Epoch: 278 [32/50000]	Loss: 1.6388	LR: 0.000181
Training Epoch: 278 [32/50000]	Loss: 1.5129	LR: 0.000181
Training Epoch: 278 [32/50000]	Loss: 1.2854	LR: 0.000181
Training Epoch: 278 [32/50000]	Loss: 0.6351	LR: 0.000181
Training Epoch: 278 [32/50000]	Loss: 1.6420	LR: 0.000181
Evaluating Network.....
Test set: Epoch: 278, Average loss: 0.0466, Top1Accuracy: 0.5907, Top3Accuracy: 0.7895, Top5Accuracy: 0.8603, Time consumed:1.77s

Training Epoch: 279 [32/50000]	Loss: 1.4863	LR: 0.000177
Training Epoch: 279 [32/50000]	Loss: 1.7888	LR: 0.000177
Training Epoch: 279 [32/50000]	Loss: 1.2587	LR: 0.000177
Training Epoch: 279 [32/50000]	Loss: 1.3825	LR: 0.000177
Training Epoch: 279 [32/50000]	Loss: 1.3951	LR: 0.000177
Training Epoch: 279 [32/50000]	Loss: 0.9055	LR: 0.000177
Training Epoch: 279 [32/50000]	Loss: 1.0736	LR: 0.000177
Training Epoch: 279 [32/50000]	Loss: 1.2652	LR: 0.000177
Training Epoch: 279 [32/50000]	Loss: 1.1139	LR: 0.000177
Training Epoch: 279 [32/50000]	Loss: 1.6530	LR: 0.000177
Evaluating Network.....
Test set: Epoch: 279, Average loss: 0.0466, Top1Accuracy: 0.5880, Top3Accuracy: 0.7889, Top5Accuracy: 0.8600, Time consumed:1.78s

Training Epoch: 280 [32/50000]	Loss: 0.9686	LR: 0.000172
Training Epoch: 280 [32/50000]	Loss: 1.4535	LR: 0.000172
Training Epoch: 280 [32/50000]	Loss: 1.3870	LR: 0.000172
Training Epoch: 280 [32/50000]	Loss: 1.4737	LR: 0.000172
Training Epoch: 280 [32/50000]	Loss: 1.3672	LR: 0.000172
Training Epoch: 280 [32/50000]	Loss: 1.5692	LR: 0.000172
Training Epoch: 280 [32/50000]	Loss: 1.1558	LR: 0.000172
Training Epoch: 280 [32/50000]	Loss: 1.4038	LR: 0.000172
Training Epoch: 280 [32/50000]	Loss: 1.2944	LR: 0.000172
Training Epoch: 280 [32/50000]	Loss: 1.5415	LR: 0.000172
Evaluating Network.....
Test set: Epoch: 280, Average loss: 0.0466, Top1Accuracy: 0.5905, Top3Accuracy: 0.7877, Top5Accuracy: 0.8602, Time consumed:1.75s

Training Epoch: 281 [32/50000]	Loss: 0.9968	LR: 0.000167
Training Epoch: 281 [32/50000]	Loss: 1.6705	LR: 0.000167
Training Epoch: 281 [32/50000]	Loss: 0.9832	LR: 0.000167
Training Epoch: 281 [32/50000]	Loss: 1.1154	LR: 0.000167
Training Epoch: 281 [32/50000]	Loss: 1.0873	LR: 0.000167
Training Epoch: 281 [32/50000]	Loss: 1.1366	LR: 0.000167
Training Epoch: 281 [32/50000]	Loss: 1.3111	LR: 0.000167
Training Epoch: 281 [32/50000]	Loss: 1.2313	LR: 0.000167
Training Epoch: 281 [32/50000]	Loss: 1.2202	LR: 0.000167
Training Epoch: 281 [32/50000]	Loss: 1.5329	LR: 0.000167
Evaluating Network.....
Test set: Epoch: 281, Average loss: 0.0465, Top1Accuracy: 0.5905, Top3Accuracy: 0.7912, Top5Accuracy: 0.8605, Time consumed:1.85s

Training Epoch: 282 [32/50000]	Loss: 1.2315	LR: 0.000163
Training Epoch: 282 [32/50000]	Loss: 1.2914	LR: 0.000163
Training Epoch: 282 [32/50000]	Loss: 1.8225	LR: 0.000163
Training Epoch: 282 [32/50000]	Loss: 1.0640	LR: 0.000163
Training Epoch: 282 [32/50000]	Loss: 1.6581	LR: 0.000163
Training Epoch: 282 [32/50000]	Loss: 1.1569	LR: 0.000163
Training Epoch: 282 [32/50000]	Loss: 1.6316	LR: 0.000163
Training Epoch: 282 [32/50000]	Loss: 1.2804	LR: 0.000163
Training Epoch: 282 [32/50000]	Loss: 1.1730	LR: 0.000163
Training Epoch: 282 [32/50000]	Loss: 1.3469	LR: 0.000163
Evaluating Network.....
Test set: Epoch: 282, Average loss: 0.0465, Top1Accuracy: 0.5915, Top3Accuracy: 0.7894, Top5Accuracy: 0.8603, Time consumed:1.79s

Training Epoch: 283 [32/50000]	Loss: 1.3749	LR: 0.000159
Training Epoch: 283 [32/50000]	Loss: 1.1837	LR: 0.000159
Training Epoch: 283 [32/50000]	Loss: 1.4480	LR: 0.000159
Training Epoch: 283 [32/50000]	Loss: 1.7970	LR: 0.000159
Training Epoch: 283 [32/50000]	Loss: 1.3764	LR: 0.000159
Training Epoch: 283 [32/50000]	Loss: 1.4109	LR: 0.000159
Training Epoch: 283 [32/50000]	Loss: 1.0507	LR: 0.000159
Training Epoch: 283 [32/50000]	Loss: 1.3564	LR: 0.000159
Training Epoch: 283 [32/50000]	Loss: 1.0572	LR: 0.000159
Training Epoch: 283 [32/50000]	Loss: 1.3984	LR: 0.000159
Evaluating Network.....
Test set: Epoch: 283, Average loss: 0.0465, Top1Accuracy: 0.5916, Top3Accuracy: 0.7884, Top5Accuracy: 0.8606, Time consumed:1.78s

Training Epoch: 284 [32/50000]	Loss: 1.4955	LR: 0.000154
Training Epoch: 284 [32/50000]	Loss: 0.9353	LR: 0.000154
Training Epoch: 284 [32/50000]	Loss: 1.1084	LR: 0.000154
Training Epoch: 284 [32/50000]	Loss: 1.2282	LR: 0.000154
Training Epoch: 284 [32/50000]	Loss: 1.0563	LR: 0.000154
Training Epoch: 284 [32/50000]	Loss: 1.0252	LR: 0.000154
Training Epoch: 284 [32/50000]	Loss: 1.6442	LR: 0.000154
Training Epoch: 284 [32/50000]	Loss: 1.3080	LR: 0.000154
Training Epoch: 284 [32/50000]	Loss: 1.3642	LR: 0.000154
Training Epoch: 284 [32/50000]	Loss: 1.1825	LR: 0.000154
Evaluating Network.....
Test set: Epoch: 284, Average loss: 0.0465, Top1Accuracy: 0.5900, Top3Accuracy: 0.7900, Top5Accuracy: 0.8605, Time consumed:1.79s

Training Epoch: 285 [32/50000]	Loss: 1.1983	LR: 0.000150
Training Epoch: 285 [32/50000]	Loss: 1.0680	LR: 0.000150
Training Epoch: 285 [32/50000]	Loss: 1.6580	LR: 0.000150
Training Epoch: 285 [32/50000]	Loss: 1.3852	LR: 0.000150
Training Epoch: 285 [32/50000]	Loss: 1.1985	LR: 0.000150
Training Epoch: 285 [32/50000]	Loss: 0.9066	LR: 0.000150
Training Epoch: 285 [32/50000]	Loss: 0.9256	LR: 0.000150
Training Epoch: 285 [32/50000]	Loss: 0.9642	LR: 0.000150
Training Epoch: 285 [32/50000]	Loss: 1.1136	LR: 0.000150
Training Epoch: 285 [32/50000]	Loss: 1.5870	LR: 0.000150
Evaluating Network.....
Test set: Epoch: 285, Average loss: 0.0466, Top1Accuracy: 0.5932, Top3Accuracy: 0.7903, Top5Accuracy: 0.8599, Time consumed:1.83s

Training Epoch: 286 [32/50000]	Loss: 1.5419	LR: 0.000146
Training Epoch: 286 [32/50000]	Loss: 1.8097	LR: 0.000146
Training Epoch: 286 [32/50000]	Loss: 1.2578	LR: 0.000146
Training Epoch: 286 [32/50000]	Loss: 1.1240	LR: 0.000146
Training Epoch: 286 [32/50000]	Loss: 1.2333	LR: 0.000146
Training Epoch: 286 [32/50000]	Loss: 1.3504	LR: 0.000146
Training Epoch: 286 [32/50000]	Loss: 1.3979	LR: 0.000146
Training Epoch: 286 [32/50000]	Loss: 0.9842	LR: 0.000146
Training Epoch: 286 [32/50000]	Loss: 1.1605	LR: 0.000146
Training Epoch: 286 [32/50000]	Loss: 1.1178	LR: 0.000146
Evaluating Network.....
Test set: Epoch: 286, Average loss: 0.0465, Top1Accuracy: 0.5895, Top3Accuracy: 0.7899, Top5Accuracy: 0.8618, Time consumed:1.79s

Training Epoch: 287 [32/50000]	Loss: 0.9538	LR: 0.000143
Training Epoch: 287 [32/50000]	Loss: 1.3363	LR: 0.000143
Training Epoch: 287 [32/50000]	Loss: 1.7569	LR: 0.000143
Training Epoch: 287 [32/50000]	Loss: 1.5617	LR: 0.000143
Training Epoch: 287 [32/50000]	Loss: 1.0604	LR: 0.000143
Training Epoch: 287 [32/50000]	Loss: 1.4873	LR: 0.000143
Training Epoch: 287 [32/50000]	Loss: 1.4122	LR: 0.000143
Training Epoch: 287 [32/50000]	Loss: 1.3540	LR: 0.000143
Training Epoch: 287 [32/50000]	Loss: 1.1508	LR: 0.000143
Training Epoch: 287 [32/50000]	Loss: 1.1557	LR: 0.000143
Evaluating Network.....
Test set: Epoch: 287, Average loss: 0.0466, Top1Accuracy: 0.5915, Top3Accuracy: 0.7901, Top5Accuracy: 0.8615, Time consumed:1.78s

Training Epoch: 288 [32/50000]	Loss: 1.4945	LR: 0.000139
Training Epoch: 288 [32/50000]	Loss: 1.0873	LR: 0.000139
Training Epoch: 288 [32/50000]	Loss: 1.3905	LR: 0.000139
Training Epoch: 288 [32/50000]	Loss: 0.9054	LR: 0.000139
Training Epoch: 288 [32/50000]	Loss: 1.8422	LR: 0.000139
Training Epoch: 288 [32/50000]	Loss: 1.3126	LR: 0.000139
Training Epoch: 288 [32/50000]	Loss: 1.7201	LR: 0.000139
Training Epoch: 288 [32/50000]	Loss: 0.9911	LR: 0.000139
Training Epoch: 288 [32/50000]	Loss: 1.3737	LR: 0.000139
Training Epoch: 288 [32/50000]	Loss: 1.3686	LR: 0.000139
Evaluating Network.....
Test set: Epoch: 288, Average loss: 0.0464, Top1Accuracy: 0.5907, Top3Accuracy: 0.7899, Top5Accuracy: 0.8611, Time consumed:1.84s

Training Epoch: 289 [32/50000]	Loss: 1.2215	LR: 0.000135
Training Epoch: 289 [32/50000]	Loss: 1.4886	LR: 0.000135
Training Epoch: 289 [32/50000]	Loss: 1.2051	LR: 0.000135
Training Epoch: 289 [32/50000]	Loss: 1.5573	LR: 0.000135
Training Epoch: 289 [32/50000]	Loss: 1.6140	LR: 0.000135
Training Epoch: 289 [32/50000]	Loss: 1.1479	LR: 0.000135
Training Epoch: 289 [32/50000]	Loss: 1.3487	LR: 0.000135
Training Epoch: 289 [32/50000]	Loss: 1.1145	LR: 0.000135
Training Epoch: 289 [32/50000]	Loss: 1.3421	LR: 0.000135
Training Epoch: 289 [32/50000]	Loss: 1.3347	LR: 0.000135
Evaluating Network.....
Test set: Epoch: 289, Average loss: 0.0465, Top1Accuracy: 0.5918, Top3Accuracy: 0.7900, Top5Accuracy: 0.8603, Time consumed:1.80s

Training Epoch: 290 [32/50000]	Loss: 0.9401	LR: 0.000132
Training Epoch: 290 [32/50000]	Loss: 1.4837	LR: 0.000132
Training Epoch: 290 [32/50000]	Loss: 1.1599	LR: 0.000132
Training Epoch: 290 [32/50000]	Loss: 1.1735	LR: 0.000132
Training Epoch: 290 [32/50000]	Loss: 1.2367	LR: 0.000132
Training Epoch: 290 [32/50000]	Loss: 1.1490	LR: 0.000132
Training Epoch: 290 [32/50000]	Loss: 1.0668	LR: 0.000132
Training Epoch: 290 [32/50000]	Loss: 1.3371	LR: 0.000132
Training Epoch: 290 [32/50000]	Loss: 1.3116	LR: 0.000132
Training Epoch: 290 [32/50000]	Loss: 1.3559	LR: 0.000132
Evaluating Network.....
Test set: Epoch: 290, Average loss: 0.0466, Top1Accuracy: 0.5899, Top3Accuracy: 0.7894, Top5Accuracy: 0.8606, Time consumed:1.79s

Training Epoch: 291 [32/50000]	Loss: 1.4847	LR: 0.000128
Training Epoch: 291 [32/50000]	Loss: 1.4939	LR: 0.000128
Training Epoch: 291 [32/50000]	Loss: 0.8971	LR: 0.000128
Training Epoch: 291 [32/50000]	Loss: 1.4637	LR: 0.000128
Training Epoch: 291 [32/50000]	Loss: 1.4689	LR: 0.000128
Training Epoch: 291 [32/50000]	Loss: 1.1414	LR: 0.000128
Training Epoch: 291 [32/50000]	Loss: 2.1651	LR: 0.000128
Training Epoch: 291 [32/50000]	Loss: 1.0997	LR: 0.000128
Training Epoch: 291 [32/50000]	Loss: 1.0863	LR: 0.000128
Training Epoch: 291 [32/50000]	Loss: 1.1466	LR: 0.000128
Evaluating Network.....
Test set: Epoch: 291, Average loss: 0.0465, Top1Accuracy: 0.5920, Top3Accuracy: 0.7892, Top5Accuracy: 0.8620, Time consumed:1.76s

Training Epoch: 292 [32/50000]	Loss: 1.4896	LR: 0.000125
Training Epoch: 292 [32/50000]	Loss: 1.0418	LR: 0.000125
Training Epoch: 292 [32/50000]	Loss: 1.3147	LR: 0.000125
Training Epoch: 292 [32/50000]	Loss: 0.7674	LR: 0.000125
Training Epoch: 292 [32/50000]	Loss: 1.5722	LR: 0.000125
Training Epoch: 292 [32/50000]	Loss: 1.4965	LR: 0.000125
Training Epoch: 292 [32/50000]	Loss: 1.3411	LR: 0.000125
Training Epoch: 292 [32/50000]	Loss: 1.0623	LR: 0.000125
Training Epoch: 292 [32/50000]	Loss: 1.2301	LR: 0.000125
Training Epoch: 292 [32/50000]	Loss: 1.1015	LR: 0.000125
Evaluating Network.....
Test set: Epoch: 292, Average loss: 0.0465, Top1Accuracy: 0.5920, Top3Accuracy: 0.7900, Top5Accuracy: 0.8610, Time consumed:1.78s

Training Epoch: 293 [32/50000]	Loss: 1.5050	LR: 0.000121
Training Epoch: 293 [32/50000]	Loss: 1.7680	LR: 0.000121
Training Epoch: 293 [32/50000]	Loss: 1.1326	LR: 0.000121
Training Epoch: 293 [32/50000]	Loss: 1.6872	LR: 0.000121
Training Epoch: 293 [32/50000]	Loss: 1.1002	LR: 0.000121
Training Epoch: 293 [32/50000]	Loss: 1.4956	LR: 0.000121
Training Epoch: 293 [32/50000]	Loss: 1.4168	LR: 0.000121
Training Epoch: 293 [32/50000]	Loss: 1.2816	LR: 0.000121
Training Epoch: 293 [32/50000]	Loss: 1.2423	LR: 0.000121
Training Epoch: 293 [32/50000]	Loss: 1.1858	LR: 0.000121
Evaluating Network.....
Test set: Epoch: 293, Average loss: 0.0465, Top1Accuracy: 0.5917, Top3Accuracy: 0.7890, Top5Accuracy: 0.8610, Time consumed:1.80s

Training Epoch: 294 [32/50000]	Loss: 1.4190	LR: 0.000118
Training Epoch: 294 [32/50000]	Loss: 1.6731	LR: 0.000118
Training Epoch: 294 [32/50000]	Loss: 0.9922	LR: 0.000118
Training Epoch: 294 [32/50000]	Loss: 1.2086	LR: 0.000118
Training Epoch: 294 [32/50000]	Loss: 1.1801	LR: 0.000118
Training Epoch: 294 [32/50000]	Loss: 1.1521	LR: 0.000118
Training Epoch: 294 [32/50000]	Loss: 1.3442	LR: 0.000118
Training Epoch: 294 [32/50000]	Loss: 1.7157	LR: 0.000118
Training Epoch: 294 [32/50000]	Loss: 1.1387	LR: 0.000118
Training Epoch: 294 [32/50000]	Loss: 1.3834	LR: 0.000118
Evaluating Network.....
Test set: Epoch: 294, Average loss: 0.0466, Top1Accuracy: 0.5910, Top3Accuracy: 0.7894, Top5Accuracy: 0.8608, Time consumed:1.77s

Training Epoch: 295 [32/50000]	Loss: 1.2993	LR: 0.000115
Training Epoch: 295 [32/50000]	Loss: 1.5750	LR: 0.000115
Training Epoch: 295 [32/50000]	Loss: 1.4090	LR: 0.000115
Training Epoch: 295 [32/50000]	Loss: 1.2432	LR: 0.000115
Training Epoch: 295 [32/50000]	Loss: 1.3734	LR: 0.000115
Training Epoch: 295 [32/50000]	Loss: 1.7587	LR: 0.000115
Training Epoch: 295 [32/50000]	Loss: 1.6423	LR: 0.000115
Training Epoch: 295 [32/50000]	Loss: 1.8563	LR: 0.000115
Training Epoch: 295 [32/50000]	Loss: 1.1077	LR: 0.000115
Training Epoch: 295 [32/50000]	Loss: 1.5211	LR: 0.000115
Evaluating Network.....
Test set: Epoch: 295, Average loss: 0.0465, Top1Accuracy: 0.5931, Top3Accuracy: 0.7887, Top5Accuracy: 0.8606, Time consumed:1.97s

Training Epoch: 296 [32/50000]	Loss: 1.2286	LR: 0.000112
Training Epoch: 296 [32/50000]	Loss: 1.4873	LR: 0.000112
Training Epoch: 296 [32/50000]	Loss: 0.9114	LR: 0.000112
Training Epoch: 296 [32/50000]	Loss: 1.0153	LR: 0.000112
Training Epoch: 296 [32/50000]	Loss: 1.3429	LR: 0.000112
Training Epoch: 296 [32/50000]	Loss: 1.4807	LR: 0.000112
Training Epoch: 296 [32/50000]	Loss: 0.9427	LR: 0.000112
Training Epoch: 296 [32/50000]	Loss: 1.1432	LR: 0.000112
Training Epoch: 296 [32/50000]	Loss: 1.3767	LR: 0.000112
Training Epoch: 296 [32/50000]	Loss: 1.2644	LR: 0.000112
Evaluating Network.....
Test set: Epoch: 296, Average loss: 0.0466, Top1Accuracy: 0.5920, Top3Accuracy: 0.7888, Top5Accuracy: 0.8596, Time consumed:1.77s

Training Epoch: 297 [32/50000]	Loss: 1.1774	LR: 0.000109
Training Epoch: 297 [32/50000]	Loss: 1.4704	LR: 0.000109
Training Epoch: 297 [32/50000]	Loss: 0.9626	LR: 0.000109
Training Epoch: 297 [32/50000]	Loss: 1.6724	LR: 0.000109
Training Epoch: 297 [32/50000]	Loss: 1.5452	LR: 0.000109
Training Epoch: 297 [32/50000]	Loss: 1.5764	LR: 0.000109
Training Epoch: 297 [32/50000]	Loss: 1.2010	LR: 0.000109
Training Epoch: 297 [32/50000]	Loss: 1.1672	LR: 0.000109
Training Epoch: 297 [32/50000]	Loss: 1.3219	LR: 0.000109
Training Epoch: 297 [32/50000]	Loss: 0.9835	LR: 0.000109
Evaluating Network.....
Test set: Epoch: 297, Average loss: 0.0465, Top1Accuracy: 0.5934, Top3Accuracy: 0.7913, Top5Accuracy: 0.8602, Time consumed:1.78s

Training Epoch: 298 [32/50000]	Loss: 0.9000	LR: 0.000106
Training Epoch: 298 [32/50000]	Loss: 1.0828	LR: 0.000106
Training Epoch: 298 [32/50000]	Loss: 1.1208	LR: 0.000106
Training Epoch: 298 [32/50000]	Loss: 1.0702	LR: 0.000106
Training Epoch: 298 [32/50000]	Loss: 1.2430	LR: 0.000106
Training Epoch: 298 [32/50000]	Loss: 1.5010	LR: 0.000106
Training Epoch: 298 [32/50000]	Loss: 1.4589	LR: 0.000106
Training Epoch: 298 [32/50000]	Loss: 1.4411	LR: 0.000106
Training Epoch: 298 [32/50000]	Loss: 1.0690	LR: 0.000106
Training Epoch: 298 [32/50000]	Loss: 1.2082	LR: 0.000106
Evaluating Network.....
Test set: Epoch: 298, Average loss: 0.0464, Top1Accuracy: 0.5917, Top3Accuracy: 0.7906, Top5Accuracy: 0.8606, Time consumed:1.75s

Training Epoch: 299 [32/50000]	Loss: 1.2624	LR: 0.000103
Training Epoch: 299 [32/50000]	Loss: 1.1484	LR: 0.000103
Training Epoch: 299 [32/50000]	Loss: 1.3216	LR: 0.000103
Training Epoch: 299 [32/50000]	Loss: 1.5232	LR: 0.000103
Training Epoch: 299 [32/50000]	Loss: 1.2809	LR: 0.000103
Training Epoch: 299 [32/50000]	Loss: 1.2299	LR: 0.000103
Training Epoch: 299 [32/50000]	Loss: 1.3775	LR: 0.000103
Training Epoch: 299 [32/50000]	Loss: 1.1862	LR: 0.000103
Training Epoch: 299 [32/50000]	Loss: 1.4000	LR: 0.000103
Training Epoch: 299 [32/50000]	Loss: 1.5771	LR: 0.000103
Evaluating Network.....
Test set: Epoch: 299, Average loss: 0.0465, Top1Accuracy: 0.5922, Top3Accuracy: 0.7908, Top5Accuracy: 0.8603, Time consumed:1.80s

Training Epoch: 300 [32/50000]	Loss: 1.3237	LR: 0.000101
Training Epoch: 300 [32/50000]	Loss: 1.3058	LR: 0.000101
Training Epoch: 300 [32/50000]	Loss: 0.8171	LR: 0.000101
Training Epoch: 300 [32/50000]	Loss: 1.1619	LR: 0.000101
Training Epoch: 300 [32/50000]	Loss: 1.7375	LR: 0.000101
Training Epoch: 300 [32/50000]	Loss: 1.2639	LR: 0.000101
Training Epoch: 300 [32/50000]	Loss: 1.3246	LR: 0.000101
Training Epoch: 300 [32/50000]	Loss: 1.1615	LR: 0.000101
Training Epoch: 300 [32/50000]	Loss: 1.5286	LR: 0.000101
Training Epoch: 300 [32/50000]	Loss: 1.2120	LR: 0.000101
Evaluating Network.....
Test set: Epoch: 300, Average loss: 0.0464, Top1Accuracy: 0.5918, Top3Accuracy: 0.7903, Top5Accuracy: 0.8602, Time consumed:1.75s

Training Epoch: 301 [32/50000]	Loss: 1.4108	LR: 0.000098
Training Epoch: 301 [32/50000]	Loss: 1.0582	LR: 0.000098
Training Epoch: 301 [32/50000]	Loss: 1.1056	LR: 0.000098
Training Epoch: 301 [32/50000]	Loss: 1.3151	LR: 0.000098
Training Epoch: 301 [32/50000]	Loss: 1.2664	LR: 0.000098
Training Epoch: 301 [32/50000]	Loss: 1.6938	LR: 0.000098
Training Epoch: 301 [32/50000]	Loss: 1.5825	LR: 0.000098
Training Epoch: 301 [32/50000]	Loss: 1.4975	LR: 0.000098
Training Epoch: 301 [32/50000]	Loss: 1.4416	LR: 0.000098
Training Epoch: 301 [32/50000]	Loss: 1.6039	LR: 0.000098
Evaluating Network.....
Test set: Epoch: 301, Average loss: 0.0464, Top1Accuracy: 0.5910, Top3Accuracy: 0.7903, Top5Accuracy: 0.8602, Time consumed:1.78s

Training Epoch: 302 [32/50000]	Loss: 1.3879	LR: 0.000095
Training Epoch: 302 [32/50000]	Loss: 1.5754	LR: 0.000095
Training Epoch: 302 [32/50000]	Loss: 1.6299	LR: 0.000095
Training Epoch: 302 [32/50000]	Loss: 1.1892	LR: 0.000095
Training Epoch: 302 [32/50000]	Loss: 1.1279	LR: 0.000095
Training Epoch: 302 [32/50000]	Loss: 1.0182	LR: 0.000095
Training Epoch: 302 [32/50000]	Loss: 1.4035	LR: 0.000095
Training Epoch: 302 [32/50000]	Loss: 1.8989	LR: 0.000095
Training Epoch: 302 [32/50000]	Loss: 1.4362	LR: 0.000095
Training Epoch: 302 [32/50000]	Loss: 2.0359	LR: 0.000095
Evaluating Network.....
Test set: Epoch: 302, Average loss: 0.0465, Top1Accuracy: 0.5904, Top3Accuracy: 0.7900, Top5Accuracy: 0.8604, Time consumed:1.91s

Training Epoch: 303 [32/50000]	Loss: 1.2320	LR: 0.000093
Training Epoch: 303 [32/50000]	Loss: 1.3132	LR: 0.000093
Training Epoch: 303 [32/50000]	Loss: 1.2463	LR: 0.000093
Training Epoch: 303 [32/50000]	Loss: 1.2264	LR: 0.000093
Training Epoch: 303 [32/50000]	Loss: 1.2637	LR: 0.000093
Training Epoch: 303 [32/50000]	Loss: 0.9415	LR: 0.000093
Training Epoch: 303 [32/50000]	Loss: 1.4812	LR: 0.000093
Training Epoch: 303 [32/50000]	Loss: 1.6656	LR: 0.000093
Training Epoch: 303 [32/50000]	Loss: 1.5250	LR: 0.000093
Training Epoch: 303 [32/50000]	Loss: 1.3340	LR: 0.000093
Evaluating Network.....
Test set: Epoch: 303, Average loss: 0.0465, Top1Accuracy: 0.5920, Top3Accuracy: 0.7909, Top5Accuracy: 0.8608, Time consumed:1.82s

Training Epoch: 304 [32/50000]	Loss: 0.8649	LR: 0.000090
Training Epoch: 304 [32/50000]	Loss: 1.1179	LR: 0.000090
Training Epoch: 304 [32/50000]	Loss: 1.5009	LR: 0.000090
Training Epoch: 304 [32/50000]	Loss: 1.7041	LR: 0.000090
Training Epoch: 304 [32/50000]	Loss: 0.7864	LR: 0.000090
Training Epoch: 304 [32/50000]	Loss: 1.3143	LR: 0.000090
Training Epoch: 304 [32/50000]	Loss: 1.4233	LR: 0.000090
Training Epoch: 304 [32/50000]	Loss: 1.8786	LR: 0.000090
Training Epoch: 304 [32/50000]	Loss: 1.2420	LR: 0.000090
Training Epoch: 304 [32/50000]	Loss: 1.0066	LR: 0.000090
Evaluating Network.....
Test set: Epoch: 304, Average loss: 0.0464, Top1Accuracy: 0.5930, Top3Accuracy: 0.7889, Top5Accuracy: 0.8605, Time consumed:1.86s

Training Epoch: 305 [32/50000]	Loss: 1.5740	LR: 0.000088
Training Epoch: 305 [32/50000]	Loss: 1.5715	LR: 0.000088
Training Epoch: 305 [32/50000]	Loss: 1.5012	LR: 0.000088
Training Epoch: 305 [32/50000]	Loss: 0.9826	LR: 0.000088
Training Epoch: 305 [32/50000]	Loss: 1.0723	LR: 0.000088
Training Epoch: 305 [32/50000]	Loss: 1.1691	LR: 0.000088
Training Epoch: 305 [32/50000]	Loss: 1.6770	LR: 0.000088
Training Epoch: 305 [32/50000]	Loss: 1.3071	LR: 0.000088
Training Epoch: 305 [32/50000]	Loss: 1.6759	LR: 0.000088
Training Epoch: 305 [32/50000]	Loss: 1.8500	LR: 0.000088
Evaluating Network.....
Test set: Epoch: 305, Average loss: 0.0464, Top1Accuracy: 0.5912, Top3Accuracy: 0.7905, Top5Accuracy: 0.8609, Time consumed:1.83s

Training Epoch: 306 [32/50000]	Loss: 1.2275	LR: 0.000086
Training Epoch: 306 [32/50000]	Loss: 1.3421	LR: 0.000086
Training Epoch: 306 [32/50000]	Loss: 1.0749	LR: 0.000086
Training Epoch: 306 [32/50000]	Loss: 1.5173	LR: 0.000086
Training Epoch: 306 [32/50000]	Loss: 1.3222	LR: 0.000086
Training Epoch: 306 [32/50000]	Loss: 1.8574	LR: 0.000086
Training Epoch: 306 [32/50000]	Loss: 1.4940	LR: 0.000086
Training Epoch: 306 [32/50000]	Loss: 1.5341	LR: 0.000086
Training Epoch: 306 [32/50000]	Loss: 0.8982	LR: 0.000086
Training Epoch: 306 [32/50000]	Loss: 0.9555	LR: 0.000086
Evaluating Network.....
Test set: Epoch: 306, Average loss: 0.0465, Top1Accuracy: 0.5903, Top3Accuracy: 0.7912, Top5Accuracy: 0.8617, Time consumed:1.82s

Training Epoch: 307 [32/50000]	Loss: 1.4386	LR: 0.000083
Training Epoch: 307 [32/50000]	Loss: 1.0089	LR: 0.000083
Training Epoch: 307 [32/50000]	Loss: 1.1109	LR: 0.000083
Training Epoch: 307 [32/50000]	Loss: 1.2072	LR: 0.000083
Training Epoch: 307 [32/50000]	Loss: 1.5952	LR: 0.000083
Training Epoch: 307 [32/50000]	Loss: 1.5511	LR: 0.000083
Training Epoch: 307 [32/50000]	Loss: 1.0753	LR: 0.000083
Training Epoch: 307 [32/50000]	Loss: 1.3767	LR: 0.000083
Training Epoch: 307 [32/50000]	Loss: 1.1558	LR: 0.000083
Training Epoch: 307 [32/50000]	Loss: 1.6900	LR: 0.000083
Evaluating Network.....
Test set: Epoch: 307, Average loss: 0.0465, Top1Accuracy: 0.5914, Top3Accuracy: 0.7896, Top5Accuracy: 0.8613, Time consumed:1.90s

Training Epoch: 308 [32/50000]	Loss: 1.5039	LR: 0.000081
Training Epoch: 308 [32/50000]	Loss: 1.1214	LR: 0.000081
Training Epoch: 308 [32/50000]	Loss: 1.1422	LR: 0.000081
Training Epoch: 308 [32/50000]	Loss: 0.9356	LR: 0.000081
Training Epoch: 308 [32/50000]	Loss: 1.0676	LR: 0.000081
Training Epoch: 308 [32/50000]	Loss: 1.7656	LR: 0.000081
Training Epoch: 308 [32/50000]	Loss: 1.5246	LR: 0.000081
Training Epoch: 308 [32/50000]	Loss: 1.1246	LR: 0.000081
Training Epoch: 308 [32/50000]	Loss: 1.1987	LR: 0.000081
Training Epoch: 308 [32/50000]	Loss: 1.0009	LR: 0.000081
Evaluating Network.....
Test set: Epoch: 308, Average loss: 0.0464, Top1Accuracy: 0.5918, Top3Accuracy: 0.7915, Top5Accuracy: 0.8615, Time consumed:1.83s

Training Epoch: 309 [32/50000]	Loss: 1.6913	LR: 0.000079
Training Epoch: 309 [32/50000]	Loss: 1.8780	LR: 0.000079
Training Epoch: 309 [32/50000]	Loss: 1.1723	LR: 0.000079
Training Epoch: 309 [32/50000]	Loss: 1.3484	LR: 0.000079
Training Epoch: 309 [32/50000]	Loss: 1.7952	LR: 0.000079
Training Epoch: 309 [32/50000]	Loss: 1.5211	LR: 0.000079
Training Epoch: 309 [32/50000]	Loss: 1.2250	LR: 0.000079
Training Epoch: 309 [32/50000]	Loss: 0.9310	LR: 0.000079
Training Epoch: 309 [32/50000]	Loss: 1.4109	LR: 0.000079
Training Epoch: 309 [32/50000]	Loss: 1.6122	LR: 0.000079
Evaluating Network.....
Test set: Epoch: 309, Average loss: 0.0465, Top1Accuracy: 0.5905, Top3Accuracy: 0.7915, Top5Accuracy: 0.8612, Time consumed:1.86s

Training Epoch: 310 [32/50000]	Loss: 1.4406	LR: 0.000077
Training Epoch: 310 [32/50000]	Loss: 1.4973	LR: 0.000077
Training Epoch: 310 [32/50000]	Loss: 1.3215	LR: 0.000077
Training Epoch: 310 [32/50000]	Loss: 1.5401	LR: 0.000077
Training Epoch: 310 [32/50000]	Loss: 1.1599	LR: 0.000077
Training Epoch: 310 [32/50000]	Loss: 1.3416	LR: 0.000077
Training Epoch: 310 [32/50000]	Loss: 1.2744	LR: 0.000077
Training Epoch: 310 [32/50000]	Loss: 1.6430	LR: 0.000077
Training Epoch: 310 [32/50000]	Loss: 1.2377	LR: 0.000077
Training Epoch: 310 [32/50000]	Loss: 1.0404	LR: 0.000077
Evaluating Network.....
Test set: Epoch: 310, Average loss: 0.0464, Top1Accuracy: 0.5914, Top3Accuracy: 0.7901, Top5Accuracy: 0.8614, Time consumed:1.76s

Training Epoch: 311 [32/50000]	Loss: 1.3947	LR: 0.000075
Training Epoch: 311 [32/50000]	Loss: 1.4421	LR: 0.000075
Training Epoch: 311 [32/50000]	Loss: 1.4529	LR: 0.000075
Training Epoch: 311 [32/50000]	Loss: 2.3067	LR: 0.000075
Training Epoch: 311 [32/50000]	Loss: 0.8473	LR: 0.000075
Training Epoch: 311 [32/50000]	Loss: 1.1823	LR: 0.000075
Training Epoch: 311 [32/50000]	Loss: 1.1779	LR: 0.000075
Training Epoch: 311 [32/50000]	Loss: 1.2992	LR: 0.000075
Training Epoch: 311 [32/50000]	Loss: 1.3157	LR: 0.000075
Training Epoch: 311 [32/50000]	Loss: 1.3351	LR: 0.000075
Evaluating Network.....
Test set: Epoch: 311, Average loss: 0.0464, Top1Accuracy: 0.5926, Top3Accuracy: 0.7907, Top5Accuracy: 0.8621, Time consumed:1.84s

Training Epoch: 312 [32/50000]	Loss: 1.3687	LR: 0.000073
Training Epoch: 312 [32/50000]	Loss: 1.0705	LR: 0.000073
Training Epoch: 312 [32/50000]	Loss: 1.2845	LR: 0.000073
Training Epoch: 312 [32/50000]	Loss: 1.2522	LR: 0.000073
Training Epoch: 312 [32/50000]	Loss: 1.0178	LR: 0.000073
Training Epoch: 312 [32/50000]	Loss: 1.4314	LR: 0.000073
Training Epoch: 312 [32/50000]	Loss: 1.0277	LR: 0.000073
Training Epoch: 312 [32/50000]	Loss: 1.2114	LR: 0.000073
Training Epoch: 312 [32/50000]	Loss: 0.9966	LR: 0.000073
Training Epoch: 312 [32/50000]	Loss: 0.8841	LR: 0.000073
Evaluating Network.....
Test set: Epoch: 312, Average loss: 0.0464, Top1Accuracy: 0.5912, Top3Accuracy: 0.7910, Top5Accuracy: 0.8618, Time consumed:1.80s

Training Epoch: 313 [32/50000]	Loss: 1.2327	LR: 0.000071
Training Epoch: 313 [32/50000]	Loss: 1.4112	LR: 0.000071
Training Epoch: 313 [32/50000]	Loss: 1.2400	LR: 0.000071
Training Epoch: 313 [32/50000]	Loss: 1.0906	LR: 0.000071
Training Epoch: 313 [32/50000]	Loss: 1.4052	LR: 0.000071
Training Epoch: 313 [32/50000]	Loss: 1.0568	LR: 0.000071
Training Epoch: 313 [32/50000]	Loss: 1.4144	LR: 0.000071
Training Epoch: 313 [32/50000]	Loss: 1.5623	LR: 0.000071
Training Epoch: 313 [32/50000]	Loss: 1.6111	LR: 0.000071
Training Epoch: 313 [32/50000]	Loss: 1.4232	LR: 0.000071
Evaluating Network.....
Test set: Epoch: 313, Average loss: 0.0465, Top1Accuracy: 0.5918, Top3Accuracy: 0.7917, Top5Accuracy: 0.8620, Time consumed:1.85s

Training Epoch: 314 [32/50000]	Loss: 1.5034	LR: 0.000069
Training Epoch: 314 [32/50000]	Loss: 1.6191	LR: 0.000069
Training Epoch: 314 [32/50000]	Loss: 1.3513	LR: 0.000069
Training Epoch: 314 [32/50000]	Loss: 1.3086	LR: 0.000069
Training Epoch: 314 [32/50000]	Loss: 1.3220	LR: 0.000069
Training Epoch: 314 [32/50000]	Loss: 1.6771	LR: 0.000069
Training Epoch: 314 [32/50000]	Loss: 1.1230	LR: 0.000069
Training Epoch: 314 [32/50000]	Loss: 1.2022	LR: 0.000069
Training Epoch: 314 [32/50000]	Loss: 0.9980	LR: 0.000069
Training Epoch: 314 [32/50000]	Loss: 1.3600	LR: 0.000069
Evaluating Network.....
Test set: Epoch: 314, Average loss: 0.0465, Top1Accuracy: 0.5918, Top3Accuracy: 0.7886, Top5Accuracy: 0.8614, Time consumed:1.81s

Training Epoch: 315 [32/50000]	Loss: 1.3818	LR: 0.000067
Training Epoch: 315 [32/50000]	Loss: 1.2717	LR: 0.000067
Training Epoch: 315 [32/50000]	Loss: 1.4789	LR: 0.000067
Training Epoch: 315 [32/50000]	Loss: 1.5008	LR: 0.000067
Training Epoch: 315 [32/50000]	Loss: 1.6106	LR: 0.000067
Training Epoch: 315 [32/50000]	Loss: 1.2553	LR: 0.000067
Training Epoch: 315 [32/50000]	Loss: 1.4619	LR: 0.000067
Training Epoch: 315 [32/50000]	Loss: 1.5420	LR: 0.000067
Training Epoch: 315 [32/50000]	Loss: 1.2051	LR: 0.000067
Training Epoch: 315 [32/50000]	Loss: 1.1286	LR: 0.000067
Evaluating Network.....
Test set: Epoch: 315, Average loss: 0.0464, Top1Accuracy: 0.5917, Top3Accuracy: 0.7905, Top5Accuracy: 0.8596, Time consumed:2.09s

Training Epoch: 316 [32/50000]	Loss: 1.0762	LR: 0.000066
Training Epoch: 316 [32/50000]	Loss: 1.3843	LR: 0.000066
Training Epoch: 316 [32/50000]	Loss: 1.3605	LR: 0.000066
Training Epoch: 316 [32/50000]	Loss: 1.4905	LR: 0.000066
Training Epoch: 316 [32/50000]	Loss: 1.8819	LR: 0.000066
Training Epoch: 316 [32/50000]	Loss: 0.8092	LR: 0.000066
Training Epoch: 316 [32/50000]	Loss: 1.4286	LR: 0.000066
Training Epoch: 316 [32/50000]	Loss: 1.2095	LR: 0.000066
Training Epoch: 316 [32/50000]	Loss: 1.3665	LR: 0.000066
Training Epoch: 316 [32/50000]	Loss: 1.4923	LR: 0.000066
Evaluating Network.....
Test set: Epoch: 316, Average loss: 0.0464, Top1Accuracy: 0.5917, Top3Accuracy: 0.7903, Top5Accuracy: 0.8618, Time consumed:1.83s

Training Epoch: 317 [32/50000]	Loss: 1.2043	LR: 0.000064
Training Epoch: 317 [32/50000]	Loss: 1.5442	LR: 0.000064
Training Epoch: 317 [32/50000]	Loss: 1.4097	LR: 0.000064
Training Epoch: 317 [32/50000]	Loss: 1.1692	LR: 0.000064
Training Epoch: 317 [32/50000]	Loss: 1.3527	LR: 0.000064
Training Epoch: 317 [32/50000]	Loss: 1.2773	LR: 0.000064
Training Epoch: 317 [32/50000]	Loss: 1.2807	LR: 0.000064
Training Epoch: 317 [32/50000]	Loss: 1.3987	LR: 0.000064
Training Epoch: 317 [32/50000]	Loss: 1.3332	LR: 0.000064
Training Epoch: 317 [32/50000]	Loss: 1.2218	LR: 0.000064
Evaluating Network.....
Test set: Epoch: 317, Average loss: 0.0464, Top1Accuracy: 0.5911, Top3Accuracy: 0.7896, Top5Accuracy: 0.8615, Time consumed:1.77s

Training Epoch: 318 [32/50000]	Loss: 1.2292	LR: 0.000062
Training Epoch: 318 [32/50000]	Loss: 1.4686	LR: 0.000062
Training Epoch: 318 [32/50000]	Loss: 0.9072	LR: 0.000062
Training Epoch: 318 [32/50000]	Loss: 1.3871	LR: 0.000062
Training Epoch: 318 [32/50000]	Loss: 1.1643	LR: 0.000062
Training Epoch: 318 [32/50000]	Loss: 1.8729	LR: 0.000062
Training Epoch: 318 [32/50000]	Loss: 1.2189	LR: 0.000062
Training Epoch: 318 [32/50000]	Loss: 0.9387	LR: 0.000062
Training Epoch: 318 [32/50000]	Loss: 1.5144	LR: 0.000062
Training Epoch: 318 [32/50000]	Loss: 1.1074	LR: 0.000062
Evaluating Network.....
Test set: Epoch: 318, Average loss: 0.0463, Top1Accuracy: 0.5926, Top3Accuracy: 0.7900, Top5Accuracy: 0.8621, Time consumed:1.83s

Training Epoch: 319 [32/50000]	Loss: 1.3541	LR: 0.000061
Training Epoch: 319 [32/50000]	Loss: 1.2904	LR: 0.000061
Training Epoch: 319 [32/50000]	Loss: 2.0830	LR: 0.000061
Training Epoch: 319 [32/50000]	Loss: 1.5793	LR: 0.000061
Training Epoch: 319 [32/50000]	Loss: 1.4209	LR: 0.000061
Training Epoch: 319 [32/50000]	Loss: 1.3727	LR: 0.000061
Training Epoch: 319 [32/50000]	Loss: 1.2459	LR: 0.000061
Training Epoch: 319 [32/50000]	Loss: 1.0577	LR: 0.000061
Training Epoch: 319 [32/50000]	Loss: 0.9565	LR: 0.000061
Training Epoch: 319 [32/50000]	Loss: 1.0990	LR: 0.000061
Evaluating Network.....
Test set: Epoch: 319, Average loss: 0.0464, Top1Accuracy: 0.5910, Top3Accuracy: 0.7904, Top5Accuracy: 0.8612, Time consumed:1.80s

Training Epoch: 320 [32/50000]	Loss: 1.1550	LR: 0.000059
Training Epoch: 320 [32/50000]	Loss: 0.9917	LR: 0.000059
Training Epoch: 320 [32/50000]	Loss: 1.2443	LR: 0.000059
Training Epoch: 320 [32/50000]	Loss: 1.7613	LR: 0.000059
Training Epoch: 320 [32/50000]	Loss: 1.1434	LR: 0.000059
Training Epoch: 320 [32/50000]	Loss: 1.4548	LR: 0.000059
Training Epoch: 320 [32/50000]	Loss: 1.2679	LR: 0.000059
Training Epoch: 320 [32/50000]	Loss: 1.7583	LR: 0.000059
Training Epoch: 320 [32/50000]	Loss: 0.9297	LR: 0.000059
Training Epoch: 320 [32/50000]	Loss: 1.8442	LR: 0.000059
Evaluating Network.....
Test set: Epoch: 320, Average loss: 0.0464, Top1Accuracy: 0.5919, Top3Accuracy: 0.7895, Top5Accuracy: 0.8611, Time consumed:1.80s

Training Epoch: 321 [32/50000]	Loss: 1.3775	LR: 0.000057
Training Epoch: 321 [32/50000]	Loss: 1.2037	LR: 0.000057
Training Epoch: 321 [32/50000]	Loss: 1.1780	LR: 0.000057
Training Epoch: 321 [32/50000]	Loss: 0.7354	LR: 0.000057
Training Epoch: 321 [32/50000]	Loss: 1.2323	LR: 0.000057
Training Epoch: 321 [32/50000]	Loss: 1.3836	LR: 0.000057
Training Epoch: 321 [32/50000]	Loss: 1.1130	LR: 0.000057
Training Epoch: 321 [32/50000]	Loss: 1.3226	LR: 0.000057
Training Epoch: 321 [32/50000]	Loss: 0.9630	LR: 0.000057
Training Epoch: 321 [32/50000]	Loss: 1.2187	LR: 0.000057
Evaluating Network.....
Test set: Epoch: 321, Average loss: 0.0463, Top1Accuracy: 0.5915, Top3Accuracy: 0.7892, Top5Accuracy: 0.8608, Time consumed:1.92s

Training Epoch: 322 [32/50000]	Loss: 1.6941	LR: 0.000056
Training Epoch: 322 [32/50000]	Loss: 1.2203	LR: 0.000056
Training Epoch: 322 [32/50000]	Loss: 1.3156	LR: 0.000056
Training Epoch: 322 [32/50000]	Loss: 1.2948	LR: 0.000056
Training Epoch: 322 [32/50000]	Loss: 1.5583	LR: 0.000056
Training Epoch: 322 [32/50000]	Loss: 1.0246	LR: 0.000056
Training Epoch: 322 [32/50000]	Loss: 1.3434	LR: 0.000056
Training Epoch: 322 [32/50000]	Loss: 1.4879	LR: 0.000056
Training Epoch: 322 [32/50000]	Loss: 1.3495	LR: 0.000056
Training Epoch: 322 [32/50000]	Loss: 1.3016	LR: 0.000056
Evaluating Network.....
Test set: Epoch: 322, Average loss: 0.0464, Top1Accuracy: 0.5927, Top3Accuracy: 0.7917, Top5Accuracy: 0.8621, Time consumed:1.79s

Training Epoch: 323 [32/50000]	Loss: 1.2279	LR: 0.000054
Training Epoch: 323 [32/50000]	Loss: 1.3158	LR: 0.000054
Training Epoch: 323 [32/50000]	Loss: 1.5091	LR: 0.000054
Training Epoch: 323 [32/50000]	Loss: 1.8463	LR: 0.000054
Training Epoch: 323 [32/50000]	Loss: 1.1963	LR: 0.000054
Training Epoch: 323 [32/50000]	Loss: 1.2026	LR: 0.000054
Training Epoch: 323 [32/50000]	Loss: 1.5201	LR: 0.000054
Training Epoch: 323 [32/50000]	Loss: 1.2674	LR: 0.000054
Training Epoch: 323 [32/50000]	Loss: 1.0542	LR: 0.000054
Training Epoch: 323 [32/50000]	Loss: 1.6644	LR: 0.000054
Evaluating Network.....
Test set: Epoch: 323, Average loss: 0.0464, Top1Accuracy: 0.5920, Top3Accuracy: 0.7906, Top5Accuracy: 0.8619, Time consumed:1.82s

Training Epoch: 324 [32/50000]	Loss: 1.2557	LR: 0.000053
Training Epoch: 324 [32/50000]	Loss: 1.2150	LR: 0.000053
Training Epoch: 324 [32/50000]	Loss: 1.1752	LR: 0.000053
Training Epoch: 324 [32/50000]	Loss: 1.1221	LR: 0.000053
Training Epoch: 324 [32/50000]	Loss: 1.3839	LR: 0.000053
Training Epoch: 324 [32/50000]	Loss: 1.0821	LR: 0.000053
Training Epoch: 324 [32/50000]	Loss: 1.8208	LR: 0.000053
Training Epoch: 324 [32/50000]	Loss: 1.2852	LR: 0.000053
Training Epoch: 324 [32/50000]	Loss: 1.5385	LR: 0.000053
Training Epoch: 324 [32/50000]	Loss: 1.2408	LR: 0.000053
Evaluating Network.....
Test set: Epoch: 324, Average loss: 0.0464, Top1Accuracy: 0.5919, Top3Accuracy: 0.7903, Top5Accuracy: 0.8612, Time consumed:1.83s

Training Epoch: 325 [32/50000]	Loss: 1.2189	LR: 0.000052
Training Epoch: 325 [32/50000]	Loss: 1.7821	LR: 0.000052
Training Epoch: 325 [32/50000]	Loss: 1.4351	LR: 0.000052
Training Epoch: 325 [32/50000]	Loss: 1.2381	LR: 0.000052
Training Epoch: 325 [32/50000]	Loss: 1.2282	LR: 0.000052
Training Epoch: 325 [32/50000]	Loss: 1.4332	LR: 0.000052
Training Epoch: 325 [32/50000]	Loss: 1.6516	LR: 0.000052
Training Epoch: 325 [32/50000]	Loss: 1.0284	LR: 0.000052
Training Epoch: 325 [32/50000]	Loss: 1.0778	LR: 0.000052
Training Epoch: 325 [32/50000]	Loss: 1.3716	LR: 0.000052
Evaluating Network.....
Test set: Epoch: 325, Average loss: 0.0465, Top1Accuracy: 0.5907, Top3Accuracy: 0.7908, Top5Accuracy: 0.8610, Time consumed:1.80s

Training Epoch: 326 [32/50000]	Loss: 1.2429	LR: 0.000050
Training Epoch: 326 [32/50000]	Loss: 0.9820	LR: 0.000050
Training Epoch: 326 [32/50000]	Loss: 1.0188	LR: 0.000050
Training Epoch: 326 [32/50000]	Loss: 1.7123	LR: 0.000050
Training Epoch: 326 [32/50000]	Loss: 1.1590	LR: 0.000050
Training Epoch: 326 [32/50000]	Loss: 1.2209	LR: 0.000050
Training Epoch: 326 [32/50000]	Loss: 1.1007	LR: 0.000050
Training Epoch: 326 [32/50000]	Loss: 1.2909	LR: 0.000050
Training Epoch: 326 [32/50000]	Loss: 1.2951	LR: 0.000050
Training Epoch: 326 [32/50000]	Loss: 1.7098	LR: 0.000050
Evaluating Network.....
Test set: Epoch: 326, Average loss: 0.0464, Top1Accuracy: 0.5907, Top3Accuracy: 0.7910, Top5Accuracy: 0.8604, Time consumed:1.90s

Training Epoch: 327 [32/50000]	Loss: 1.3857	LR: 0.000049
Training Epoch: 327 [32/50000]	Loss: 1.1833	LR: 0.000049
Training Epoch: 327 [32/50000]	Loss: 1.1050	LR: 0.000049
Training Epoch: 327 [32/50000]	Loss: 1.3533	LR: 0.000049
Training Epoch: 327 [32/50000]	Loss: 1.4301	LR: 0.000049
Training Epoch: 327 [32/50000]	Loss: 0.8872	LR: 0.000049
Training Epoch: 327 [32/50000]	Loss: 1.4237	LR: 0.000049
Training Epoch: 327 [32/50000]	Loss: 1.3581	LR: 0.000049
Training Epoch: 327 [32/50000]	Loss: 1.2874	LR: 0.000049
Training Epoch: 327 [32/50000]	Loss: 1.4126	LR: 0.000049
Evaluating Network.....
Test set: Epoch: 327, Average loss: 0.0464, Top1Accuracy: 0.5903, Top3Accuracy: 0.7910, Top5Accuracy: 0.8616, Time consumed:1.76s

Training Epoch: 328 [32/50000]	Loss: 1.3764	LR: 0.000048
Training Epoch: 328 [32/50000]	Loss: 1.2443	LR: 0.000048
Training Epoch: 328 [32/50000]	Loss: 1.5344	LR: 0.000048
Training Epoch: 328 [32/50000]	Loss: 1.3061	LR: 0.000048
Training Epoch: 328 [32/50000]	Loss: 1.3011	LR: 0.000048
Training Epoch: 328 [32/50000]	Loss: 1.3513	LR: 0.000048
Training Epoch: 328 [32/50000]	Loss: 1.8873	LR: 0.000048
Training Epoch: 328 [32/50000]	Loss: 1.9363	LR: 0.000048
Training Epoch: 328 [32/50000]	Loss: 1.1412	LR: 0.000048
Training Epoch: 328 [32/50000]	Loss: 1.0336	LR: 0.000048
Evaluating Network.....
Test set: Epoch: 328, Average loss: 0.0464, Top1Accuracy: 0.5904, Top3Accuracy: 0.7911, Top5Accuracy: 0.8620, Time consumed:1.80s

Training Epoch: 329 [32/50000]	Loss: 1.3658	LR: 0.000046
Training Epoch: 329 [32/50000]	Loss: 1.2190	LR: 0.000046
Training Epoch: 329 [32/50000]	Loss: 1.6830	LR: 0.000046
Training Epoch: 329 [32/50000]	Loss: 1.0191	LR: 0.000046
Training Epoch: 329 [32/50000]	Loss: 0.9914	LR: 0.000046
Training Epoch: 329 [32/50000]	Loss: 1.5322	LR: 0.000046
Training Epoch: 329 [32/50000]	Loss: 0.9927	LR: 0.000046
Training Epoch: 329 [32/50000]	Loss: 1.4652	LR: 0.000046
Training Epoch: 329 [32/50000]	Loss: 1.1728	LR: 0.000046
Training Epoch: 329 [32/50000]	Loss: 1.0956	LR: 0.000046
Evaluating Network.....
Test set: Epoch: 329, Average loss: 0.0464, Top1Accuracy: 0.5922, Top3Accuracy: 0.7908, Top5Accuracy: 0.8609, Time consumed:1.74s

Training Epoch: 330 [32/50000]	Loss: 1.2009	LR: 0.000045
Training Epoch: 330 [32/50000]	Loss: 1.3432	LR: 0.000045
Training Epoch: 330 [32/50000]	Loss: 1.4680	LR: 0.000045
Training Epoch: 330 [32/50000]	Loss: 1.8896	LR: 0.000045
Training Epoch: 330 [32/50000]	Loss: 1.4431	LR: 0.000045
Training Epoch: 330 [32/50000]	Loss: 1.9732	LR: 0.000045
Training Epoch: 330 [32/50000]	Loss: 1.4239	LR: 0.000045
Training Epoch: 330 [32/50000]	Loss: 1.2495	LR: 0.000045
Training Epoch: 330 [32/50000]	Loss: 1.3098	LR: 0.000045
Training Epoch: 330 [32/50000]	Loss: 1.1482	LR: 0.000045
Evaluating Network.....
Test set: Epoch: 330, Average loss: 0.0464, Top1Accuracy: 0.5924, Top3Accuracy: 0.7919, Top5Accuracy: 0.8616, Time consumed:1.80s

Training Epoch: 331 [32/50000]	Loss: 1.6405	LR: 0.000044
Training Epoch: 331 [32/50000]	Loss: 1.5026	LR: 0.000044
Training Epoch: 331 [32/50000]	Loss: 1.4144	LR: 0.000044
Training Epoch: 331 [32/50000]	Loss: 1.2224	LR: 0.000044
Training Epoch: 331 [32/50000]	Loss: 1.6581	LR: 0.000044
Training Epoch: 331 [32/50000]	Loss: 1.0519	LR: 0.000044
Training Epoch: 331 [32/50000]	Loss: 1.2757	LR: 0.000044
Training Epoch: 331 [32/50000]	Loss: 1.1435	LR: 0.000044
Training Epoch: 331 [32/50000]	Loss: 1.2193	LR: 0.000044
Training Epoch: 331 [32/50000]	Loss: 1.5993	LR: 0.000044
Evaluating Network.....
Test set: Epoch: 331, Average loss: 0.0463, Top1Accuracy: 0.5919, Top3Accuracy: 0.7913, Top5Accuracy: 0.8633, Time consumed:1.78s

Training Epoch: 332 [32/50000]	Loss: 1.0996	LR: 0.000043
Training Epoch: 332 [32/50000]	Loss: 1.2474	LR: 0.000043
Training Epoch: 332 [32/50000]	Loss: 1.7039	LR: 0.000043
Training Epoch: 332 [32/50000]	Loss: 1.4002	LR: 0.000043
Training Epoch: 332 [32/50000]	Loss: 1.6352	LR: 0.000043
Training Epoch: 332 [32/50000]	Loss: 1.2829	LR: 0.000043
Training Epoch: 332 [32/50000]	Loss: 1.2054	LR: 0.000043
Training Epoch: 332 [32/50000]	Loss: 1.0230	LR: 0.000043
Training Epoch: 332 [32/50000]	Loss: 1.2101	LR: 0.000043
Training Epoch: 332 [32/50000]	Loss: 1.2653	LR: 0.000043
Evaluating Network.....
Test set: Epoch: 332, Average loss: 0.0464, Top1Accuracy: 0.5906, Top3Accuracy: 0.7905, Top5Accuracy: 0.8614, Time consumed:1.78s

Training Epoch: 333 [32/50000]	Loss: 1.4650	LR: 0.000042
Training Epoch: 333 [32/50000]	Loss: 1.4457	LR: 0.000042
Training Epoch: 333 [32/50000]	Loss: 1.3974	LR: 0.000042
Training Epoch: 333 [32/50000]	Loss: 1.0757	LR: 0.000042
Training Epoch: 333 [32/50000]	Loss: 1.3452	LR: 0.000042
Training Epoch: 333 [32/50000]	Loss: 0.9324	LR: 0.000042
Training Epoch: 333 [32/50000]	Loss: 1.3186	LR: 0.000042
Training Epoch: 333 [32/50000]	Loss: 1.2826	LR: 0.000042
Training Epoch: 333 [32/50000]	Loss: 1.2002	LR: 0.000042
Training Epoch: 333 [32/50000]	Loss: 1.1007	LR: 0.000042
Evaluating Network.....
Test set: Epoch: 333, Average loss: 0.0465, Top1Accuracy: 0.5919, Top3Accuracy: 0.7900, Top5Accuracy: 0.8620, Time consumed:1.89s

Training Epoch: 334 [32/50000]	Loss: 1.0498	LR: 0.000041
Training Epoch: 334 [32/50000]	Loss: 1.4031	LR: 0.000041
Training Epoch: 334 [32/50000]	Loss: 1.0906	LR: 0.000041
Training Epoch: 334 [32/50000]	Loss: 1.4135	LR: 0.000041
Training Epoch: 334 [32/50000]	Loss: 1.5638	LR: 0.000041
Training Epoch: 334 [32/50000]	Loss: 1.3266	LR: 0.000041
Training Epoch: 334 [32/50000]	Loss: 1.5512	LR: 0.000041
Training Epoch: 334 [32/50000]	Loss: 1.3371	LR: 0.000041
Training Epoch: 334 [32/50000]	Loss: 1.3662	LR: 0.000041
Training Epoch: 334 [32/50000]	Loss: 0.9436	LR: 0.000041
Evaluating Network.....
Test set: Epoch: 334, Average loss: 0.0464, Top1Accuracy: 0.5912, Top3Accuracy: 0.7919, Top5Accuracy: 0.8619, Time consumed:1.78s

Training Epoch: 335 [32/50000]	Loss: 1.2982	LR: 0.000039
Training Epoch: 335 [32/50000]	Loss: 1.7830	LR: 0.000039
Training Epoch: 335 [32/50000]	Loss: 1.5103	LR: 0.000039
Training Epoch: 335 [32/50000]	Loss: 1.2271	LR: 0.000039
Training Epoch: 335 [32/50000]	Loss: 1.6223	LR: 0.000039
Training Epoch: 335 [32/50000]	Loss: 1.0894	LR: 0.000039
Training Epoch: 335 [32/50000]	Loss: 1.1186	LR: 0.000039
Training Epoch: 335 [32/50000]	Loss: 1.2428	LR: 0.000039
Training Epoch: 335 [32/50000]	Loss: 1.0107	LR: 0.000039
Training Epoch: 335 [32/50000]	Loss: 1.3930	LR: 0.000039
Evaluating Network.....
Test set: Epoch: 335, Average loss: 0.0464, Top1Accuracy: 0.5917, Top3Accuracy: 0.7907, Top5Accuracy: 0.8614, Time consumed:1.78s

Training Epoch: 336 [32/50000]	Loss: 1.1955	LR: 0.000038
Training Epoch: 336 [32/50000]	Loss: 1.6866	LR: 0.000038
Training Epoch: 336 [32/50000]	Loss: 1.2080	LR: 0.000038
Training Epoch: 336 [32/50000]	Loss: 1.5882	LR: 0.000038
Training Epoch: 336 [32/50000]	Loss: 1.3190	LR: 0.000038
Training Epoch: 336 [32/50000]	Loss: 1.6281	LR: 0.000038
Training Epoch: 336 [32/50000]	Loss: 1.2745	LR: 0.000038
Training Epoch: 336 [32/50000]	Loss: 1.3906	LR: 0.000038
Training Epoch: 336 [32/50000]	Loss: 1.0528	LR: 0.000038
Training Epoch: 336 [32/50000]	Loss: 1.2876	LR: 0.000038
Evaluating Network.....
Test set: Epoch: 336, Average loss: 0.0464, Top1Accuracy: 0.5922, Top3Accuracy: 0.7909, Top5Accuracy: 0.8618, Time consumed:1.78s

Training Epoch: 337 [32/50000]	Loss: 1.4854	LR: 0.000037
Training Epoch: 337 [32/50000]	Loss: 1.1589	LR: 0.000037
Training Epoch: 337 [32/50000]	Loss: 1.3109	LR: 0.000037
Training Epoch: 337 [32/50000]	Loss: 1.6709	LR: 0.000037
Training Epoch: 337 [32/50000]	Loss: 1.1941	LR: 0.000037
Training Epoch: 337 [32/50000]	Loss: 1.5026	LR: 0.000037
Training Epoch: 337 [32/50000]	Loss: 1.3663	LR: 0.000037
Training Epoch: 337 [32/50000]	Loss: 1.4562	LR: 0.000037
Training Epoch: 337 [32/50000]	Loss: 1.2564	LR: 0.000037
Training Epoch: 337 [32/50000]	Loss: 1.1156	LR: 0.000037
Evaluating Network.....
Test set: Epoch: 337, Average loss: 0.0464, Top1Accuracy: 0.5933, Top3Accuracy: 0.7919, Top5Accuracy: 0.8612, Time consumed:1.77s

Training Epoch: 338 [32/50000]	Loss: 1.5051	LR: 0.000036
Training Epoch: 338 [32/50000]	Loss: 1.4197	LR: 0.000036
Training Epoch: 338 [32/50000]	Loss: 1.2067	LR: 0.000036
Training Epoch: 338 [32/50000]	Loss: 1.3153	LR: 0.000036
Training Epoch: 338 [32/50000]	Loss: 1.3769	LR: 0.000036
Training Epoch: 338 [32/50000]	Loss: 1.6974	LR: 0.000036
Training Epoch: 338 [32/50000]	Loss: 1.9289	LR: 0.000036
Training Epoch: 338 [32/50000]	Loss: 1.2399	LR: 0.000036
Training Epoch: 338 [32/50000]	Loss: 1.7432	LR: 0.000036
Training Epoch: 338 [32/50000]	Loss: 1.0182	LR: 0.000036
Evaluating Network.....
Test set: Epoch: 338, Average loss: 0.0464, Top1Accuracy: 0.5924, Top3Accuracy: 0.7920, Top5Accuracy: 0.8613, Time consumed:1.80s

Training Epoch: 339 [32/50000]	Loss: 1.2102	LR: 0.000035
Training Epoch: 339 [32/50000]	Loss: 1.0230	LR: 0.000035
Training Epoch: 339 [32/50000]	Loss: 1.2244	LR: 0.000035
Training Epoch: 339 [32/50000]	Loss: 1.3072	LR: 0.000035
Training Epoch: 339 [32/50000]	Loss: 1.3436	LR: 0.000035
Training Epoch: 339 [32/50000]	Loss: 1.3634	LR: 0.000035
Training Epoch: 339 [32/50000]	Loss: 1.5079	LR: 0.000035
Training Epoch: 339 [32/50000]	Loss: 1.2480	LR: 0.000035
Training Epoch: 339 [32/50000]	Loss: 1.5528	LR: 0.000035
Training Epoch: 339 [32/50000]	Loss: 1.2730	LR: 0.000035
Evaluating Network.....
Test set: Epoch: 339, Average loss: 0.0463, Top1Accuracy: 0.5916, Top3Accuracy: 0.7907, Top5Accuracy: 0.8614, Time consumed:1.76s

Training Epoch: 340 [32/50000]	Loss: 1.3960	LR: 0.000035
Training Epoch: 340 [32/50000]	Loss: 1.3147	LR: 0.000035
Training Epoch: 340 [32/50000]	Loss: 1.1186	LR: 0.000035
Training Epoch: 340 [32/50000]	Loss: 0.9985	LR: 0.000035
Training Epoch: 340 [32/50000]	Loss: 1.7305	LR: 0.000035
Training Epoch: 340 [32/50000]	Loss: 1.2859	LR: 0.000035
Training Epoch: 340 [32/50000]	Loss: 1.1200	LR: 0.000035
Training Epoch: 340 [32/50000]	Loss: 0.9859	LR: 0.000035
Training Epoch: 340 [32/50000]	Loss: 1.1184	LR: 0.000035
Training Epoch: 340 [32/50000]	Loss: 1.1882	LR: 0.000035
Evaluating Network.....
Test set: Epoch: 340, Average loss: 0.0463, Top1Accuracy: 0.5923, Top3Accuracy: 0.7913, Top5Accuracy: 0.8615, Time consumed:1.87s

Training Epoch: 341 [32/50000]	Loss: 1.2203	LR: 0.000034
Training Epoch: 341 [32/50000]	Loss: 1.2965	LR: 0.000034
Training Epoch: 341 [32/50000]	Loss: 1.5964	LR: 0.000034
Training Epoch: 341 [32/50000]	Loss: 1.2996	LR: 0.000034
Training Epoch: 341 [32/50000]	Loss: 1.1813	LR: 0.000034
Training Epoch: 341 [32/50000]	Loss: 1.3355	LR: 0.000034
Training Epoch: 341 [32/50000]	Loss: 1.8237	LR: 0.000034
Training Epoch: 341 [32/50000]	Loss: 1.0664	LR: 0.000034
Training Epoch: 341 [32/50000]	Loss: 1.3035	LR: 0.000034
Training Epoch: 341 [32/50000]	Loss: 1.0080	LR: 0.000034
Evaluating Network.....
Test set: Epoch: 341, Average loss: 0.0464, Top1Accuracy: 0.5924, Top3Accuracy: 0.7912, Top5Accuracy: 0.8615, Time consumed:1.82s

Training Epoch: 342 [32/50000]	Loss: 1.1003	LR: 0.000033
Training Epoch: 342 [32/50000]	Loss: 1.0537	LR: 0.000033
Training Epoch: 342 [32/50000]	Loss: 1.2524	LR: 0.000033
Training Epoch: 342 [32/50000]	Loss: 1.6173	LR: 0.000033
Training Epoch: 342 [32/50000]	Loss: 1.2267	LR: 0.000033
Training Epoch: 342 [32/50000]	Loss: 1.2410	LR: 0.000033
Training Epoch: 342 [32/50000]	Loss: 1.6235	LR: 0.000033
Training Epoch: 342 [32/50000]	Loss: 1.3378	LR: 0.000033
Training Epoch: 342 [32/50000]	Loss: 1.3190	LR: 0.000033
Training Epoch: 342 [32/50000]	Loss: 1.3800	LR: 0.000033
Evaluating Network.....
Test set: Epoch: 342, Average loss: 0.0464, Top1Accuracy: 0.5920, Top3Accuracy: 0.7901, Top5Accuracy: 0.8612, Time consumed:1.91s

Training Epoch: 343 [32/50000]	Loss: 1.5796	LR: 0.000032
Training Epoch: 343 [32/50000]	Loss: 1.2050	LR: 0.000032
Training Epoch: 343 [32/50000]	Loss: 1.4127	LR: 0.000032
Training Epoch: 343 [32/50000]	Loss: 1.5522	LR: 0.000032
Training Epoch: 343 [32/50000]	Loss: 1.3196	LR: 0.000032
Training Epoch: 343 [32/50000]	Loss: 1.1011	LR: 0.000032
Training Epoch: 343 [32/50000]	Loss: 1.2686	LR: 0.000032
Training Epoch: 343 [32/50000]	Loss: 1.1562	LR: 0.000032
Training Epoch: 343 [32/50000]	Loss: 1.0132	LR: 0.000032
Training Epoch: 343 [32/50000]	Loss: 1.4883	LR: 0.000032
Evaluating Network.....
Test set: Epoch: 343, Average loss: 0.0463, Top1Accuracy: 0.5914, Top3Accuracy: 0.7919, Top5Accuracy: 0.8615, Time consumed:1.83s

Training Epoch: 344 [32/50000]	Loss: 1.9556	LR: 0.000031
Training Epoch: 344 [32/50000]	Loss: 1.0903	LR: 0.000031
Training Epoch: 344 [32/50000]	Loss: 1.5595	LR: 0.000031
Training Epoch: 344 [32/50000]	Loss: 1.1840	LR: 0.000031
Training Epoch: 344 [32/50000]	Loss: 1.7058	LR: 0.000031
Training Epoch: 344 [32/50000]	Loss: 1.2558	LR: 0.000031
Training Epoch: 344 [32/50000]	Loss: 1.3054	LR: 0.000031
Training Epoch: 344 [32/50000]	Loss: 1.1557	LR: 0.000031
Training Epoch: 344 [32/50000]	Loss: 1.1197	LR: 0.000031
Training Epoch: 344 [32/50000]	Loss: 0.9004	LR: 0.000031
Evaluating Network.....
Test set: Epoch: 344, Average loss: 0.0464, Top1Accuracy: 0.5919, Top3Accuracy: 0.7922, Top5Accuracy: 0.8610, Time consumed:1.77s

Training Epoch: 345 [32/50000]	Loss: 1.0276	LR: 0.000030
Training Epoch: 345 [32/50000]	Loss: 1.2408	LR: 0.000030
Training Epoch: 345 [32/50000]	Loss: 0.9082	LR: 0.000030
Training Epoch: 345 [32/50000]	Loss: 1.1727	LR: 0.000030
Training Epoch: 345 [32/50000]	Loss: 1.3595	LR: 0.000030
Training Epoch: 345 [32/50000]	Loss: 1.2649	LR: 0.000030
Training Epoch: 345 [32/50000]	Loss: 1.2836	LR: 0.000030
Training Epoch: 345 [32/50000]	Loss: 1.4463	LR: 0.000030
Training Epoch: 345 [32/50000]	Loss: 1.2749	LR: 0.000030
Training Epoch: 345 [32/50000]	Loss: 1.7050	LR: 0.000030
Evaluating Network.....
Test set: Epoch: 345, Average loss: 0.0463, Top1Accuracy: 0.5921, Top3Accuracy: 0.7918, Top5Accuracy: 0.8611, Time consumed:1.90s

Training Epoch: 346 [32/50000]	Loss: 1.1070	LR: 0.000029
Training Epoch: 346 [32/50000]	Loss: 1.2070	LR: 0.000029
Training Epoch: 346 [32/50000]	Loss: 1.2879	LR: 0.000029
Training Epoch: 346 [32/50000]	Loss: 1.0280	LR: 0.000029
Training Epoch: 346 [32/50000]	Loss: 1.6664	LR: 0.000029
Training Epoch: 346 [32/50000]	Loss: 1.4018	LR: 0.000029
Training Epoch: 346 [32/50000]	Loss: 1.3696	LR: 0.000029
Training Epoch: 346 [32/50000]	Loss: 1.3092	LR: 0.000029
Training Epoch: 346 [32/50000]	Loss: 0.9702	LR: 0.000029
Training Epoch: 346 [32/50000]	Loss: 1.2355	LR: 0.000029
Evaluating Network.....
Test set: Epoch: 346, Average loss: 0.0463, Top1Accuracy: 0.5923, Top3Accuracy: 0.7908, Top5Accuracy: 0.8609, Time consumed:1.95s

Training Epoch: 347 [32/50000]	Loss: 1.5603	LR: 0.000029
Training Epoch: 347 [32/50000]	Loss: 1.4799	LR: 0.000029
Training Epoch: 347 [32/50000]	Loss: 1.5091	LR: 0.000029
Training Epoch: 347 [32/50000]	Loss: 1.0366	LR: 0.000029
Training Epoch: 347 [32/50000]	Loss: 1.6925	LR: 0.000029
Training Epoch: 347 [32/50000]	Loss: 1.4611	LR: 0.000029
Training Epoch: 347 [32/50000]	Loss: 0.8325	LR: 0.000029
Training Epoch: 347 [32/50000]	Loss: 1.8391	LR: 0.000029
Training Epoch: 347 [32/50000]	Loss: 1.9121	LR: 0.000029
Training Epoch: 347 [32/50000]	Loss: 1.7352	LR: 0.000029
Evaluating Network.....
Test set: Epoch: 347, Average loss: 0.0464, Top1Accuracy: 0.5904, Top3Accuracy: 0.7901, Top5Accuracy: 0.8611, Time consumed:1.85s

Training Epoch: 348 [32/50000]	Loss: 1.1425	LR: 0.000028
Training Epoch: 348 [32/50000]	Loss: 1.1582	LR: 0.000028
Training Epoch: 348 [32/50000]	Loss: 1.3073	LR: 0.000028
Training Epoch: 348 [32/50000]	Loss: 1.2971	LR: 0.000028
Training Epoch: 348 [32/50000]	Loss: 1.4223	LR: 0.000028
Training Epoch: 348 [32/50000]	Loss: 1.0111	LR: 0.000028
Training Epoch: 348 [32/50000]	Loss: 1.2230	LR: 0.000028
Training Epoch: 348 [32/50000]	Loss: 1.4012	LR: 0.000028
Training Epoch: 348 [32/50000]	Loss: 1.2848	LR: 0.000028
Training Epoch: 348 [32/50000]	Loss: 1.0461	LR: 0.000028
Evaluating Network.....
Test set: Epoch: 348, Average loss: 0.0464, Top1Accuracy: 0.5927, Top3Accuracy: 0.7916, Top5Accuracy: 0.8620, Time consumed:1.84s

Training Epoch: 349 [32/50000]	Loss: 1.1385	LR: 0.000027
Training Epoch: 349 [32/50000]	Loss: 1.3684	LR: 0.000027
Training Epoch: 349 [32/50000]	Loss: 1.2804	LR: 0.000027
Training Epoch: 349 [32/50000]	Loss: 1.2408	LR: 0.000027
Training Epoch: 349 [32/50000]	Loss: 1.4320	LR: 0.000027
Training Epoch: 349 [32/50000]	Loss: 1.0213	LR: 0.000027
Training Epoch: 349 [32/50000]	Loss: 1.7222	LR: 0.000027
Training Epoch: 349 [32/50000]	Loss: 1.5119	LR: 0.000027
Training Epoch: 349 [32/50000]	Loss: 1.0103	LR: 0.000027
Training Epoch: 349 [32/50000]	Loss: 1.4346	LR: 0.000027
Evaluating Network.....
Test set: Epoch: 349, Average loss: 0.0464, Top1Accuracy: 0.5917, Top3Accuracy: 0.7898, Top5Accuracy: 0.8621, Time consumed:1.79s

Training Epoch: 350 [32/50000]	Loss: 1.5836	LR: 0.000026
Training Epoch: 350 [32/50000]	Loss: 1.1102	LR: 0.000026
Training Epoch: 350 [32/50000]	Loss: 1.5947	LR: 0.000026
Training Epoch: 350 [32/50000]	Loss: 1.0303	LR: 0.000026
Training Epoch: 350 [32/50000]	Loss: 1.2245	LR: 0.000026
Training Epoch: 350 [32/50000]	Loss: 1.7364	LR: 0.000026
Training Epoch: 350 [32/50000]	Loss: 1.4524	LR: 0.000026
Training Epoch: 350 [32/50000]	Loss: 1.4144	LR: 0.000026
Training Epoch: 350 [32/50000]	Loss: 1.0580	LR: 0.000026
Training Epoch: 350 [32/50000]	Loss: 1.2372	LR: 0.000026
Evaluating Network.....
Test set: Epoch: 350, Average loss: 0.0464, Top1Accuracy: 0.5912, Top3Accuracy: 0.7904, Top5Accuracy: 0.8623, Time consumed:1.86s

Training Epoch: 351 [32/50000]	Loss: 0.8921	LR: 0.000026
Training Epoch: 351 [32/50000]	Loss: 1.2433	LR: 0.000026
Training Epoch: 351 [32/50000]	Loss: 1.4309	LR: 0.000026
Training Epoch: 351 [32/50000]	Loss: 1.4449	LR: 0.000026
Training Epoch: 351 [32/50000]	Loss: 1.1328	LR: 0.000026
Training Epoch: 351 [32/50000]	Loss: 1.5041	LR: 0.000026
Training Epoch: 351 [32/50000]	Loss: 0.9873	LR: 0.000026
Training Epoch: 351 [32/50000]	Loss: 1.3591	LR: 0.000026
Training Epoch: 351 [32/50000]	Loss: 1.6546	LR: 0.000026
Training Epoch: 351 [32/50000]	Loss: 1.7496	LR: 0.000026
Evaluating Network.....
Test set: Epoch: 351, Average loss: 0.0463, Top1Accuracy: 0.5909, Top3Accuracy: 0.7910, Top5Accuracy: 0.8625, Time consumed:1.84s

Training Epoch: 352 [32/50000]	Loss: 1.0798	LR: 0.000025
Training Epoch: 352 [32/50000]	Loss: 1.4674	LR: 0.000025
Training Epoch: 352 [32/50000]	Loss: 0.9813	LR: 0.000025
Training Epoch: 352 [32/50000]	Loss: 1.1974	LR: 0.000025
Training Epoch: 352 [32/50000]	Loss: 1.9029	LR: 0.000025
Training Epoch: 352 [32/50000]	Loss: 1.3813	LR: 0.000025
Training Epoch: 352 [32/50000]	Loss: 1.1922	LR: 0.000025
Training Epoch: 352 [32/50000]	Loss: 1.1127	LR: 0.000025
Training Epoch: 352 [32/50000]	Loss: 0.9246	LR: 0.000025
Training Epoch: 352 [32/50000]	Loss: 1.1772	LR: 0.000025
Evaluating Network.....
Test set: Epoch: 352, Average loss: 0.0464, Top1Accuracy: 0.5911, Top3Accuracy: 0.7919, Top5Accuracy: 0.8611, Time consumed:1.88s

Training Epoch: 353 [32/50000]	Loss: 1.3917	LR: 0.000024
Training Epoch: 353 [32/50000]	Loss: 1.7425	LR: 0.000024
Training Epoch: 353 [32/50000]	Loss: 0.7800	LR: 0.000024
Training Epoch: 353 [32/50000]	Loss: 1.1769	LR: 0.000024
Training Epoch: 353 [32/50000]	Loss: 1.7196	LR: 0.000024
Training Epoch: 353 [32/50000]	Loss: 1.1303	LR: 0.000024
Training Epoch: 353 [32/50000]	Loss: 0.9251	LR: 0.000024
Training Epoch: 353 [32/50000]	Loss: 1.4708	LR: 0.000024
Training Epoch: 353 [32/50000]	Loss: 1.1179	LR: 0.000024
Training Epoch: 353 [32/50000]	Loss: 1.6126	LR: 0.000024
Evaluating Network.....
Test set: Epoch: 353, Average loss: 0.0464, Top1Accuracy: 0.5927, Top3Accuracy: 0.7909, Top5Accuracy: 0.8620, Time consumed:1.73s

Training Epoch: 354 [32/50000]	Loss: 1.6529	LR: 0.000024
Training Epoch: 354 [32/50000]	Loss: 1.1312	LR: 0.000024
Training Epoch: 354 [32/50000]	Loss: 1.2128	LR: 0.000024
Training Epoch: 354 [32/50000]	Loss: 1.8359	LR: 0.000024
Training Epoch: 354 [32/50000]	Loss: 1.4708	LR: 0.000024
Training Epoch: 354 [32/50000]	Loss: 1.2958	LR: 0.000024
Training Epoch: 354 [32/50000]	Loss: 1.6428	LR: 0.000024
Training Epoch: 354 [32/50000]	Loss: 1.3632	LR: 0.000024
Training Epoch: 354 [32/50000]	Loss: 1.3990	LR: 0.000024
Training Epoch: 354 [32/50000]	Loss: 1.4848	LR: 0.000024
Evaluating Network.....
Test set: Epoch: 354, Average loss: 0.0464, Top1Accuracy: 0.5923, Top3Accuracy: 0.7931, Top5Accuracy: 0.8615, Time consumed:1.84s

Training Epoch: 355 [32/50000]	Loss: 0.9228	LR: 0.000023
Training Epoch: 355 [32/50000]	Loss: 1.2243	LR: 0.000023
Training Epoch: 355 [32/50000]	Loss: 1.6736	LR: 0.000023
Training Epoch: 355 [32/50000]	Loss: 1.4949	LR: 0.000023
Training Epoch: 355 [32/50000]	Loss: 1.2791	LR: 0.000023
Training Epoch: 355 [32/50000]	Loss: 1.3348	LR: 0.000023
Training Epoch: 355 [32/50000]	Loss: 1.7266	LR: 0.000023
Training Epoch: 355 [32/50000]	Loss: 1.2736	LR: 0.000023
Training Epoch: 355 [32/50000]	Loss: 1.2512	LR: 0.000023
Training Epoch: 355 [32/50000]	Loss: 1.4943	LR: 0.000023
Evaluating Network.....
Test set: Epoch: 355, Average loss: 0.0464, Top1Accuracy: 0.5926, Top3Accuracy: 0.7902, Top5Accuracy: 0.8610, Time consumed:1.76s

Training Epoch: 356 [32/50000]	Loss: 1.1826	LR: 0.000023
Training Epoch: 356 [32/50000]	Loss: 1.3901	LR: 0.000023
Training Epoch: 356 [32/50000]	Loss: 1.4153	LR: 0.000023
Training Epoch: 356 [32/50000]	Loss: 1.2225	LR: 0.000023
Training Epoch: 356 [32/50000]	Loss: 1.1284	LR: 0.000023
Training Epoch: 356 [32/50000]	Loss: 1.3343	LR: 0.000023
Training Epoch: 356 [32/50000]	Loss: 1.3295	LR: 0.000023
Training Epoch: 356 [32/50000]	Loss: 1.8857	LR: 0.000023
Training Epoch: 356 [32/50000]	Loss: 1.0608	LR: 0.000023
Training Epoch: 356 [32/50000]	Loss: 1.5779	LR: 0.000023
Evaluating Network.....
Test set: Epoch: 356, Average loss: 0.0464, Top1Accuracy: 0.5941, Top3Accuracy: 0.7898, Top5Accuracy: 0.8624, Time consumed:1.82s

Training Epoch: 357 [32/50000]	Loss: 1.4901	LR: 0.000022
Training Epoch: 357 [32/50000]	Loss: 1.2408	LR: 0.000022
Training Epoch: 357 [32/50000]	Loss: 1.1806	LR: 0.000022
Training Epoch: 357 [32/50000]	Loss: 1.4427	LR: 0.000022
Training Epoch: 357 [32/50000]	Loss: 1.2524	LR: 0.000022
Training Epoch: 357 [32/50000]	Loss: 1.1450	LR: 0.000022
Training Epoch: 357 [32/50000]	Loss: 1.6278	LR: 0.000022
Training Epoch: 357 [32/50000]	Loss: 1.4759	LR: 0.000022
Training Epoch: 357 [32/50000]	Loss: 0.6758	LR: 0.000022
Training Epoch: 357 [32/50000]	Loss: 1.5636	LR: 0.000022
Evaluating Network.....
Test set: Epoch: 357, Average loss: 0.0463, Top1Accuracy: 0.5908, Top3Accuracy: 0.7921, Top5Accuracy: 0.8624, Time consumed:1.91s

Training Epoch: 358 [32/50000]	Loss: 1.2288	LR: 0.000021
Training Epoch: 358 [32/50000]	Loss: 0.9746	LR: 0.000021
Training Epoch: 358 [32/50000]	Loss: 1.4562	LR: 0.000021
Training Epoch: 358 [32/50000]	Loss: 1.6062	LR: 0.000021
Training Epoch: 358 [32/50000]	Loss: 1.0870	LR: 0.000021
Training Epoch: 358 [32/50000]	Loss: 1.4494	LR: 0.000021
Training Epoch: 358 [32/50000]	Loss: 1.3346	LR: 0.000021
Training Epoch: 358 [32/50000]	Loss: 1.1989	LR: 0.000021
Training Epoch: 358 [32/50000]	Loss: 0.8752	LR: 0.000021
Training Epoch: 358 [32/50000]	Loss: 1.5769	LR: 0.000021
Evaluating Network.....
Test set: Epoch: 358, Average loss: 0.0465, Top1Accuracy: 0.5914, Top3Accuracy: 0.7914, Top5Accuracy: 0.8619, Time consumed:1.80s

Training Epoch: 359 [32/50000]	Loss: 1.4008	LR: 0.000021
Training Epoch: 359 [32/50000]	Loss: 1.4182	LR: 0.000021
Training Epoch: 359 [32/50000]	Loss: 1.2016	LR: 0.000021
Training Epoch: 359 [32/50000]	Loss: 1.6047	LR: 0.000021
Training Epoch: 359 [32/50000]	Loss: 1.1362	LR: 0.000021
Training Epoch: 359 [32/50000]	Loss: 1.0373	LR: 0.000021
Training Epoch: 359 [32/50000]	Loss: 1.2922	LR: 0.000021
Training Epoch: 359 [32/50000]	Loss: 1.0441	LR: 0.000021
Training Epoch: 359 [32/50000]	Loss: 1.6945	LR: 0.000021
Training Epoch: 359 [32/50000]	Loss: 1.0882	LR: 0.000021
Evaluating Network.....
Test set: Epoch: 359, Average loss: 0.0463, Top1Accuracy: 0.5916, Top3Accuracy: 0.7907, Top5Accuracy: 0.8605, Time consumed:1.78s

Training Epoch: 360 [32/50000]	Loss: 1.2184	LR: 0.000020
Training Epoch: 360 [32/50000]	Loss: 1.0837	LR: 0.000020
Training Epoch: 360 [32/50000]	Loss: 1.4748	LR: 0.000020
Training Epoch: 360 [32/50000]	Loss: 1.6704	LR: 0.000020
Training Epoch: 360 [32/50000]	Loss: 1.5398	LR: 0.000020
Training Epoch: 360 [32/50000]	Loss: 1.2137	LR: 0.000020
Training Epoch: 360 [32/50000]	Loss: 1.8456	LR: 0.000020
Training Epoch: 360 [32/50000]	Loss: 1.3160	LR: 0.000020
Training Epoch: 360 [32/50000]	Loss: 1.1010	LR: 0.000020
Training Epoch: 360 [32/50000]	Loss: 1.3582	LR: 0.000020
Evaluating Network.....
Test set: Epoch: 360, Average loss: 0.0463, Top1Accuracy: 0.5932, Top3Accuracy: 0.7911, Top5Accuracy: 0.8612, Time consumed:1.94s

Training Epoch: 361 [32/50000]	Loss: 0.9820	LR: 0.000020
Training Epoch: 361 [32/50000]	Loss: 1.9088	LR: 0.000020
Training Epoch: 361 [32/50000]	Loss: 1.5255	LR: 0.000020
Training Epoch: 361 [32/50000]	Loss: 1.4326	LR: 0.000020
Training Epoch: 361 [32/50000]	Loss: 1.4971	LR: 0.000020
Training Epoch: 361 [32/50000]	Loss: 1.2852	LR: 0.000020
Training Epoch: 361 [32/50000]	Loss: 1.0028	LR: 0.000020
Training Epoch: 361 [32/50000]	Loss: 1.5135	LR: 0.000020
Training Epoch: 361 [32/50000]	Loss: 1.4813	LR: 0.000020
Training Epoch: 361 [32/50000]	Loss: 0.9613	LR: 0.000020
Evaluating Network.....
Test set: Epoch: 361, Average loss: 0.0464, Top1Accuracy: 0.5924, Top3Accuracy: 0.7908, Top5Accuracy: 0.8616, Time consumed:1.79s

Training Epoch: 362 [32/50000]	Loss: 1.2292	LR: 0.000019
Training Epoch: 362 [32/50000]	Loss: 1.0734	LR: 0.000019
Training Epoch: 362 [32/50000]	Loss: 1.1672	LR: 0.000019
Training Epoch: 362 [32/50000]	Loss: 1.2300	LR: 0.000019
Training Epoch: 362 [32/50000]	Loss: 1.3999	LR: 0.000019
Training Epoch: 362 [32/50000]	Loss: 1.2864	LR: 0.000019
Training Epoch: 362 [32/50000]	Loss: 1.4589	LR: 0.000019
Training Epoch: 362 [32/50000]	Loss: 1.6338	LR: 0.000019
Training Epoch: 362 [32/50000]	Loss: 1.3258	LR: 0.000019
Training Epoch: 362 [32/50000]	Loss: 1.5261	LR: 0.000019
Evaluating Network.....
Test set: Epoch: 362, Average loss: 0.0463, Top1Accuracy: 0.5914, Top3Accuracy: 0.7918, Top5Accuracy: 0.8621, Time consumed:1.82s

Training Epoch: 363 [32/50000]	Loss: 1.3101	LR: 0.000019
Training Epoch: 363 [32/50000]	Loss: 0.9192	LR: 0.000019
Training Epoch: 363 [32/50000]	Loss: 0.9143	LR: 0.000019
Training Epoch: 363 [32/50000]	Loss: 1.6072	LR: 0.000019
Training Epoch: 363 [32/50000]	Loss: 1.1984	LR: 0.000019
Training Epoch: 363 [32/50000]	Loss: 0.9792	LR: 0.000019
Training Epoch: 363 [32/50000]	Loss: 1.2465	LR: 0.000019
Training Epoch: 363 [32/50000]	Loss: 1.5890	LR: 0.000019
Training Epoch: 363 [32/50000]	Loss: 1.2910	LR: 0.000019
Training Epoch: 363 [32/50000]	Loss: 1.6538	LR: 0.000019
Evaluating Network.....
Test set: Epoch: 363, Average loss: 0.0464, Top1Accuracy: 0.5927, Top3Accuracy: 0.7915, Top5Accuracy: 0.8615, Time consumed:1.85s

Training Epoch: 364 [32/50000]	Loss: 1.3037	LR: 0.000018
Training Epoch: 364 [32/50000]	Loss: 0.8718	LR: 0.000018
Training Epoch: 364 [32/50000]	Loss: 1.1002	LR: 0.000018
Training Epoch: 364 [32/50000]	Loss: 1.0888	LR: 0.000018
Training Epoch: 364 [32/50000]	Loss: 1.2677	LR: 0.000018
Training Epoch: 364 [32/50000]	Loss: 1.6191	LR: 0.000018
Training Epoch: 364 [32/50000]	Loss: 1.2177	LR: 0.000018
Training Epoch: 364 [32/50000]	Loss: 1.3635	LR: 0.000018
Training Epoch: 364 [32/50000]	Loss: 1.1147	LR: 0.000018
Training Epoch: 364 [32/50000]	Loss: 1.0228	LR: 0.000018
Evaluating Network.....
Test set: Epoch: 364, Average loss: 0.0463, Top1Accuracy: 0.5918, Top3Accuracy: 0.7914, Top5Accuracy: 0.8611, Time consumed:1.81s

Training Epoch: 365 [32/50000]	Loss: 1.5301	LR: 0.000018
Training Epoch: 365 [32/50000]	Loss: 1.4915	LR: 0.000018
Training Epoch: 365 [32/50000]	Loss: 1.3171	LR: 0.000018
Training Epoch: 365 [32/50000]	Loss: 1.0583	LR: 0.000018
Training Epoch: 365 [32/50000]	Loss: 1.0480	LR: 0.000018
Training Epoch: 365 [32/50000]	Loss: 1.0688	LR: 0.000018
Training Epoch: 365 [32/50000]	Loss: 1.1670	LR: 0.000018
Training Epoch: 365 [32/50000]	Loss: 0.7966	LR: 0.000018
Training Epoch: 365 [32/50000]	Loss: 1.4585	LR: 0.000018
Training Epoch: 365 [32/50000]	Loss: 1.2300	LR: 0.000018
Evaluating Network.....
Test set: Epoch: 365, Average loss: 0.0463, Top1Accuracy: 0.5934, Top3Accuracy: 0.7910, Top5Accuracy: 0.8620, Time consumed:1.85s

Training Epoch: 366 [32/50000]	Loss: 1.2300	LR: 0.000017
Training Epoch: 366 [32/50000]	Loss: 1.5892	LR: 0.000017
Training Epoch: 366 [32/50000]	Loss: 1.5922	LR: 0.000017
Training Epoch: 366 [32/50000]	Loss: 1.1871	LR: 0.000017
Training Epoch: 366 [32/50000]	Loss: 1.3126	LR: 0.000017
Training Epoch: 366 [32/50000]	Loss: 1.4208	LR: 0.000017
Training Epoch: 366 [32/50000]	Loss: 1.4317	LR: 0.000017
Training Epoch: 366 [32/50000]	Loss: 1.3021	LR: 0.000017
Training Epoch: 366 [32/50000]	Loss: 1.0712	LR: 0.000017
Training Epoch: 366 [32/50000]	Loss: 1.3362	LR: 0.000017
Evaluating Network.....
Test set: Epoch: 366, Average loss: 0.0463, Top1Accuracy: 0.5925, Top3Accuracy: 0.7923, Top5Accuracy: 0.8614, Time consumed:1.71s

Training Epoch: 367 [32/50000]	Loss: 1.1478	LR: 0.000017
Training Epoch: 367 [32/50000]	Loss: 1.1323	LR: 0.000017
Training Epoch: 367 [32/50000]	Loss: 1.7918	LR: 0.000017
Training Epoch: 367 [32/50000]	Loss: 1.3341	LR: 0.000017
Training Epoch: 367 [32/50000]	Loss: 1.3554	LR: 0.000017
Training Epoch: 367 [32/50000]	Loss: 1.1751	LR: 0.000017
Training Epoch: 367 [32/50000]	Loss: 1.3435	LR: 0.000017
Training Epoch: 367 [32/50000]	Loss: 0.7428	LR: 0.000017
Training Epoch: 367 [32/50000]	Loss: 1.3046	LR: 0.000017
Training Epoch: 367 [32/50000]	Loss: 1.2599	LR: 0.000017
Evaluating Network.....
Test set: Epoch: 367, Average loss: 0.0463, Top1Accuracy: 0.5938, Top3Accuracy: 0.7908, Top5Accuracy: 0.8620, Time consumed:1.80s

Training Epoch: 368 [32/50000]	Loss: 1.5621	LR: 0.000016
Training Epoch: 368 [32/50000]	Loss: 1.2829	LR: 0.000016
Training Epoch: 368 [32/50000]	Loss: 1.3349	LR: 0.000016
Training Epoch: 368 [32/50000]	Loss: 1.2700	LR: 0.000016
Training Epoch: 368 [32/50000]	Loss: 1.7445	LR: 0.000016
Training Epoch: 368 [32/50000]	Loss: 0.8847	LR: 0.000016
Training Epoch: 368 [32/50000]	Loss: 1.1877	LR: 0.000016
Training Epoch: 368 [32/50000]	Loss: 1.1376	LR: 0.000016
Training Epoch: 368 [32/50000]	Loss: 1.4787	LR: 0.000016
Training Epoch: 368 [32/50000]	Loss: 1.2359	LR: 0.000016
Evaluating Network.....
Test set: Epoch: 368, Average loss: 0.0463, Top1Accuracy: 0.5920, Top3Accuracy: 0.7919, Top5Accuracy: 0.8623, Time consumed:1.88s

Training Epoch: 369 [32/50000]	Loss: 1.6182	LR: 0.000016
Training Epoch: 369 [32/50000]	Loss: 1.1052	LR: 0.000016
Training Epoch: 369 [32/50000]	Loss: 1.3817	LR: 0.000016
Training Epoch: 369 [32/50000]	Loss: 1.0526	LR: 0.000016
Training Epoch: 369 [32/50000]	Loss: 1.3156	LR: 0.000016
Training Epoch: 369 [32/50000]	Loss: 1.3429	LR: 0.000016
Training Epoch: 369 [32/50000]	Loss: 1.3396	LR: 0.000016
Training Epoch: 369 [32/50000]	Loss: 1.1755	LR: 0.000016
Training Epoch: 369 [32/50000]	Loss: 1.2100	LR: 0.000016
Training Epoch: 369 [32/50000]	Loss: 1.1961	LR: 0.000016
Evaluating Network.....
Test set: Epoch: 369, Average loss: 0.0464, Top1Accuracy: 0.5919, Top3Accuracy: 0.7918, Top5Accuracy: 0.8612, Time consumed:1.70s

Training Epoch: 370 [32/50000]	Loss: 0.7495	LR: 0.000015
Training Epoch: 370 [32/50000]	Loss: 1.3024	LR: 0.000015
Training Epoch: 370 [32/50000]	Loss: 1.4405	LR: 0.000015
Training Epoch: 370 [32/50000]	Loss: 1.4579	LR: 0.000015
Training Epoch: 370 [32/50000]	Loss: 1.1842	LR: 0.000015
Training Epoch: 370 [32/50000]	Loss: 1.4289	LR: 0.000015
Training Epoch: 370 [32/50000]	Loss: 1.2755	LR: 0.000015
Training Epoch: 370 [32/50000]	Loss: 0.8873	LR: 0.000015
Training Epoch: 370 [32/50000]	Loss: 0.9930	LR: 0.000015
Training Epoch: 370 [32/50000]	Loss: 1.3276	LR: 0.000015
Evaluating Network.....
Test set: Epoch: 370, Average loss: 0.0463, Top1Accuracy: 0.5919, Top3Accuracy: 0.7911, Top5Accuracy: 0.8625, Time consumed:1.78s

Training Epoch: 371 [32/50000]	Loss: 1.1996	LR: 0.000015
Training Epoch: 371 [32/50000]	Loss: 0.9670	LR: 0.000015
Training Epoch: 371 [32/50000]	Loss: 1.3312	LR: 0.000015
Training Epoch: 371 [32/50000]	Loss: 1.4200	LR: 0.000015
Training Epoch: 371 [32/50000]	Loss: 1.7310	LR: 0.000015
Training Epoch: 371 [32/50000]	Loss: 1.1743	LR: 0.000015
Training Epoch: 371 [32/50000]	Loss: 1.3079	LR: 0.000015
Training Epoch: 371 [32/50000]	Loss: 1.3009	LR: 0.000015
Training Epoch: 371 [32/50000]	Loss: 1.8964	LR: 0.000015
Training Epoch: 371 [32/50000]	Loss: 1.0737	LR: 0.000015
Evaluating Network.....
Test set: Epoch: 371, Average loss: 0.0464, Top1Accuracy: 0.5915, Top3Accuracy: 0.7920, Top5Accuracy: 0.8624, Time consumed:1.85s

Training Epoch: 372 [32/50000]	Loss: 1.0683	LR: 0.000015
Training Epoch: 372 [32/50000]	Loss: 1.5451	LR: 0.000015
Training Epoch: 372 [32/50000]	Loss: 1.0437	LR: 0.000015
Training Epoch: 372 [32/50000]	Loss: 0.8513	LR: 0.000015
Training Epoch: 372 [32/50000]	Loss: 1.5581	LR: 0.000015
Training Epoch: 372 [32/50000]	Loss: 1.3379	LR: 0.000015
Training Epoch: 372 [32/50000]	Loss: 1.2457	LR: 0.000015
Training Epoch: 372 [32/50000]	Loss: 1.5411	LR: 0.000015
Training Epoch: 372 [32/50000]	Loss: 1.5469	LR: 0.000015
Training Epoch: 372 [32/50000]	Loss: 1.3882	LR: 0.000015
Evaluating Network.....
Test set: Epoch: 372, Average loss: 0.0463, Top1Accuracy: 0.5926, Top3Accuracy: 0.7926, Top5Accuracy: 0.8628, Time consumed:1.82s

Training Epoch: 373 [32/50000]	Loss: 1.5832	LR: 0.000014
Training Epoch: 373 [32/50000]	Loss: 1.1753	LR: 0.000014
Training Epoch: 373 [32/50000]	Loss: 1.1686	LR: 0.000014
Training Epoch: 373 [32/50000]	Loss: 1.0797	LR: 0.000014
Training Epoch: 373 [32/50000]	Loss: 1.5015	LR: 0.000014
Training Epoch: 373 [32/50000]	Loss: 1.3772	LR: 0.000014
Training Epoch: 373 [32/50000]	Loss: 0.9669	LR: 0.000014
Training Epoch: 373 [32/50000]	Loss: 0.8860	LR: 0.000014
Training Epoch: 373 [32/50000]	Loss: 1.5824	LR: 0.000014
Training Epoch: 373 [32/50000]	Loss: 1.3600	LR: 0.000014
Evaluating Network.....
Test set: Epoch: 373, Average loss: 0.0463, Top1Accuracy: 0.5938, Top3Accuracy: 0.7912, Top5Accuracy: 0.8622, Time consumed:1.85s

Training Epoch: 374 [32/50000]	Loss: 1.4712	LR: 0.000014
Training Epoch: 374 [32/50000]	Loss: 1.3183	LR: 0.000014
Training Epoch: 374 [32/50000]	Loss: 1.1837	LR: 0.000014
Training Epoch: 374 [32/50000]	Loss: 1.0197	LR: 0.000014
Training Epoch: 374 [32/50000]	Loss: 1.6614	LR: 0.000014
Training Epoch: 374 [32/50000]	Loss: 1.1753	LR: 0.000014
Training Epoch: 374 [32/50000]	Loss: 1.6535	LR: 0.000014
Training Epoch: 374 [32/50000]	Loss: 1.0928	LR: 0.000014
Training Epoch: 374 [32/50000]	Loss: 0.6418	LR: 0.000014
Training Epoch: 374 [32/50000]	Loss: 1.4261	LR: 0.000014
Evaluating Network.....
Test set: Epoch: 374, Average loss: 0.0464, Top1Accuracy: 0.5910, Top3Accuracy: 0.7908, Top5Accuracy: 0.8620, Time consumed:1.78s

Training Epoch: 375 [32/50000]	Loss: 1.0728	LR: 0.000014
Training Epoch: 375 [32/50000]	Loss: 1.5046	LR: 0.000014
Training Epoch: 375 [32/50000]	Loss: 1.2440	LR: 0.000014
Training Epoch: 375 [32/50000]	Loss: 1.6233	LR: 0.000014
Training Epoch: 375 [32/50000]	Loss: 1.4675	LR: 0.000014
Training Epoch: 375 [32/50000]	Loss: 1.2875	LR: 0.000014
Training Epoch: 375 [32/50000]	Loss: 1.1955	LR: 0.000014
Training Epoch: 375 [32/50000]	Loss: 1.1364	LR: 0.000014
Training Epoch: 375 [32/50000]	Loss: 1.3633	LR: 0.000014
Training Epoch: 375 [32/50000]	Loss: 1.2187	LR: 0.000014
Evaluating Network.....
Test set: Epoch: 375, Average loss: 0.0464, Top1Accuracy: 0.5924, Top3Accuracy: 0.7903, Top5Accuracy: 0.8627, Time consumed:1.83s

Training Epoch: 376 [32/50000]	Loss: 1.0492	LR: 0.000013
Training Epoch: 376 [32/50000]	Loss: 1.3956	LR: 0.000013
Training Epoch: 376 [32/50000]	Loss: 1.1941	LR: 0.000013
Training Epoch: 376 [32/50000]	Loss: 1.7536	LR: 0.000013
Training Epoch: 376 [32/50000]	Loss: 1.4222	LR: 0.000013
Training Epoch: 376 [32/50000]	Loss: 1.2526	LR: 0.000013
Training Epoch: 376 [32/50000]	Loss: 1.2044	LR: 0.000013
Training Epoch: 376 [32/50000]	Loss: 1.2713	LR: 0.000013
Training Epoch: 376 [32/50000]	Loss: 1.4360	LR: 0.000013
Training Epoch: 376 [32/50000]	Loss: 1.1233	LR: 0.000013
Evaluating Network.....
Test set: Epoch: 376, Average loss: 0.0463, Top1Accuracy: 0.5919, Top3Accuracy: 0.7889, Top5Accuracy: 0.8621, Time consumed:1.77s

Training Epoch: 377 [32/50000]	Loss: 1.2558	LR: 0.000013
Training Epoch: 377 [32/50000]	Loss: 1.0930	LR: 0.000013
Training Epoch: 377 [32/50000]	Loss: 1.3665	LR: 0.000013
Training Epoch: 377 [32/50000]	Loss: 1.1871	LR: 0.000013
Training Epoch: 377 [32/50000]	Loss: 1.5756	LR: 0.000013
Training Epoch: 377 [32/50000]	Loss: 1.1607	LR: 0.000013
Training Epoch: 377 [32/50000]	Loss: 1.3180	LR: 0.000013
Training Epoch: 377 [32/50000]	Loss: 1.0606	LR: 0.000013
Training Epoch: 377 [32/50000]	Loss: 1.3148	LR: 0.000013
Training Epoch: 377 [32/50000]	Loss: 1.1919	LR: 0.000013
Evaluating Network.....
Test set: Epoch: 377, Average loss: 0.0463, Top1Accuracy: 0.5927, Top3Accuracy: 0.7919, Top5Accuracy: 0.8622, Time consumed:1.76s

Training Epoch: 378 [32/50000]	Loss: 0.9360	LR: 0.000012
Training Epoch: 378 [32/50000]	Loss: 1.2618	LR: 0.000012
Training Epoch: 378 [32/50000]	Loss: 1.3696	LR: 0.000012
Training Epoch: 378 [32/50000]	Loss: 1.0056	LR: 0.000012
Training Epoch: 378 [32/50000]	Loss: 1.6601	LR: 0.000012
Training Epoch: 378 [32/50000]	Loss: 1.0696	LR: 0.000012
Training Epoch: 378 [32/50000]	Loss: 1.1769	LR: 0.000012
Training Epoch: 378 [32/50000]	Loss: 1.1077	LR: 0.000012
Training Epoch: 378 [32/50000]	Loss: 1.6563	LR: 0.000012
Training Epoch: 378 [32/50000]	Loss: 1.2788	LR: 0.000012
Evaluating Network.....
Test set: Epoch: 378, Average loss: 0.0464, Top1Accuracy: 0.5920, Top3Accuracy: 0.7919, Top5Accuracy: 0.8607, Time consumed:1.76s

Training Epoch: 379 [32/50000]	Loss: 1.5927	LR: 0.000012
Training Epoch: 379 [32/50000]	Loss: 1.3659	LR: 0.000012
Training Epoch: 379 [32/50000]	Loss: 1.0973	LR: 0.000012
Training Epoch: 379 [32/50000]	Loss: 1.4571	LR: 0.000012
Training Epoch: 379 [32/50000]	Loss: 1.4876	LR: 0.000012
Training Epoch: 379 [32/50000]	Loss: 1.4528	LR: 0.000012
Training Epoch: 379 [32/50000]	Loss: 1.5557	LR: 0.000012
Training Epoch: 379 [32/50000]	Loss: 1.7557	LR: 0.000012
Training Epoch: 379 [32/50000]	Loss: 1.1710	LR: 0.000012
Training Epoch: 379 [32/50000]	Loss: 1.2836	LR: 0.000012
Evaluating Network.....
Test set: Epoch: 379, Average loss: 0.0463, Top1Accuracy: 0.5921, Top3Accuracy: 0.7923, Top5Accuracy: 0.8625, Time consumed:1.82s

Training Epoch: 380 [32/50000]	Loss: 1.5492	LR: 0.000012
Training Epoch: 380 [32/50000]	Loss: 1.4141	LR: 0.000012
Training Epoch: 380 [32/50000]	Loss: 1.3776	LR: 0.000012
Training Epoch: 380 [32/50000]	Loss: 1.3846	LR: 0.000012
Training Epoch: 380 [32/50000]	Loss: 1.4397	LR: 0.000012
Training Epoch: 380 [32/50000]	Loss: 1.3864	LR: 0.000012
Training Epoch: 380 [32/50000]	Loss: 1.4249	LR: 0.000012
Training Epoch: 380 [32/50000]	Loss: 0.9917	LR: 0.000012
Training Epoch: 380 [32/50000]	Loss: 1.1214	LR: 0.000012
Training Epoch: 380 [32/50000]	Loss: 0.8306	LR: 0.000012
Evaluating Network.....
Test set: Epoch: 380, Average loss: 0.0464, Top1Accuracy: 0.5923, Top3Accuracy: 0.7903, Top5Accuracy: 0.8609, Time consumed:1.96s

Training Epoch: 381 [32/50000]	Loss: 1.1601	LR: 0.000012
Training Epoch: 381 [32/50000]	Loss: 1.1855	LR: 0.000012
Training Epoch: 381 [32/50000]	Loss: 1.1512	LR: 0.000012
Training Epoch: 381 [32/50000]	Loss: 1.0410	LR: 0.000012
Training Epoch: 381 [32/50000]	Loss: 1.4627	LR: 0.000012
Training Epoch: 381 [32/50000]	Loss: 1.5862	LR: 0.000012
Training Epoch: 381 [32/50000]	Loss: 1.5188	LR: 0.000012
Training Epoch: 381 [32/50000]	Loss: 1.2536	LR: 0.000012
Training Epoch: 381 [32/50000]	Loss: 1.2044	LR: 0.000012
Training Epoch: 381 [32/50000]	Loss: 1.4056	LR: 0.000012
Evaluating Network.....
Test set: Epoch: 381, Average loss: 0.0463, Top1Accuracy: 0.5915, Top3Accuracy: 0.7930, Top5Accuracy: 0.8617, Time consumed:1.82s

Training Epoch: 382 [32/50000]	Loss: 1.1483	LR: 0.000011
Training Epoch: 382 [32/50000]	Loss: 1.4785	LR: 0.000011
Training Epoch: 382 [32/50000]	Loss: 1.3450	LR: 0.000011
Training Epoch: 382 [32/50000]	Loss: 1.1633	LR: 0.000011
Training Epoch: 382 [32/50000]	Loss: 1.5463	LR: 0.000011
Training Epoch: 382 [32/50000]	Loss: 1.7521	LR: 0.000011
Training Epoch: 382 [32/50000]	Loss: 2.1158	LR: 0.000011
Training Epoch: 382 [32/50000]	Loss: 1.1735	LR: 0.000011
Training Epoch: 382 [32/50000]	Loss: 1.4548	LR: 0.000011
Training Epoch: 382 [32/50000]	Loss: 1.2177	LR: 0.000011
Evaluating Network.....
Test set: Epoch: 382, Average loss: 0.0464, Top1Accuracy: 0.5917, Top3Accuracy: 0.7899, Top5Accuracy: 0.8611, Time consumed:1.72s

Training Epoch: 383 [32/50000]	Loss: 1.4783	LR: 0.000011
Training Epoch: 383 [32/50000]	Loss: 1.6540	LR: 0.000011
Training Epoch: 383 [32/50000]	Loss: 1.6000	LR: 0.000011
Training Epoch: 383 [32/50000]	Loss: 1.1533	LR: 0.000011
Training Epoch: 383 [32/50000]	Loss: 1.5018	LR: 0.000011
Training Epoch: 383 [32/50000]	Loss: 1.8242	LR: 0.000011
Training Epoch: 383 [32/50000]	Loss: 1.1641	LR: 0.000011
Training Epoch: 383 [32/50000]	Loss: 1.7219	LR: 0.000011
Training Epoch: 383 [32/50000]	Loss: 1.1368	LR: 0.000011
Training Epoch: 383 [32/50000]	Loss: 1.5987	LR: 0.000011
Evaluating Network.....
Test set: Epoch: 383, Average loss: 0.0464, Top1Accuracy: 0.5926, Top3Accuracy: 0.7910, Top5Accuracy: 0.8620, Time consumed:1.79s

Training Epoch: 384 [32/50000]	Loss: 1.6066	LR: 0.000011
Training Epoch: 384 [32/50000]	Loss: 0.8925	LR: 0.000011
Training Epoch: 384 [32/50000]	Loss: 1.1252	LR: 0.000011
Training Epoch: 384 [32/50000]	Loss: 1.4091	LR: 0.000011
Training Epoch: 384 [32/50000]	Loss: 1.1166	LR: 0.000011
Training Epoch: 384 [32/50000]	Loss: 1.3585	LR: 0.000011
Training Epoch: 384 [32/50000]	Loss: 1.1279	LR: 0.000011
Training Epoch: 384 [32/50000]	Loss: 1.4023	LR: 0.000011
Training Epoch: 384 [32/50000]	Loss: 1.4608	LR: 0.000011
Training Epoch: 384 [32/50000]	Loss: 1.6586	LR: 0.000011
Evaluating Network.....
Test set: Epoch: 384, Average loss: 0.0463, Top1Accuracy: 0.5928, Top3Accuracy: 0.7917, Top5Accuracy: 0.8627, Time consumed:1.89s

Training Epoch: 385 [32/50000]	Loss: 1.1966	LR: 0.000010
Training Epoch: 385 [32/50000]	Loss: 1.0115	LR: 0.000010
Training Epoch: 385 [32/50000]	Loss: 0.9148	LR: 0.000010
Training Epoch: 385 [32/50000]	Loss: 1.2338	LR: 0.000010
Training Epoch: 385 [32/50000]	Loss: 1.6655	LR: 0.000010
Training Epoch: 385 [32/50000]	Loss: 0.9322	LR: 0.000010
Training Epoch: 385 [32/50000]	Loss: 1.2004	LR: 0.000010
Training Epoch: 385 [32/50000]	Loss: 1.0271	LR: 0.000010
Training Epoch: 385 [32/50000]	Loss: 1.5837	LR: 0.000010
Training Epoch: 385 [32/50000]	Loss: 1.2780	LR: 0.000010
Evaluating Network.....
Test set: Epoch: 385, Average loss: 0.0463, Top1Accuracy: 0.5930, Top3Accuracy: 0.7897, Top5Accuracy: 0.8613, Time consumed:1.82s

Training Epoch: 386 [32/50000]	Loss: 0.8988	LR: 0.000010
Training Epoch: 386 [32/50000]	Loss: 1.2755	LR: 0.000010
Training Epoch: 386 [32/50000]	Loss: 1.6749	LR: 0.000010
Training Epoch: 386 [32/50000]	Loss: 1.6581	LR: 0.000010
Training Epoch: 386 [32/50000]	Loss: 1.6660	LR: 0.000010
Training Epoch: 386 [32/50000]	Loss: 1.0730	LR: 0.000010
Training Epoch: 386 [32/50000]	Loss: 1.2568	LR: 0.000010
Training Epoch: 386 [32/50000]	Loss: 1.2513	LR: 0.000010
Training Epoch: 386 [32/50000]	Loss: 1.3807	LR: 0.000010
Training Epoch: 386 [32/50000]	Loss: 2.0111	LR: 0.000010
Evaluating Network.....
Test set: Epoch: 386, Average loss: 0.0464, Top1Accuracy: 0.5928, Top3Accuracy: 0.7903, Top5Accuracy: 0.8618, Time consumed:1.97s

Training Epoch: 387 [32/50000]	Loss: 1.3037	LR: 0.000010
Training Epoch: 387 [32/50000]	Loss: 1.3738	LR: 0.000010
Training Epoch: 387 [32/50000]	Loss: 1.1878	LR: 0.000010
Training Epoch: 387 [32/50000]	Loss: 1.4584	LR: 0.000010
Training Epoch: 387 [32/50000]	Loss: 1.2948	LR: 0.000010
Training Epoch: 387 [32/50000]	Loss: 1.0869	LR: 0.000010
Training Epoch: 387 [32/50000]	Loss: 1.7011	LR: 0.000010
Training Epoch: 387 [32/50000]	Loss: 1.1764	LR: 0.000010
Training Epoch: 387 [32/50000]	Loss: 1.2734	LR: 0.000010
Training Epoch: 387 [32/50000]	Loss: 1.4550	LR: 0.000010
Evaluating Network.....
Test set: Epoch: 387, Average loss: 0.0464, Top1Accuracy: 0.5924, Top3Accuracy: 0.7914, Top5Accuracy: 0.8618, Time consumed:1.70s

Training Epoch: 388 [32/50000]	Loss: 1.0180	LR: 0.000010
Training Epoch: 388 [32/50000]	Loss: 1.3566	LR: 0.000010
Training Epoch: 388 [32/50000]	Loss: 0.9882	LR: 0.000010
Training Epoch: 388 [32/50000]	Loss: 1.4770	LR: 0.000010
Training Epoch: 388 [32/50000]	Loss: 1.4258	LR: 0.000010
Training Epoch: 388 [32/50000]	Loss: 1.6793	LR: 0.000010
Training Epoch: 388 [32/50000]	Loss: 1.1384	LR: 0.000010
Training Epoch: 388 [32/50000]	Loss: 1.1969	LR: 0.000010
Training Epoch: 388 [32/50000]	Loss: 1.4083	LR: 0.000010
Training Epoch: 388 [32/50000]	Loss: 1.1646	LR: 0.000010
Evaluating Network.....
Test set: Epoch: 388, Average loss: 0.0463, Top1Accuracy: 0.5927, Top3Accuracy: 0.7919, Top5Accuracy: 0.8620, Time consumed:1.77s

Training Epoch: 389 [32/50000]	Loss: 1.8898	LR: 0.000009
Training Epoch: 389 [32/50000]	Loss: 1.4940	LR: 0.000009
Training Epoch: 389 [32/50000]	Loss: 1.2542	LR: 0.000009
Training Epoch: 389 [32/50000]	Loss: 0.9847	LR: 0.000009
Training Epoch: 389 [32/50000]	Loss: 1.2292	LR: 0.000009
Training Epoch: 389 [32/50000]	Loss: 1.3730	LR: 0.000009
Training Epoch: 389 [32/50000]	Loss: 1.7140	LR: 0.000009
Training Epoch: 389 [32/50000]	Loss: 1.5142	LR: 0.000009
Training Epoch: 389 [32/50000]	Loss: 1.3351	LR: 0.000009
Training Epoch: 389 [32/50000]	Loss: 1.3058	LR: 0.000009
Evaluating Network.....
Test set: Epoch: 389, Average loss: 0.0464, Top1Accuracy: 0.5916, Top3Accuracy: 0.7919, Top5Accuracy: 0.8627, Time consumed:1.74s

Training Epoch: 390 [32/50000]	Loss: 1.3564	LR: 0.000009
Training Epoch: 390 [32/50000]	Loss: 0.8133	LR: 0.000009
Training Epoch: 390 [32/50000]	Loss: 1.2532	LR: 0.000009
Training Epoch: 390 [32/50000]	Loss: 0.8993	LR: 0.000009
Training Epoch: 390 [32/50000]	Loss: 1.2265	LR: 0.000009
Training Epoch: 390 [32/50000]	Loss: 0.9049	LR: 0.000009
Training Epoch: 390 [32/50000]	Loss: 1.3519	LR: 0.000009
Training Epoch: 390 [32/50000]	Loss: 1.2299	LR: 0.000009
Training Epoch: 390 [32/50000]	Loss: 1.6141	LR: 0.000009
Training Epoch: 390 [32/50000]	Loss: 1.4790	LR: 0.000009
Evaluating Network.....
Test set: Epoch: 390, Average loss: 0.0464, Top1Accuracy: 0.5915, Top3Accuracy: 0.7911, Top5Accuracy: 0.8623, Time consumed:2.02s

Training Epoch: 391 [32/50000]	Loss: 1.3863	LR: 0.000009
Training Epoch: 391 [32/50000]	Loss: 1.4554	LR: 0.000009
Training Epoch: 391 [32/50000]	Loss: 1.3230	LR: 0.000009
Training Epoch: 391 [32/50000]	Loss: 1.1617	LR: 0.000009
Training Epoch: 391 [32/50000]	Loss: 1.1901	LR: 0.000009
Training Epoch: 391 [32/50000]	Loss: 1.5844	LR: 0.000009
Training Epoch: 391 [32/50000]	Loss: 1.6923	LR: 0.000009
Training Epoch: 391 [32/50000]	Loss: 1.1441	LR: 0.000009
Training Epoch: 391 [32/50000]	Loss: 1.4586	LR: 0.000009
Training Epoch: 391 [32/50000]	Loss: 1.0279	LR: 0.000009
Evaluating Network.....
Test set: Epoch: 391, Average loss: 0.0464, Top1Accuracy: 0.5923, Top3Accuracy: 0.7899, Top5Accuracy: 0.8621, Time consumed:1.85s

Training Epoch: 392 [32/50000]	Loss: 1.1448	LR: 0.000009
Training Epoch: 392 [32/50000]	Loss: 1.3791	LR: 0.000009
Training Epoch: 392 [32/50000]	Loss: 1.3912	LR: 0.000009
Training Epoch: 392 [32/50000]	Loss: 1.1652	LR: 0.000009
Training Epoch: 392 [32/50000]	Loss: 1.3499	LR: 0.000009
Training Epoch: 392 [32/50000]	Loss: 1.2336	LR: 0.000009
Training Epoch: 392 [32/50000]	Loss: 1.3446	LR: 0.000009
Training Epoch: 392 [32/50000]	Loss: 1.0781	LR: 0.000009
Training Epoch: 392 [32/50000]	Loss: 1.1697	LR: 0.000009
Training Epoch: 392 [32/50000]	Loss: 1.0173	LR: 0.000009
Evaluating Network.....
Test set: Epoch: 392, Average loss: 0.0464, Top1Accuracy: 0.5922, Top3Accuracy: 0.7908, Top5Accuracy: 0.8623, Time consumed:1.78s

Training Epoch: 393 [32/50000]	Loss: 1.8553	LR: 0.000008
Training Epoch: 393 [32/50000]	Loss: 1.0879	LR: 0.000008
Training Epoch: 393 [32/50000]	Loss: 1.2576	LR: 0.000008
Training Epoch: 393 [32/50000]	Loss: 1.3674	LR: 0.000008
Training Epoch: 393 [32/50000]	Loss: 0.9537	LR: 0.000008
Training Epoch: 393 [32/50000]	Loss: 0.9450	LR: 0.000008
Training Epoch: 393 [32/50000]	Loss: 1.2118	LR: 0.000008
Training Epoch: 393 [32/50000]	Loss: 1.4047	LR: 0.000008
Training Epoch: 393 [32/50000]	Loss: 1.5997	LR: 0.000008
Training Epoch: 393 [32/50000]	Loss: 1.0817	LR: 0.000008
Evaluating Network.....
Test set: Epoch: 393, Average loss: 0.0465, Top1Accuracy: 0.5916, Top3Accuracy: 0.7911, Top5Accuracy: 0.8617, Time consumed:1.79s

Training Epoch: 394 [32/50000]	Loss: 1.3058	LR: 0.000008
Training Epoch: 394 [32/50000]	Loss: 0.9589	LR: 0.000008
Training Epoch: 394 [32/50000]	Loss: 1.5619	LR: 0.000008
Training Epoch: 394 [32/50000]	Loss: 1.4562	LR: 0.000008
Training Epoch: 394 [32/50000]	Loss: 1.5452	LR: 0.000008
Training Epoch: 394 [32/50000]	Loss: 1.2566	LR: 0.000008
Training Epoch: 394 [32/50000]	Loss: 1.2678	LR: 0.000008
Training Epoch: 394 [32/50000]	Loss: 1.0095	LR: 0.000008
Training Epoch: 394 [32/50000]	Loss: 0.7918	LR: 0.000008
Training Epoch: 394 [32/50000]	Loss: 1.4743	LR: 0.000008
Evaluating Network.....
Test set: Epoch: 394, Average loss: 0.0463, Top1Accuracy: 0.5920, Top3Accuracy: 0.7910, Top5Accuracy: 0.8622, Time consumed:1.81s

Training Epoch: 395 [32/50000]	Loss: 1.6093	LR: 0.000008
Training Epoch: 395 [32/50000]	Loss: 1.3914	LR: 0.000008
Training Epoch: 395 [32/50000]	Loss: 1.5238	LR: 0.000008
Training Epoch: 395 [32/50000]	Loss: 1.3775	LR: 0.000008
Training Epoch: 395 [32/50000]	Loss: 1.1544	LR: 0.000008
Training Epoch: 395 [32/50000]	Loss: 1.5168	LR: 0.000008
Training Epoch: 395 [32/50000]	Loss: 1.5032	LR: 0.000008
Training Epoch: 395 [32/50000]	Loss: 2.0151	LR: 0.000008
Training Epoch: 395 [32/50000]	Loss: 1.5447	LR: 0.000008
Training Epoch: 395 [32/50000]	Loss: 0.9577	LR: 0.000008
Evaluating Network.....
Test set: Epoch: 395, Average loss: 0.0464, Top1Accuracy: 0.5922, Top3Accuracy: 0.7908, Top5Accuracy: 0.8620, Time consumed:1.84s

Training Epoch: 396 [32/50000]	Loss: 1.2044	LR: 0.000008
Training Epoch: 396 [32/50000]	Loss: 1.8736	LR: 0.000008
Training Epoch: 396 [32/50000]	Loss: 1.4003	LR: 0.000008
Training Epoch: 396 [32/50000]	Loss: 1.4160	LR: 0.000008
Training Epoch: 396 [32/50000]	Loss: 1.5933	LR: 0.000008
Training Epoch: 396 [32/50000]	Loss: 1.5055	LR: 0.000008
Training Epoch: 396 [32/50000]	Loss: 1.3485	LR: 0.000008
Training Epoch: 396 [32/50000]	Loss: 0.9521	LR: 0.000008
Training Epoch: 396 [32/50000]	Loss: 0.9289	LR: 0.000008
Training Epoch: 396 [32/50000]	Loss: 1.4230	LR: 0.000008
Evaluating Network.....
Test set: Epoch: 396, Average loss: 0.0464, Top1Accuracy: 0.5922, Top3Accuracy: 0.7924, Top5Accuracy: 0.8624, Time consumed:1.86s

Training Epoch: 397 [32/50000]	Loss: 1.6437	LR: 0.000008
Training Epoch: 397 [32/50000]	Loss: 1.4740	LR: 0.000008
Training Epoch: 397 [32/50000]	Loss: 1.2856	LR: 0.000008
Training Epoch: 397 [32/50000]	Loss: 0.8915	LR: 0.000008
Training Epoch: 397 [32/50000]	Loss: 1.6776	LR: 0.000008
Training Epoch: 397 [32/50000]	Loss: 1.3985	LR: 0.000008
Training Epoch: 397 [32/50000]	Loss: 1.1560	LR: 0.000008
Training Epoch: 397 [32/50000]	Loss: 1.7532	LR: 0.000008
Training Epoch: 397 [32/50000]	Loss: 1.1028	LR: 0.000008
Training Epoch: 397 [32/50000]	Loss: 1.5187	LR: 0.000008
Evaluating Network.....
Test set: Epoch: 397, Average loss: 0.0463, Top1Accuracy: 0.5920, Top3Accuracy: 0.7923, Top5Accuracy: 0.8623, Time consumed:1.80s

Training Epoch: 398 [32/50000]	Loss: 1.1470	LR: 0.000007
Training Epoch: 398 [32/50000]	Loss: 1.4486	LR: 0.000007
Training Epoch: 398 [32/50000]	Loss: 1.5124	LR: 0.000007
Training Epoch: 398 [32/50000]	Loss: 0.9320	LR: 0.000007
Training Epoch: 398 [32/50000]	Loss: 1.0082	LR: 0.000007
Training Epoch: 398 [32/50000]	Loss: 1.3357	LR: 0.000007
Training Epoch: 398 [32/50000]	Loss: 0.8140	LR: 0.000007
Training Epoch: 398 [32/50000]	Loss: 1.0437	LR: 0.000007
Training Epoch: 398 [32/50000]	Loss: 1.5051	LR: 0.000007
Training Epoch: 398 [32/50000]	Loss: 1.3799	LR: 0.000007
Evaluating Network.....
Test set: Epoch: 398, Average loss: 0.0464, Top1Accuracy: 0.5911, Top3Accuracy: 0.7903, Top5Accuracy: 0.8622, Time consumed:1.81s

Training Epoch: 399 [32/50000]	Loss: 1.1189	LR: 0.000007
Training Epoch: 399 [32/50000]	Loss: 1.3463	LR: 0.000007
Training Epoch: 399 [32/50000]	Loss: 1.1826	LR: 0.000007
Training Epoch: 399 [32/50000]	Loss: 1.2670	LR: 0.000007
Training Epoch: 399 [32/50000]	Loss: 1.5434	LR: 0.000007
Training Epoch: 399 [32/50000]	Loss: 1.4979	LR: 0.000007
Training Epoch: 399 [32/50000]	Loss: 1.4797	LR: 0.000007
Training Epoch: 399 [32/50000]	Loss: 1.4977	LR: 0.000007
Training Epoch: 399 [32/50000]	Loss: 1.2533	LR: 0.000007
Training Epoch: 399 [32/50000]	Loss: 1.3986	LR: 0.000007
Evaluating Network.....
Test set: Epoch: 399, Average loss: 0.0464, Top1Accuracy: 0.5913, Top3Accuracy: 0.7916, Top5Accuracy: 0.8615, Time consumed:1.69s

Training Epoch: 400 [32/50000]	Loss: 1.6483	LR: 0.000007
Training Epoch: 400 [32/50000]	Loss: 0.9898	LR: 0.000007
Training Epoch: 400 [32/50000]	Loss: 1.3109	LR: 0.000007
Training Epoch: 400 [32/50000]	Loss: 1.3065	LR: 0.000007
Training Epoch: 400 [32/50000]	Loss: 1.2009	LR: 0.000007
Training Epoch: 400 [32/50000]	Loss: 1.1412	LR: 0.000007
Training Epoch: 400 [32/50000]	Loss: 0.9735	LR: 0.000007
Training Epoch: 400 [32/50000]	Loss: 1.7386	LR: 0.000007
Training Epoch: 400 [32/50000]	Loss: 1.1773	LR: 0.000007
Training Epoch: 400 [32/50000]	Loss: 1.4548	LR: 0.000007
Evaluating Network.....
Test set: Epoch: 400, Average loss: 0.0463, Top1Accuracy: 0.5934, Top3Accuracy: 0.7910, Top5Accuracy: 0.8626, Time consumed:1.79s

