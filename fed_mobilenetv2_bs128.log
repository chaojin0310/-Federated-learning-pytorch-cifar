Files already downloaded and verified
Files already downloaded and verified
Training Epoch: 1 [128/50000]	Loss: 4.6431	LR: 0.200000
Training Epoch: 1 [128/50000]	Loss: 4.6691	LR: 0.200000
Training Epoch: 1 [128/50000]	Loss: 4.6349	LR: 0.200000
Training Epoch: 1 [128/50000]	Loss: 4.6433	LR: 0.200000
Training Epoch: 1 [128/50000]	Loss: 4.6408	LR: 0.200000
Training Epoch: 1 [128/50000]	Loss: 4.5980	LR: 0.200000
Training Epoch: 1 [128/50000]	Loss: 4.6472	LR: 0.200000
Training Epoch: 1 [128/50000]	Loss: 4.6089	LR: 0.200000
Training Epoch: 1 [128/50000]	Loss: 4.6199	LR: 0.200000
Training Epoch: 1 [128/50000]	Loss: 4.6719	LR: 0.200000
Evaluating Network.....
Test set: Epoch: 1, Average loss: 0.0367, Top1Accuracy: 0.0100, Top3Accuracy: 0.0300, Top5Accuracy: 0.0500, Time consumed:1.79s

Training Epoch: 2 [128/50000]	Loss: 4.6358	LR: 0.194720
Training Epoch: 2 [128/50000]	Loss: 4.6245	LR: 0.194720
Training Epoch: 2 [128/50000]	Loss: 4.6548	LR: 0.194720
Training Epoch: 2 [128/50000]	Loss: 4.6777	LR: 0.194720
Training Epoch: 2 [128/50000]	Loss: 4.6580	LR: 0.194720
Training Epoch: 2 [128/50000]	Loss: 4.6077	LR: 0.194720
Training Epoch: 2 [128/50000]	Loss: 4.6531	LR: 0.194720
Training Epoch: 2 [128/50000]	Loss: 4.6453	LR: 0.194720
Training Epoch: 2 [128/50000]	Loss: 4.6736	LR: 0.194720
Training Epoch: 2 [128/50000]	Loss: 4.6042	LR: 0.194720
Evaluating Network.....
Test set: Epoch: 2, Average loss: 0.0378, Top1Accuracy: 0.0100, Top3Accuracy: 0.0300, Top5Accuracy: 0.0500, Time consumed:1.80s

Training Epoch: 3 [128/50000]	Loss: 4.2774	LR: 0.189579
Training Epoch: 3 [128/50000]	Loss: 4.2050	LR: 0.189579
Training Epoch: 3 [128/50000]	Loss: 4.2158	LR: 0.189579
Training Epoch: 3 [128/50000]	Loss: 4.3106	LR: 0.189579
Training Epoch: 3 [128/50000]	Loss: 4.3193	LR: 0.189579
Training Epoch: 3 [128/50000]	Loss: 4.2252	LR: 0.189579
Training Epoch: 3 [128/50000]	Loss: 4.2917	LR: 0.189579
Training Epoch: 3 [128/50000]	Loss: 4.3138	LR: 0.189579
Training Epoch: 3 [128/50000]	Loss: 4.2461	LR: 0.189579
Training Epoch: 3 [128/50000]	Loss: 4.2369	LR: 0.189579
Evaluating Network.....
Test set: Epoch: 3, Average loss: 0.0356, Top1Accuracy: 0.0239, Top3Accuracy: 0.0705, Top5Accuracy: 0.1130, Time consumed:1.79s

Training Epoch: 4 [128/50000]	Loss: 4.1663	LR: 0.184574
Training Epoch: 4 [128/50000]	Loss: 4.0017	LR: 0.184574
Training Epoch: 4 [128/50000]	Loss: 4.1044	LR: 0.184574
Training Epoch: 4 [128/50000]	Loss: 4.0695	LR: 0.184574
Training Epoch: 4 [128/50000]	Loss: 4.0657	LR: 0.184574
Training Epoch: 4 [128/50000]	Loss: 4.1391	LR: 0.184574
Training Epoch: 4 [128/50000]	Loss: 4.1579	LR: 0.184574
Training Epoch: 4 [128/50000]	Loss: 4.0575	LR: 0.184574
Training Epoch: 4 [128/50000]	Loss: 4.0496	LR: 0.184574
Training Epoch: 4 [128/50000]	Loss: 4.1497	LR: 0.184574
Evaluating Network.....
Test set: Epoch: 4, Average loss: 0.0350, Top1Accuracy: 0.0239, Top3Accuracy: 0.0704, Top5Accuracy: 0.1167, Time consumed:1.80s

Training Epoch: 5 [128/50000]	Loss: 3.9755	LR: 0.179702
Training Epoch: 5 [128/50000]	Loss: 4.0146	LR: 0.179702
Training Epoch: 5 [128/50000]	Loss: 4.0383	LR: 0.179702
Training Epoch: 5 [128/50000]	Loss: 3.9935	LR: 0.179702
Training Epoch: 5 [128/50000]	Loss: 3.9409	LR: 0.179702
Training Epoch: 5 [128/50000]	Loss: 3.9656	LR: 0.179702
Training Epoch: 5 [128/50000]	Loss: 4.0885	LR: 0.179702
Training Epoch: 5 [128/50000]	Loss: 4.0730	LR: 0.179702
Training Epoch: 5 [128/50000]	Loss: 4.0611	LR: 0.179702
Training Epoch: 5 [128/50000]	Loss: 3.9734	LR: 0.179702
Evaluating Network.....
Test set: Epoch: 5, Average loss: 0.0337, Top1Accuracy: 0.0391, Top3Accuracy: 0.1018, Top5Accuracy: 0.1633, Time consumed:1.79s

Training Epoch: 6 [128/50000]	Loss: 3.8566	LR: 0.174958
Training Epoch: 6 [128/50000]	Loss: 3.9773	LR: 0.174958
Training Epoch: 6 [128/50000]	Loss: 3.8965	LR: 0.174958
Training Epoch: 6 [128/50000]	Loss: 3.8647	LR: 0.174958
Training Epoch: 6 [128/50000]	Loss: 4.0640	LR: 0.174958
Training Epoch: 6 [128/50000]	Loss: 4.0125	LR: 0.174958
Training Epoch: 6 [128/50000]	Loss: 3.9864	LR: 0.174958
Training Epoch: 6 [128/50000]	Loss: 3.9602	LR: 0.174958
Training Epoch: 6 [128/50000]	Loss: 4.0462	LR: 0.174958
Training Epoch: 6 [128/50000]	Loss: 3.8647	LR: 0.174958
Evaluating Network.....
Test set: Epoch: 6, Average loss: 0.0323, Top1Accuracy: 0.0544, Top3Accuracy: 0.1454, Top5Accuracy: 0.2151, Time consumed:1.81s

Training Epoch: 7 [128/50000]	Loss: 3.9393	LR: 0.170339
Training Epoch: 7 [128/50000]	Loss: 3.7326	LR: 0.170339
Training Epoch: 7 [128/50000]	Loss: 3.7388	LR: 0.170339
Training Epoch: 7 [128/50000]	Loss: 3.8945	LR: 0.170339
Training Epoch: 7 [128/50000]	Loss: 3.8404	LR: 0.170339
Training Epoch: 7 [128/50000]	Loss: 3.9639	LR: 0.170339
Training Epoch: 7 [128/50000]	Loss: 3.8192	LR: 0.170339
Training Epoch: 7 [128/50000]	Loss: 3.8672	LR: 0.170339
Training Epoch: 7 [128/50000]	Loss: 3.8621	LR: 0.170339
Training Epoch: 7 [128/50000]	Loss: 3.9116	LR: 0.170339
Evaluating Network.....
Test set: Epoch: 7, Average loss: 0.0322, Top1Accuracy: 0.0665, Top3Accuracy: 0.1554, Top5Accuracy: 0.2251, Time consumed:1.79s

Training Epoch: 8 [128/50000]	Loss: 3.7541	LR: 0.165842
Training Epoch: 8 [128/50000]	Loss: 3.7064	LR: 0.165842
Training Epoch: 8 [128/50000]	Loss: 3.7898	LR: 0.165842
Training Epoch: 8 [128/50000]	Loss: 3.7067	LR: 0.165842
Training Epoch: 8 [128/50000]	Loss: 3.7508	LR: 0.165842
Training Epoch: 8 [128/50000]	Loss: 3.9015	LR: 0.165842
Training Epoch: 8 [128/50000]	Loss: 3.7669	LR: 0.165842
Training Epoch: 8 [128/50000]	Loss: 3.7384	LR: 0.165842
Training Epoch: 8 [128/50000]	Loss: 3.9687	LR: 0.165842
Training Epoch: 8 [128/50000]	Loss: 3.7440	LR: 0.165842
Evaluating Network.....
Test set: Epoch: 8, Average loss: 0.0322, Top1Accuracy: 0.0565, Top3Accuracy: 0.1581, Top5Accuracy: 0.2236, Time consumed:1.79s

Training Epoch: 9 [128/50000]	Loss: 3.8014	LR: 0.161464
Training Epoch: 9 [128/50000]	Loss: 3.7561	LR: 0.161464
Training Epoch: 9 [128/50000]	Loss: 3.8931	LR: 0.161464
Training Epoch: 9 [128/50000]	Loss: 3.8544	LR: 0.161464
Training Epoch: 9 [128/50000]	Loss: 3.8330	LR: 0.161464
Training Epoch: 9 [128/50000]	Loss: 3.6694	LR: 0.161464
Training Epoch: 9 [128/50000]	Loss: 3.7625	LR: 0.161464
Training Epoch: 9 [128/50000]	Loss: 3.8851	LR: 0.161464
Training Epoch: 9 [128/50000]	Loss: 3.7063	LR: 0.161464
Training Epoch: 9 [128/50000]	Loss: 3.8654	LR: 0.161464
Evaluating Network.....
Test set: Epoch: 9, Average loss: 0.0305, Top1Accuracy: 0.0952, Top3Accuracy: 0.2079, Top5Accuracy: 0.2923, Time consumed:1.79s

Training Epoch: 10 [128/50000]	Loss: 3.8450	LR: 0.157201
Training Epoch: 10 [128/50000]	Loss: 3.4829	LR: 0.157201
Training Epoch: 10 [128/50000]	Loss: 3.6255	LR: 0.157201
Training Epoch: 10 [128/50000]	Loss: 3.6579	LR: 0.157201
Training Epoch: 10 [128/50000]	Loss: 3.6232	LR: 0.157201
Training Epoch: 10 [128/50000]	Loss: 3.8061	LR: 0.157201
Training Epoch: 10 [128/50000]	Loss: 3.7678	LR: 0.157201
Training Epoch: 10 [128/50000]	Loss: 3.9818	LR: 0.157201
Training Epoch: 10 [128/50000]	Loss: 3.8267	LR: 0.157201
Training Epoch: 10 [128/50000]	Loss: 3.7370	LR: 0.157201
Evaluating Network.....
Test set: Epoch: 10, Average loss: 0.0302, Top1Accuracy: 0.1022, Top3Accuracy: 0.2245, Top5Accuracy: 0.3084, Time consumed:1.79s

Training Epoch: 11 [128/50000]	Loss: 3.6675	LR: 0.153051
Training Epoch: 11 [128/50000]	Loss: 3.5938	LR: 0.153051
Training Epoch: 11 [128/50000]	Loss: 3.7640	LR: 0.153051
Training Epoch: 11 [128/50000]	Loss: 3.7252	LR: 0.153051
Training Epoch: 11 [128/50000]	Loss: 3.7481	LR: 0.153051
Training Epoch: 11 [128/50000]	Loss: 3.8182	LR: 0.153051
Training Epoch: 11 [128/50000]	Loss: 3.5872	LR: 0.153051
Training Epoch: 11 [128/50000]	Loss: 3.7710	LR: 0.153051
Training Epoch: 11 [128/50000]	Loss: 3.5848	LR: 0.153051
Training Epoch: 11 [128/50000]	Loss: 3.5695	LR: 0.153051
Evaluating Network.....
Test set: Epoch: 11, Average loss: 0.0309, Top1Accuracy: 0.0870, Top3Accuracy: 0.1947, Top5Accuracy: 0.2789, Time consumed:1.80s

Training Epoch: 12 [128/50000]	Loss: 3.5457	LR: 0.149010
Training Epoch: 12 [128/50000]	Loss: 3.5929	LR: 0.149010
Training Epoch: 12 [128/50000]	Loss: 3.4934	LR: 0.149010
Training Epoch: 12 [128/50000]	Loss: 3.7025	LR: 0.149010
Training Epoch: 12 [128/50000]	Loss: 3.5099	LR: 0.149010
Training Epoch: 12 [128/50000]	Loss: 3.6446	LR: 0.149010
Training Epoch: 12 [128/50000]	Loss: 3.6065	LR: 0.149010
Training Epoch: 12 [128/50000]	Loss: 3.7417	LR: 0.149010
Training Epoch: 12 [128/50000]	Loss: 3.6219	LR: 0.149010
Training Epoch: 12 [128/50000]	Loss: 3.5494	LR: 0.149010
Evaluating Network.....
Test set: Epoch: 12, Average loss: 0.0300, Top1Accuracy: 0.1000, Top3Accuracy: 0.2181, Top5Accuracy: 0.3112, Time consumed:1.78s

Training Epoch: 13 [128/50000]	Loss: 3.7561	LR: 0.145076
Training Epoch: 13 [128/50000]	Loss: 3.6109	LR: 0.145076
Training Epoch: 13 [128/50000]	Loss: 3.5723	LR: 0.145076
Training Epoch: 13 [128/50000]	Loss: 3.5732	LR: 0.145076
Training Epoch: 13 [128/50000]	Loss: 3.6170	LR: 0.145076
Training Epoch: 13 [128/50000]	Loss: 3.5365	LR: 0.145076
Training Epoch: 13 [128/50000]	Loss: 3.6211	LR: 0.145076
Training Epoch: 13 [128/50000]	Loss: 3.4303	LR: 0.145076
Training Epoch: 13 [128/50000]	Loss: 3.5455	LR: 0.145076
Training Epoch: 13 [128/50000]	Loss: 3.5640	LR: 0.145076
Evaluating Network.....
Test set: Epoch: 13, Average loss: 0.0298, Top1Accuracy: 0.1015, Top3Accuracy: 0.2344, Top5Accuracy: 0.3215, Time consumed:1.79s

Training Epoch: 14 [128/50000]	Loss: 3.5689	LR: 0.141246
Training Epoch: 14 [128/50000]	Loss: 3.6303	LR: 0.141246
Training Epoch: 14 [128/50000]	Loss: 3.5174	LR: 0.141246
Training Epoch: 14 [128/50000]	Loss: 3.5796	LR: 0.141246
Training Epoch: 14 [128/50000]	Loss: 3.5288	LR: 0.141246
Training Epoch: 14 [128/50000]	Loss: 3.4310	LR: 0.141246
Training Epoch: 14 [128/50000]	Loss: 3.4713	LR: 0.141246
Training Epoch: 14 [128/50000]	Loss: 3.5903	LR: 0.141246
Training Epoch: 14 [128/50000]	Loss: 3.3918	LR: 0.141246
Training Epoch: 14 [128/50000]	Loss: 3.4504	LR: 0.141246
Evaluating Network.....
Test set: Epoch: 14, Average loss: 0.0286, Top1Accuracy: 0.1337, Top3Accuracy: 0.2770, Top5Accuracy: 0.3700, Time consumed:1.78s

Training Epoch: 15 [128/50000]	Loss: 3.4096	LR: 0.137517
Training Epoch: 15 [128/50000]	Loss: 3.6135	LR: 0.137517
Training Epoch: 15 [128/50000]	Loss: 3.3206	LR: 0.137517
Training Epoch: 15 [128/50000]	Loss: 3.3579	LR: 0.137517
Training Epoch: 15 [128/50000]	Loss: 3.3095	LR: 0.137517
Training Epoch: 15 [128/50000]	Loss: 3.4435	LR: 0.137517
Training Epoch: 15 [128/50000]	Loss: 3.2882	LR: 0.137517
Training Epoch: 15 [128/50000]	Loss: 3.4075	LR: 0.137517
Training Epoch: 15 [128/50000]	Loss: 3.3488	LR: 0.137517
Training Epoch: 15 [128/50000]	Loss: 3.6080	LR: 0.137517
Evaluating Network.....
Test set: Epoch: 15, Average loss: 0.0286, Top1Accuracy: 0.1307, Top3Accuracy: 0.2696, Top5Accuracy: 0.3661, Time consumed:1.79s

Training Epoch: 16 [128/50000]	Loss: 3.3067	LR: 0.133887
Training Epoch: 16 [128/50000]	Loss: 3.4546	LR: 0.133887
Training Epoch: 16 [128/50000]	Loss: 3.3003	LR: 0.133887
Training Epoch: 16 [128/50000]	Loss: 3.2901	LR: 0.133887
Training Epoch: 16 [128/50000]	Loss: 3.5631	LR: 0.133887
Training Epoch: 16 [128/50000]	Loss: 3.6299	LR: 0.133887
Training Epoch: 16 [128/50000]	Loss: 3.4851	LR: 0.133887
Training Epoch: 16 [128/50000]	Loss: 3.3436	LR: 0.133887
Training Epoch: 16 [128/50000]	Loss: 3.2314	LR: 0.133887
Training Epoch: 16 [128/50000]	Loss: 3.4698	LR: 0.133887
Evaluating Network.....
Test set: Epoch: 16, Average loss: 0.0278, Top1Accuracy: 0.1463, Top3Accuracy: 0.2999, Top5Accuracy: 0.4049, Time consumed:1.81s

Training Epoch: 17 [128/50000]	Loss: 3.4528	LR: 0.130352
Training Epoch: 17 [128/50000]	Loss: 3.3342	LR: 0.130352
Training Epoch: 17 [128/50000]	Loss: 3.3124	LR: 0.130352
Training Epoch: 17 [128/50000]	Loss: 3.5952	LR: 0.130352
Training Epoch: 17 [128/50000]	Loss: 3.1168	LR: 0.130352
Training Epoch: 17 [128/50000]	Loss: 3.2639	LR: 0.130352
Training Epoch: 17 [128/50000]	Loss: 3.4390	LR: 0.130352
Training Epoch: 17 [128/50000]	Loss: 3.4393	LR: 0.130352
Training Epoch: 17 [128/50000]	Loss: 3.2964	LR: 0.130352
Training Epoch: 17 [128/50000]	Loss: 3.6089	LR: 0.130352
Evaluating Network.....
Test set: Epoch: 17, Average loss: 0.0272, Top1Accuracy: 0.1567, Top3Accuracy: 0.3201, Top5Accuracy: 0.4213, Time consumed:1.79s

Training Epoch: 18 [128/50000]	Loss: 3.2651	LR: 0.126911
Training Epoch: 18 [128/50000]	Loss: 3.4288	LR: 0.126911
Training Epoch: 18 [128/50000]	Loss: 3.3511	LR: 0.126911
Training Epoch: 18 [128/50000]	Loss: 3.2972	LR: 0.126911
Training Epoch: 18 [128/50000]	Loss: 3.4462	LR: 0.126911
Training Epoch: 18 [128/50000]	Loss: 3.1754	LR: 0.126911
Training Epoch: 18 [128/50000]	Loss: 3.1829	LR: 0.126911
Training Epoch: 18 [128/50000]	Loss: 3.1748	LR: 0.126911
Training Epoch: 18 [128/50000]	Loss: 3.3038	LR: 0.126911
Training Epoch: 18 [128/50000]	Loss: 3.4116	LR: 0.126911
Evaluating Network.....
Test set: Epoch: 18, Average loss: 0.0268, Top1Accuracy: 0.1717, Top3Accuracy: 0.3399, Top5Accuracy: 0.4442, Time consumed:1.79s

Training Epoch: 19 [128/50000]	Loss: 3.1822	LR: 0.123561
Training Epoch: 19 [128/50000]	Loss: 3.2785	LR: 0.123561
Training Epoch: 19 [128/50000]	Loss: 3.1677	LR: 0.123561
Training Epoch: 19 [128/50000]	Loss: 3.1571	LR: 0.123561
Training Epoch: 19 [128/50000]	Loss: 3.3984	LR: 0.123561
Training Epoch: 19 [128/50000]	Loss: 3.4011	LR: 0.123561
Training Epoch: 19 [128/50000]	Loss: 3.5835	LR: 0.123561
Training Epoch: 19 [128/50000]	Loss: 3.2787	LR: 0.123561
Training Epoch: 19 [128/50000]	Loss: 3.2684	LR: 0.123561
Training Epoch: 19 [128/50000]	Loss: 3.1926	LR: 0.123561
Evaluating Network.....
Test set: Epoch: 19, Average loss: 0.0264, Top1Accuracy: 0.1779, Top3Accuracy: 0.3455, Top5Accuracy: 0.4545, Time consumed:1.81s

Training Epoch: 20 [128/50000]	Loss: 3.3907	LR: 0.120299
Training Epoch: 20 [128/50000]	Loss: 3.1144	LR: 0.120299
Training Epoch: 20 [128/50000]	Loss: 3.0960	LR: 0.120299
Training Epoch: 20 [128/50000]	Loss: 3.3241	LR: 0.120299
Training Epoch: 20 [128/50000]	Loss: 3.3984	LR: 0.120299
Training Epoch: 20 [128/50000]	Loss: 3.2977	LR: 0.120299
Training Epoch: 20 [128/50000]	Loss: 3.4053	LR: 0.120299
Training Epoch: 20 [128/50000]	Loss: 3.1733	LR: 0.120299
Training Epoch: 20 [128/50000]	Loss: 3.1604	LR: 0.120299
Training Epoch: 20 [128/50000]	Loss: 3.3079	LR: 0.120299
Evaluating Network.....
Test set: Epoch: 20, Average loss: 0.0265, Top1Accuracy: 0.1833, Top3Accuracy: 0.3517, Top5Accuracy: 0.4550, Time consumed:1.78s

Training Epoch: 21 [128/50000]	Loss: 3.1902	LR: 0.117123
Training Epoch: 21 [128/50000]	Loss: 3.3635	LR: 0.117123
Training Epoch: 21 [128/50000]	Loss: 3.3597	LR: 0.117123
Training Epoch: 21 [128/50000]	Loss: 3.1775	LR: 0.117123
Training Epoch: 21 [128/50000]	Loss: 3.0876	LR: 0.117123
Training Epoch: 21 [128/50000]	Loss: 3.2268	LR: 0.117123
Training Epoch: 21 [128/50000]	Loss: 3.2650	LR: 0.117123
Training Epoch: 21 [128/50000]	Loss: 3.1015	LR: 0.117123
Training Epoch: 21 [128/50000]	Loss: 3.0616	LR: 0.117123
Training Epoch: 21 [128/50000]	Loss: 3.2746	LR: 0.117123
Evaluating Network.....
Test set: Epoch: 21, Average loss: 0.0255, Top1Accuracy: 0.1937, Top3Accuracy: 0.3790, Top5Accuracy: 0.4842, Time consumed:2.02s

Training Epoch: 22 [128/50000]	Loss: 3.1222	LR: 0.114031
Training Epoch: 22 [128/50000]	Loss: 2.9960	LR: 0.114031
Training Epoch: 22 [128/50000]	Loss: 3.2079	LR: 0.114031
Training Epoch: 22 [128/50000]	Loss: 3.2010	LR: 0.114031
Training Epoch: 22 [128/50000]	Loss: 3.0556	LR: 0.114031
Training Epoch: 22 [128/50000]	Loss: 3.0380	LR: 0.114031
Training Epoch: 22 [128/50000]	Loss: 3.1871	LR: 0.114031
Training Epoch: 22 [128/50000]	Loss: 3.2896	LR: 0.114031
Training Epoch: 22 [128/50000]	Loss: 3.1436	LR: 0.114031
Training Epoch: 22 [128/50000]	Loss: 3.2689	LR: 0.114031
Evaluating Network.....
Test set: Epoch: 22, Average loss: 0.0256, Top1Accuracy: 0.2024, Top3Accuracy: 0.3830, Top5Accuracy: 0.4886, Time consumed:1.78s

Training Epoch: 23 [128/50000]	Loss: 3.1243	LR: 0.111020
Training Epoch: 23 [128/50000]	Loss: 3.0951	LR: 0.111020
Training Epoch: 23 [128/50000]	Loss: 3.1112	LR: 0.111020
Training Epoch: 23 [128/50000]	Loss: 2.9902	LR: 0.111020
Training Epoch: 23 [128/50000]	Loss: 3.2234	LR: 0.111020
Training Epoch: 23 [128/50000]	Loss: 3.0748	LR: 0.111020
Training Epoch: 23 [128/50000]	Loss: 3.1422	LR: 0.111020
Training Epoch: 23 [128/50000]	Loss: 2.8401	LR: 0.111020
Training Epoch: 23 [128/50000]	Loss: 3.0108	LR: 0.111020
Training Epoch: 23 [128/50000]	Loss: 2.6405	LR: 0.111020
Evaluating Network.....
Test set: Epoch: 23, Average loss: 0.0249, Top1Accuracy: 0.2143, Top3Accuracy: 0.4021, Top5Accuracy: 0.5023, Time consumed:1.78s

Training Epoch: 24 [128/50000]	Loss: 2.9023	LR: 0.108089
Training Epoch: 24 [128/50000]	Loss: 3.2162	LR: 0.108089
Training Epoch: 24 [128/50000]	Loss: 3.2295	LR: 0.108089
Training Epoch: 24 [128/50000]	Loss: 3.1529	LR: 0.108089
Training Epoch: 24 [128/50000]	Loss: 3.0968	LR: 0.108089
Training Epoch: 24 [128/50000]	Loss: 3.2013	LR: 0.108089
Training Epoch: 24 [128/50000]	Loss: 2.9927	LR: 0.108089
Training Epoch: 24 [128/50000]	Loss: 3.1241	LR: 0.108089
Training Epoch: 24 [128/50000]	Loss: 3.3021	LR: 0.108089
Training Epoch: 24 [128/50000]	Loss: 2.9420	LR: 0.108089
Evaluating Network.....
Test set: Epoch: 24, Average loss: 0.0246, Top1Accuracy: 0.2202, Top3Accuracy: 0.4141, Top5Accuracy: 0.5187, Time consumed:1.79s

Training Epoch: 25 [128/50000]	Loss: 3.0016	LR: 0.105236
Training Epoch: 25 [128/50000]	Loss: 2.8622	LR: 0.105236
Training Epoch: 25 [128/50000]	Loss: 3.2015	LR: 0.105236
Training Epoch: 25 [128/50000]	Loss: 2.8642	LR: 0.105236
Training Epoch: 25 [128/50000]	Loss: 2.8086	LR: 0.105236
Training Epoch: 25 [128/50000]	Loss: 3.0804	LR: 0.105236
Training Epoch: 25 [128/50000]	Loss: 2.9550	LR: 0.105236
Training Epoch: 25 [128/50000]	Loss: 2.9636	LR: 0.105236
Training Epoch: 25 [128/50000]	Loss: 2.9567	LR: 0.105236
Training Epoch: 25 [128/50000]	Loss: 2.8578	LR: 0.105236
Evaluating Network.....
Test set: Epoch: 25, Average loss: 0.0242, Top1Accuracy: 0.2263, Top3Accuracy: 0.4199, Top5Accuracy: 0.5236, Time consumed:1.79s

Training Epoch: 26 [128/50000]	Loss: 2.9224	LR: 0.102458
Training Epoch: 26 [128/50000]	Loss: 2.8751	LR: 0.102458
Training Epoch: 26 [128/50000]	Loss: 2.8862	LR: 0.102458
Training Epoch: 26 [128/50000]	Loss: 2.9093	LR: 0.102458
Training Epoch: 26 [128/50000]	Loss: 2.9958	LR: 0.102458
Training Epoch: 26 [128/50000]	Loss: 2.9865	LR: 0.102458
Training Epoch: 26 [128/50000]	Loss: 3.2964	LR: 0.102458
Training Epoch: 26 [128/50000]	Loss: 3.1232	LR: 0.102458
Training Epoch: 26 [128/50000]	Loss: 3.0079	LR: 0.102458
Training Epoch: 26 [128/50000]	Loss: 3.0059	LR: 0.102458
Evaluating Network.....
Test set: Epoch: 26, Average loss: 0.0237, Top1Accuracy: 0.2410, Top3Accuracy: 0.4361, Top5Accuracy: 0.5483, Time consumed:1.78s

Training Epoch: 27 [128/50000]	Loss: 2.9804	LR: 0.099753
Training Epoch: 27 [128/50000]	Loss: 2.9018	LR: 0.099753
Training Epoch: 27 [128/50000]	Loss: 3.0563	LR: 0.099753
Training Epoch: 27 [128/50000]	Loss: 2.8253	LR: 0.099753
Training Epoch: 27 [128/50000]	Loss: 2.9871	LR: 0.099753
Training Epoch: 27 [128/50000]	Loss: 2.7238	LR: 0.099753
Training Epoch: 27 [128/50000]	Loss: 2.7938	LR: 0.099753
Training Epoch: 27 [128/50000]	Loss: 2.7620	LR: 0.099753
Training Epoch: 27 [128/50000]	Loss: 3.0780	LR: 0.099753
Training Epoch: 27 [128/50000]	Loss: 3.1219	LR: 0.099753
Evaluating Network.....
Test set: Epoch: 27, Average loss: 0.0235, Top1Accuracy: 0.2469, Top3Accuracy: 0.4462, Top5Accuracy: 0.5527, Time consumed:1.80s

Training Epoch: 28 [128/50000]	Loss: 2.8681	LR: 0.097119
Training Epoch: 28 [128/50000]	Loss: 3.0267	LR: 0.097119
Training Epoch: 28 [128/50000]	Loss: 2.7251	LR: 0.097119
Training Epoch: 28 [128/50000]	Loss: 2.7062	LR: 0.097119
Training Epoch: 28 [128/50000]	Loss: 2.8411	LR: 0.097119
Training Epoch: 28 [128/50000]	Loss: 2.6140	LR: 0.097119
Training Epoch: 28 [128/50000]	Loss: 3.0575	LR: 0.097119
Training Epoch: 28 [128/50000]	Loss: 2.8258	LR: 0.097119
Training Epoch: 28 [128/50000]	Loss: 2.8046	LR: 0.097119
Training Epoch: 28 [128/50000]	Loss: 3.0074	LR: 0.097119
Evaluating Network.....
Test set: Epoch: 28, Average loss: 0.0229, Top1Accuracy: 0.2627, Top3Accuracy: 0.4677, Top5Accuracy: 0.5731, Time consumed:1.79s

Training Epoch: 29 [128/50000]	Loss: 2.7273	LR: 0.094555
Training Epoch: 29 [128/50000]	Loss: 2.7280	LR: 0.094555
Training Epoch: 29 [128/50000]	Loss: 3.0326	LR: 0.094555
Training Epoch: 29 [128/50000]	Loss: 2.7968	LR: 0.094555
Training Epoch: 29 [128/50000]	Loss: 2.7030	LR: 0.094555
Training Epoch: 29 [128/50000]	Loss: 2.6887	LR: 0.094555
Training Epoch: 29 [128/50000]	Loss: 2.8389	LR: 0.094555
Training Epoch: 29 [128/50000]	Loss: 2.7013	LR: 0.094555
Training Epoch: 29 [128/50000]	Loss: 2.9929	LR: 0.094555
Training Epoch: 29 [128/50000]	Loss: 2.6073	LR: 0.094555
Evaluating Network.....
Test set: Epoch: 29, Average loss: 0.0229, Top1Accuracy: 0.2606, Top3Accuracy: 0.4668, Top5Accuracy: 0.5749, Time consumed:1.79s

Training Epoch: 30 [128/50000]	Loss: 2.8825	LR: 0.092059
Training Epoch: 30 [128/50000]	Loss: 2.5717	LR: 0.092059
Training Epoch: 30 [128/50000]	Loss: 2.6426	LR: 0.092059
Training Epoch: 30 [128/50000]	Loss: 3.0252	LR: 0.092059
Training Epoch: 30 [128/50000]	Loss: 2.6246	LR: 0.092059
Training Epoch: 30 [128/50000]	Loss: 2.5997	LR: 0.092059
Training Epoch: 30 [128/50000]	Loss: 2.8629	LR: 0.092059
Training Epoch: 30 [128/50000]	Loss: 2.6041	LR: 0.092059
Training Epoch: 30 [128/50000]	Loss: 2.7500	LR: 0.092059
Training Epoch: 30 [128/50000]	Loss: 2.7203	LR: 0.092059
Evaluating Network.....
Test set: Epoch: 30, Average loss: 0.0223, Top1Accuracy: 0.2719, Top3Accuracy: 0.4830, Top5Accuracy: 0.5910, Time consumed:1.83s

Training Epoch: 31 [128/50000]	Loss: 2.8148	LR: 0.089629
Training Epoch: 31 [128/50000]	Loss: 2.7572	LR: 0.089629
Training Epoch: 31 [128/50000]	Loss: 2.5676	LR: 0.089629
Training Epoch: 31 [128/50000]	Loss: 2.7074	LR: 0.089629
Training Epoch: 31 [128/50000]	Loss: 2.7605	LR: 0.089629
Training Epoch: 31 [128/50000]	Loss: 2.6948	LR: 0.089629
Training Epoch: 31 [128/50000]	Loss: 2.4112	LR: 0.089629
Training Epoch: 31 [128/50000]	Loss: 2.8399	LR: 0.089629
Training Epoch: 31 [128/50000]	Loss: 2.6576	LR: 0.089629
Training Epoch: 31 [128/50000]	Loss: 2.8342	LR: 0.089629
Evaluating Network.....
Test set: Epoch: 31, Average loss: 0.0220, Top1Accuracy: 0.2790, Top3Accuracy: 0.4991, Top5Accuracy: 0.6068, Time consumed:1.79s

Training Epoch: 32 [128/50000]	Loss: 2.7274	LR: 0.087262
Training Epoch: 32 [128/50000]	Loss: 2.7957	LR: 0.087262
Training Epoch: 32 [128/50000]	Loss: 2.6890	LR: 0.087262
Training Epoch: 32 [128/50000]	Loss: 2.6341	LR: 0.087262
Training Epoch: 32 [128/50000]	Loss: 2.6410	LR: 0.087262
Training Epoch: 32 [128/50000]	Loss: 2.9724	LR: 0.087262
Training Epoch: 32 [128/50000]	Loss: 2.5494	LR: 0.087262
Training Epoch: 32 [128/50000]	Loss: 2.5183	LR: 0.087262
Training Epoch: 32 [128/50000]	Loss: 2.6151	LR: 0.087262
Training Epoch: 32 [128/50000]	Loss: 2.8309	LR: 0.087262
Evaluating Network.....
Test set: Epoch: 32, Average loss: 0.0220, Top1Accuracy: 0.2835, Top3Accuracy: 0.4916, Top5Accuracy: 0.5975, Time consumed:1.80s

Training Epoch: 33 [128/50000]	Loss: 2.5464	LR: 0.084959
Training Epoch: 33 [128/50000]	Loss: 2.6990	LR: 0.084959
Training Epoch: 33 [128/50000]	Loss: 2.7333	LR: 0.084959
Training Epoch: 33 [128/50000]	Loss: 2.6667	LR: 0.084959
Training Epoch: 33 [128/50000]	Loss: 2.3962	LR: 0.084959
Training Epoch: 33 [128/50000]	Loss: 2.6939	LR: 0.084959
Training Epoch: 33 [128/50000]	Loss: 2.6505	LR: 0.084959
Training Epoch: 33 [128/50000]	Loss: 2.6947	LR: 0.084959
Training Epoch: 33 [128/50000]	Loss: 2.5861	LR: 0.084959
Training Epoch: 33 [128/50000]	Loss: 2.5339	LR: 0.084959
Evaluating Network.....
Test set: Epoch: 33, Average loss: 0.0211, Top1Accuracy: 0.3064, Top3Accuracy: 0.5262, Top5Accuracy: 0.6297, Time consumed:1.80s

Training Epoch: 34 [128/50000]	Loss: 2.6962	LR: 0.082716
Training Epoch: 34 [128/50000]	Loss: 2.7034	LR: 0.082716
Training Epoch: 34 [128/50000]	Loss: 2.6212	LR: 0.082716
Training Epoch: 34 [128/50000]	Loss: 2.4226	LR: 0.082716
Training Epoch: 34 [128/50000]	Loss: 2.7280	LR: 0.082716
Training Epoch: 34 [128/50000]	Loss: 2.5545	LR: 0.082716
Training Epoch: 34 [128/50000]	Loss: 2.9039	LR: 0.082716
Training Epoch: 34 [128/50000]	Loss: 2.8692	LR: 0.082716
Training Epoch: 34 [128/50000]	Loss: 2.5158	LR: 0.082716
Training Epoch: 34 [128/50000]	Loss: 2.5811	LR: 0.082716
Evaluating Network.....
Test set: Epoch: 34, Average loss: 0.0207, Top1Accuracy: 0.3145, Top3Accuracy: 0.5317, Top5Accuracy: 0.6370, Time consumed:1.81s

Training Epoch: 35 [128/50000]	Loss: 2.6710	LR: 0.080532
Training Epoch: 35 [128/50000]	Loss: 2.7956	LR: 0.080532
Training Epoch: 35 [128/50000]	Loss: 2.2677	LR: 0.080532
Training Epoch: 35 [128/50000]	Loss: 2.4790	LR: 0.080532
Training Epoch: 35 [128/50000]	Loss: 2.2740	LR: 0.080532
Training Epoch: 35 [128/50000]	Loss: 2.7334	LR: 0.080532
Training Epoch: 35 [128/50000]	Loss: 2.6733	LR: 0.080532
Training Epoch: 35 [128/50000]	Loss: 2.7578	LR: 0.080532
Training Epoch: 35 [128/50000]	Loss: 2.6750	LR: 0.080532
Training Epoch: 35 [128/50000]	Loss: 2.6981	LR: 0.080532
Evaluating Network.....
Test set: Epoch: 35, Average loss: 0.0202, Top1Accuracy: 0.3285, Top3Accuracy: 0.5419, Top5Accuracy: 0.6539, Time consumed:1.78s

Training Epoch: 36 [128/50000]	Loss: 2.2932	LR: 0.078406
Training Epoch: 36 [128/50000]	Loss: 2.6433	LR: 0.078406
Training Epoch: 36 [128/50000]	Loss: 2.6877	LR: 0.078406
Training Epoch: 36 [128/50000]	Loss: 2.4801	LR: 0.078406
Training Epoch: 36 [128/50000]	Loss: 2.4081	LR: 0.078406
Training Epoch: 36 [128/50000]	Loss: 2.5577	LR: 0.078406
Training Epoch: 36 [128/50000]	Loss: 2.4120	LR: 0.078406
Training Epoch: 36 [128/50000]	Loss: 2.5025	LR: 0.078406
Training Epoch: 36 [128/50000]	Loss: 2.3874	LR: 0.078406
Training Epoch: 36 [128/50000]	Loss: 2.4758	LR: 0.078406
Evaluating Network.....
Test set: Epoch: 36, Average loss: 0.0201, Top1Accuracy: 0.3338, Top3Accuracy: 0.5552, Top5Accuracy: 0.6584, Time consumed:1.81s

Training Epoch: 37 [128/50000]	Loss: 2.4999	LR: 0.076336
Training Epoch: 37 [128/50000]	Loss: 2.3574	LR: 0.076336
Training Epoch: 37 [128/50000]	Loss: 2.4277	LR: 0.076336
Training Epoch: 37 [128/50000]	Loss: 2.5734	LR: 0.076336
Training Epoch: 37 [128/50000]	Loss: 2.5128	LR: 0.076336
Training Epoch: 37 [128/50000]	Loss: 2.5911	LR: 0.076336
Training Epoch: 37 [128/50000]	Loss: 2.5051	LR: 0.076336
Training Epoch: 37 [128/50000]	Loss: 2.6958	LR: 0.076336
Training Epoch: 37 [128/50000]	Loss: 2.4367	LR: 0.076336
Training Epoch: 37 [128/50000]	Loss: 2.1629	LR: 0.076336
Evaluating Network.....
Test set: Epoch: 37, Average loss: 0.0194, Top1Accuracy: 0.3458, Top3Accuracy: 0.5730, Top5Accuracy: 0.6750, Time consumed:1.78s

Training Epoch: 38 [128/50000]	Loss: 2.4734	LR: 0.074321
Training Epoch: 38 [128/50000]	Loss: 2.6092	LR: 0.074321
Training Epoch: 38 [128/50000]	Loss: 2.2920	LR: 0.074321
Training Epoch: 38 [128/50000]	Loss: 2.6056	LR: 0.074321
Training Epoch: 38 [128/50000]	Loss: 2.3252	LR: 0.074321
Training Epoch: 38 [128/50000]	Loss: 2.5222	LR: 0.074321
Training Epoch: 38 [128/50000]	Loss: 2.4662	LR: 0.074321
Training Epoch: 38 [128/50000]	Loss: 2.5037	LR: 0.074321
Training Epoch: 38 [128/50000]	Loss: 2.4823	LR: 0.074321
Training Epoch: 38 [128/50000]	Loss: 2.4894	LR: 0.074321
Evaluating Network.....
Test set: Epoch: 38, Average loss: 0.0193, Top1Accuracy: 0.3450, Top3Accuracy: 0.5749, Top5Accuracy: 0.6821, Time consumed:1.79s

Training Epoch: 39 [128/50000]	Loss: 2.5522	LR: 0.072359
Training Epoch: 39 [128/50000]	Loss: 2.3019	LR: 0.072359
Training Epoch: 39 [128/50000]	Loss: 2.4914	LR: 0.072359
Training Epoch: 39 [128/50000]	Loss: 2.6377	LR: 0.072359
Training Epoch: 39 [128/50000]	Loss: 2.5086	LR: 0.072359
Training Epoch: 39 [128/50000]	Loss: 2.3287	LR: 0.072359
Training Epoch: 39 [128/50000]	Loss: 2.3965	LR: 0.072359
Training Epoch: 39 [128/50000]	Loss: 2.4711	LR: 0.072359
Training Epoch: 39 [128/50000]	Loss: 2.5330	LR: 0.072359
Training Epoch: 39 [128/50000]	Loss: 2.5060	LR: 0.072359
Evaluating Network.....
Test set: Epoch: 39, Average loss: 0.0193, Top1Accuracy: 0.3447, Top3Accuracy: 0.5747, Top5Accuracy: 0.6791, Time consumed:1.79s

Training Epoch: 40 [128/50000]	Loss: 2.4595	LR: 0.070449
Training Epoch: 40 [128/50000]	Loss: 2.3051	LR: 0.070449
Training Epoch: 40 [128/50000]	Loss: 2.5432	LR: 0.070449
Training Epoch: 40 [128/50000]	Loss: 2.5011	LR: 0.070449
Training Epoch: 40 [128/50000]	Loss: 2.5180	LR: 0.070449
Training Epoch: 40 [128/50000]	Loss: 2.5692	LR: 0.070449
Training Epoch: 40 [128/50000]	Loss: 2.3785	LR: 0.070449
Training Epoch: 40 [128/50000]	Loss: 2.5611	LR: 0.070449
Training Epoch: 40 [128/50000]	Loss: 2.1156	LR: 0.070449
Training Epoch: 40 [128/50000]	Loss: 2.2647	LR: 0.070449
Evaluating Network.....
Test set: Epoch: 40, Average loss: 0.0187, Top1Accuracy: 0.3685, Top3Accuracy: 0.5902, Top5Accuracy: 0.6980, Time consumed:1.78s

Training Epoch: 41 [128/50000]	Loss: 2.2513	LR: 0.068589
Training Epoch: 41 [128/50000]	Loss: 2.5506	LR: 0.068589
Training Epoch: 41 [128/50000]	Loss: 2.3780	LR: 0.068589
Training Epoch: 41 [128/50000]	Loss: 2.4143	LR: 0.068589
Training Epoch: 41 [128/50000]	Loss: 2.3198	LR: 0.068589
Training Epoch: 41 [128/50000]	Loss: 2.2049	LR: 0.068589
Training Epoch: 41 [128/50000]	Loss: 2.4944	LR: 0.068589
Training Epoch: 41 [128/50000]	Loss: 2.2093	LR: 0.068589
Training Epoch: 41 [128/50000]	Loss: 2.2930	LR: 0.068589
Training Epoch: 41 [128/50000]	Loss: 2.2856	LR: 0.068589
Evaluating Network.....
Test set: Epoch: 41, Average loss: 0.0186, Top1Accuracy: 0.3674, Top3Accuracy: 0.5941, Top5Accuracy: 0.6981, Time consumed:1.81s

Training Epoch: 42 [128/50000]	Loss: 2.3072	LR: 0.066778
Training Epoch: 42 [128/50000]	Loss: 2.3429	LR: 0.066778
Training Epoch: 42 [128/50000]	Loss: 2.3123	LR: 0.066778
Training Epoch: 42 [128/50000]	Loss: 2.3735	LR: 0.066778
Training Epoch: 42 [128/50000]	Loss: 2.1894	LR: 0.066778
Training Epoch: 42 [128/50000]	Loss: 2.3545	LR: 0.066778
Training Epoch: 42 [128/50000]	Loss: 2.3281	LR: 0.066778
Training Epoch: 42 [128/50000]	Loss: 2.2063	LR: 0.066778
Training Epoch: 42 [128/50000]	Loss: 2.4516	LR: 0.066778
Training Epoch: 42 [128/50000]	Loss: 2.1587	LR: 0.066778
Evaluating Network.....
Test set: Epoch: 42, Average loss: 0.0181, Top1Accuracy: 0.3783, Top3Accuracy: 0.6119, Top5Accuracy: 0.7120, Time consumed:1.80s

Training Epoch: 43 [128/50000]	Loss: 2.3595	LR: 0.065015
Training Epoch: 43 [128/50000]	Loss: 2.1624	LR: 0.065015
Training Epoch: 43 [128/50000]	Loss: 2.3010	LR: 0.065015
Training Epoch: 43 [128/50000]	Loss: 2.2342	LR: 0.065015
Training Epoch: 43 [128/50000]	Loss: 2.3434	LR: 0.065015
Training Epoch: 43 [128/50000]	Loss: 2.2333	LR: 0.065015
Training Epoch: 43 [128/50000]	Loss: 2.3316	LR: 0.065015
Training Epoch: 43 [128/50000]	Loss: 2.0254	LR: 0.065015
Training Epoch: 43 [128/50000]	Loss: 2.3380	LR: 0.065015
Training Epoch: 43 [128/50000]	Loss: 2.3775	LR: 0.065015
Evaluating Network.....
Test set: Epoch: 43, Average loss: 0.0182, Top1Accuracy: 0.3822, Top3Accuracy: 0.6084, Top5Accuracy: 0.7071, Time consumed:1.79s

Training Epoch: 44 [128/50000]	Loss: 2.2388	LR: 0.063299
Training Epoch: 44 [128/50000]	Loss: 2.1596	LR: 0.063299
Training Epoch: 44 [128/50000]	Loss: 2.1554	LR: 0.063299
Training Epoch: 44 [128/50000]	Loss: 2.2511	LR: 0.063299
Training Epoch: 44 [128/50000]	Loss: 2.1891	LR: 0.063299
Training Epoch: 44 [128/50000]	Loss: 2.3235	LR: 0.063299
Training Epoch: 44 [128/50000]	Loss: 1.9833	LR: 0.063299
Training Epoch: 44 [128/50000]	Loss: 2.2271	LR: 0.063299
Training Epoch: 44 [128/50000]	Loss: 2.3051	LR: 0.063299
Training Epoch: 44 [128/50000]	Loss: 2.4445	LR: 0.063299
Evaluating Network.....
Test set: Epoch: 44, Average loss: 0.0175, Top1Accuracy: 0.3988, Top3Accuracy: 0.6317, Top5Accuracy: 0.7314, Time consumed:2.32s

Training Epoch: 45 [128/50000]	Loss: 2.2530	LR: 0.061628
Training Epoch: 45 [128/50000]	Loss: 2.3264	LR: 0.061628
Training Epoch: 45 [128/50000]	Loss: 2.3805	LR: 0.061628
Training Epoch: 45 [128/50000]	Loss: 2.1689	LR: 0.061628
Training Epoch: 45 [128/50000]	Loss: 2.2294	LR: 0.061628
Training Epoch: 45 [128/50000]	Loss: 2.0991	LR: 0.061628
Training Epoch: 45 [128/50000]	Loss: 2.1698	LR: 0.061628
Training Epoch: 45 [128/50000]	Loss: 2.4150	LR: 0.061628
Training Epoch: 45 [128/50000]	Loss: 2.2441	LR: 0.061628
Training Epoch: 45 [128/50000]	Loss: 2.4275	LR: 0.061628
Evaluating Network.....
Test set: Epoch: 45, Average loss: 0.0175, Top1Accuracy: 0.4012, Top3Accuracy: 0.6262, Top5Accuracy: 0.7262, Time consumed:1.78s

Training Epoch: 46 [128/50000]	Loss: 2.2375	LR: 0.060001
Training Epoch: 46 [128/50000]	Loss: 2.2072	LR: 0.060001
Training Epoch: 46 [128/50000]	Loss: 2.3467	LR: 0.060001
Training Epoch: 46 [128/50000]	Loss: 2.1527	LR: 0.060001
Training Epoch: 46 [128/50000]	Loss: 2.1202	LR: 0.060001
Training Epoch: 46 [128/50000]	Loss: 2.4678	LR: 0.060001
Training Epoch: 46 [128/50000]	Loss: 2.4208	LR: 0.060001
Training Epoch: 46 [128/50000]	Loss: 2.2599	LR: 0.060001
Training Epoch: 46 [128/50000]	Loss: 2.1479	LR: 0.060001
Training Epoch: 46 [128/50000]	Loss: 2.0600	LR: 0.060001
Evaluating Network.....
Test set: Epoch: 46, Average loss: 0.0176, Top1Accuracy: 0.3926, Top3Accuracy: 0.6244, Top5Accuracy: 0.7267, Time consumed:1.80s

Training Epoch: 47 [128/50000]	Loss: 2.3317	LR: 0.058417
Training Epoch: 47 [128/50000]	Loss: 1.9880	LR: 0.058417
Training Epoch: 47 [128/50000]	Loss: 2.2056	LR: 0.058417
Training Epoch: 47 [128/50000]	Loss: 2.0723	LR: 0.058417
Training Epoch: 47 [128/50000]	Loss: 2.1389	LR: 0.058417
Training Epoch: 47 [128/50000]	Loss: 2.2400	LR: 0.058417
Training Epoch: 47 [128/50000]	Loss: 2.3397	LR: 0.058417
Training Epoch: 47 [128/50000]	Loss: 2.1849	LR: 0.058417
Training Epoch: 47 [128/50000]	Loss: 2.0016	LR: 0.058417
Training Epoch: 47 [128/50000]	Loss: 2.0038	LR: 0.058417
Evaluating Network.....
Test set: Epoch: 47, Average loss: 0.0172, Top1Accuracy: 0.4092, Top3Accuracy: 0.6370, Top5Accuracy: 0.7392, Time consumed:1.86s

Training Epoch: 48 [128/50000]	Loss: 2.1300	LR: 0.056874
Training Epoch: 48 [128/50000]	Loss: 2.3935	LR: 0.056874
Training Epoch: 48 [128/50000]	Loss: 2.0931	LR: 0.056874
Training Epoch: 48 [128/50000]	Loss: 2.0994	LR: 0.056874
Training Epoch: 48 [128/50000]	Loss: 2.0764	LR: 0.056874
Training Epoch: 48 [128/50000]	Loss: 2.4282	LR: 0.056874
Training Epoch: 48 [128/50000]	Loss: 1.9877	LR: 0.056874
Training Epoch: 48 [128/50000]	Loss: 2.2951	LR: 0.056874
Training Epoch: 48 [128/50000]	Loss: 2.0323	LR: 0.056874
Training Epoch: 48 [128/50000]	Loss: 1.9945	LR: 0.056874
Evaluating Network.....
Test set: Epoch: 48, Average loss: 0.0167, Top1Accuracy: 0.4175, Top3Accuracy: 0.6528, Top5Accuracy: 0.7491, Time consumed:1.79s

Training Epoch: 49 [128/50000]	Loss: 1.9679	LR: 0.055373
Training Epoch: 49 [128/50000]	Loss: 1.9740	LR: 0.055373
Training Epoch: 49 [128/50000]	Loss: 2.2559	LR: 0.055373
Training Epoch: 49 [128/50000]	Loss: 2.1784	LR: 0.055373
Training Epoch: 49 [128/50000]	Loss: 2.0500	LR: 0.055373
Training Epoch: 49 [128/50000]	Loss: 2.0190	LR: 0.055373
Training Epoch: 49 [128/50000]	Loss: 2.1379	LR: 0.055373
Training Epoch: 49 [128/50000]	Loss: 2.0855	LR: 0.055373
Training Epoch: 49 [128/50000]	Loss: 2.4493	LR: 0.055373
Training Epoch: 49 [128/50000]	Loss: 2.1873	LR: 0.055373
Evaluating Network.....
Test set: Epoch: 49, Average loss: 0.0167, Top1Accuracy: 0.4231, Top3Accuracy: 0.6544, Top5Accuracy: 0.7515, Time consumed:1.80s

Training Epoch: 50 [128/50000]	Loss: 1.9572	LR: 0.053911
Training Epoch: 50 [128/50000]	Loss: 2.3546	LR: 0.053911
Training Epoch: 50 [128/50000]	Loss: 2.0293	LR: 0.053911
Training Epoch: 50 [128/50000]	Loss: 1.9431	LR: 0.053911
Training Epoch: 50 [128/50000]	Loss: 1.9238	LR: 0.053911
Training Epoch: 50 [128/50000]	Loss: 1.9531	LR: 0.053911
Training Epoch: 50 [128/50000]	Loss: 2.0258	LR: 0.053911
Training Epoch: 50 [128/50000]	Loss: 2.2169	LR: 0.053911
Training Epoch: 50 [128/50000]	Loss: 1.9358	LR: 0.053911
Training Epoch: 50 [128/50000]	Loss: 2.3988	LR: 0.053911
Evaluating Network.....
Test set: Epoch: 50, Average loss: 0.0166, Top1Accuracy: 0.4175, Top3Accuracy: 0.6510, Top5Accuracy: 0.7519, Time consumed:1.82s

Training Epoch: 51 [128/50000]	Loss: 1.9375	LR: 0.052488
Training Epoch: 51 [128/50000]	Loss: 2.1041	LR: 0.052488
Training Epoch: 51 [128/50000]	Loss: 2.2501	LR: 0.052488
Training Epoch: 51 [128/50000]	Loss: 1.9929	LR: 0.052488
Training Epoch: 51 [128/50000]	Loss: 2.0428	LR: 0.052488
Training Epoch: 51 [128/50000]	Loss: 1.9868	LR: 0.052488
Training Epoch: 51 [128/50000]	Loss: 2.2699	LR: 0.052488
Training Epoch: 51 [128/50000]	Loss: 1.8668	LR: 0.052488
Training Epoch: 51 [128/50000]	Loss: 2.2470	LR: 0.052488
Training Epoch: 51 [128/50000]	Loss: 2.1214	LR: 0.052488
Evaluating Network.....
Test set: Epoch: 51, Average loss: 0.0162, Top1Accuracy: 0.4352, Top3Accuracy: 0.6671, Top5Accuracy: 0.7622, Time consumed:1.81s

Training Epoch: 52 [128/50000]	Loss: 1.9060	LR: 0.051102
Training Epoch: 52 [128/50000]	Loss: 2.1777	LR: 0.051102
Training Epoch: 52 [128/50000]	Loss: 2.0302	LR: 0.051102
Training Epoch: 52 [128/50000]	Loss: 1.9880	LR: 0.051102
Training Epoch: 52 [128/50000]	Loss: 2.0476	LR: 0.051102
Training Epoch: 52 [128/50000]	Loss: 2.0083	LR: 0.051102
Training Epoch: 52 [128/50000]	Loss: 1.9106	LR: 0.051102
Training Epoch: 52 [128/50000]	Loss: 2.1424	LR: 0.051102
Training Epoch: 52 [128/50000]	Loss: 2.0700	LR: 0.051102
Training Epoch: 52 [128/50000]	Loss: 2.1180	LR: 0.051102
Evaluating Network.....
Test set: Epoch: 52, Average loss: 0.0160, Top1Accuracy: 0.4371, Top3Accuracy: 0.6714, Top5Accuracy: 0.7641, Time consumed:1.82s

Training Epoch: 53 [128/50000]	Loss: 1.8358	LR: 0.049753
Training Epoch: 53 [128/50000]	Loss: 1.8319	LR: 0.049753
Training Epoch: 53 [128/50000]	Loss: 2.1192	LR: 0.049753
Training Epoch: 53 [128/50000]	Loss: 2.0866	LR: 0.049753
Training Epoch: 53 [128/50000]	Loss: 1.8287	LR: 0.049753
Training Epoch: 53 [128/50000]	Loss: 1.9005	LR: 0.049753
Training Epoch: 53 [128/50000]	Loss: 1.9109	LR: 0.049753
Training Epoch: 53 [128/50000]	Loss: 2.0659	LR: 0.049753
Training Epoch: 53 [128/50000]	Loss: 2.0144	LR: 0.049753
Training Epoch: 53 [128/50000]	Loss: 1.9087	LR: 0.049753
Evaluating Network.....
Test set: Epoch: 53, Average loss: 0.0158, Top1Accuracy: 0.4493, Top3Accuracy: 0.6796, Top5Accuracy: 0.7740, Time consumed:1.79s

Training Epoch: 54 [128/50000]	Loss: 2.0121	LR: 0.048440
Training Epoch: 54 [128/50000]	Loss: 1.9972	LR: 0.048440
Training Epoch: 54 [128/50000]	Loss: 2.0270	LR: 0.048440
Training Epoch: 54 [128/50000]	Loss: 2.1838	LR: 0.048440
Training Epoch: 54 [128/50000]	Loss: 2.1777	LR: 0.048440
Training Epoch: 54 [128/50000]	Loss: 2.0661	LR: 0.048440
Training Epoch: 54 [128/50000]	Loss: 2.2433	LR: 0.048440
Training Epoch: 54 [128/50000]	Loss: 2.1532	LR: 0.048440
Training Epoch: 54 [128/50000]	Loss: 2.0580	LR: 0.048440
Training Epoch: 54 [128/50000]	Loss: 2.0497	LR: 0.048440
Evaluating Network.....
Test set: Epoch: 54, Average loss: 0.0159, Top1Accuracy: 0.4461, Top3Accuracy: 0.6796, Top5Accuracy: 0.7732, Time consumed:1.77s

Training Epoch: 55 [128/50000]	Loss: 1.7204	LR: 0.047161
Training Epoch: 55 [128/50000]	Loss: 1.9345	LR: 0.047161
Training Epoch: 55 [128/50000]	Loss: 1.9336	LR: 0.047161
Training Epoch: 55 [128/50000]	Loss: 2.1757	LR: 0.047161
Training Epoch: 55 [128/50000]	Loss: 1.8353	LR: 0.047161
Training Epoch: 55 [128/50000]	Loss: 1.7962	LR: 0.047161
Training Epoch: 55 [128/50000]	Loss: 2.1022	LR: 0.047161
Training Epoch: 55 [128/50000]	Loss: 1.8952	LR: 0.047161
Training Epoch: 55 [128/50000]	Loss: 2.1228	LR: 0.047161
Training Epoch: 55 [128/50000]	Loss: 1.8159	LR: 0.047161
Evaluating Network.....
Test set: Epoch: 55, Average loss: 0.0156, Top1Accuracy: 0.4527, Top3Accuracy: 0.6855, Top5Accuracy: 0.7790, Time consumed:1.80s

Training Epoch: 56 [128/50000]	Loss: 2.0886	LR: 0.045916
Training Epoch: 56 [128/50000]	Loss: 1.9812	LR: 0.045916
Training Epoch: 56 [128/50000]	Loss: 1.8505	LR: 0.045916
Training Epoch: 56 [128/50000]	Loss: 2.0133	LR: 0.045916
Training Epoch: 56 [128/50000]	Loss: 2.0397	LR: 0.045916
Training Epoch: 56 [128/50000]	Loss: 1.8069	LR: 0.045916
Training Epoch: 56 [128/50000]	Loss: 1.9571	LR: 0.045916
Training Epoch: 56 [128/50000]	Loss: 1.9072	LR: 0.045916
Training Epoch: 56 [128/50000]	Loss: 2.0769	LR: 0.045916
Training Epoch: 56 [128/50000]	Loss: 1.8448	LR: 0.045916
Evaluating Network.....
Test set: Epoch: 56, Average loss: 0.0154, Top1Accuracy: 0.4595, Top3Accuracy: 0.6951, Top5Accuracy: 0.7850, Time consumed:1.81s

Training Epoch: 57 [128/50000]	Loss: 1.8816	LR: 0.044704
Training Epoch: 57 [128/50000]	Loss: 1.9897	LR: 0.044704
Training Epoch: 57 [128/50000]	Loss: 2.0211	LR: 0.044704
Training Epoch: 57 [128/50000]	Loss: 1.9405	LR: 0.044704
Training Epoch: 57 [128/50000]	Loss: 1.7834	LR: 0.044704
Training Epoch: 57 [128/50000]	Loss: 1.9293	LR: 0.044704
Training Epoch: 57 [128/50000]	Loss: 2.0288	LR: 0.044704
Training Epoch: 57 [128/50000]	Loss: 1.8221	LR: 0.044704
Training Epoch: 57 [128/50000]	Loss: 1.9793	LR: 0.044704
Training Epoch: 57 [128/50000]	Loss: 1.8154	LR: 0.044704
Evaluating Network.....
Test set: Epoch: 57, Average loss: 0.0152, Top1Accuracy: 0.4621, Top3Accuracy: 0.6939, Top5Accuracy: 0.7855, Time consumed:1.79s

Training Epoch: 58 [128/50000]	Loss: 1.9656	LR: 0.043523
Training Epoch: 58 [128/50000]	Loss: 1.8659	LR: 0.043523
Training Epoch: 58 [128/50000]	Loss: 1.8617	LR: 0.043523
Training Epoch: 58 [128/50000]	Loss: 2.0562	LR: 0.043523
Training Epoch: 58 [128/50000]	Loss: 2.0434	LR: 0.043523
Training Epoch: 58 [128/50000]	Loss: 1.9857	LR: 0.043523
Training Epoch: 58 [128/50000]	Loss: 2.0055	LR: 0.043523
Training Epoch: 58 [128/50000]	Loss: 1.7162	LR: 0.043523
Training Epoch: 58 [128/50000]	Loss: 1.8222	LR: 0.043523
Training Epoch: 58 [128/50000]	Loss: 1.7849	LR: 0.043523
Evaluating Network.....
Test set: Epoch: 58, Average loss: 0.0152, Top1Accuracy: 0.4617, Top3Accuracy: 0.6938, Top5Accuracy: 0.7878, Time consumed:1.80s

Training Epoch: 59 [128/50000]	Loss: 2.0104	LR: 0.042374
Training Epoch: 59 [128/50000]	Loss: 1.8096	LR: 0.042374
Training Epoch: 59 [128/50000]	Loss: 1.9047	LR: 0.042374
Training Epoch: 59 [128/50000]	Loss: 1.7069	LR: 0.042374
Training Epoch: 59 [128/50000]	Loss: 1.8177	LR: 0.042374
Training Epoch: 59 [128/50000]	Loss: 1.6900	LR: 0.042374
Training Epoch: 59 [128/50000]	Loss: 1.9949	LR: 0.042374
Training Epoch: 59 [128/50000]	Loss: 1.8690	LR: 0.042374
Training Epoch: 59 [128/50000]	Loss: 1.6907	LR: 0.042374
Training Epoch: 59 [128/50000]	Loss: 1.9427	LR: 0.042374
Evaluating Network.....
Test set: Epoch: 59, Average loss: 0.0150, Top1Accuracy: 0.4660, Top3Accuracy: 0.7025, Top5Accuracy: 0.7951, Time consumed:1.80s

Training Epoch: 60 [128/50000]	Loss: 1.7560	LR: 0.041256
Training Epoch: 60 [128/50000]	Loss: 1.9746	LR: 0.041256
Training Epoch: 60 [128/50000]	Loss: 2.0398	LR: 0.041256
Training Epoch: 60 [128/50000]	Loss: 1.8207	LR: 0.041256
Training Epoch: 60 [128/50000]	Loss: 1.9676	LR: 0.041256
Training Epoch: 60 [128/50000]	Loss: 2.1219	LR: 0.041256
Training Epoch: 60 [128/50000]	Loss: 2.0090	LR: 0.041256
Training Epoch: 60 [128/50000]	Loss: 2.0128	LR: 0.041256
Training Epoch: 60 [128/50000]	Loss: 1.9506	LR: 0.041256
Training Epoch: 60 [128/50000]	Loss: 1.8919	LR: 0.041256
Evaluating Network.....
Test set: Epoch: 60, Average loss: 0.0147, Top1Accuracy: 0.4794, Top3Accuracy: 0.7103, Top5Accuracy: 0.8020, Time consumed:1.80s

Training Epoch: 61 [128/50000]	Loss: 1.6697	LR: 0.040166
Training Epoch: 61 [128/50000]	Loss: 1.7059	LR: 0.040166
Training Epoch: 61 [128/50000]	Loss: 1.8882	LR: 0.040166
Training Epoch: 61 [128/50000]	Loss: 1.8106	LR: 0.040166
Training Epoch: 61 [128/50000]	Loss: 1.7937	LR: 0.040166
Training Epoch: 61 [128/50000]	Loss: 2.0004	LR: 0.040166
Training Epoch: 61 [128/50000]	Loss: 1.5507	LR: 0.040166
Training Epoch: 61 [128/50000]	Loss: 1.9105	LR: 0.040166
Training Epoch: 61 [128/50000]	Loss: 1.8175	LR: 0.040166
Training Epoch: 61 [128/50000]	Loss: 1.9283	LR: 0.040166
Evaluating Network.....
Test set: Epoch: 61, Average loss: 0.0148, Top1Accuracy: 0.4721, Top3Accuracy: 0.7098, Top5Accuracy: 0.7984, Time consumed:1.81s

Training Epoch: 62 [128/50000]	Loss: 1.8174	LR: 0.039106
Training Epoch: 62 [128/50000]	Loss: 1.8787	LR: 0.039106
Training Epoch: 62 [128/50000]	Loss: 1.7564	LR: 0.039106
Training Epoch: 62 [128/50000]	Loss: 1.7655	LR: 0.039106
Training Epoch: 62 [128/50000]	Loss: 1.6260	LR: 0.039106
Training Epoch: 62 [128/50000]	Loss: 2.1071	LR: 0.039106
Training Epoch: 62 [128/50000]	Loss: 1.8150	LR: 0.039106
Training Epoch: 62 [128/50000]	Loss: 1.6793	LR: 0.039106
Training Epoch: 62 [128/50000]	Loss: 1.8928	LR: 0.039106
Training Epoch: 62 [128/50000]	Loss: 1.7523	LR: 0.039106
Evaluating Network.....
Test set: Epoch: 62, Average loss: 0.0146, Top1Accuracy: 0.4823, Top3Accuracy: 0.7148, Top5Accuracy: 0.8026, Time consumed:1.79s

Training Epoch: 63 [128/50000]	Loss: 1.8610	LR: 0.038074
Training Epoch: 63 [128/50000]	Loss: 1.7942	LR: 0.038074
Training Epoch: 63 [128/50000]	Loss: 1.7070	LR: 0.038074
Training Epoch: 63 [128/50000]	Loss: 1.6800	LR: 0.038074
Training Epoch: 63 [128/50000]	Loss: 1.7220	LR: 0.038074
Training Epoch: 63 [128/50000]	Loss: 1.8751	LR: 0.038074
Training Epoch: 63 [128/50000]	Loss: 1.8184	LR: 0.038074
Training Epoch: 63 [128/50000]	Loss: 2.1063	LR: 0.038074
Training Epoch: 63 [128/50000]	Loss: 1.6835	LR: 0.038074
Training Epoch: 63 [128/50000]	Loss: 1.7218	LR: 0.038074
Evaluating Network.....
Test set: Epoch: 63, Average loss: 0.0146, Top1Accuracy: 0.4843, Top3Accuracy: 0.7160, Top5Accuracy: 0.8033, Time consumed:1.77s

Training Epoch: 64 [128/50000]	Loss: 1.8366	LR: 0.037069
Training Epoch: 64 [128/50000]	Loss: 1.8272	LR: 0.037069
Training Epoch: 64 [128/50000]	Loss: 1.9633	LR: 0.037069
Training Epoch: 64 [128/50000]	Loss: 1.5917	LR: 0.037069
Training Epoch: 64 [128/50000]	Loss: 1.9171	LR: 0.037069
Training Epoch: 64 [128/50000]	Loss: 1.8202	LR: 0.037069
Training Epoch: 64 [128/50000]	Loss: 1.7917	LR: 0.037069
Training Epoch: 64 [128/50000]	Loss: 2.0160	LR: 0.037069
Training Epoch: 64 [128/50000]	Loss: 1.7389	LR: 0.037069
Training Epoch: 64 [128/50000]	Loss: 1.8851	LR: 0.037069
Evaluating Network.....
Test set: Epoch: 64, Average loss: 0.0144, Top1Accuracy: 0.4859, Top3Accuracy: 0.7168, Top5Accuracy: 0.8098, Time consumed:1.81s

Training Epoch: 65 [128/50000]	Loss: 1.9152	LR: 0.036090
Training Epoch: 65 [128/50000]	Loss: 1.6979	LR: 0.036090
Training Epoch: 65 [128/50000]	Loss: 1.9500	LR: 0.036090
Training Epoch: 65 [128/50000]	Loss: 1.8180	LR: 0.036090
Training Epoch: 65 [128/50000]	Loss: 1.9738	LR: 0.036090
Training Epoch: 65 [128/50000]	Loss: 1.9435	LR: 0.036090
Training Epoch: 65 [128/50000]	Loss: 1.8806	LR: 0.036090
Training Epoch: 65 [128/50000]	Loss: 1.5477	LR: 0.036090
Training Epoch: 65 [128/50000]	Loss: 2.0192	LR: 0.036090
Training Epoch: 65 [128/50000]	Loss: 1.8270	LR: 0.036090
Evaluating Network.....
Test set: Epoch: 65, Average loss: 0.0141, Top1Accuracy: 0.4965, Top3Accuracy: 0.7292, Top5Accuracy: 0.8162, Time consumed:1.77s

Training Epoch: 66 [128/50000]	Loss: 1.8968	LR: 0.035137
Training Epoch: 66 [128/50000]	Loss: 1.9779	LR: 0.035137
Training Epoch: 66 [128/50000]	Loss: 1.7452	LR: 0.035137
Training Epoch: 66 [128/50000]	Loss: 1.8547	LR: 0.035137
Training Epoch: 66 [128/50000]	Loss: 1.7492	LR: 0.035137
Training Epoch: 66 [128/50000]	Loss: 2.0648	LR: 0.035137
Training Epoch: 66 [128/50000]	Loss: 1.5039	LR: 0.035137
Training Epoch: 66 [128/50000]	Loss: 1.7790	LR: 0.035137
Training Epoch: 66 [128/50000]	Loss: 1.7380	LR: 0.035137
Training Epoch: 66 [128/50000]	Loss: 1.8966	LR: 0.035137
Evaluating Network.....
Test set: Epoch: 66, Average loss: 0.0142, Top1Accuracy: 0.4927, Top3Accuracy: 0.7245, Top5Accuracy: 0.8134, Time consumed:1.82s

Training Epoch: 67 [128/50000]	Loss: 1.7044	LR: 0.034210
Training Epoch: 67 [128/50000]	Loss: 1.7929	LR: 0.034210
Training Epoch: 67 [128/50000]	Loss: 1.8050	LR: 0.034210
Training Epoch: 67 [128/50000]	Loss: 1.5802	LR: 0.034210
Training Epoch: 67 [128/50000]	Loss: 1.6375	LR: 0.034210
Training Epoch: 67 [128/50000]	Loss: 1.5588	LR: 0.034210
Training Epoch: 67 [128/50000]	Loss: 1.8911	LR: 0.034210
Training Epoch: 67 [128/50000]	Loss: 1.8645	LR: 0.034210
Training Epoch: 67 [128/50000]	Loss: 1.4867	LR: 0.034210
Training Epoch: 67 [128/50000]	Loss: 1.6883	LR: 0.034210
Evaluating Network.....
Test set: Epoch: 67, Average loss: 0.0142, Top1Accuracy: 0.4962, Top3Accuracy: 0.7255, Top5Accuracy: 0.8120, Time consumed:1.90s

Training Epoch: 68 [128/50000]	Loss: 1.6256	LR: 0.033306
Training Epoch: 68 [128/50000]	Loss: 1.9317	LR: 0.033306
Training Epoch: 68 [128/50000]	Loss: 1.6329	LR: 0.033306
Training Epoch: 68 [128/50000]	Loss: 1.9079	LR: 0.033306
Training Epoch: 68 [128/50000]	Loss: 1.9968	LR: 0.033306
Training Epoch: 68 [128/50000]	Loss: 1.8089	LR: 0.033306
Training Epoch: 68 [128/50000]	Loss: 1.7338	LR: 0.033306
Training Epoch: 68 [128/50000]	Loss: 1.9130	LR: 0.033306
Training Epoch: 68 [128/50000]	Loss: 1.9053	LR: 0.033306
Training Epoch: 68 [128/50000]	Loss: 1.8683	LR: 0.033306
Evaluating Network.....
Test set: Epoch: 68, Average loss: 0.0138, Top1Accuracy: 0.5079, Top3Accuracy: 0.7357, Top5Accuracy: 0.8203, Time consumed:1.80s

Training Epoch: 69 [128/50000]	Loss: 1.4206	LR: 0.032427
Training Epoch: 69 [128/50000]	Loss: 1.7186	LR: 0.032427
Training Epoch: 69 [128/50000]	Loss: 1.8031	LR: 0.032427
Training Epoch: 69 [128/50000]	Loss: 1.6978	LR: 0.032427
Training Epoch: 69 [128/50000]	Loss: 1.7468	LR: 0.032427
Training Epoch: 69 [128/50000]	Loss: 1.6703	LR: 0.032427
Training Epoch: 69 [128/50000]	Loss: 1.6439	LR: 0.032427
Training Epoch: 69 [128/50000]	Loss: 1.7246	LR: 0.032427
Training Epoch: 69 [128/50000]	Loss: 1.6782	LR: 0.032427
Training Epoch: 69 [128/50000]	Loss: 1.9153	LR: 0.032427
Evaluating Network.....
Test set: Epoch: 69, Average loss: 0.0136, Top1Accuracy: 0.5101, Top3Accuracy: 0.7401, Top5Accuracy: 0.8253, Time consumed:1.82s

Training Epoch: 70 [128/50000]	Loss: 1.5647	LR: 0.031571
Training Epoch: 70 [128/50000]	Loss: 1.7032	LR: 0.031571
Training Epoch: 70 [128/50000]	Loss: 1.7795	LR: 0.031571
Training Epoch: 70 [128/50000]	Loss: 1.7147	LR: 0.031571
Training Epoch: 70 [128/50000]	Loss: 1.6335	LR: 0.031571
Training Epoch: 70 [128/50000]	Loss: 1.7406	LR: 0.031571
Training Epoch: 70 [128/50000]	Loss: 2.0658	LR: 0.031571
Training Epoch: 70 [128/50000]	Loss: 1.5238	LR: 0.031571
Training Epoch: 70 [128/50000]	Loss: 1.6502	LR: 0.031571
Training Epoch: 70 [128/50000]	Loss: 1.6942	LR: 0.031571
Evaluating Network.....
Test set: Epoch: 70, Average loss: 0.0137, Top1Accuracy: 0.5133, Top3Accuracy: 0.7379, Top5Accuracy: 0.8202, Time consumed:1.80s

Training Epoch: 71 [128/50000]	Loss: 1.5861	LR: 0.030738
Training Epoch: 71 [128/50000]	Loss: 1.7496	LR: 0.030738
Training Epoch: 71 [128/50000]	Loss: 1.6993	LR: 0.030738
Training Epoch: 71 [128/50000]	Loss: 1.6219	LR: 0.030738
Training Epoch: 71 [128/50000]	Loss: 1.5713	LR: 0.030738
Training Epoch: 71 [128/50000]	Loss: 1.7566	LR: 0.030738
Training Epoch: 71 [128/50000]	Loss: 1.6558	LR: 0.030738
Training Epoch: 71 [128/50000]	Loss: 1.6257	LR: 0.030738
Training Epoch: 71 [128/50000]	Loss: 1.9075	LR: 0.030738
Training Epoch: 71 [128/50000]	Loss: 1.7944	LR: 0.030738
Evaluating Network.....
Test set: Epoch: 71, Average loss: 0.0136, Top1Accuracy: 0.5129, Top3Accuracy: 0.7419, Top5Accuracy: 0.8247, Time consumed:1.76s

Training Epoch: 72 [128/50000]	Loss: 1.6245	LR: 0.029926
Training Epoch: 72 [128/50000]	Loss: 1.8359	LR: 0.029926
Training Epoch: 72 [128/50000]	Loss: 1.9788	LR: 0.029926
Training Epoch: 72 [128/50000]	Loss: 1.6242	LR: 0.029926
Training Epoch: 72 [128/50000]	Loss: 1.9233	LR: 0.029926
Training Epoch: 72 [128/50000]	Loss: 1.7524	LR: 0.029926
Training Epoch: 72 [128/50000]	Loss: 1.4038	LR: 0.029926
Training Epoch: 72 [128/50000]	Loss: 1.6829	LR: 0.029926
Training Epoch: 72 [128/50000]	Loss: 1.5878	LR: 0.029926
Training Epoch: 72 [128/50000]	Loss: 1.6681	LR: 0.029926
Evaluating Network.....
Test set: Epoch: 72, Average loss: 0.0134, Top1Accuracy: 0.5226, Top3Accuracy: 0.7445, Top5Accuracy: 0.8297, Time consumed:1.81s

Training Epoch: 73 [128/50000]	Loss: 1.6655	LR: 0.029136
Training Epoch: 73 [128/50000]	Loss: 1.5120	LR: 0.029136
Training Epoch: 73 [128/50000]	Loss: 1.5590	LR: 0.029136
Training Epoch: 73 [128/50000]	Loss: 1.7920	LR: 0.029136
Training Epoch: 73 [128/50000]	Loss: 1.8131	LR: 0.029136
Training Epoch: 73 [128/50000]	Loss: 1.5199	LR: 0.029136
Training Epoch: 73 [128/50000]	Loss: 1.7619	LR: 0.029136
Training Epoch: 73 [128/50000]	Loss: 1.8573	LR: 0.029136
Training Epoch: 73 [128/50000]	Loss: 1.6008	LR: 0.029136
Training Epoch: 73 [128/50000]	Loss: 1.8552	LR: 0.029136
Evaluating Network.....
Test set: Epoch: 73, Average loss: 0.0135, Top1Accuracy: 0.5215, Top3Accuracy: 0.7460, Top5Accuracy: 0.8281, Time consumed:1.76s

Training Epoch: 74 [128/50000]	Loss: 1.7553	LR: 0.028367
Training Epoch: 74 [128/50000]	Loss: 1.8031	LR: 0.028367
Training Epoch: 74 [128/50000]	Loss: 1.4425	LR: 0.028367
Training Epoch: 74 [128/50000]	Loss: 1.5553	LR: 0.028367
Training Epoch: 74 [128/50000]	Loss: 1.8274	LR: 0.028367
Training Epoch: 74 [128/50000]	Loss: 1.8435	LR: 0.028367
Training Epoch: 74 [128/50000]	Loss: 1.6306	LR: 0.028367
Training Epoch: 74 [128/50000]	Loss: 1.5763	LR: 0.028367
Training Epoch: 74 [128/50000]	Loss: 1.7573	LR: 0.028367
Training Epoch: 74 [128/50000]	Loss: 1.8176	LR: 0.028367
Evaluating Network.....
Test set: Epoch: 74, Average loss: 0.0132, Top1Accuracy: 0.5262, Top3Accuracy: 0.7499, Top5Accuracy: 0.8330, Time consumed:2.01s

Training Epoch: 75 [128/50000]	Loss: 1.5872	LR: 0.027618
Training Epoch: 75 [128/50000]	Loss: 1.6628	LR: 0.027618
Training Epoch: 75 [128/50000]	Loss: 1.6032	LR: 0.027618
Training Epoch: 75 [128/50000]	Loss: 1.6261	LR: 0.027618
Training Epoch: 75 [128/50000]	Loss: 1.6923	LR: 0.027618
Training Epoch: 75 [128/50000]	Loss: 1.6513	LR: 0.027618
Training Epoch: 75 [128/50000]	Loss: 1.6332	LR: 0.027618
Training Epoch: 75 [128/50000]	Loss: 1.7023	LR: 0.027618
Training Epoch: 75 [128/50000]	Loss: 1.4499	LR: 0.027618
Training Epoch: 75 [128/50000]	Loss: 1.5419	LR: 0.027618
Evaluating Network.....
Test set: Epoch: 75, Average loss: 0.0132, Top1Accuracy: 0.5263, Top3Accuracy: 0.7555, Top5Accuracy: 0.8344, Time consumed:1.80s

Training Epoch: 76 [128/50000]	Loss: 1.7902	LR: 0.026889
Training Epoch: 76 [128/50000]	Loss: 1.4753	LR: 0.026889
Training Epoch: 76 [128/50000]	Loss: 1.6510	LR: 0.026889
Training Epoch: 76 [128/50000]	Loss: 1.4964	LR: 0.026889
Training Epoch: 76 [128/50000]	Loss: 1.8238	LR: 0.026889
Training Epoch: 76 [128/50000]	Loss: 1.5954	LR: 0.026889
Training Epoch: 76 [128/50000]	Loss: 1.5157	LR: 0.026889
Training Epoch: 76 [128/50000]	Loss: 1.7412	LR: 0.026889
Training Epoch: 76 [128/50000]	Loss: 1.6334	LR: 0.026889
Training Epoch: 76 [128/50000]	Loss: 1.8097	LR: 0.026889
Evaluating Network.....
Test set: Epoch: 76, Average loss: 0.0133, Top1Accuracy: 0.5228, Top3Accuracy: 0.7514, Top5Accuracy: 0.8294, Time consumed:1.80s

Training Epoch: 77 [128/50000]	Loss: 1.5415	LR: 0.026179
Training Epoch: 77 [128/50000]	Loss: 1.7204	LR: 0.026179
Training Epoch: 77 [128/50000]	Loss: 1.5131	LR: 0.026179
Training Epoch: 77 [128/50000]	Loss: 1.4151	LR: 0.026179
Training Epoch: 77 [128/50000]	Loss: 1.5537	LR: 0.026179
Training Epoch: 77 [128/50000]	Loss: 1.5423	LR: 0.026179
Training Epoch: 77 [128/50000]	Loss: 1.6882	LR: 0.026179
Training Epoch: 77 [128/50000]	Loss: 1.5094	LR: 0.026179
Training Epoch: 77 [128/50000]	Loss: 1.4825	LR: 0.026179
Training Epoch: 77 [128/50000]	Loss: 1.5768	LR: 0.026179
Evaluating Network.....
Test set: Epoch: 77, Average loss: 0.0130, Top1Accuracy: 0.5340, Top3Accuracy: 0.7554, Top5Accuracy: 0.8372, Time consumed:1.77s

Training Epoch: 78 [128/50000]	Loss: 1.6970	LR: 0.025488
Training Epoch: 78 [128/50000]	Loss: 1.4903	LR: 0.025488
Training Epoch: 78 [128/50000]	Loss: 1.6160	LR: 0.025488
Training Epoch: 78 [128/50000]	Loss: 1.7698	LR: 0.025488
Training Epoch: 78 [128/50000]	Loss: 1.6810	LR: 0.025488
Training Epoch: 78 [128/50000]	Loss: 1.7348	LR: 0.025488
Training Epoch: 78 [128/50000]	Loss: 1.4013	LR: 0.025488
Training Epoch: 78 [128/50000]	Loss: 1.5992	LR: 0.025488
Training Epoch: 78 [128/50000]	Loss: 1.6425	LR: 0.025488
Training Epoch: 78 [128/50000]	Loss: 1.4067	LR: 0.025488
Evaluating Network.....
Test set: Epoch: 78, Average loss: 0.0132, Top1Accuracy: 0.5325, Top3Accuracy: 0.7528, Top5Accuracy: 0.8326, Time consumed:1.78s

Training Epoch: 79 [128/50000]	Loss: 1.7998	LR: 0.024815
Training Epoch: 79 [128/50000]	Loss: 1.4735	LR: 0.024815
Training Epoch: 79 [128/50000]	Loss: 1.5794	LR: 0.024815
Training Epoch: 79 [128/50000]	Loss: 1.4936	LR: 0.024815
Training Epoch: 79 [128/50000]	Loss: 1.7454	LR: 0.024815
Training Epoch: 79 [128/50000]	Loss: 1.4420	LR: 0.024815
Training Epoch: 79 [128/50000]	Loss: 1.9097	LR: 0.024815
Training Epoch: 79 [128/50000]	Loss: 1.7605	LR: 0.024815
Training Epoch: 79 [128/50000]	Loss: 1.5725	LR: 0.024815
Training Epoch: 79 [128/50000]	Loss: 1.4659	LR: 0.024815
Evaluating Network.....
Test set: Epoch: 79, Average loss: 0.0129, Top1Accuracy: 0.5373, Top3Accuracy: 0.7599, Top5Accuracy: 0.8418, Time consumed:1.80s

Training Epoch: 80 [128/50000]	Loss: 1.6598	LR: 0.024160
Training Epoch: 80 [128/50000]	Loss: 1.5161	LR: 0.024160
Training Epoch: 80 [128/50000]	Loss: 1.6962	LR: 0.024160
Training Epoch: 80 [128/50000]	Loss: 1.3893	LR: 0.024160
Training Epoch: 80 [128/50000]	Loss: 1.3035	LR: 0.024160
Training Epoch: 80 [128/50000]	Loss: 1.4605	LR: 0.024160
Training Epoch: 80 [128/50000]	Loss: 1.6638	LR: 0.024160
Training Epoch: 80 [128/50000]	Loss: 1.5779	LR: 0.024160
Training Epoch: 80 [128/50000]	Loss: 1.6057	LR: 0.024160
Training Epoch: 80 [128/50000]	Loss: 1.7033	LR: 0.024160
Evaluating Network.....
Test set: Epoch: 80, Average loss: 0.0131, Top1Accuracy: 0.5293, Top3Accuracy: 0.7579, Top5Accuracy: 0.8380, Time consumed:1.79s

Training Epoch: 81 [128/50000]	Loss: 1.4604	LR: 0.023522
Training Epoch: 81 [128/50000]	Loss: 1.7159	LR: 0.023522
Training Epoch: 81 [128/50000]	Loss: 1.7360	LR: 0.023522
Training Epoch: 81 [128/50000]	Loss: 1.4163	LR: 0.023522
Training Epoch: 81 [128/50000]	Loss: 1.4212	LR: 0.023522
Training Epoch: 81 [128/50000]	Loss: 1.3848	LR: 0.023522
Training Epoch: 81 [128/50000]	Loss: 1.7169	LR: 0.023522
Training Epoch: 81 [128/50000]	Loss: 1.4888	LR: 0.023522
Training Epoch: 81 [128/50000]	Loss: 1.6134	LR: 0.023522
Training Epoch: 81 [128/50000]	Loss: 1.5431	LR: 0.023522
Evaluating Network.....
Test set: Epoch: 81, Average loss: 0.0129, Top1Accuracy: 0.5373, Top3Accuracy: 0.7578, Top5Accuracy: 0.8406, Time consumed:1.81s

Training Epoch: 82 [128/50000]	Loss: 1.5438	LR: 0.022901
Training Epoch: 82 [128/50000]	Loss: 1.5641	LR: 0.022901
Training Epoch: 82 [128/50000]	Loss: 1.3173	LR: 0.022901
Training Epoch: 82 [128/50000]	Loss: 1.7376	LR: 0.022901
Training Epoch: 82 [128/50000]	Loss: 1.4699	LR: 0.022901
Training Epoch: 82 [128/50000]	Loss: 1.5115	LR: 0.022901
Training Epoch: 82 [128/50000]	Loss: 1.7439	LR: 0.022901
Training Epoch: 82 [128/50000]	Loss: 1.4959	LR: 0.022901
Training Epoch: 82 [128/50000]	Loss: 1.5419	LR: 0.022901
Training Epoch: 82 [128/50000]	Loss: 1.3249	LR: 0.022901
Evaluating Network.....
Test set: Epoch: 82, Average loss: 0.0126, Top1Accuracy: 0.5422, Top3Accuracy: 0.7681, Top5Accuracy: 0.8469, Time consumed:1.79s

Training Epoch: 83 [128/50000]	Loss: 1.6782	LR: 0.022296
Training Epoch: 83 [128/50000]	Loss: 1.3758	LR: 0.022296
Training Epoch: 83 [128/50000]	Loss: 1.6408	LR: 0.022296
Training Epoch: 83 [128/50000]	Loss: 1.4920	LR: 0.022296
Training Epoch: 83 [128/50000]	Loss: 1.6354	LR: 0.022296
Training Epoch: 83 [128/50000]	Loss: 1.5151	LR: 0.022296
Training Epoch: 83 [128/50000]	Loss: 1.4233	LR: 0.022296
Training Epoch: 83 [128/50000]	Loss: 1.4050	LR: 0.022296
Training Epoch: 83 [128/50000]	Loss: 1.6498	LR: 0.022296
Training Epoch: 83 [128/50000]	Loss: 1.2556	LR: 0.022296
Evaluating Network.....
Test set: Epoch: 83, Average loss: 0.0128, Top1Accuracy: 0.5424, Top3Accuracy: 0.7657, Top5Accuracy: 0.8457, Time consumed:1.79s

Training Epoch: 84 [128/50000]	Loss: 1.5555	LR: 0.021708
Training Epoch: 84 [128/50000]	Loss: 1.4020	LR: 0.021708
Training Epoch: 84 [128/50000]	Loss: 1.4446	LR: 0.021708
Training Epoch: 84 [128/50000]	Loss: 1.4228	LR: 0.021708
Training Epoch: 84 [128/50000]	Loss: 1.5594	LR: 0.021708
Training Epoch: 84 [128/50000]	Loss: 1.5819	LR: 0.021708
Training Epoch: 84 [128/50000]	Loss: 1.8381	LR: 0.021708
Training Epoch: 84 [128/50000]	Loss: 1.3863	LR: 0.021708
Training Epoch: 84 [128/50000]	Loss: 1.5117	LR: 0.021708
Training Epoch: 84 [128/50000]	Loss: 1.4064	LR: 0.021708
Evaluating Network.....
Test set: Epoch: 84, Average loss: 0.0125, Top1Accuracy: 0.5486, Top3Accuracy: 0.7677, Top5Accuracy: 0.8459, Time consumed:1.77s

Training Epoch: 85 [128/50000]	Loss: 1.6415	LR: 0.021135
Training Epoch: 85 [128/50000]	Loss: 1.4614	LR: 0.021135
Training Epoch: 85 [128/50000]	Loss: 1.5827	LR: 0.021135
Training Epoch: 85 [128/50000]	Loss: 1.3666	LR: 0.021135
Training Epoch: 85 [128/50000]	Loss: 1.4414	LR: 0.021135
Training Epoch: 85 [128/50000]	Loss: 1.3090	LR: 0.021135
Training Epoch: 85 [128/50000]	Loss: 1.3921	LR: 0.021135
Training Epoch: 85 [128/50000]	Loss: 1.4561	LR: 0.021135
Training Epoch: 85 [128/50000]	Loss: 1.4681	LR: 0.021135
Training Epoch: 85 [128/50000]	Loss: 1.6320	LR: 0.021135
Evaluating Network.....
Test set: Epoch: 85, Average loss: 0.0127, Top1Accuracy: 0.5434, Top3Accuracy: 0.7645, Top5Accuracy: 0.8467, Time consumed:1.77s

Training Epoch: 86 [128/50000]	Loss: 1.5105	LR: 0.020577
Training Epoch: 86 [128/50000]	Loss: 1.4853	LR: 0.020577
Training Epoch: 86 [128/50000]	Loss: 1.4075	LR: 0.020577
Training Epoch: 86 [128/50000]	Loss: 1.3490	LR: 0.020577
Training Epoch: 86 [128/50000]	Loss: 1.6338	LR: 0.020577
Training Epoch: 86 [128/50000]	Loss: 1.8484	LR: 0.020577
Training Epoch: 86 [128/50000]	Loss: 1.5865	LR: 0.020577
Training Epoch: 86 [128/50000]	Loss: 1.3958	LR: 0.020577
Training Epoch: 86 [128/50000]	Loss: 1.5033	LR: 0.020577
Training Epoch: 86 [128/50000]	Loss: 1.2379	LR: 0.020577
Evaluating Network.....
Test set: Epoch: 86, Average loss: 0.0124, Top1Accuracy: 0.5508, Top3Accuracy: 0.7737, Top5Accuracy: 0.8519, Time consumed:1.80s

Training Epoch: 87 [128/50000]	Loss: 1.5647	LR: 0.020034
Training Epoch: 87 [128/50000]	Loss: 1.4484	LR: 0.020034
Training Epoch: 87 [128/50000]	Loss: 1.4301	LR: 0.020034
Training Epoch: 87 [128/50000]	Loss: 1.5117	LR: 0.020034
Training Epoch: 87 [128/50000]	Loss: 1.5421	LR: 0.020034
Training Epoch: 87 [128/50000]	Loss: 1.3304	LR: 0.020034
Training Epoch: 87 [128/50000]	Loss: 1.6683	LR: 0.020034
Training Epoch: 87 [128/50000]	Loss: 1.4856	LR: 0.020034
Training Epoch: 87 [128/50000]	Loss: 1.5496	LR: 0.020034
Training Epoch: 87 [128/50000]	Loss: 1.5286	LR: 0.020034
Evaluating Network.....
Test set: Epoch: 87, Average loss: 0.0124, Top1Accuracy: 0.5504, Top3Accuracy: 0.7723, Top5Accuracy: 0.8494, Time consumed:1.82s

Training Epoch: 88 [128/50000]	Loss: 1.3796	LR: 0.019505
Training Epoch: 88 [128/50000]	Loss: 1.3441	LR: 0.019505
Training Epoch: 88 [128/50000]	Loss: 1.4482	LR: 0.019505
Training Epoch: 88 [128/50000]	Loss: 1.6967	LR: 0.019505
Training Epoch: 88 [128/50000]	Loss: 1.4308	LR: 0.019505
Training Epoch: 88 [128/50000]	Loss: 1.4996	LR: 0.019505
Training Epoch: 88 [128/50000]	Loss: 1.4367	LR: 0.019505
Training Epoch: 88 [128/50000]	Loss: 1.6571	LR: 0.019505
Training Epoch: 88 [128/50000]	Loss: 1.3812	LR: 0.019505
Training Epoch: 88 [128/50000]	Loss: 1.5750	LR: 0.019505
Evaluating Network.....
Test set: Epoch: 88, Average loss: 0.0124, Top1Accuracy: 0.5536, Top3Accuracy: 0.7729, Top5Accuracy: 0.8543, Time consumed:1.78s

Training Epoch: 89 [128/50000]	Loss: 1.4913	LR: 0.018990
Training Epoch: 89 [128/50000]	Loss: 1.4597	LR: 0.018990
Training Epoch: 89 [128/50000]	Loss: 1.4795	LR: 0.018990
Training Epoch: 89 [128/50000]	Loss: 1.6859	LR: 0.018990
Training Epoch: 89 [128/50000]	Loss: 1.6748	LR: 0.018990
Training Epoch: 89 [128/50000]	Loss: 1.4385	LR: 0.018990
Training Epoch: 89 [128/50000]	Loss: 1.3478	LR: 0.018990
Training Epoch: 89 [128/50000]	Loss: 1.4989	LR: 0.018990
Training Epoch: 89 [128/50000]	Loss: 1.4797	LR: 0.018990
Training Epoch: 89 [128/50000]	Loss: 1.5880	LR: 0.018990
Evaluating Network.....
Test set: Epoch: 89, Average loss: 0.0123, Top1Accuracy: 0.5572, Top3Accuracy: 0.7752, Top5Accuracy: 0.8530, Time consumed:1.81s

Training Epoch: 90 [128/50000]	Loss: 1.5699	LR: 0.018488
Training Epoch: 90 [128/50000]	Loss: 1.4028	LR: 0.018488
Training Epoch: 90 [128/50000]	Loss: 1.3507	LR: 0.018488
Training Epoch: 90 [128/50000]	Loss: 1.6331	LR: 0.018488
Training Epoch: 90 [128/50000]	Loss: 1.6737	LR: 0.018488
Training Epoch: 90 [128/50000]	Loss: 1.5174	LR: 0.018488
Training Epoch: 90 [128/50000]	Loss: 1.5259	LR: 0.018488
Training Epoch: 90 [128/50000]	Loss: 1.5032	LR: 0.018488
Training Epoch: 90 [128/50000]	Loss: 1.3894	LR: 0.018488
Training Epoch: 90 [128/50000]	Loss: 1.3417	LR: 0.018488
Evaluating Network.....
Test set: Epoch: 90, Average loss: 0.0123, Top1Accuracy: 0.5552, Top3Accuracy: 0.7759, Top5Accuracy: 0.8544, Time consumed:2.09s

Training Epoch: 91 [128/50000]	Loss: 1.6168	LR: 0.018000
Training Epoch: 91 [128/50000]	Loss: 1.3913	LR: 0.018000
Training Epoch: 91 [128/50000]	Loss: 1.3333	LR: 0.018000
Training Epoch: 91 [128/50000]	Loss: 1.3810	LR: 0.018000
Training Epoch: 91 [128/50000]	Loss: 1.4577	LR: 0.018000
Training Epoch: 91 [128/50000]	Loss: 1.2972	LR: 0.018000
Training Epoch: 91 [128/50000]	Loss: 1.4177	LR: 0.018000
Training Epoch: 91 [128/50000]	Loss: 1.7735	LR: 0.018000
Training Epoch: 91 [128/50000]	Loss: 1.4464	LR: 0.018000
Training Epoch: 91 [128/50000]	Loss: 1.6771	LR: 0.018000
Evaluating Network.....
Test set: Epoch: 91, Average loss: 0.0123, Top1Accuracy: 0.5544, Top3Accuracy: 0.7764, Top5Accuracy: 0.8521, Time consumed:1.80s

Training Epoch: 92 [128/50000]	Loss: 1.4196	LR: 0.017525
Training Epoch: 92 [128/50000]	Loss: 1.4556	LR: 0.017525
Training Epoch: 92 [128/50000]	Loss: 1.3272	LR: 0.017525
Training Epoch: 92 [128/50000]	Loss: 1.4032	LR: 0.017525
Training Epoch: 92 [128/50000]	Loss: 1.2461	LR: 0.017525
Training Epoch: 92 [128/50000]	Loss: 1.7014	LR: 0.017525
Training Epoch: 92 [128/50000]	Loss: 1.5468	LR: 0.017525
Training Epoch: 92 [128/50000]	Loss: 1.2064	LR: 0.017525
Training Epoch: 92 [128/50000]	Loss: 1.5676	LR: 0.017525
Training Epoch: 92 [128/50000]	Loss: 1.4297	LR: 0.017525
Evaluating Network.....
Test set: Epoch: 92, Average loss: 0.0121, Top1Accuracy: 0.5668, Top3Accuracy: 0.7823, Top5Accuracy: 0.8570, Time consumed:1.79s

Training Epoch: 93 [128/50000]	Loss: 1.5638	LR: 0.017062
Training Epoch: 93 [128/50000]	Loss: 1.4746	LR: 0.017062
Training Epoch: 93 [128/50000]	Loss: 1.4022	LR: 0.017062
Training Epoch: 93 [128/50000]	Loss: 1.3623	LR: 0.017062
Training Epoch: 93 [128/50000]	Loss: 1.5217	LR: 0.017062
Training Epoch: 93 [128/50000]	Loss: 1.4288	LR: 0.017062
Training Epoch: 93 [128/50000]	Loss: 1.3340	LR: 0.017062
Training Epoch: 93 [128/50000]	Loss: 1.5233	LR: 0.017062
Training Epoch: 93 [128/50000]	Loss: 1.3950	LR: 0.017062
Training Epoch: 93 [128/50000]	Loss: 1.6052	LR: 0.017062
Evaluating Network.....
Test set: Epoch: 93, Average loss: 0.0121, Top1Accuracy: 0.5580, Top3Accuracy: 0.7831, Top5Accuracy: 0.8592, Time consumed:1.82s

Training Epoch: 94 [128/50000]	Loss: 1.5093	LR: 0.016612
Training Epoch: 94 [128/50000]	Loss: 1.3827	LR: 0.016612
Training Epoch: 94 [128/50000]	Loss: 1.4806	LR: 0.016612
Training Epoch: 94 [128/50000]	Loss: 1.5441	LR: 0.016612
Training Epoch: 94 [128/50000]	Loss: 1.1627	LR: 0.016612
Training Epoch: 94 [128/50000]	Loss: 1.5522	LR: 0.016612
Training Epoch: 94 [128/50000]	Loss: 1.3680	LR: 0.016612
Training Epoch: 94 [128/50000]	Loss: 1.4393	LR: 0.016612
Training Epoch: 94 [128/50000]	Loss: 1.3916	LR: 0.016612
Training Epoch: 94 [128/50000]	Loss: 1.3117	LR: 0.016612
Evaluating Network.....
Test set: Epoch: 94, Average loss: 0.0120, Top1Accuracy: 0.5643, Top3Accuracy: 0.7848, Top5Accuracy: 0.8581, Time consumed:1.80s

Training Epoch: 95 [128/50000]	Loss: 1.3496	LR: 0.016173
Training Epoch: 95 [128/50000]	Loss: 1.3859	LR: 0.016173
Training Epoch: 95 [128/50000]	Loss: 1.2942	LR: 0.016173
Training Epoch: 95 [128/50000]	Loss: 1.4795	LR: 0.016173
Training Epoch: 95 [128/50000]	Loss: 1.3895	LR: 0.016173
Training Epoch: 95 [128/50000]	Loss: 1.3964	LR: 0.016173
Training Epoch: 95 [128/50000]	Loss: 1.5103	LR: 0.016173
Training Epoch: 95 [128/50000]	Loss: 1.4326	LR: 0.016173
Training Epoch: 95 [128/50000]	Loss: 1.6277	LR: 0.016173
Training Epoch: 95 [128/50000]	Loss: 1.4914	LR: 0.016173
Evaluating Network.....
Test set: Epoch: 95, Average loss: 0.0120, Top1Accuracy: 0.5654, Top3Accuracy: 0.7870, Top5Accuracy: 0.8582, Time consumed:1.80s

Training Epoch: 96 [128/50000]	Loss: 1.5981	LR: 0.015746
Training Epoch: 96 [128/50000]	Loss: 1.6031	LR: 0.015746
Training Epoch: 96 [128/50000]	Loss: 1.4257	LR: 0.015746
Training Epoch: 96 [128/50000]	Loss: 1.4251	LR: 0.015746
Training Epoch: 96 [128/50000]	Loss: 1.2666	LR: 0.015746
Training Epoch: 96 [128/50000]	Loss: 1.3088	LR: 0.015746
Training Epoch: 96 [128/50000]	Loss: 1.3825	LR: 0.015746
Training Epoch: 96 [128/50000]	Loss: 1.4302	LR: 0.015746
Training Epoch: 96 [128/50000]	Loss: 1.4771	LR: 0.015746
Training Epoch: 96 [128/50000]	Loss: 1.3929	LR: 0.015746
Evaluating Network.....
Test set: Epoch: 96, Average loss: 0.0119, Top1Accuracy: 0.5700, Top3Accuracy: 0.7861, Top5Accuracy: 0.8626, Time consumed:1.78s

Training Epoch: 97 [128/50000]	Loss: 1.3374	LR: 0.015331
Training Epoch: 97 [128/50000]	Loss: 1.3719	LR: 0.015331
Training Epoch: 97 [128/50000]	Loss: 1.4070	LR: 0.015331
Training Epoch: 97 [128/50000]	Loss: 1.3952	LR: 0.015331
Training Epoch: 97 [128/50000]	Loss: 1.4896	LR: 0.015331
Training Epoch: 97 [128/50000]	Loss: 1.6378	LR: 0.015331
Training Epoch: 97 [128/50000]	Loss: 1.4687	LR: 0.015331
Training Epoch: 97 [128/50000]	Loss: 1.3459	LR: 0.015331
Training Epoch: 97 [128/50000]	Loss: 1.1652	LR: 0.015331
Training Epoch: 97 [128/50000]	Loss: 1.2159	LR: 0.015331
Evaluating Network.....
Test set: Epoch: 97, Average loss: 0.0119, Top1Accuracy: 0.5732, Top3Accuracy: 0.7858, Top5Accuracy: 0.8580, Time consumed:1.76s

Training Epoch: 98 [128/50000]	Loss: 1.3354	LR: 0.014926
Training Epoch: 98 [128/50000]	Loss: 1.4319	LR: 0.014926
Training Epoch: 98 [128/50000]	Loss: 1.2130	LR: 0.014926
Training Epoch: 98 [128/50000]	Loss: 1.4804	LR: 0.014926
Training Epoch: 98 [128/50000]	Loss: 1.3525	LR: 0.014926
Training Epoch: 98 [128/50000]	Loss: 1.3900	LR: 0.014926
Training Epoch: 98 [128/50000]	Loss: 1.4570	LR: 0.014926
Training Epoch: 98 [128/50000]	Loss: 1.4793	LR: 0.014926
Training Epoch: 98 [128/50000]	Loss: 1.4689	LR: 0.014926
Training Epoch: 98 [128/50000]	Loss: 1.2291	LR: 0.014926
Evaluating Network.....
Test set: Epoch: 98, Average loss: 0.0119, Top1Accuracy: 0.5697, Top3Accuracy: 0.7865, Top5Accuracy: 0.8609, Time consumed:1.77s

Training Epoch: 99 [128/50000]	Loss: 1.4208	LR: 0.014532
Training Epoch: 99 [128/50000]	Loss: 1.3075	LR: 0.014532
Training Epoch: 99 [128/50000]	Loss: 1.4397	LR: 0.014532
Training Epoch: 99 [128/50000]	Loss: 1.4464	LR: 0.014532
Training Epoch: 99 [128/50000]	Loss: 1.5759	LR: 0.014532
Training Epoch: 99 [128/50000]	Loss: 1.2926	LR: 0.014532
Training Epoch: 99 [128/50000]	Loss: 1.4433	LR: 0.014532
Training Epoch: 99 [128/50000]	Loss: 1.3894	LR: 0.014532
Training Epoch: 99 [128/50000]	Loss: 1.1385	LR: 0.014532
Training Epoch: 99 [128/50000]	Loss: 1.2606	LR: 0.014532
Evaluating Network.....
Test set: Epoch: 99, Average loss: 0.0119, Top1Accuracy: 0.5718, Top3Accuracy: 0.7846, Top5Accuracy: 0.8584, Time consumed:1.89s

Training Epoch: 100 [128/50000]	Loss: 1.8428	LR: 0.014148
Training Epoch: 100 [128/50000]	Loss: 1.1290	LR: 0.014148
Training Epoch: 100 [128/50000]	Loss: 1.2346	LR: 0.014148
Training Epoch: 100 [128/50000]	Loss: 1.2188	LR: 0.014148
Training Epoch: 100 [128/50000]	Loss: 1.4200	LR: 0.014148
Training Epoch: 100 [128/50000]	Loss: 1.2475	LR: 0.014148
Training Epoch: 100 [128/50000]	Loss: 1.4685	LR: 0.014148
Training Epoch: 100 [128/50000]	Loss: 1.4344	LR: 0.014148
Training Epoch: 100 [128/50000]	Loss: 1.2795	LR: 0.014148
Training Epoch: 100 [128/50000]	Loss: 1.4598	LR: 0.014148
Evaluating Network.....
Test set: Epoch: 100, Average loss: 0.0119, Top1Accuracy: 0.5694, Top3Accuracy: 0.7855, Top5Accuracy: 0.8609, Time consumed:1.82s

Training Epoch: 101 [128/50000]	Loss: 1.3591	LR: 0.013775
Training Epoch: 101 [128/50000]	Loss: 1.2100	LR: 0.013775
Training Epoch: 101 [128/50000]	Loss: 1.5191	LR: 0.013775
Training Epoch: 101 [128/50000]	Loss: 1.3958	LR: 0.013775
Training Epoch: 101 [128/50000]	Loss: 1.3117	LR: 0.013775
Training Epoch: 101 [128/50000]	Loss: 1.4657	LR: 0.013775
Training Epoch: 101 [128/50000]	Loss: 1.2675	LR: 0.013775
Training Epoch: 101 [128/50000]	Loss: 1.4502	LR: 0.013775
Training Epoch: 101 [128/50000]	Loss: 1.3328	LR: 0.013775
Training Epoch: 101 [128/50000]	Loss: 1.2426	LR: 0.013775
Evaluating Network.....
Test set: Epoch: 101, Average loss: 0.0118, Top1Accuracy: 0.5712, Top3Accuracy: 0.7910, Top5Accuracy: 0.8631, Time consumed:1.79s

Training Epoch: 102 [128/50000]	Loss: 1.4512	LR: 0.013411
Training Epoch: 102 [128/50000]	Loss: 1.2937	LR: 0.013411
Training Epoch: 102 [128/50000]	Loss: 1.4048	LR: 0.013411
Training Epoch: 102 [128/50000]	Loss: 1.3772	LR: 0.013411
Training Epoch: 102 [128/50000]	Loss: 1.4037	LR: 0.013411
Training Epoch: 102 [128/50000]	Loss: 1.3212	LR: 0.013411
Training Epoch: 102 [128/50000]	Loss: 1.4573	LR: 0.013411
Training Epoch: 102 [128/50000]	Loss: 1.3416	LR: 0.013411
Training Epoch: 102 [128/50000]	Loss: 1.2952	LR: 0.013411
Training Epoch: 102 [128/50000]	Loss: 1.5545	LR: 0.013411
Evaluating Network.....
Test set: Epoch: 102, Average loss: 0.0118, Top1Accuracy: 0.5731, Top3Accuracy: 0.7900, Top5Accuracy: 0.8615, Time consumed:1.77s

Training Epoch: 103 [128/50000]	Loss: 1.2812	LR: 0.013057
Training Epoch: 103 [128/50000]	Loss: 1.3569	LR: 0.013057
Training Epoch: 103 [128/50000]	Loss: 1.4018	LR: 0.013057
Training Epoch: 103 [128/50000]	Loss: 1.3238	LR: 0.013057
Training Epoch: 103 [128/50000]	Loss: 1.6927	LR: 0.013057
Training Epoch: 103 [128/50000]	Loss: 1.2502	LR: 0.013057
Training Epoch: 103 [128/50000]	Loss: 1.4062	LR: 0.013057
Training Epoch: 103 [128/50000]	Loss: 1.2495	LR: 0.013057
Training Epoch: 103 [128/50000]	Loss: 1.1869	LR: 0.013057
Training Epoch: 103 [128/50000]	Loss: 1.2974	LR: 0.013057
Evaluating Network.....
Test set: Epoch: 103, Average loss: 0.0118, Top1Accuracy: 0.5718, Top3Accuracy: 0.7901, Top5Accuracy: 0.8635, Time consumed:1.78s

Training Epoch: 104 [128/50000]	Loss: 1.4885	LR: 0.012712
Training Epoch: 104 [128/50000]	Loss: 1.4377	LR: 0.012712
Training Epoch: 104 [128/50000]	Loss: 1.3049	LR: 0.012712
Training Epoch: 104 [128/50000]	Loss: 1.3121	LR: 0.012712
Training Epoch: 104 [128/50000]	Loss: 1.3023	LR: 0.012712
Training Epoch: 104 [128/50000]	Loss: 1.3187	LR: 0.012712
Training Epoch: 104 [128/50000]	Loss: 1.4365	LR: 0.012712
Training Epoch: 104 [128/50000]	Loss: 1.4447	LR: 0.012712
Training Epoch: 104 [128/50000]	Loss: 1.3768	LR: 0.012712
Training Epoch: 104 [128/50000]	Loss: 1.1122	LR: 0.012712
Evaluating Network.....
Test set: Epoch: 104, Average loss: 0.0116, Top1Accuracy: 0.5780, Top3Accuracy: 0.7944, Top5Accuracy: 0.8664, Time consumed:1.81s

Training Epoch: 105 [128/50000]	Loss: 1.5112	LR: 0.012377
Training Epoch: 105 [128/50000]	Loss: 1.4013	LR: 0.012377
Training Epoch: 105 [128/50000]	Loss: 1.2410	LR: 0.012377
Training Epoch: 105 [128/50000]	Loss: 1.5981	LR: 0.012377
Training Epoch: 105 [128/50000]	Loss: 1.3162	LR: 0.012377
Training Epoch: 105 [128/50000]	Loss: 1.3146	LR: 0.012377
Training Epoch: 105 [128/50000]	Loss: 1.4555	LR: 0.012377
Training Epoch: 105 [128/50000]	Loss: 1.3083	LR: 0.012377
Training Epoch: 105 [128/50000]	Loss: 1.3812	LR: 0.012377
Training Epoch: 105 [128/50000]	Loss: 1.3577	LR: 0.012377
Evaluating Network.....
Test set: Epoch: 105, Average loss: 0.0117, Top1Accuracy: 0.5775, Top3Accuracy: 0.7940, Top5Accuracy: 0.8650, Time consumed:1.80s

Training Epoch: 106 [128/50000]	Loss: 1.2881	LR: 0.012050
Training Epoch: 106 [128/50000]	Loss: 1.2860	LR: 0.012050
Training Epoch: 106 [128/50000]	Loss: 1.4480	LR: 0.012050
Training Epoch: 106 [128/50000]	Loss: 1.1474	LR: 0.012050
Training Epoch: 106 [128/50000]	Loss: 1.1322	LR: 0.012050
Training Epoch: 106 [128/50000]	Loss: 1.3796	LR: 0.012050
Training Epoch: 106 [128/50000]	Loss: 1.2950	LR: 0.012050
Training Epoch: 106 [128/50000]	Loss: 1.3218	LR: 0.012050
Training Epoch: 106 [128/50000]	Loss: 1.5469	LR: 0.012050
Training Epoch: 106 [128/50000]	Loss: 1.2648	LR: 0.012050
Evaluating Network.....
Test set: Epoch: 106, Average loss: 0.0116, Top1Accuracy: 0.5804, Top3Accuracy: 0.7990, Top5Accuracy: 0.8671, Time consumed:1.78s

Training Epoch: 107 [128/50000]	Loss: 1.2733	LR: 0.011732
Training Epoch: 107 [128/50000]	Loss: 1.1044	LR: 0.011732
Training Epoch: 107 [128/50000]	Loss: 1.4101	LR: 0.011732
Training Epoch: 107 [128/50000]	Loss: 1.4486	LR: 0.011732
Training Epoch: 107 [128/50000]	Loss: 1.3273	LR: 0.011732
Training Epoch: 107 [128/50000]	Loss: 1.2435	LR: 0.011732
Training Epoch: 107 [128/50000]	Loss: 1.2855	LR: 0.011732
Training Epoch: 107 [128/50000]	Loss: 1.4635	LR: 0.011732
Training Epoch: 107 [128/50000]	Loss: 1.3803	LR: 0.011732
Training Epoch: 107 [128/50000]	Loss: 1.2155	LR: 0.011732
Evaluating Network.....
Test set: Epoch: 107, Average loss: 0.0115, Top1Accuracy: 0.5837, Top3Accuracy: 0.7953, Top5Accuracy: 0.8670, Time consumed:1.79s

Training Epoch: 108 [128/50000]	Loss: 1.2699	LR: 0.011422
Training Epoch: 108 [128/50000]	Loss: 1.2005	LR: 0.011422
Training Epoch: 108 [128/50000]	Loss: 1.2592	LR: 0.011422
Training Epoch: 108 [128/50000]	Loss: 1.2999	LR: 0.011422
Training Epoch: 108 [128/50000]	Loss: 1.1702	LR: 0.011422
Training Epoch: 108 [128/50000]	Loss: 1.4083	LR: 0.011422
Training Epoch: 108 [128/50000]	Loss: 1.3541	LR: 0.011422
Training Epoch: 108 [128/50000]	Loss: 1.2630	LR: 0.011422
Training Epoch: 108 [128/50000]	Loss: 1.1166	LR: 0.011422
Training Epoch: 108 [128/50000]	Loss: 1.4404	LR: 0.011422
Evaluating Network.....
Test set: Epoch: 108, Average loss: 0.0116, Top1Accuracy: 0.5824, Top3Accuracy: 0.7979, Top5Accuracy: 0.8672, Time consumed:1.77s

Training Epoch: 109 [128/50000]	Loss: 1.4783	LR: 0.011121
Training Epoch: 109 [128/50000]	Loss: 1.4394	LR: 0.011121
Training Epoch: 109 [128/50000]	Loss: 1.3545	LR: 0.011121
Training Epoch: 109 [128/50000]	Loss: 1.3615	LR: 0.011121
Training Epoch: 109 [128/50000]	Loss: 1.1366	LR: 0.011121
Training Epoch: 109 [128/50000]	Loss: 1.5255	LR: 0.011121
Training Epoch: 109 [128/50000]	Loss: 1.3355	LR: 0.011121
Training Epoch: 109 [128/50000]	Loss: 1.3655	LR: 0.011121
Training Epoch: 109 [128/50000]	Loss: 1.3597	LR: 0.011121
Training Epoch: 109 [128/50000]	Loss: 1.4111	LR: 0.011121
Evaluating Network.....
Test set: Epoch: 109, Average loss: 0.0116, Top1Accuracy: 0.5795, Top3Accuracy: 0.7974, Top5Accuracy: 0.8678, Time consumed:1.78s

Training Epoch: 110 [128/50000]	Loss: 1.3873	LR: 0.010827
Training Epoch: 110 [128/50000]	Loss: 1.2593	LR: 0.010827
Training Epoch: 110 [128/50000]	Loss: 1.2514	LR: 0.010827
Training Epoch: 110 [128/50000]	Loss: 1.4746	LR: 0.010827
Training Epoch: 110 [128/50000]	Loss: 1.5470	LR: 0.010827
Training Epoch: 110 [128/50000]	Loss: 1.2695	LR: 0.010827
Training Epoch: 110 [128/50000]	Loss: 1.0125	LR: 0.010827
Training Epoch: 110 [128/50000]	Loss: 1.2578	LR: 0.010827
Training Epoch: 110 [128/50000]	Loss: 1.3408	LR: 0.010827
Training Epoch: 110 [128/50000]	Loss: 1.2562	LR: 0.010827
Evaluating Network.....
Test set: Epoch: 110, Average loss: 0.0116, Top1Accuracy: 0.5828, Top3Accuracy: 0.7945, Top5Accuracy: 0.8666, Time consumed:1.79s

Training Epoch: 111 [128/50000]	Loss: 1.2999	LR: 0.010541
Training Epoch: 111 [128/50000]	Loss: 1.2938	LR: 0.010541
Training Epoch: 111 [128/50000]	Loss: 1.3656	LR: 0.010541
Training Epoch: 111 [128/50000]	Loss: 1.2991	LR: 0.010541
Training Epoch: 111 [128/50000]	Loss: 1.2073	LR: 0.010541
Training Epoch: 111 [128/50000]	Loss: 1.2515	LR: 0.010541
Training Epoch: 111 [128/50000]	Loss: 1.2698	LR: 0.010541
Training Epoch: 111 [128/50000]	Loss: 1.3344	LR: 0.010541
Training Epoch: 111 [128/50000]	Loss: 1.1470	LR: 0.010541
Training Epoch: 111 [128/50000]	Loss: 1.1156	LR: 0.010541
Evaluating Network.....
Test set: Epoch: 111, Average loss: 0.0114, Top1Accuracy: 0.5844, Top3Accuracy: 0.7981, Top5Accuracy: 0.8682, Time consumed:1.79s

Training Epoch: 112 [128/50000]	Loss: 1.3065	LR: 0.010263
Training Epoch: 112 [128/50000]	Loss: 1.0716	LR: 0.010263
Training Epoch: 112 [128/50000]	Loss: 1.3454	LR: 0.010263
Training Epoch: 112 [128/50000]	Loss: 1.4821	LR: 0.010263
Training Epoch: 112 [128/50000]	Loss: 1.1663	LR: 0.010263
Training Epoch: 112 [128/50000]	Loss: 1.3582	LR: 0.010263
Training Epoch: 112 [128/50000]	Loss: 1.2525	LR: 0.010263
Training Epoch: 112 [128/50000]	Loss: 1.3666	LR: 0.010263
Training Epoch: 112 [128/50000]	Loss: 1.3189	LR: 0.010263
Training Epoch: 112 [128/50000]	Loss: 1.3490	LR: 0.010263
Evaluating Network.....
Test set: Epoch: 112, Average loss: 0.0114, Top1Accuracy: 0.5854, Top3Accuracy: 0.8025, Top5Accuracy: 0.8691, Time consumed:1.79s

Training Epoch: 113 [128/50000]	Loss: 1.2621	LR: 0.009992
Training Epoch: 113 [128/50000]	Loss: 1.3507	LR: 0.009992
Training Epoch: 113 [128/50000]	Loss: 1.3578	LR: 0.009992
Training Epoch: 113 [128/50000]	Loss: 1.1017	LR: 0.009992
Training Epoch: 113 [128/50000]	Loss: 1.1577	LR: 0.009992
Training Epoch: 113 [128/50000]	Loss: 1.4089	LR: 0.009992
Training Epoch: 113 [128/50000]	Loss: 1.1344	LR: 0.009992
Training Epoch: 113 [128/50000]	Loss: 1.2080	LR: 0.009992
Training Epoch: 113 [128/50000]	Loss: 1.3450	LR: 0.009992
Training Epoch: 113 [128/50000]	Loss: 1.3738	LR: 0.009992
Evaluating Network.....
Test set: Epoch: 113, Average loss: 0.0115, Top1Accuracy: 0.5860, Top3Accuracy: 0.8000, Top5Accuracy: 0.8712, Time consumed:1.97s

Training Epoch: 114 [128/50000]	Loss: 1.2938	LR: 0.009728
Training Epoch: 114 [128/50000]	Loss: 1.2863	LR: 0.009728
Training Epoch: 114 [128/50000]	Loss: 1.2607	LR: 0.009728
Training Epoch: 114 [128/50000]	Loss: 1.1457	LR: 0.009728
Training Epoch: 114 [128/50000]	Loss: 1.1631	LR: 0.009728
Training Epoch: 114 [128/50000]	Loss: 1.2563	LR: 0.009728
Training Epoch: 114 [128/50000]	Loss: 1.2509	LR: 0.009728
Training Epoch: 114 [128/50000]	Loss: 1.4253	LR: 0.009728
Training Epoch: 114 [128/50000]	Loss: 1.2788	LR: 0.009728
Training Epoch: 114 [128/50000]	Loss: 1.1329	LR: 0.009728
Evaluating Network.....
Test set: Epoch: 114, Average loss: 0.0114, Top1Accuracy: 0.5838, Top3Accuracy: 0.7994, Top5Accuracy: 0.8711, Time consumed:1.78s

Training Epoch: 115 [128/50000]	Loss: 1.1527	LR: 0.009471
Training Epoch: 115 [128/50000]	Loss: 1.0887	LR: 0.009471
Training Epoch: 115 [128/50000]	Loss: 1.1880	LR: 0.009471
Training Epoch: 115 [128/50000]	Loss: 1.2932	LR: 0.009471
Training Epoch: 115 [128/50000]	Loss: 1.1007	LR: 0.009471
Training Epoch: 115 [128/50000]	Loss: 1.2433	LR: 0.009471
Training Epoch: 115 [128/50000]	Loss: 1.2703	LR: 0.009471
Training Epoch: 115 [128/50000]	Loss: 1.4221	LR: 0.009471
Training Epoch: 115 [128/50000]	Loss: 1.4779	LR: 0.009471
Training Epoch: 115 [128/50000]	Loss: 1.2559	LR: 0.009471
Evaluating Network.....
Test set: Epoch: 115, Average loss: 0.0114, Top1Accuracy: 0.5865, Top3Accuracy: 0.8024, Top5Accuracy: 0.8697, Time consumed:1.79s

Training Epoch: 116 [128/50000]	Loss: 0.9631	LR: 0.009221
Training Epoch: 116 [128/50000]	Loss: 1.1389	LR: 0.009221
Training Epoch: 116 [128/50000]	Loss: 1.3860	LR: 0.009221
Training Epoch: 116 [128/50000]	Loss: 1.3610	LR: 0.009221
Training Epoch: 116 [128/50000]	Loss: 1.1382	LR: 0.009221
Training Epoch: 116 [128/50000]	Loss: 1.1716	LR: 0.009221
Training Epoch: 116 [128/50000]	Loss: 1.0731	LR: 0.009221
Training Epoch: 116 [128/50000]	Loss: 1.1857	LR: 0.009221
Training Epoch: 116 [128/50000]	Loss: 1.3524	LR: 0.009221
Training Epoch: 116 [128/50000]	Loss: 1.1819	LR: 0.009221
Evaluating Network.....
Test set: Epoch: 116, Average loss: 0.0114, Top1Accuracy: 0.5880, Top3Accuracy: 0.8008, Top5Accuracy: 0.8710, Time consumed:2.03s

Training Epoch: 117 [128/50000]	Loss: 1.2255	LR: 0.008978
Training Epoch: 117 [128/50000]	Loss: 1.1163	LR: 0.008978
Training Epoch: 117 [128/50000]	Loss: 1.0823	LR: 0.008978
Training Epoch: 117 [128/50000]	Loss: 1.1331	LR: 0.008978
Training Epoch: 117 [128/50000]	Loss: 1.1511	LR: 0.008978
Training Epoch: 117 [128/50000]	Loss: 1.2045	LR: 0.008978
Training Epoch: 117 [128/50000]	Loss: 1.3664	LR: 0.008978
Training Epoch: 117 [128/50000]	Loss: 1.0372	LR: 0.008978
Training Epoch: 117 [128/50000]	Loss: 1.5097	LR: 0.008978
Training Epoch: 117 [128/50000]	Loss: 1.4306	LR: 0.008978
Evaluating Network.....
Test set: Epoch: 117, Average loss: 0.0113, Top1Accuracy: 0.5921, Top3Accuracy: 0.8043, Top5Accuracy: 0.8690, Time consumed:1.80s

Training Epoch: 118 [128/50000]	Loss: 1.1352	LR: 0.008741
Training Epoch: 118 [128/50000]	Loss: 1.1217	LR: 0.008741
Training Epoch: 118 [128/50000]	Loss: 1.3581	LR: 0.008741
Training Epoch: 118 [128/50000]	Loss: 1.2922	LR: 0.008741
Training Epoch: 118 [128/50000]	Loss: 1.2647	LR: 0.008741
Training Epoch: 118 [128/50000]	Loss: 1.4740	LR: 0.008741
Training Epoch: 118 [128/50000]	Loss: 1.3853	LR: 0.008741
Training Epoch: 118 [128/50000]	Loss: 1.2978	LR: 0.008741
Training Epoch: 118 [128/50000]	Loss: 1.1371	LR: 0.008741
Training Epoch: 118 [128/50000]	Loss: 1.1809	LR: 0.008741
Evaluating Network.....
Test set: Epoch: 118, Average loss: 0.0113, Top1Accuracy: 0.5932, Top3Accuracy: 0.8040, Top5Accuracy: 0.8721, Time consumed:1.79s

Training Epoch: 119 [128/50000]	Loss: 1.1597	LR: 0.008510
Training Epoch: 119 [128/50000]	Loss: 1.2992	LR: 0.008510
Training Epoch: 119 [128/50000]	Loss: 1.2432	LR: 0.008510
Training Epoch: 119 [128/50000]	Loss: 1.2862	LR: 0.008510
Training Epoch: 119 [128/50000]	Loss: 1.2621	LR: 0.008510
Training Epoch: 119 [128/50000]	Loss: 1.3656	LR: 0.008510
Training Epoch: 119 [128/50000]	Loss: 1.2336	LR: 0.008510
Training Epoch: 119 [128/50000]	Loss: 1.1917	LR: 0.008510
Training Epoch: 119 [128/50000]	Loss: 1.2760	LR: 0.008510
Training Epoch: 119 [128/50000]	Loss: 1.3236	LR: 0.008510
Evaluating Network.....
Test set: Epoch: 119, Average loss: 0.0113, Top1Accuracy: 0.5943, Top3Accuracy: 0.8043, Top5Accuracy: 0.8714, Time consumed:1.79s

Training Epoch: 120 [128/50000]	Loss: 1.3696	LR: 0.008285
Training Epoch: 120 [128/50000]	Loss: 1.1210	LR: 0.008285
Training Epoch: 120 [128/50000]	Loss: 1.0602	LR: 0.008285
Training Epoch: 120 [128/50000]	Loss: 1.3295	LR: 0.008285
Training Epoch: 120 [128/50000]	Loss: 1.0588	LR: 0.008285
Training Epoch: 120 [128/50000]	Loss: 1.2693	LR: 0.008285
Training Epoch: 120 [128/50000]	Loss: 1.1303	LR: 0.008285
Training Epoch: 120 [128/50000]	Loss: 1.2953	LR: 0.008285
Training Epoch: 120 [128/50000]	Loss: 1.2985	LR: 0.008285
Training Epoch: 120 [128/50000]	Loss: 1.3602	LR: 0.008285
Evaluating Network.....
Test set: Epoch: 120, Average loss: 0.0113, Top1Accuracy: 0.5889, Top3Accuracy: 0.8032, Top5Accuracy: 0.8721, Time consumed:1.78s

Training Epoch: 121 [128/50000]	Loss: 1.1075	LR: 0.008067
Training Epoch: 121 [128/50000]	Loss: 1.1527	LR: 0.008067
Training Epoch: 121 [128/50000]	Loss: 1.1858	LR: 0.008067
Training Epoch: 121 [128/50000]	Loss: 1.3597	LR: 0.008067
Training Epoch: 121 [128/50000]	Loss: 1.2588	LR: 0.008067
Training Epoch: 121 [128/50000]	Loss: 1.1049	LR: 0.008067
Training Epoch: 121 [128/50000]	Loss: 1.1809	LR: 0.008067
Training Epoch: 121 [128/50000]	Loss: 1.2118	LR: 0.008067
Training Epoch: 121 [128/50000]	Loss: 1.1665	LR: 0.008067
Training Epoch: 121 [128/50000]	Loss: 1.3879	LR: 0.008067
Evaluating Network.....
Test set: Epoch: 121, Average loss: 0.0112, Top1Accuracy: 0.5916, Top3Accuracy: 0.8040, Top5Accuracy: 0.8723, Time consumed:1.80s

Training Epoch: 122 [128/50000]	Loss: 1.2416	LR: 0.007854
Training Epoch: 122 [128/50000]	Loss: 1.1168	LR: 0.007854
Training Epoch: 122 [128/50000]	Loss: 1.2548	LR: 0.007854
Training Epoch: 122 [128/50000]	Loss: 1.2289	LR: 0.007854
Training Epoch: 122 [128/50000]	Loss: 1.1341	LR: 0.007854
Training Epoch: 122 [128/50000]	Loss: 1.2408	LR: 0.007854
Training Epoch: 122 [128/50000]	Loss: 1.5990	LR: 0.007854
Training Epoch: 122 [128/50000]	Loss: 1.2291	LR: 0.007854
Training Epoch: 122 [128/50000]	Loss: 1.2171	LR: 0.007854
Training Epoch: 122 [128/50000]	Loss: 1.1114	LR: 0.007854
Evaluating Network.....
Test set: Epoch: 122, Average loss: 0.0112, Top1Accuracy: 0.5927, Top3Accuracy: 0.8038, Top5Accuracy: 0.8735, Time consumed:1.78s

Training Epoch: 123 [128/50000]	Loss: 1.0387	LR: 0.007646
Training Epoch: 123 [128/50000]	Loss: 1.2731	LR: 0.007646
Training Epoch: 123 [128/50000]	Loss: 1.1640	LR: 0.007646
Training Epoch: 123 [128/50000]	Loss: 1.2136	LR: 0.007646
Training Epoch: 123 [128/50000]	Loss: 1.1910	LR: 0.007646
Training Epoch: 123 [128/50000]	Loss: 1.1677	LR: 0.007646
Training Epoch: 123 [128/50000]	Loss: 1.1470	LR: 0.007646
Training Epoch: 123 [128/50000]	Loss: 1.1967	LR: 0.007646
Training Epoch: 123 [128/50000]	Loss: 1.1959	LR: 0.007646
Training Epoch: 123 [128/50000]	Loss: 1.3361	LR: 0.007646
Evaluating Network.....
Test set: Epoch: 123, Average loss: 0.0112, Top1Accuracy: 0.5936, Top3Accuracy: 0.8061, Top5Accuracy: 0.8727, Time consumed:1.79s

Training Epoch: 124 [128/50000]	Loss: 1.0354	LR: 0.007445
Training Epoch: 124 [128/50000]	Loss: 1.1510	LR: 0.007445
Training Epoch: 124 [128/50000]	Loss: 1.0491	LR: 0.007445
Training Epoch: 124 [128/50000]	Loss: 1.0291	LR: 0.007445
Training Epoch: 124 [128/50000]	Loss: 1.0447	LR: 0.007445
Training Epoch: 124 [128/50000]	Loss: 1.1265	LR: 0.007445
Training Epoch: 124 [128/50000]	Loss: 1.0564	LR: 0.007445
Training Epoch: 124 [128/50000]	Loss: 1.1347	LR: 0.007445
Training Epoch: 124 [128/50000]	Loss: 1.0645	LR: 0.007445
Training Epoch: 124 [128/50000]	Loss: 1.2612	LR: 0.007445
Evaluating Network.....
Test set: Epoch: 124, Average loss: 0.0112, Top1Accuracy: 0.5979, Top3Accuracy: 0.8047, Top5Accuracy: 0.8732, Time consumed:1.78s

Training Epoch: 125 [128/50000]	Loss: 1.2231	LR: 0.007248
Training Epoch: 125 [128/50000]	Loss: 1.2534	LR: 0.007248
Training Epoch: 125 [128/50000]	Loss: 1.2833	LR: 0.007248
Training Epoch: 125 [128/50000]	Loss: 1.1314	LR: 0.007248
Training Epoch: 125 [128/50000]	Loss: 1.1670	LR: 0.007248
Training Epoch: 125 [128/50000]	Loss: 1.1292	LR: 0.007248
Training Epoch: 125 [128/50000]	Loss: 1.1310	LR: 0.007248
Training Epoch: 125 [128/50000]	Loss: 1.2684	LR: 0.007248
Training Epoch: 125 [128/50000]	Loss: 1.2527	LR: 0.007248
Training Epoch: 125 [128/50000]	Loss: 1.2602	LR: 0.007248
Evaluating Network.....
Test set: Epoch: 125, Average loss: 0.0112, Top1Accuracy: 0.5949, Top3Accuracy: 0.8053, Top5Accuracy: 0.8717, Time consumed:1.79s

Training Epoch: 126 [128/50000]	Loss: 1.2675	LR: 0.007057
Training Epoch: 126 [128/50000]	Loss: 1.0748	LR: 0.007057
Training Epoch: 126 [128/50000]	Loss: 1.1902	LR: 0.007057
Training Epoch: 126 [128/50000]	Loss: 1.1896	LR: 0.007057
Training Epoch: 126 [128/50000]	Loss: 1.2217	LR: 0.007057
Training Epoch: 126 [128/50000]	Loss: 1.1889	LR: 0.007057
Training Epoch: 126 [128/50000]	Loss: 1.1250	LR: 0.007057
Training Epoch: 126 [128/50000]	Loss: 1.1653	LR: 0.007057
Training Epoch: 126 [128/50000]	Loss: 1.0352	LR: 0.007057
Training Epoch: 126 [128/50000]	Loss: 1.1081	LR: 0.007057
Evaluating Network.....
Test set: Epoch: 126, Average loss: 0.0112, Top1Accuracy: 0.5942, Top3Accuracy: 0.8074, Top5Accuracy: 0.8723, Time consumed:1.83s

Training Epoch: 127 [128/50000]	Loss: 1.1069	LR: 0.006870
Training Epoch: 127 [128/50000]	Loss: 1.4064	LR: 0.006870
Training Epoch: 127 [128/50000]	Loss: 0.8532	LR: 0.006870
Training Epoch: 127 [128/50000]	Loss: 1.2191	LR: 0.006870
Training Epoch: 127 [128/50000]	Loss: 1.1272	LR: 0.006870
Training Epoch: 127 [128/50000]	Loss: 1.2689	LR: 0.006870
Training Epoch: 127 [128/50000]	Loss: 1.0536	LR: 0.006870
Training Epoch: 127 [128/50000]	Loss: 1.2230	LR: 0.006870
Training Epoch: 127 [128/50000]	Loss: 1.2207	LR: 0.006870
Training Epoch: 127 [128/50000]	Loss: 1.1592	LR: 0.006870
Evaluating Network.....
Test set: Epoch: 127, Average loss: 0.0111, Top1Accuracy: 0.6025, Top3Accuracy: 0.8084, Top5Accuracy: 0.8740, Time consumed:1.80s

Training Epoch: 128 [128/50000]	Loss: 1.0182	LR: 0.006689
Training Epoch: 128 [128/50000]	Loss: 1.0475	LR: 0.006689
Training Epoch: 128 [128/50000]	Loss: 1.4371	LR: 0.006689
Training Epoch: 128 [128/50000]	Loss: 1.1989	LR: 0.006689
Training Epoch: 128 [128/50000]	Loss: 0.9877	LR: 0.006689
Training Epoch: 128 [128/50000]	Loss: 1.2645	LR: 0.006689
Training Epoch: 128 [128/50000]	Loss: 1.1503	LR: 0.006689
Training Epoch: 128 [128/50000]	Loss: 1.1079	LR: 0.006689
Training Epoch: 128 [128/50000]	Loss: 0.9928	LR: 0.006689
Training Epoch: 128 [128/50000]	Loss: 0.9611	LR: 0.006689
Evaluating Network.....
Test set: Epoch: 128, Average loss: 0.0111, Top1Accuracy: 0.5951, Top3Accuracy: 0.8075, Top5Accuracy: 0.8731, Time consumed:1.80s

Training Epoch: 129 [128/50000]	Loss: 1.1127	LR: 0.006512
Training Epoch: 129 [128/50000]	Loss: 1.1042	LR: 0.006512
Training Epoch: 129 [128/50000]	Loss: 1.0362	LR: 0.006512
Training Epoch: 129 [128/50000]	Loss: 1.2854	LR: 0.006512
Training Epoch: 129 [128/50000]	Loss: 1.1920	LR: 0.006512
Training Epoch: 129 [128/50000]	Loss: 1.2398	LR: 0.006512
Training Epoch: 129 [128/50000]	Loss: 1.3576	LR: 0.006512
Training Epoch: 129 [128/50000]	Loss: 1.3623	LR: 0.006512
Training Epoch: 129 [128/50000]	Loss: 1.2787	LR: 0.006512
Training Epoch: 129 [128/50000]	Loss: 1.0467	LR: 0.006512
Evaluating Network.....
Test set: Epoch: 129, Average loss: 0.0111, Top1Accuracy: 0.5976, Top3Accuracy: 0.8068, Top5Accuracy: 0.8756, Time consumed:1.80s

Training Epoch: 130 [128/50000]	Loss: 1.0657	LR: 0.006340
Training Epoch: 130 [128/50000]	Loss: 1.1498	LR: 0.006340
Training Epoch: 130 [128/50000]	Loss: 1.0336	LR: 0.006340
Training Epoch: 130 [128/50000]	Loss: 1.2996	LR: 0.006340
Training Epoch: 130 [128/50000]	Loss: 1.2772	LR: 0.006340
Training Epoch: 130 [128/50000]	Loss: 1.4635	LR: 0.006340
Training Epoch: 130 [128/50000]	Loss: 1.0220	LR: 0.006340
Training Epoch: 130 [128/50000]	Loss: 1.2258	LR: 0.006340
Training Epoch: 130 [128/50000]	Loss: 1.1980	LR: 0.006340
Training Epoch: 130 [128/50000]	Loss: 1.0538	LR: 0.006340
Evaluating Network.....
Test set: Epoch: 130, Average loss: 0.0111, Top1Accuracy: 0.6007, Top3Accuracy: 0.8065, Top5Accuracy: 0.8754, Time consumed:1.78s

Training Epoch: 131 [128/50000]	Loss: 1.0558	LR: 0.006173
Training Epoch: 131 [128/50000]	Loss: 1.0564	LR: 0.006173
Training Epoch: 131 [128/50000]	Loss: 1.1851	LR: 0.006173
Training Epoch: 131 [128/50000]	Loss: 1.0248	LR: 0.006173
Training Epoch: 131 [128/50000]	Loss: 1.0905	LR: 0.006173
Training Epoch: 131 [128/50000]	Loss: 0.9935	LR: 0.006173
Training Epoch: 131 [128/50000]	Loss: 1.2883	LR: 0.006173
Training Epoch: 131 [128/50000]	Loss: 1.1149	LR: 0.006173
Training Epoch: 131 [128/50000]	Loss: 1.1259	LR: 0.006173
Training Epoch: 131 [128/50000]	Loss: 1.0593	LR: 0.006173
Evaluating Network.....
Test set: Epoch: 131, Average loss: 0.0110, Top1Accuracy: 0.6050, Top3Accuracy: 0.8074, Top5Accuracy: 0.8760, Time consumed:1.78s

Training Epoch: 132 [128/50000]	Loss: 0.9104	LR: 0.006010
Training Epoch: 132 [128/50000]	Loss: 1.0338	LR: 0.006010
Training Epoch: 132 [128/50000]	Loss: 1.3817	LR: 0.006010
Training Epoch: 132 [128/50000]	Loss: 1.4122	LR: 0.006010
Training Epoch: 132 [128/50000]	Loss: 1.2172	LR: 0.006010
Training Epoch: 132 [128/50000]	Loss: 1.3049	LR: 0.006010
Training Epoch: 132 [128/50000]	Loss: 0.9161	LR: 0.006010
Training Epoch: 132 [128/50000]	Loss: 0.9475	LR: 0.006010
Training Epoch: 132 [128/50000]	Loss: 1.3569	LR: 0.006010
Training Epoch: 132 [128/50000]	Loss: 1.4676	LR: 0.006010
Evaluating Network.....
Test set: Epoch: 132, Average loss: 0.0111, Top1Accuracy: 0.6007, Top3Accuracy: 0.8094, Top5Accuracy: 0.8755, Time consumed:1.80s

Training Epoch: 133 [128/50000]	Loss: 1.0201	LR: 0.005851
Training Epoch: 133 [128/50000]	Loss: 1.3472	LR: 0.005851
Training Epoch: 133 [128/50000]	Loss: 0.9709	LR: 0.005851
Training Epoch: 133 [128/50000]	Loss: 1.2044	LR: 0.005851
Training Epoch: 133 [128/50000]	Loss: 1.1116	LR: 0.005851
Training Epoch: 133 [128/50000]	Loss: 1.2766	LR: 0.005851
Training Epoch: 133 [128/50000]	Loss: 1.1338	LR: 0.005851
Training Epoch: 133 [128/50000]	Loss: 1.0906	LR: 0.005851
Training Epoch: 133 [128/50000]	Loss: 1.1467	LR: 0.005851
Training Epoch: 133 [128/50000]	Loss: 1.0836	LR: 0.005851
Evaluating Network.....
Test set: Epoch: 133, Average loss: 0.0110, Top1Accuracy: 0.6011, Top3Accuracy: 0.8094, Top5Accuracy: 0.8757, Time consumed:1.79s

Training Epoch: 134 [128/50000]	Loss: 1.1957	LR: 0.005697
Training Epoch: 134 [128/50000]	Loss: 1.1790	LR: 0.005697
Training Epoch: 134 [128/50000]	Loss: 1.3545	LR: 0.005697
Training Epoch: 134 [128/50000]	Loss: 1.2820	LR: 0.005697
Training Epoch: 134 [128/50000]	Loss: 1.3720	LR: 0.005697
Training Epoch: 134 [128/50000]	Loss: 0.9694	LR: 0.005697
Training Epoch: 134 [128/50000]	Loss: 0.9771	LR: 0.005697
Training Epoch: 134 [128/50000]	Loss: 1.1267	LR: 0.005697
Training Epoch: 134 [128/50000]	Loss: 1.1452	LR: 0.005697
Training Epoch: 134 [128/50000]	Loss: 1.1271	LR: 0.005697
Evaluating Network.....
Test set: Epoch: 134, Average loss: 0.0110, Top1Accuracy: 0.6046, Top3Accuracy: 0.8081, Top5Accuracy: 0.8754, Time consumed:1.80s

Training Epoch: 135 [128/50000]	Loss: 1.2610	LR: 0.005547
Training Epoch: 135 [128/50000]	Loss: 1.0645	LR: 0.005547
Training Epoch: 135 [128/50000]	Loss: 1.1942	LR: 0.005547
Training Epoch: 135 [128/50000]	Loss: 1.1212	LR: 0.005547
Training Epoch: 135 [128/50000]	Loss: 1.2667	LR: 0.005547
Training Epoch: 135 [128/50000]	Loss: 1.2287	LR: 0.005547
Training Epoch: 135 [128/50000]	Loss: 1.3388	LR: 0.005547
Training Epoch: 135 [128/50000]	Loss: 1.0698	LR: 0.005547
Training Epoch: 135 [128/50000]	Loss: 1.1240	LR: 0.005547
Training Epoch: 135 [128/50000]	Loss: 0.8943	LR: 0.005547
Evaluating Network.....
Test set: Epoch: 135, Average loss: 0.0110, Top1Accuracy: 0.6026, Top3Accuracy: 0.8100, Top5Accuracy: 0.8774, Time consumed:1.79s

Training Epoch: 136 [128/50000]	Loss: 1.1473	LR: 0.005400
Training Epoch: 136 [128/50000]	Loss: 1.0528	LR: 0.005400
Training Epoch: 136 [128/50000]	Loss: 1.0620	LR: 0.005400
Training Epoch: 136 [128/50000]	Loss: 0.9012	LR: 0.005400
Training Epoch: 136 [128/50000]	Loss: 0.8763	LR: 0.005400
Training Epoch: 136 [128/50000]	Loss: 1.2204	LR: 0.005400
Training Epoch: 136 [128/50000]	Loss: 1.1018	LR: 0.005400
Training Epoch: 136 [128/50000]	Loss: 1.2175	LR: 0.005400
Training Epoch: 136 [128/50000]	Loss: 1.1403	LR: 0.005400
Training Epoch: 136 [128/50000]	Loss: 1.0733	LR: 0.005400
Evaluating Network.....
Test set: Epoch: 136, Average loss: 0.0110, Top1Accuracy: 0.6051, Top3Accuracy: 0.8104, Top5Accuracy: 0.8756, Time consumed:1.79s

Training Epoch: 137 [128/50000]	Loss: 1.0529	LR: 0.005258
Training Epoch: 137 [128/50000]	Loss: 1.1213	LR: 0.005258
Training Epoch: 137 [128/50000]	Loss: 1.0456	LR: 0.005258
Training Epoch: 137 [128/50000]	Loss: 1.1272	LR: 0.005258
Training Epoch: 137 [128/50000]	Loss: 1.2321	LR: 0.005258
Training Epoch: 137 [128/50000]	Loss: 1.0553	LR: 0.005258
Training Epoch: 137 [128/50000]	Loss: 1.4764	LR: 0.005258
Training Epoch: 137 [128/50000]	Loss: 1.1302	LR: 0.005258
Training Epoch: 137 [128/50000]	Loss: 1.1418	LR: 0.005258
Training Epoch: 137 [128/50000]	Loss: 1.1462	LR: 0.005258
Evaluating Network.....
Test set: Epoch: 137, Average loss: 0.0110, Top1Accuracy: 0.6047, Top3Accuracy: 0.8095, Top5Accuracy: 0.8754, Time consumed:1.80s

Training Epoch: 138 [128/50000]	Loss: 1.1245	LR: 0.005119
Training Epoch: 138 [128/50000]	Loss: 0.9110	LR: 0.005119
Training Epoch: 138 [128/50000]	Loss: 1.1084	LR: 0.005119
Training Epoch: 138 [128/50000]	Loss: 1.0267	LR: 0.005119
Training Epoch: 138 [128/50000]	Loss: 1.0991	LR: 0.005119
Training Epoch: 138 [128/50000]	Loss: 1.1079	LR: 0.005119
Training Epoch: 138 [128/50000]	Loss: 1.0206	LR: 0.005119
Training Epoch: 138 [128/50000]	Loss: 1.1401	LR: 0.005119
Training Epoch: 138 [128/50000]	Loss: 1.0841	LR: 0.005119
Training Epoch: 138 [128/50000]	Loss: 1.0130	LR: 0.005119
Evaluating Network.....
Test set: Epoch: 138, Average loss: 0.0109, Top1Accuracy: 0.6063, Top3Accuracy: 0.8117, Top5Accuracy: 0.8791, Time consumed:1.79s

Training Epoch: 139 [128/50000]	Loss: 1.1259	LR: 0.004984
Training Epoch: 139 [128/50000]	Loss: 1.1513	LR: 0.004984
Training Epoch: 139 [128/50000]	Loss: 0.9318	LR: 0.004984
Training Epoch: 139 [128/50000]	Loss: 1.2481	LR: 0.004984
Training Epoch: 139 [128/50000]	Loss: 1.3386	LR: 0.004984
Training Epoch: 139 [128/50000]	Loss: 1.0928	LR: 0.004984
Training Epoch: 139 [128/50000]	Loss: 1.1052	LR: 0.004984
Training Epoch: 139 [128/50000]	Loss: 1.1797	LR: 0.004984
Training Epoch: 139 [128/50000]	Loss: 1.0787	LR: 0.004984
Training Epoch: 139 [128/50000]	Loss: 1.0749	LR: 0.004984
Evaluating Network.....
Test set: Epoch: 139, Average loss: 0.0109, Top1Accuracy: 0.6036, Top3Accuracy: 0.8095, Top5Accuracy: 0.8746, Time consumed:1.77s

Training Epoch: 140 [128/50000]	Loss: 1.1058	LR: 0.004852
Training Epoch: 140 [128/50000]	Loss: 1.2089	LR: 0.004852
Training Epoch: 140 [128/50000]	Loss: 1.1025	LR: 0.004852
Training Epoch: 140 [128/50000]	Loss: 1.3466	LR: 0.004852
Training Epoch: 140 [128/50000]	Loss: 1.0168	LR: 0.004852
Training Epoch: 140 [128/50000]	Loss: 0.9609	LR: 0.004852
Training Epoch: 140 [128/50000]	Loss: 1.1008	LR: 0.004852
Training Epoch: 140 [128/50000]	Loss: 1.0910	LR: 0.004852
Training Epoch: 140 [128/50000]	Loss: 1.0435	LR: 0.004852
Training Epoch: 140 [128/50000]	Loss: 1.1322	LR: 0.004852
Evaluating Network.....
Test set: Epoch: 140, Average loss: 0.0110, Top1Accuracy: 0.6079, Top3Accuracy: 0.8104, Top5Accuracy: 0.8766, Time consumed:1.78s

Training Epoch: 141 [128/50000]	Loss: 1.2527	LR: 0.004724
Training Epoch: 141 [128/50000]	Loss: 0.9209	LR: 0.004724
Training Epoch: 141 [128/50000]	Loss: 0.8892	LR: 0.004724
Training Epoch: 141 [128/50000]	Loss: 0.9317	LR: 0.004724
Training Epoch: 141 [128/50000]	Loss: 1.0883	LR: 0.004724
Training Epoch: 141 [128/50000]	Loss: 0.8928	LR: 0.004724
Training Epoch: 141 [128/50000]	Loss: 1.1339	LR: 0.004724
Training Epoch: 141 [128/50000]	Loss: 1.0571	LR: 0.004724
Training Epoch: 141 [128/50000]	Loss: 0.8927	LR: 0.004724
Training Epoch: 141 [128/50000]	Loss: 1.1370	LR: 0.004724
Evaluating Network.....
Test set: Epoch: 141, Average loss: 0.0110, Top1Accuracy: 0.6088, Top3Accuracy: 0.8120, Top5Accuracy: 0.8758, Time consumed:1.78s

Training Epoch: 142 [128/50000]	Loss: 1.0411	LR: 0.004599
Training Epoch: 142 [128/50000]	Loss: 1.2324	LR: 0.004599
Training Epoch: 142 [128/50000]	Loss: 0.9338	LR: 0.004599
Training Epoch: 142 [128/50000]	Loss: 1.1482	LR: 0.004599
Training Epoch: 142 [128/50000]	Loss: 0.9726	LR: 0.004599
Training Epoch: 142 [128/50000]	Loss: 1.0958	LR: 0.004599
Training Epoch: 142 [128/50000]	Loss: 1.1905	LR: 0.004599
Training Epoch: 142 [128/50000]	Loss: 1.0102	LR: 0.004599
Training Epoch: 142 [128/50000]	Loss: 1.0817	LR: 0.004599
Training Epoch: 142 [128/50000]	Loss: 1.3641	LR: 0.004599
Evaluating Network.....
Test set: Epoch: 142, Average loss: 0.0110, Top1Accuracy: 0.6060, Top3Accuracy: 0.8097, Top5Accuracy: 0.8753, Time consumed:1.78s

Training Epoch: 143 [128/50000]	Loss: 1.1808	LR: 0.004478
Training Epoch: 143 [128/50000]	Loss: 1.0356	LR: 0.004478
Training Epoch: 143 [128/50000]	Loss: 1.0554	LR: 0.004478
Training Epoch: 143 [128/50000]	Loss: 1.0049	LR: 0.004478
Training Epoch: 143 [128/50000]	Loss: 0.8508	LR: 0.004478
Training Epoch: 143 [128/50000]	Loss: 1.0869	LR: 0.004478
Training Epoch: 143 [128/50000]	Loss: 1.0448	LR: 0.004478
Training Epoch: 143 [128/50000]	Loss: 1.1366	LR: 0.004478
Training Epoch: 143 [128/50000]	Loss: 1.2753	LR: 0.004478
Training Epoch: 143 [128/50000]	Loss: 1.2040	LR: 0.004478
Evaluating Network.....
Test set: Epoch: 143, Average loss: 0.0109, Top1Accuracy: 0.6106, Top3Accuracy: 0.8124, Top5Accuracy: 0.8762, Time consumed:1.78s

Training Epoch: 144 [128/50000]	Loss: 1.0539	LR: 0.004360
Training Epoch: 144 [128/50000]	Loss: 0.9978	LR: 0.004360
Training Epoch: 144 [128/50000]	Loss: 1.0181	LR: 0.004360
Training Epoch: 144 [128/50000]	Loss: 1.0622	LR: 0.004360
Training Epoch: 144 [128/50000]	Loss: 1.3082	LR: 0.004360
Training Epoch: 144 [128/50000]	Loss: 0.9376	LR: 0.004360
Training Epoch: 144 [128/50000]	Loss: 1.0835	LR: 0.004360
Training Epoch: 144 [128/50000]	Loss: 1.3127	LR: 0.004360
Training Epoch: 144 [128/50000]	Loss: 1.2159	LR: 0.004360
Training Epoch: 144 [128/50000]	Loss: 0.9847	LR: 0.004360
Evaluating Network.....
Test set: Epoch: 144, Average loss: 0.0109, Top1Accuracy: 0.6117, Top3Accuracy: 0.8091, Top5Accuracy: 0.8774, Time consumed:1.79s

Training Epoch: 145 [128/50000]	Loss: 1.2280	LR: 0.004245
Training Epoch: 145 [128/50000]	Loss: 1.0937	LR: 0.004245
Training Epoch: 145 [128/50000]	Loss: 1.0490	LR: 0.004245
Training Epoch: 145 [128/50000]	Loss: 1.0216	LR: 0.004245
Training Epoch: 145 [128/50000]	Loss: 0.8964	LR: 0.004245
Training Epoch: 145 [128/50000]	Loss: 0.9705	LR: 0.004245
Training Epoch: 145 [128/50000]	Loss: 1.1646	LR: 0.004245
Training Epoch: 145 [128/50000]	Loss: 1.2408	LR: 0.004245
Training Epoch: 145 [128/50000]	Loss: 0.8336	LR: 0.004245
Training Epoch: 145 [128/50000]	Loss: 1.0054	LR: 0.004245
Evaluating Network.....
Test set: Epoch: 145, Average loss: 0.0109, Top1Accuracy: 0.6090, Top3Accuracy: 0.8134, Top5Accuracy: 0.8787, Time consumed:1.81s

Training Epoch: 146 [128/50000]	Loss: 1.0616	LR: 0.004132
Training Epoch: 146 [128/50000]	Loss: 0.9170	LR: 0.004132
Training Epoch: 146 [128/50000]	Loss: 1.0264	LR: 0.004132
Training Epoch: 146 [128/50000]	Loss: 1.2458	LR: 0.004132
Training Epoch: 146 [128/50000]	Loss: 1.0213	LR: 0.004132
Training Epoch: 146 [128/50000]	Loss: 0.9882	LR: 0.004132
Training Epoch: 146 [128/50000]	Loss: 1.1249	LR: 0.004132
Training Epoch: 146 [128/50000]	Loss: 1.0428	LR: 0.004132
Training Epoch: 146 [128/50000]	Loss: 1.0829	LR: 0.004132
Training Epoch: 146 [128/50000]	Loss: 1.0742	LR: 0.004132
Evaluating Network.....
Test set: Epoch: 146, Average loss: 0.0109, Top1Accuracy: 0.6073, Top3Accuracy: 0.8123, Top5Accuracy: 0.8787, Time consumed:1.78s

Training Epoch: 147 [128/50000]	Loss: 0.9279	LR: 0.004023
Training Epoch: 147 [128/50000]	Loss: 1.2911	LR: 0.004023
Training Epoch: 147 [128/50000]	Loss: 1.0523	LR: 0.004023
Training Epoch: 147 [128/50000]	Loss: 1.0357	LR: 0.004023
Training Epoch: 147 [128/50000]	Loss: 1.0712	LR: 0.004023
Training Epoch: 147 [128/50000]	Loss: 1.0411	LR: 0.004023
Training Epoch: 147 [128/50000]	Loss: 1.1879	LR: 0.004023
Training Epoch: 147 [128/50000]	Loss: 1.0847	LR: 0.004023
Training Epoch: 147 [128/50000]	Loss: 1.0750	LR: 0.004023
Training Epoch: 147 [128/50000]	Loss: 1.0465	LR: 0.004023
Evaluating Network.....
Test set: Epoch: 147, Average loss: 0.0110, Top1Accuracy: 0.6100, Top3Accuracy: 0.8104, Top5Accuracy: 0.8771, Time consumed:1.79s

Training Epoch: 148 [128/50000]	Loss: 1.1577	LR: 0.003917
Training Epoch: 148 [128/50000]	Loss: 0.9885	LR: 0.003917
Training Epoch: 148 [128/50000]	Loss: 0.8089	LR: 0.003917
Training Epoch: 148 [128/50000]	Loss: 1.0201	LR: 0.003917
Training Epoch: 148 [128/50000]	Loss: 1.0406	LR: 0.003917
Training Epoch: 148 [128/50000]	Loss: 1.4529	LR: 0.003917
Training Epoch: 148 [128/50000]	Loss: 1.2292	LR: 0.003917
Training Epoch: 148 [128/50000]	Loss: 1.0897	LR: 0.003917
Training Epoch: 148 [128/50000]	Loss: 1.0096	LR: 0.003917
Training Epoch: 148 [128/50000]	Loss: 1.1679	LR: 0.003917
Evaluating Network.....
Test set: Epoch: 148, Average loss: 0.0109, Top1Accuracy: 0.6098, Top3Accuracy: 0.8120, Top5Accuracy: 0.8789, Time consumed:1.80s

Training Epoch: 149 [128/50000]	Loss: 1.0309	LR: 0.003814
Training Epoch: 149 [128/50000]	Loss: 0.7392	LR: 0.003814
Training Epoch: 149 [128/50000]	Loss: 1.0411	LR: 0.003814
Training Epoch: 149 [128/50000]	Loss: 1.0104	LR: 0.003814
Training Epoch: 149 [128/50000]	Loss: 1.1098	LR: 0.003814
Training Epoch: 149 [128/50000]	Loss: 1.0931	LR: 0.003814
Training Epoch: 149 [128/50000]	Loss: 1.2901	LR: 0.003814
Training Epoch: 149 [128/50000]	Loss: 1.0712	LR: 0.003814
Training Epoch: 149 [128/50000]	Loss: 1.1216	LR: 0.003814
Training Epoch: 149 [128/50000]	Loss: 1.0935	LR: 0.003814
Evaluating Network.....
Test set: Epoch: 149, Average loss: 0.0109, Top1Accuracy: 0.6114, Top3Accuracy: 0.8109, Top5Accuracy: 0.8798, Time consumed:1.78s

Training Epoch: 150 [128/50000]	Loss: 1.0423	LR: 0.003713
Training Epoch: 150 [128/50000]	Loss: 1.0553	LR: 0.003713
Training Epoch: 150 [128/50000]	Loss: 1.2124	LR: 0.003713
Training Epoch: 150 [128/50000]	Loss: 1.0845	LR: 0.003713
Training Epoch: 150 [128/50000]	Loss: 1.0344	LR: 0.003713
Training Epoch: 150 [128/50000]	Loss: 0.9395	LR: 0.003713
Training Epoch: 150 [128/50000]	Loss: 0.9496	LR: 0.003713
Training Epoch: 150 [128/50000]	Loss: 1.0898	LR: 0.003713
Training Epoch: 150 [128/50000]	Loss: 1.2067	LR: 0.003713
Training Epoch: 150 [128/50000]	Loss: 1.1318	LR: 0.003713
Evaluating Network.....
Test set: Epoch: 150, Average loss: 0.0110, Top1Accuracy: 0.6105, Top3Accuracy: 0.8125, Top5Accuracy: 0.8780, Time consumed:1.78s

Training Epoch: 151 [128/50000]	Loss: 0.9466	LR: 0.003615
Training Epoch: 151 [128/50000]	Loss: 1.0888	LR: 0.003615
Training Epoch: 151 [128/50000]	Loss: 0.9220	LR: 0.003615
Training Epoch: 151 [128/50000]	Loss: 1.1146	LR: 0.003615
Training Epoch: 151 [128/50000]	Loss: 1.0310	LR: 0.003615
Training Epoch: 151 [128/50000]	Loss: 1.2139	LR: 0.003615
Training Epoch: 151 [128/50000]	Loss: 1.0867	LR: 0.003615
Training Epoch: 151 [128/50000]	Loss: 1.0133	LR: 0.003615
Training Epoch: 151 [128/50000]	Loss: 1.0738	LR: 0.003615
Training Epoch: 151 [128/50000]	Loss: 0.9799	LR: 0.003615
Evaluating Network.....
Test set: Epoch: 151, Average loss: 0.0109, Top1Accuracy: 0.6100, Top3Accuracy: 0.8133, Top5Accuracy: 0.8772, Time consumed:1.80s

Training Epoch: 152 [128/50000]	Loss: 1.0288	LR: 0.003520
Training Epoch: 152 [128/50000]	Loss: 1.1357	LR: 0.003520
Training Epoch: 152 [128/50000]	Loss: 1.0527	LR: 0.003520
Training Epoch: 152 [128/50000]	Loss: 1.1411	LR: 0.003520
Training Epoch: 152 [128/50000]	Loss: 1.0937	LR: 0.003520
Training Epoch: 152 [128/50000]	Loss: 1.0224	LR: 0.003520
Training Epoch: 152 [128/50000]	Loss: 1.1144	LR: 0.003520
Training Epoch: 152 [128/50000]	Loss: 1.0888	LR: 0.003520
Training Epoch: 152 [128/50000]	Loss: 1.2002	LR: 0.003520
Training Epoch: 152 [128/50000]	Loss: 0.8217	LR: 0.003520
Evaluating Network.....
Test set: Epoch: 152, Average loss: 0.0109, Top1Accuracy: 0.6107, Top3Accuracy: 0.8124, Top5Accuracy: 0.8769, Time consumed:1.79s

Training Epoch: 153 [128/50000]	Loss: 0.9097	LR: 0.003427
Training Epoch: 153 [128/50000]	Loss: 0.9418	LR: 0.003427
Training Epoch: 153 [128/50000]	Loss: 1.1233	LR: 0.003427
Training Epoch: 153 [128/50000]	Loss: 1.2894	LR: 0.003427
Training Epoch: 153 [128/50000]	Loss: 1.0183	LR: 0.003427
Training Epoch: 153 [128/50000]	Loss: 1.0601	LR: 0.003427
Training Epoch: 153 [128/50000]	Loss: 1.1253	LR: 0.003427
Training Epoch: 153 [128/50000]	Loss: 0.9625	LR: 0.003427
Training Epoch: 153 [128/50000]	Loss: 1.2048	LR: 0.003427
Training Epoch: 153 [128/50000]	Loss: 1.0794	LR: 0.003427
Evaluating Network.....
Test set: Epoch: 153, Average loss: 0.0109, Top1Accuracy: 0.6124, Top3Accuracy: 0.8135, Top5Accuracy: 0.8798, Time consumed:1.79s

Training Epoch: 154 [128/50000]	Loss: 1.0192	LR: 0.003336
Training Epoch: 154 [128/50000]	Loss: 1.0512	LR: 0.003336
Training Epoch: 154 [128/50000]	Loss: 0.9880	LR: 0.003336
Training Epoch: 154 [128/50000]	Loss: 1.0029	LR: 0.003336
Training Epoch: 154 [128/50000]	Loss: 1.1092	LR: 0.003336
Training Epoch: 154 [128/50000]	Loss: 1.1600	LR: 0.003336
Training Epoch: 154 [128/50000]	Loss: 1.0647	LR: 0.003336
Training Epoch: 154 [128/50000]	Loss: 0.9803	LR: 0.003336
Training Epoch: 154 [128/50000]	Loss: 1.0126	LR: 0.003336
Training Epoch: 154 [128/50000]	Loss: 0.9755	LR: 0.003336
Evaluating Network.....
Test set: Epoch: 154, Average loss: 0.0108, Top1Accuracy: 0.6130, Top3Accuracy: 0.8104, Top5Accuracy: 0.8778, Time consumed:1.79s

Training Epoch: 155 [128/50000]	Loss: 0.9339	LR: 0.003248
Training Epoch: 155 [128/50000]	Loss: 1.0586	LR: 0.003248
Training Epoch: 155 [128/50000]	Loss: 1.1365	LR: 0.003248
Training Epoch: 155 [128/50000]	Loss: 1.0847	LR: 0.003248
Training Epoch: 155 [128/50000]	Loss: 1.1125	LR: 0.003248
Training Epoch: 155 [128/50000]	Loss: 1.0223	LR: 0.003248
Training Epoch: 155 [128/50000]	Loss: 1.0974	LR: 0.003248
Training Epoch: 155 [128/50000]	Loss: 1.0752	LR: 0.003248
Training Epoch: 155 [128/50000]	Loss: 0.8899	LR: 0.003248
Training Epoch: 155 [128/50000]	Loss: 1.2222	LR: 0.003248
Evaluating Network.....
Test set: Epoch: 155, Average loss: 0.0108, Top1Accuracy: 0.6129, Top3Accuracy: 0.8140, Top5Accuracy: 0.8778, Time consumed:2.11s

Training Epoch: 156 [128/50000]	Loss: 0.9100	LR: 0.003162
Training Epoch: 156 [128/50000]	Loss: 1.0694	LR: 0.003162
Training Epoch: 156 [128/50000]	Loss: 0.9672	LR: 0.003162
Training Epoch: 156 [128/50000]	Loss: 1.0211	LR: 0.003162
Training Epoch: 156 [128/50000]	Loss: 1.0501	LR: 0.003162
Training Epoch: 156 [128/50000]	Loss: 1.1873	LR: 0.003162
Training Epoch: 156 [128/50000]	Loss: 1.0260	LR: 0.003162
Training Epoch: 156 [128/50000]	Loss: 1.1207	LR: 0.003162
Training Epoch: 156 [128/50000]	Loss: 1.0848	LR: 0.003162
Training Epoch: 156 [128/50000]	Loss: 1.0577	LR: 0.003162
Evaluating Network.....
Test set: Epoch: 156, Average loss: 0.0109, Top1Accuracy: 0.6118, Top3Accuracy: 0.8120, Top5Accuracy: 0.8793, Time consumed:1.79s

Training Epoch: 157 [128/50000]	Loss: 1.0619	LR: 0.003079
Training Epoch: 157 [128/50000]	Loss: 1.0694	LR: 0.003079
Training Epoch: 157 [128/50000]	Loss: 1.1818	LR: 0.003079
Training Epoch: 157 [128/50000]	Loss: 1.0540	LR: 0.003079
Training Epoch: 157 [128/50000]	Loss: 0.8667	LR: 0.003079
Training Epoch: 157 [128/50000]	Loss: 0.9555	LR: 0.003079
Training Epoch: 157 [128/50000]	Loss: 0.9957	LR: 0.003079
Training Epoch: 157 [128/50000]	Loss: 0.9607	LR: 0.003079
Training Epoch: 157 [128/50000]	Loss: 1.0647	LR: 0.003079
Training Epoch: 157 [128/50000]	Loss: 1.0132	LR: 0.003079
Evaluating Network.....
Test set: Epoch: 157, Average loss: 0.0109, Top1Accuracy: 0.6146, Top3Accuracy: 0.8156, Top5Accuracy: 0.8786, Time consumed:1.79s

Training Epoch: 158 [128/50000]	Loss: 1.0242	LR: 0.002998
Training Epoch: 158 [128/50000]	Loss: 1.0688	LR: 0.002998
Training Epoch: 158 [128/50000]	Loss: 0.8743	LR: 0.002998
Training Epoch: 158 [128/50000]	Loss: 1.1167	LR: 0.002998
Training Epoch: 158 [128/50000]	Loss: 0.8373	LR: 0.002998
Training Epoch: 158 [128/50000]	Loss: 0.9878	LR: 0.002998
Training Epoch: 158 [128/50000]	Loss: 0.9729	LR: 0.002998
Training Epoch: 158 [128/50000]	Loss: 0.9446	LR: 0.002998
Training Epoch: 158 [128/50000]	Loss: 1.0389	LR: 0.002998
Training Epoch: 158 [128/50000]	Loss: 1.0490	LR: 0.002998
Evaluating Network.....
Test set: Epoch: 158, Average loss: 0.0108, Top1Accuracy: 0.6137, Top3Accuracy: 0.8144, Top5Accuracy: 0.8802, Time consumed:1.80s

Training Epoch: 159 [128/50000]	Loss: 1.1381	LR: 0.002918
Training Epoch: 159 [128/50000]	Loss: 1.1335	LR: 0.002918
Training Epoch: 159 [128/50000]	Loss: 0.8165	LR: 0.002918
Training Epoch: 159 [128/50000]	Loss: 1.1776	LR: 0.002918
Training Epoch: 159 [128/50000]	Loss: 0.9051	LR: 0.002918
Training Epoch: 159 [128/50000]	Loss: 1.2504	LR: 0.002918
Training Epoch: 159 [128/50000]	Loss: 1.0113	LR: 0.002918
Training Epoch: 159 [128/50000]	Loss: 0.9303	LR: 0.002918
Training Epoch: 159 [128/50000]	Loss: 0.9814	LR: 0.002918
Training Epoch: 159 [128/50000]	Loss: 0.8872	LR: 0.002918
Evaluating Network.....
Test set: Epoch: 159, Average loss: 0.0108, Top1Accuracy: 0.6137, Top3Accuracy: 0.8118, Top5Accuracy: 0.8799, Time consumed:1.79s

Training Epoch: 160 [128/50000]	Loss: 1.1397	LR: 0.002841
Training Epoch: 160 [128/50000]	Loss: 1.0864	LR: 0.002841
Training Epoch: 160 [128/50000]	Loss: 0.8888	LR: 0.002841
Training Epoch: 160 [128/50000]	Loss: 1.0203	LR: 0.002841
Training Epoch: 160 [128/50000]	Loss: 1.1326	LR: 0.002841
Training Epoch: 160 [128/50000]	Loss: 1.0145	LR: 0.002841
Training Epoch: 160 [128/50000]	Loss: 1.2026	LR: 0.002841
Training Epoch: 160 [128/50000]	Loss: 1.1447	LR: 0.002841
Training Epoch: 160 [128/50000]	Loss: 1.1651	LR: 0.002841
Training Epoch: 160 [128/50000]	Loss: 1.0075	LR: 0.002841
Evaluating Network.....
Test set: Epoch: 160, Average loss: 0.0108, Top1Accuracy: 0.6150, Top3Accuracy: 0.8137, Top5Accuracy: 0.8774, Time consumed:1.78s

Training Epoch: 161 [128/50000]	Loss: 1.2103	LR: 0.002766
Training Epoch: 161 [128/50000]	Loss: 0.9901	LR: 0.002766
Training Epoch: 161 [128/50000]	Loss: 1.2016	LR: 0.002766
Training Epoch: 161 [128/50000]	Loss: 0.9599	LR: 0.002766
Training Epoch: 161 [128/50000]	Loss: 1.0829	LR: 0.002766
Training Epoch: 161 [128/50000]	Loss: 1.1880	LR: 0.002766
Training Epoch: 161 [128/50000]	Loss: 0.8737	LR: 0.002766
Training Epoch: 161 [128/50000]	Loss: 1.0065	LR: 0.002766
Training Epoch: 161 [128/50000]	Loss: 1.2159	LR: 0.002766
Training Epoch: 161 [128/50000]	Loss: 0.9793	LR: 0.002766
Evaluating Network.....
Test set: Epoch: 161, Average loss: 0.0109, Top1Accuracy: 0.6127, Top3Accuracy: 0.8146, Top5Accuracy: 0.8801, Time consumed:1.80s

Training Epoch: 162 [128/50000]	Loss: 1.1498	LR: 0.002693
Training Epoch: 162 [128/50000]	Loss: 1.0809	LR: 0.002693
Training Epoch: 162 [128/50000]	Loss: 1.1145	LR: 0.002693
Training Epoch: 162 [128/50000]	Loss: 0.8721	LR: 0.002693
Training Epoch: 162 [128/50000]	Loss: 0.9669	LR: 0.002693
Training Epoch: 162 [128/50000]	Loss: 0.9320	LR: 0.002693
Training Epoch: 162 [128/50000]	Loss: 1.1460	LR: 0.002693
Training Epoch: 162 [128/50000]	Loss: 0.9075	LR: 0.002693
Training Epoch: 162 [128/50000]	Loss: 0.9677	LR: 0.002693
Training Epoch: 162 [128/50000]	Loss: 1.1485	LR: 0.002693
Evaluating Network.....
Test set: Epoch: 162, Average loss: 0.0108, Top1Accuracy: 0.6141, Top3Accuracy: 0.8135, Top5Accuracy: 0.8777, Time consumed:1.78s

Training Epoch: 163 [128/50000]	Loss: 1.0976	LR: 0.002622
Training Epoch: 163 [128/50000]	Loss: 0.8942	LR: 0.002622
Training Epoch: 163 [128/50000]	Loss: 1.1317	LR: 0.002622
Training Epoch: 163 [128/50000]	Loss: 1.0555	LR: 0.002622
Training Epoch: 163 [128/50000]	Loss: 1.1526	LR: 0.002622
Training Epoch: 163 [128/50000]	Loss: 1.0127	LR: 0.002622
Training Epoch: 163 [128/50000]	Loss: 1.2460	LR: 0.002622
Training Epoch: 163 [128/50000]	Loss: 0.9499	LR: 0.002622
Training Epoch: 163 [128/50000]	Loss: 1.0161	LR: 0.002622
Training Epoch: 163 [128/50000]	Loss: 1.0672	LR: 0.002622
Evaluating Network.....
Test set: Epoch: 163, Average loss: 0.0108, Top1Accuracy: 0.6162, Top3Accuracy: 0.8126, Top5Accuracy: 0.8792, Time consumed:1.79s

Training Epoch: 164 [128/50000]	Loss: 0.9169	LR: 0.002553
Training Epoch: 164 [128/50000]	Loss: 0.9830	LR: 0.002553
Training Epoch: 164 [128/50000]	Loss: 1.0086	LR: 0.002553
Training Epoch: 164 [128/50000]	Loss: 0.9069	LR: 0.002553
Training Epoch: 164 [128/50000]	Loss: 0.9300	LR: 0.002553
Training Epoch: 164 [128/50000]	Loss: 1.0031	LR: 0.002553
Training Epoch: 164 [128/50000]	Loss: 0.9786	LR: 0.002553
Training Epoch: 164 [128/50000]	Loss: 1.0041	LR: 0.002553
Training Epoch: 164 [128/50000]	Loss: 0.9922	LR: 0.002553
Training Epoch: 164 [128/50000]	Loss: 1.0554	LR: 0.002553
Evaluating Network.....
Test set: Epoch: 164, Average loss: 0.0108, Top1Accuracy: 0.6143, Top3Accuracy: 0.8142, Top5Accuracy: 0.8798, Time consumed:1.79s

Training Epoch: 165 [128/50000]	Loss: 0.8638	LR: 0.002486
Training Epoch: 165 [128/50000]	Loss: 1.1798	LR: 0.002486
Training Epoch: 165 [128/50000]	Loss: 0.9944	LR: 0.002486
Training Epoch: 165 [128/50000]	Loss: 1.0422	LR: 0.002486
Training Epoch: 165 [128/50000]	Loss: 0.9866	LR: 0.002486
Training Epoch: 165 [128/50000]	Loss: 0.9498	LR: 0.002486
Training Epoch: 165 [128/50000]	Loss: 1.0179	LR: 0.002486
Training Epoch: 165 [128/50000]	Loss: 1.0832	LR: 0.002486
Training Epoch: 165 [128/50000]	Loss: 0.9411	LR: 0.002486
Training Epoch: 165 [128/50000]	Loss: 1.1650	LR: 0.002486
Evaluating Network.....
Test set: Epoch: 165, Average loss: 0.0108, Top1Accuracy: 0.6179, Top3Accuracy: 0.8147, Top5Accuracy: 0.8793, Time consumed:2.31s

Training Epoch: 166 [128/50000]	Loss: 0.7730	LR: 0.002420
Training Epoch: 166 [128/50000]	Loss: 0.9439	LR: 0.002420
Training Epoch: 166 [128/50000]	Loss: 1.0946	LR: 0.002420
Training Epoch: 166 [128/50000]	Loss: 0.9957	LR: 0.002420
Training Epoch: 166 [128/50000]	Loss: 1.0504	LR: 0.002420
Training Epoch: 166 [128/50000]	Loss: 0.8159	LR: 0.002420
Training Epoch: 166 [128/50000]	Loss: 1.0751	LR: 0.002420
Training Epoch: 166 [128/50000]	Loss: 1.1697	LR: 0.002420
Training Epoch: 166 [128/50000]	Loss: 1.1775	LR: 0.002420
Training Epoch: 166 [128/50000]	Loss: 0.8712	LR: 0.002420
Evaluating Network.....
Test set: Epoch: 166, Average loss: 0.0108, Top1Accuracy: 0.6151, Top3Accuracy: 0.8146, Top5Accuracy: 0.8795, Time consumed:1.77s

Training Epoch: 167 [128/50000]	Loss: 1.0456	LR: 0.002356
Training Epoch: 167 [128/50000]	Loss: 0.9210	LR: 0.002356
Training Epoch: 167 [128/50000]	Loss: 0.8632	LR: 0.002356
Training Epoch: 167 [128/50000]	Loss: 1.1552	LR: 0.002356
Training Epoch: 167 [128/50000]	Loss: 0.8739	LR: 0.002356
Training Epoch: 167 [128/50000]	Loss: 1.0802	LR: 0.002356
Training Epoch: 167 [128/50000]	Loss: 1.0018	LR: 0.002356
Training Epoch: 167 [128/50000]	Loss: 0.7824	LR: 0.002356
Training Epoch: 167 [128/50000]	Loss: 0.8996	LR: 0.002356
Training Epoch: 167 [128/50000]	Loss: 0.9112	LR: 0.002356
Evaluating Network.....
Test set: Epoch: 167, Average loss: 0.0108, Top1Accuracy: 0.6150, Top3Accuracy: 0.8120, Top5Accuracy: 0.8787, Time consumed:1.80s

Training Epoch: 168 [128/50000]	Loss: 1.0219	LR: 0.002294
Training Epoch: 168 [128/50000]	Loss: 1.0474	LR: 0.002294
Training Epoch: 168 [128/50000]	Loss: 0.9946	LR: 0.002294
Training Epoch: 168 [128/50000]	Loss: 1.0569	LR: 0.002294
Training Epoch: 168 [128/50000]	Loss: 0.8873	LR: 0.002294
Training Epoch: 168 [128/50000]	Loss: 1.0079	LR: 0.002294
Training Epoch: 168 [128/50000]	Loss: 0.8491	LR: 0.002294
Training Epoch: 168 [128/50000]	Loss: 1.0066	LR: 0.002294
Training Epoch: 168 [128/50000]	Loss: 0.8321	LR: 0.002294
Training Epoch: 168 [128/50000]	Loss: 1.0708	LR: 0.002294
Evaluating Network.....
Test set: Epoch: 168, Average loss: 0.0108, Top1Accuracy: 0.6181, Top3Accuracy: 0.8157, Top5Accuracy: 0.8785, Time consumed:1.80s

Training Epoch: 169 [128/50000]	Loss: 1.2788	LR: 0.002233
Training Epoch: 169 [128/50000]	Loss: 1.1364	LR: 0.002233
Training Epoch: 169 [128/50000]	Loss: 0.8952	LR: 0.002233
Training Epoch: 169 [128/50000]	Loss: 0.8921	LR: 0.002233
Training Epoch: 169 [128/50000]	Loss: 1.0296	LR: 0.002233
Training Epoch: 169 [128/50000]	Loss: 1.0733	LR: 0.002233
Training Epoch: 169 [128/50000]	Loss: 1.1726	LR: 0.002233
Training Epoch: 169 [128/50000]	Loss: 1.0732	LR: 0.002233
Training Epoch: 169 [128/50000]	Loss: 0.9560	LR: 0.002233
Training Epoch: 169 [128/50000]	Loss: 0.9386	LR: 0.002233
Evaluating Network.....
Test set: Epoch: 169, Average loss: 0.0108, Top1Accuracy: 0.6172, Top3Accuracy: 0.8128, Top5Accuracy: 0.8799, Time consumed:1.78s

Training Epoch: 170 [128/50000]	Loss: 0.9801	LR: 0.002174
Training Epoch: 170 [128/50000]	Loss: 0.8142	LR: 0.002174
Training Epoch: 170 [128/50000]	Loss: 0.8259	LR: 0.002174
Training Epoch: 170 [128/50000]	Loss: 0.8665	LR: 0.002174
Training Epoch: 170 [128/50000]	Loss: 1.0574	LR: 0.002174
Training Epoch: 170 [128/50000]	Loss: 1.0032	LR: 0.002174
Training Epoch: 170 [128/50000]	Loss: 1.1004	LR: 0.002174
Training Epoch: 170 [128/50000]	Loss: 0.9497	LR: 0.002174
Training Epoch: 170 [128/50000]	Loss: 0.9631	LR: 0.002174
Training Epoch: 170 [128/50000]	Loss: 0.9766	LR: 0.002174
Evaluating Network.....
Test set: Epoch: 170, Average loss: 0.0108, Top1Accuracy: 0.6162, Top3Accuracy: 0.8151, Top5Accuracy: 0.8815, Time consumed:1.79s

Training Epoch: 171 [128/50000]	Loss: 0.9540	LR: 0.002117
Training Epoch: 171 [128/50000]	Loss: 0.7956	LR: 0.002117
Training Epoch: 171 [128/50000]	Loss: 0.9837	LR: 0.002117
Training Epoch: 171 [128/50000]	Loss: 1.1233	LR: 0.002117
Training Epoch: 171 [128/50000]	Loss: 0.9438	LR: 0.002117
Training Epoch: 171 [128/50000]	Loss: 1.1354	LR: 0.002117
Training Epoch: 171 [128/50000]	Loss: 1.1620	LR: 0.002117
Training Epoch: 171 [128/50000]	Loss: 0.9415	LR: 0.002117
Training Epoch: 171 [128/50000]	Loss: 1.0618	LR: 0.002117
Training Epoch: 171 [128/50000]	Loss: 1.2269	LR: 0.002117
Evaluating Network.....
Test set: Epoch: 171, Average loss: 0.0108, Top1Accuracy: 0.6186, Top3Accuracy: 0.8156, Top5Accuracy: 0.8806, Time consumed:1.80s

Training Epoch: 172 [128/50000]	Loss: 0.9464	LR: 0.002061
Training Epoch: 172 [128/50000]	Loss: 1.1557	LR: 0.002061
Training Epoch: 172 [128/50000]	Loss: 0.8719	LR: 0.002061
Training Epoch: 172 [128/50000]	Loss: 0.9041	LR: 0.002061
Training Epoch: 172 [128/50000]	Loss: 0.8916	LR: 0.002061
Training Epoch: 172 [128/50000]	Loss: 0.9747	LR: 0.002061
Training Epoch: 172 [128/50000]	Loss: 1.1661	LR: 0.002061
Training Epoch: 172 [128/50000]	Loss: 0.7787	LR: 0.002061
Training Epoch: 172 [128/50000]	Loss: 0.9939	LR: 0.002061
Training Epoch: 172 [128/50000]	Loss: 1.0534	LR: 0.002061
Evaluating Network.....
Test set: Epoch: 172, Average loss: 0.0108, Top1Accuracy: 0.6195, Top3Accuracy: 0.8153, Top5Accuracy: 0.8789, Time consumed:1.80s

Training Epoch: 173 [128/50000]	Loss: 0.9320	LR: 0.002007
Training Epoch: 173 [128/50000]	Loss: 1.0145	LR: 0.002007
Training Epoch: 173 [128/50000]	Loss: 1.0229	LR: 0.002007
Training Epoch: 173 [128/50000]	Loss: 0.8920	LR: 0.002007
Training Epoch: 173 [128/50000]	Loss: 1.0775	LR: 0.002007
Training Epoch: 173 [128/50000]	Loss: 1.0502	LR: 0.002007
Training Epoch: 173 [128/50000]	Loss: 0.8596	LR: 0.002007
Training Epoch: 173 [128/50000]	Loss: 0.9220	LR: 0.002007
Training Epoch: 173 [128/50000]	Loss: 0.9083	LR: 0.002007
Training Epoch: 173 [128/50000]	Loss: 0.8471	LR: 0.002007
Evaluating Network.....
Test set: Epoch: 173, Average loss: 0.0108, Top1Accuracy: 0.6162, Top3Accuracy: 0.8140, Top5Accuracy: 0.8801, Time consumed:1.80s

Training Epoch: 174 [128/50000]	Loss: 0.9154	LR: 0.001954
Training Epoch: 174 [128/50000]	Loss: 1.0930	LR: 0.001954
Training Epoch: 174 [128/50000]	Loss: 0.9282	LR: 0.001954
Training Epoch: 174 [128/50000]	Loss: 0.8381	LR: 0.001954
Training Epoch: 174 [128/50000]	Loss: 0.8522	LR: 0.001954
Training Epoch: 174 [128/50000]	Loss: 1.1699	LR: 0.001954
Training Epoch: 174 [128/50000]	Loss: 1.0603	LR: 0.001954
Training Epoch: 174 [128/50000]	Loss: 1.1337	LR: 0.001954
Training Epoch: 174 [128/50000]	Loss: 0.9864	LR: 0.001954
Training Epoch: 174 [128/50000]	Loss: 0.9612	LR: 0.001954
Evaluating Network.....
Test set: Epoch: 174, Average loss: 0.0108, Top1Accuracy: 0.6166, Top3Accuracy: 0.8127, Top5Accuracy: 0.8786, Time consumed:1.80s

Training Epoch: 175 [128/50000]	Loss: 1.0397	LR: 0.001902
Training Epoch: 175 [128/50000]	Loss: 1.0806	LR: 0.001902
Training Epoch: 175 [128/50000]	Loss: 0.9718	LR: 0.001902
Training Epoch: 175 [128/50000]	Loss: 0.9243	LR: 0.001902
Training Epoch: 175 [128/50000]	Loss: 0.8898	LR: 0.001902
Training Epoch: 175 [128/50000]	Loss: 1.1294	LR: 0.001902
Training Epoch: 175 [128/50000]	Loss: 1.0162	LR: 0.001902
Training Epoch: 175 [128/50000]	Loss: 0.9813	LR: 0.001902
Training Epoch: 175 [128/50000]	Loss: 0.8081	LR: 0.001902
Training Epoch: 175 [128/50000]	Loss: 0.9886	LR: 0.001902
Evaluating Network.....
Test set: Epoch: 175, Average loss: 0.0108, Top1Accuracy: 0.6181, Top3Accuracy: 0.8144, Top5Accuracy: 0.8766, Time consumed:1.79s

Training Epoch: 176 [128/50000]	Loss: 0.9425	LR: 0.001852
Training Epoch: 176 [128/50000]	Loss: 0.9896	LR: 0.001852
Training Epoch: 176 [128/50000]	Loss: 0.8955	LR: 0.001852
Training Epoch: 176 [128/50000]	Loss: 1.0823	LR: 0.001852
Training Epoch: 176 [128/50000]	Loss: 0.9266	LR: 0.001852
Training Epoch: 176 [128/50000]	Loss: 0.9854	LR: 0.001852
Training Epoch: 176 [128/50000]	Loss: 0.9072	LR: 0.001852
Training Epoch: 176 [128/50000]	Loss: 0.7280	LR: 0.001852
Training Epoch: 176 [128/50000]	Loss: 0.9469	LR: 0.001852
Training Epoch: 176 [128/50000]	Loss: 0.8867	LR: 0.001852
Evaluating Network.....
Test set: Epoch: 176, Average loss: 0.0108, Top1Accuracy: 0.6177, Top3Accuracy: 0.8136, Top5Accuracy: 0.8795, Time consumed:1.78s

Training Epoch: 177 [128/50000]	Loss: 0.9808	LR: 0.001803
Training Epoch: 177 [128/50000]	Loss: 0.7783	LR: 0.001803
Training Epoch: 177 [128/50000]	Loss: 1.0663	LR: 0.001803
Training Epoch: 177 [128/50000]	Loss: 0.8429	LR: 0.001803
Training Epoch: 177 [128/50000]	Loss: 0.9505	LR: 0.001803
Training Epoch: 177 [128/50000]	Loss: 1.0210	LR: 0.001803
Training Epoch: 177 [128/50000]	Loss: 1.2177	LR: 0.001803
Training Epoch: 177 [128/50000]	Loss: 1.0626	LR: 0.001803
Training Epoch: 177 [128/50000]	Loss: 0.9952	LR: 0.001803
Training Epoch: 177 [128/50000]	Loss: 0.9213	LR: 0.001803
Evaluating Network.....
Test set: Epoch: 177, Average loss: 0.0108, Top1Accuracy: 0.6203, Top3Accuracy: 0.8153, Top5Accuracy: 0.8800, Time consumed:1.77s

Training Epoch: 178 [128/50000]	Loss: 0.9336	LR: 0.001755
Training Epoch: 178 [128/50000]	Loss: 1.0792	LR: 0.001755
Training Epoch: 178 [128/50000]	Loss: 0.9359	LR: 0.001755
Training Epoch: 178 [128/50000]	Loss: 0.9403	LR: 0.001755
Training Epoch: 178 [128/50000]	Loss: 0.9471	LR: 0.001755
Training Epoch: 178 [128/50000]	Loss: 1.0083	LR: 0.001755
Training Epoch: 178 [128/50000]	Loss: 0.9525	LR: 0.001755
Training Epoch: 178 [128/50000]	Loss: 1.0918	LR: 0.001755
Training Epoch: 178 [128/50000]	Loss: 1.0783	LR: 0.001755
Training Epoch: 178 [128/50000]	Loss: 1.0948	LR: 0.001755
Evaluating Network.....
Test set: Epoch: 178, Average loss: 0.0108, Top1Accuracy: 0.6188, Top3Accuracy: 0.8147, Top5Accuracy: 0.8801, Time consumed:1.87s

Training Epoch: 179 [128/50000]	Loss: 1.0303	LR: 0.001709
Training Epoch: 179 [128/50000]	Loss: 0.9528	LR: 0.001709
Training Epoch: 179 [128/50000]	Loss: 0.9283	LR: 0.001709
Training Epoch: 179 [128/50000]	Loss: 1.2294	LR: 0.001709
Training Epoch: 179 [128/50000]	Loss: 0.8884	LR: 0.001709
Training Epoch: 179 [128/50000]	Loss: 0.9954	LR: 0.001709
Training Epoch: 179 [128/50000]	Loss: 1.0744	LR: 0.001709
Training Epoch: 179 [128/50000]	Loss: 1.0542	LR: 0.001709
Training Epoch: 179 [128/50000]	Loss: 0.8672	LR: 0.001709
Training Epoch: 179 [128/50000]	Loss: 0.9642	LR: 0.001709
Evaluating Network.....
Test set: Epoch: 179, Average loss: 0.0109, Top1Accuracy: 0.6195, Top3Accuracy: 0.8144, Top5Accuracy: 0.8798, Time consumed:1.78s

Training Epoch: 180 [128/50000]	Loss: 0.8901	LR: 0.001664
Training Epoch: 180 [128/50000]	Loss: 1.0024	LR: 0.001664
Training Epoch: 180 [128/50000]	Loss: 1.1146	LR: 0.001664
Training Epoch: 180 [128/50000]	Loss: 0.7421	LR: 0.001664
Training Epoch: 180 [128/50000]	Loss: 0.8594	LR: 0.001664
Training Epoch: 180 [128/50000]	Loss: 1.0583	LR: 0.001664
Training Epoch: 180 [128/50000]	Loss: 1.1278	LR: 0.001664
Training Epoch: 180 [128/50000]	Loss: 1.0283	LR: 0.001664
Training Epoch: 180 [128/50000]	Loss: 0.9498	LR: 0.001664
Training Epoch: 180 [128/50000]	Loss: 1.0927	LR: 0.001664
Evaluating Network.....
Test set: Epoch: 180, Average loss: 0.0107, Top1Accuracy: 0.6209, Top3Accuracy: 0.8136, Top5Accuracy: 0.8786, Time consumed:1.80s

Training Epoch: 181 [128/50000]	Loss: 1.0185	LR: 0.001620
Training Epoch: 181 [128/50000]	Loss: 0.8946	LR: 0.001620
Training Epoch: 181 [128/50000]	Loss: 1.0600	LR: 0.001620
Training Epoch: 181 [128/50000]	Loss: 0.9680	LR: 0.001620
Training Epoch: 181 [128/50000]	Loss: 1.0092	LR: 0.001620
Training Epoch: 181 [128/50000]	Loss: 0.8080	LR: 0.001620
Training Epoch: 181 [128/50000]	Loss: 0.8237	LR: 0.001620
Training Epoch: 181 [128/50000]	Loss: 0.8605	LR: 0.001620
Training Epoch: 181 [128/50000]	Loss: 0.9014	LR: 0.001620
Training Epoch: 181 [128/50000]	Loss: 1.0966	LR: 0.001620
Evaluating Network.....
Test set: Epoch: 181, Average loss: 0.0107, Top1Accuracy: 0.6205, Top3Accuracy: 0.8149, Top5Accuracy: 0.8792, Time consumed:1.77s

Training Epoch: 182 [128/50000]	Loss: 0.9312	LR: 0.001577
Training Epoch: 182 [128/50000]	Loss: 0.8649	LR: 0.001577
Training Epoch: 182 [128/50000]	Loss: 0.9987	LR: 0.001577
Training Epoch: 182 [128/50000]	Loss: 1.0084	LR: 0.001577
Training Epoch: 182 [128/50000]	Loss: 1.0863	LR: 0.001577
Training Epoch: 182 [128/50000]	Loss: 0.9490	LR: 0.001577
Training Epoch: 182 [128/50000]	Loss: 1.0405	LR: 0.001577
Training Epoch: 182 [128/50000]	Loss: 1.1708	LR: 0.001577
Training Epoch: 182 [128/50000]	Loss: 0.9519	LR: 0.001577
Training Epoch: 182 [128/50000]	Loss: 1.0839	LR: 0.001577
Evaluating Network.....
Test set: Epoch: 182, Average loss: 0.0108, Top1Accuracy: 0.6189, Top3Accuracy: 0.8161, Top5Accuracy: 0.8789, Time consumed:1.78s

Training Epoch: 183 [128/50000]	Loss: 1.0521	LR: 0.001536
Training Epoch: 183 [128/50000]	Loss: 1.0220	LR: 0.001536
Training Epoch: 183 [128/50000]	Loss: 1.0617	LR: 0.001536
Training Epoch: 183 [128/50000]	Loss: 1.1356	LR: 0.001536
Training Epoch: 183 [128/50000]	Loss: 1.0398	LR: 0.001536
Training Epoch: 183 [128/50000]	Loss: 1.0845	LR: 0.001536
Training Epoch: 183 [128/50000]	Loss: 0.9261	LR: 0.001536
Training Epoch: 183 [128/50000]	Loss: 0.8547	LR: 0.001536
Training Epoch: 183 [128/50000]	Loss: 0.9722	LR: 0.001536
Training Epoch: 183 [128/50000]	Loss: 0.9069	LR: 0.001536
Evaluating Network.....
Test set: Epoch: 183, Average loss: 0.0107, Top1Accuracy: 0.6192, Top3Accuracy: 0.8144, Top5Accuracy: 0.8789, Time consumed:1.80s

Training Epoch: 184 [128/50000]	Loss: 0.9394	LR: 0.001495
Training Epoch: 184 [128/50000]	Loss: 0.8583	LR: 0.001495
Training Epoch: 184 [128/50000]	Loss: 0.9226	LR: 0.001495
Training Epoch: 184 [128/50000]	Loss: 1.0594	LR: 0.001495
Training Epoch: 184 [128/50000]	Loss: 0.9212	LR: 0.001495
Training Epoch: 184 [128/50000]	Loss: 1.0475	LR: 0.001495
Training Epoch: 184 [128/50000]	Loss: 0.9960	LR: 0.001495
Training Epoch: 184 [128/50000]	Loss: 1.0585	LR: 0.001495
Training Epoch: 184 [128/50000]	Loss: 1.1087	LR: 0.001495
Training Epoch: 184 [128/50000]	Loss: 0.9964	LR: 0.001495
Evaluating Network.....
Test set: Epoch: 184, Average loss: 0.0108, Top1Accuracy: 0.6173, Top3Accuracy: 0.8145, Top5Accuracy: 0.8781, Time consumed:1.79s

Training Epoch: 185 [128/50000]	Loss: 1.1558	LR: 0.001456
Training Epoch: 185 [128/50000]	Loss: 0.7703	LR: 0.001456
Training Epoch: 185 [128/50000]	Loss: 1.1749	LR: 0.001456
Training Epoch: 185 [128/50000]	Loss: 0.9638	LR: 0.001456
Training Epoch: 185 [128/50000]	Loss: 0.9564	LR: 0.001456
Training Epoch: 185 [128/50000]	Loss: 0.9684	LR: 0.001456
Training Epoch: 185 [128/50000]	Loss: 0.8401	LR: 0.001456
Training Epoch: 185 [128/50000]	Loss: 0.8616	LR: 0.001456
Training Epoch: 185 [128/50000]	Loss: 0.7053	LR: 0.001456
Training Epoch: 185 [128/50000]	Loss: 1.0780	LR: 0.001456
Evaluating Network.....
Test set: Epoch: 185, Average loss: 0.0109, Top1Accuracy: 0.6185, Top3Accuracy: 0.8153, Top5Accuracy: 0.8791, Time consumed:1.78s

Training Epoch: 186 [128/50000]	Loss: 0.8610	LR: 0.001417
Training Epoch: 186 [128/50000]	Loss: 0.9594	LR: 0.001417
Training Epoch: 186 [128/50000]	Loss: 1.0294	LR: 0.001417
Training Epoch: 186 [128/50000]	Loss: 1.0392	LR: 0.001417
Training Epoch: 186 [128/50000]	Loss: 1.0899	LR: 0.001417
Training Epoch: 186 [128/50000]	Loss: 1.0045	LR: 0.001417
Training Epoch: 186 [128/50000]	Loss: 1.1360	LR: 0.001417
Training Epoch: 186 [128/50000]	Loss: 0.8556	LR: 0.001417
Training Epoch: 186 [128/50000]	Loss: 0.9538	LR: 0.001417
Training Epoch: 186 [128/50000]	Loss: 0.9411	LR: 0.001417
Evaluating Network.....
Test set: Epoch: 186, Average loss: 0.0108, Top1Accuracy: 0.6209, Top3Accuracy: 0.8159, Top5Accuracy: 0.8769, Time consumed:1.81s

Training Epoch: 187 [128/50000]	Loss: 0.8949	LR: 0.001380
Training Epoch: 187 [128/50000]	Loss: 0.9112	LR: 0.001380
Training Epoch: 187 [128/50000]	Loss: 0.9681	LR: 0.001380
Training Epoch: 187 [128/50000]	Loss: 0.9948	LR: 0.001380
Training Epoch: 187 [128/50000]	Loss: 0.9791	LR: 0.001380
Training Epoch: 187 [128/50000]	Loss: 1.0020	LR: 0.001380
Training Epoch: 187 [128/50000]	Loss: 0.9116	LR: 0.001380
Training Epoch: 187 [128/50000]	Loss: 1.0724	LR: 0.001380
Training Epoch: 187 [128/50000]	Loss: 1.0531	LR: 0.001380
Training Epoch: 187 [128/50000]	Loss: 0.9907	LR: 0.001380
Evaluating Network.....
Test set: Epoch: 187, Average loss: 0.0108, Top1Accuracy: 0.6203, Top3Accuracy: 0.8145, Top5Accuracy: 0.8794, Time consumed:1.79s

Training Epoch: 188 [128/50000]	Loss: 1.0573	LR: 0.001343
Training Epoch: 188 [128/50000]	Loss: 0.9791	LR: 0.001343
Training Epoch: 188 [128/50000]	Loss: 0.9168	LR: 0.001343
Training Epoch: 188 [128/50000]	Loss: 1.0359	LR: 0.001343
Training Epoch: 188 [128/50000]	Loss: 0.8794	LR: 0.001343
Training Epoch: 188 [128/50000]	Loss: 0.8577	LR: 0.001343
Training Epoch: 188 [128/50000]	Loss: 0.9049	LR: 0.001343
Training Epoch: 188 [128/50000]	Loss: 0.7945	LR: 0.001343
Training Epoch: 188 [128/50000]	Loss: 0.7875	LR: 0.001343
Training Epoch: 188 [128/50000]	Loss: 0.9862	LR: 0.001343
Evaluating Network.....
Test set: Epoch: 188, Average loss: 0.0108, Top1Accuracy: 0.6182, Top3Accuracy: 0.8158, Top5Accuracy: 0.8782, Time consumed:1.79s

Training Epoch: 189 [128/50000]	Loss: 0.8954	LR: 0.001308
Training Epoch: 189 [128/50000]	Loss: 0.9495	LR: 0.001308
Training Epoch: 189 [128/50000]	Loss: 0.8730	LR: 0.001308
Training Epoch: 189 [128/50000]	Loss: 1.1309	LR: 0.001308
Training Epoch: 189 [128/50000]	Loss: 0.7868	LR: 0.001308
Training Epoch: 189 [128/50000]	Loss: 0.9025	LR: 0.001308
Training Epoch: 189 [128/50000]	Loss: 0.8163	LR: 0.001308
Training Epoch: 189 [128/50000]	Loss: 0.8554	LR: 0.001308
Training Epoch: 189 [128/50000]	Loss: 1.0156	LR: 0.001308
Training Epoch: 189 [128/50000]	Loss: 0.9244	LR: 0.001308
Evaluating Network.....
Test set: Epoch: 189, Average loss: 0.0108, Top1Accuracy: 0.6207, Top3Accuracy: 0.8156, Top5Accuracy: 0.8806, Time consumed:1.81s

Training Epoch: 190 [128/50000]	Loss: 0.7985	LR: 0.001273
Training Epoch: 190 [128/50000]	Loss: 1.0514	LR: 0.001273
Training Epoch: 190 [128/50000]	Loss: 0.8137	LR: 0.001273
Training Epoch: 190 [128/50000]	Loss: 0.8323	LR: 0.001273
Training Epoch: 190 [128/50000]	Loss: 1.0769	LR: 0.001273
Training Epoch: 190 [128/50000]	Loss: 0.9204	LR: 0.001273
Training Epoch: 190 [128/50000]	Loss: 0.8952	LR: 0.001273
Training Epoch: 190 [128/50000]	Loss: 0.8527	LR: 0.001273
Training Epoch: 190 [128/50000]	Loss: 1.1405	LR: 0.001273
Training Epoch: 190 [128/50000]	Loss: 0.8867	LR: 0.001273
Evaluating Network.....
Test set: Epoch: 190, Average loss: 0.0108, Top1Accuracy: 0.6191, Top3Accuracy: 0.8172, Top5Accuracy: 0.8789, Time consumed:1.81s

Training Epoch: 191 [128/50000]	Loss: 0.7803	LR: 0.001240
Training Epoch: 191 [128/50000]	Loss: 1.0744	LR: 0.001240
Training Epoch: 191 [128/50000]	Loss: 1.0206	LR: 0.001240
Training Epoch: 191 [128/50000]	Loss: 0.8275	LR: 0.001240
Training Epoch: 191 [128/50000]	Loss: 1.0672	LR: 0.001240
Training Epoch: 191 [128/50000]	Loss: 1.0367	LR: 0.001240
Training Epoch: 191 [128/50000]	Loss: 0.8784	LR: 0.001240
Training Epoch: 191 [128/50000]	Loss: 0.8816	LR: 0.001240
Training Epoch: 191 [128/50000]	Loss: 0.9934	LR: 0.001240
Training Epoch: 191 [128/50000]	Loss: 1.0082	LR: 0.001240
Evaluating Network.....
Test set: Epoch: 191, Average loss: 0.0108, Top1Accuracy: 0.6192, Top3Accuracy: 0.8171, Top5Accuracy: 0.8795, Time consumed:1.79s

Training Epoch: 192 [128/50000]	Loss: 0.8775	LR: 0.001207
Training Epoch: 192 [128/50000]	Loss: 1.0920	LR: 0.001207
Training Epoch: 192 [128/50000]	Loss: 1.1204	LR: 0.001207
Training Epoch: 192 [128/50000]	Loss: 0.8443	LR: 0.001207
Training Epoch: 192 [128/50000]	Loss: 0.9196	LR: 0.001207
Training Epoch: 192 [128/50000]	Loss: 0.9719	LR: 0.001207
Training Epoch: 192 [128/50000]	Loss: 0.9077	LR: 0.001207
Training Epoch: 192 [128/50000]	Loss: 1.0479	LR: 0.001207
Training Epoch: 192 [128/50000]	Loss: 0.8059	LR: 0.001207
Training Epoch: 192 [128/50000]	Loss: 0.7425	LR: 0.001207
Evaluating Network.....
Test set: Epoch: 192, Average loss: 0.0108, Top1Accuracy: 0.6194, Top3Accuracy: 0.8177, Top5Accuracy: 0.8808, Time consumed:1.79s

Training Epoch: 193 [128/50000]	Loss: 0.9310	LR: 0.001175
Training Epoch: 193 [128/50000]	Loss: 0.9009	LR: 0.001175
Training Epoch: 193 [128/50000]	Loss: 0.8958	LR: 0.001175
Training Epoch: 193 [128/50000]	Loss: 0.8180	LR: 0.001175
Training Epoch: 193 [128/50000]	Loss: 0.8429	LR: 0.001175
Training Epoch: 193 [128/50000]	Loss: 0.9643	LR: 0.001175
Training Epoch: 193 [128/50000]	Loss: 0.7425	LR: 0.001175
Training Epoch: 193 [128/50000]	Loss: 0.9957	LR: 0.001175
Training Epoch: 193 [128/50000]	Loss: 0.9993	LR: 0.001175
Training Epoch: 193 [128/50000]	Loss: 0.7754	LR: 0.001175
Evaluating Network.....
Test set: Epoch: 193, Average loss: 0.0108, Top1Accuracy: 0.6163, Top3Accuracy: 0.8155, Top5Accuracy: 0.8775, Time consumed:1.79s

Training Epoch: 194 [128/50000]	Loss: 0.6851	LR: 0.001144
Training Epoch: 194 [128/50000]	Loss: 0.8337	LR: 0.001144
Training Epoch: 194 [128/50000]	Loss: 1.0916	LR: 0.001144
Training Epoch: 194 [128/50000]	Loss: 0.9383	LR: 0.001144
Training Epoch: 194 [128/50000]	Loss: 0.8540	LR: 0.001144
Training Epoch: 194 [128/50000]	Loss: 0.7897	LR: 0.001144
Training Epoch: 194 [128/50000]	Loss: 0.7750	LR: 0.001144
Training Epoch: 194 [128/50000]	Loss: 0.9973	LR: 0.001144
Training Epoch: 194 [128/50000]	Loss: 0.9463	LR: 0.001144
Training Epoch: 194 [128/50000]	Loss: 0.8628	LR: 0.001144
Evaluating Network.....
Test set: Epoch: 194, Average loss: 0.0107, Top1Accuracy: 0.6197, Top3Accuracy: 0.8143, Top5Accuracy: 0.8806, Time consumed:1.78s

Training Epoch: 195 [128/50000]	Loss: 0.9752	LR: 0.001114
Training Epoch: 195 [128/50000]	Loss: 0.8364	LR: 0.001114
Training Epoch: 195 [128/50000]	Loss: 0.8609	LR: 0.001114
Training Epoch: 195 [128/50000]	Loss: 0.8895	LR: 0.001114
Training Epoch: 195 [128/50000]	Loss: 0.9865	LR: 0.001114
Training Epoch: 195 [128/50000]	Loss: 0.9584	LR: 0.001114
Training Epoch: 195 [128/50000]	Loss: 0.9154	LR: 0.001114
Training Epoch: 195 [128/50000]	Loss: 0.9824	LR: 0.001114
Training Epoch: 195 [128/50000]	Loss: 0.9283	LR: 0.001114
Training Epoch: 195 [128/50000]	Loss: 0.9551	LR: 0.001114
Evaluating Network.....
Test set: Epoch: 195, Average loss: 0.0108, Top1Accuracy: 0.6189, Top3Accuracy: 0.8147, Top5Accuracy: 0.8801, Time consumed:1.79s

Training Epoch: 196 [128/50000]	Loss: 1.0782	LR: 0.001085
Training Epoch: 196 [128/50000]	Loss: 0.9196	LR: 0.001085
Training Epoch: 196 [128/50000]	Loss: 0.8712	LR: 0.001085
Training Epoch: 196 [128/50000]	Loss: 0.8944	LR: 0.001085
Training Epoch: 196 [128/50000]	Loss: 0.9512	LR: 0.001085
Training Epoch: 196 [128/50000]	Loss: 0.9449	LR: 0.001085
Training Epoch: 196 [128/50000]	Loss: 1.0569	LR: 0.001085
Training Epoch: 196 [128/50000]	Loss: 1.0515	LR: 0.001085
Training Epoch: 196 [128/50000]	Loss: 0.8104	LR: 0.001085
Training Epoch: 196 [128/50000]	Loss: 0.7474	LR: 0.001085
Evaluating Network.....
Test set: Epoch: 196, Average loss: 0.0108, Top1Accuracy: 0.6212, Top3Accuracy: 0.8167, Top5Accuracy: 0.8789, Time consumed:1.86s

Training Epoch: 197 [128/50000]	Loss: 1.1868	LR: 0.001056
Training Epoch: 197 [128/50000]	Loss: 0.8662	LR: 0.001056
Training Epoch: 197 [128/50000]	Loss: 0.7965	LR: 0.001056
Training Epoch: 197 [128/50000]	Loss: 0.8956	LR: 0.001056
Training Epoch: 197 [128/50000]	Loss: 0.8551	LR: 0.001056
Training Epoch: 197 [128/50000]	Loss: 0.8847	LR: 0.001056
Training Epoch: 197 [128/50000]	Loss: 0.7766	LR: 0.001056
Training Epoch: 197 [128/50000]	Loss: 0.9277	LR: 0.001056
Training Epoch: 197 [128/50000]	Loss: 0.9667	LR: 0.001056
Training Epoch: 197 [128/50000]	Loss: 0.9037	LR: 0.001056
Evaluating Network.....
Test set: Epoch: 197, Average loss: 0.0108, Top1Accuracy: 0.6192, Top3Accuracy: 0.8171, Top5Accuracy: 0.8787, Time consumed:1.79s

Training Epoch: 198 [128/50000]	Loss: 0.8825	LR: 0.001028
Training Epoch: 198 [128/50000]	Loss: 0.9473	LR: 0.001028
Training Epoch: 198 [128/50000]	Loss: 0.8916	LR: 0.001028
Training Epoch: 198 [128/50000]	Loss: 0.8492	LR: 0.001028
Training Epoch: 198 [128/50000]	Loss: 0.8547	LR: 0.001028
Training Epoch: 198 [128/50000]	Loss: 1.1070	LR: 0.001028
Training Epoch: 198 [128/50000]	Loss: 0.9989	LR: 0.001028
Training Epoch: 198 [128/50000]	Loss: 0.9075	LR: 0.001028
Training Epoch: 198 [128/50000]	Loss: 1.0211	LR: 0.001028
Training Epoch: 198 [128/50000]	Loss: 0.8882	LR: 0.001028
Evaluating Network.....
Test set: Epoch: 198, Average loss: 0.0108, Top1Accuracy: 0.6202, Top3Accuracy: 0.8165, Top5Accuracy: 0.8783, Time consumed:1.78s

Training Epoch: 199 [128/50000]	Loss: 1.0382	LR: 0.001001
Training Epoch: 199 [128/50000]	Loss: 0.9433	LR: 0.001001
Training Epoch: 199 [128/50000]	Loss: 0.8839	LR: 0.001001
Training Epoch: 199 [128/50000]	Loss: 0.8522	LR: 0.001001
Training Epoch: 199 [128/50000]	Loss: 1.1475	LR: 0.001001
Training Epoch: 199 [128/50000]	Loss: 0.9636	LR: 0.001001
Training Epoch: 199 [128/50000]	Loss: 0.9547	LR: 0.001001
Training Epoch: 199 [128/50000]	Loss: 1.0890	LR: 0.001001
Training Epoch: 199 [128/50000]	Loss: 1.3111	LR: 0.001001
Training Epoch: 199 [128/50000]	Loss: 1.0449	LR: 0.001001
Evaluating Network.....
Test set: Epoch: 199, Average loss: 0.0108, Top1Accuracy: 0.6183, Top3Accuracy: 0.8150, Top5Accuracy: 0.8792, Time consumed:1.79s

Training Epoch: 200 [128/50000]	Loss: 0.9611	LR: 0.000974
Training Epoch: 200 [128/50000]	Loss: 0.7759	LR: 0.000974
Training Epoch: 200 [128/50000]	Loss: 0.9013	LR: 0.000974
Training Epoch: 200 [128/50000]	Loss: 0.8937	LR: 0.000974
Training Epoch: 200 [128/50000]	Loss: 0.8002	LR: 0.000974
Training Epoch: 200 [128/50000]	Loss: 0.9002	LR: 0.000974
Training Epoch: 200 [128/50000]	Loss: 1.0717	LR: 0.000974
Training Epoch: 200 [128/50000]	Loss: 0.8986	LR: 0.000974
Training Epoch: 200 [128/50000]	Loss: 0.9894	LR: 0.000974
Training Epoch: 200 [128/50000]	Loss: 0.8004	LR: 0.000974
Evaluating Network.....
Test set: Epoch: 200, Average loss: 0.0108, Top1Accuracy: 0.6187, Top3Accuracy: 0.8171, Top5Accuracy: 0.8784, Time consumed:1.78s

Training Epoch: 201 [128/50000]	Loss: 0.9478	LR: 0.000949
Training Epoch: 201 [128/50000]	Loss: 0.9535	LR: 0.000949
Training Epoch: 201 [128/50000]	Loss: 0.9039	LR: 0.000949
Training Epoch: 201 [128/50000]	Loss: 0.9693	LR: 0.000949
Training Epoch: 201 [128/50000]	Loss: 1.0558	LR: 0.000949
Training Epoch: 201 [128/50000]	Loss: 0.9658	LR: 0.000949
Training Epoch: 201 [128/50000]	Loss: 0.9840	LR: 0.000949
Training Epoch: 201 [128/50000]	Loss: 1.0703	LR: 0.000949
Training Epoch: 201 [128/50000]	Loss: 0.7174	LR: 0.000949
Training Epoch: 201 [128/50000]	Loss: 0.8863	LR: 0.000949
Evaluating Network.....
Test set: Epoch: 201, Average loss: 0.0108, Top1Accuracy: 0.6180, Top3Accuracy: 0.8179, Top5Accuracy: 0.8786, Time consumed:1.79s

Training Epoch: 202 [128/50000]	Loss: 0.9001	LR: 0.000924
Training Epoch: 202 [128/50000]	Loss: 0.8743	LR: 0.000924
Training Epoch: 202 [128/50000]	Loss: 0.8023	LR: 0.000924
Training Epoch: 202 [128/50000]	Loss: 0.8978	LR: 0.000924
Training Epoch: 202 [128/50000]	Loss: 0.8252	LR: 0.000924
Training Epoch: 202 [128/50000]	Loss: 0.9283	LR: 0.000924
Training Epoch: 202 [128/50000]	Loss: 0.8810	LR: 0.000924
Training Epoch: 202 [128/50000]	Loss: 0.8023	LR: 0.000924
Training Epoch: 202 [128/50000]	Loss: 0.9153	LR: 0.000924
Training Epoch: 202 [128/50000]	Loss: 0.8030	LR: 0.000924
Evaluating Network.....
Test set: Epoch: 202, Average loss: 0.0108, Top1Accuracy: 0.6182, Top3Accuracy: 0.8176, Top5Accuracy: 0.8795, Time consumed:1.78s

Training Epoch: 203 [128/50000]	Loss: 0.9345	LR: 0.000899
Training Epoch: 203 [128/50000]	Loss: 0.7591	LR: 0.000899
Training Epoch: 203 [128/50000]	Loss: 0.8969	LR: 0.000899
Training Epoch: 203 [128/50000]	Loss: 0.8942	LR: 0.000899
Training Epoch: 203 [128/50000]	Loss: 0.8933	LR: 0.000899
Training Epoch: 203 [128/50000]	Loss: 0.8391	LR: 0.000899
Training Epoch: 203 [128/50000]	Loss: 0.9829	LR: 0.000899
Training Epoch: 203 [128/50000]	Loss: 1.0790	LR: 0.000899
Training Epoch: 203 [128/50000]	Loss: 0.9152	LR: 0.000899
Training Epoch: 203 [128/50000]	Loss: 1.0749	LR: 0.000899
Evaluating Network.....
Test set: Epoch: 203, Average loss: 0.0108, Top1Accuracy: 0.6175, Top3Accuracy: 0.8164, Top5Accuracy: 0.8789, Time consumed:1.80s

Training Epoch: 204 [128/50000]	Loss: 1.0581	LR: 0.000876
Training Epoch: 204 [128/50000]	Loss: 0.7401	LR: 0.000876
Training Epoch: 204 [128/50000]	Loss: 0.8660	LR: 0.000876
Training Epoch: 204 [128/50000]	Loss: 0.9109	LR: 0.000876
Training Epoch: 204 [128/50000]	Loss: 0.9931	LR: 0.000876
Training Epoch: 204 [128/50000]	Loss: 0.8784	LR: 0.000876
Training Epoch: 204 [128/50000]	Loss: 0.9891	LR: 0.000876
Training Epoch: 204 [128/50000]	Loss: 0.9567	LR: 0.000876
Training Epoch: 204 [128/50000]	Loss: 0.8256	LR: 0.000876
Training Epoch: 204 [128/50000]	Loss: 1.0457	LR: 0.000876
Evaluating Network.....
Test set: Epoch: 204, Average loss: 0.0108, Top1Accuracy: 0.6189, Top3Accuracy: 0.8172, Top5Accuracy: 0.8796, Time consumed:1.80s

Training Epoch: 205 [128/50000]	Loss: 0.7457	LR: 0.000852
Training Epoch: 205 [128/50000]	Loss: 0.8114	LR: 0.000852
Training Epoch: 205 [128/50000]	Loss: 1.0241	LR: 0.000852
Training Epoch: 205 [128/50000]	Loss: 0.9610	LR: 0.000852
Training Epoch: 205 [128/50000]	Loss: 1.0271	LR: 0.000852
Training Epoch: 205 [128/50000]	Loss: 0.8873	LR: 0.000852
Training Epoch: 205 [128/50000]	Loss: 0.8918	LR: 0.000852
Training Epoch: 205 [128/50000]	Loss: 0.9819	LR: 0.000852
Training Epoch: 205 [128/50000]	Loss: 0.8724	LR: 0.000852
Training Epoch: 205 [128/50000]	Loss: 0.7650	LR: 0.000852
Evaluating Network.....
Test set: Epoch: 205, Average loss: 0.0108, Top1Accuracy: 0.6215, Top3Accuracy: 0.8175, Top5Accuracy: 0.8811, Time consumed:1.77s

Training Epoch: 206 [128/50000]	Loss: 1.0580	LR: 0.000830
Training Epoch: 206 [128/50000]	Loss: 1.1142	LR: 0.000830
Training Epoch: 206 [128/50000]	Loss: 0.7779	LR: 0.000830
Training Epoch: 206 [128/50000]	Loss: 1.1047	LR: 0.000830
Training Epoch: 206 [128/50000]	Loss: 0.8428	LR: 0.000830
Training Epoch: 206 [128/50000]	Loss: 0.8132	LR: 0.000830
Training Epoch: 206 [128/50000]	Loss: 0.9250	LR: 0.000830
Training Epoch: 206 [128/50000]	Loss: 0.7476	LR: 0.000830
Training Epoch: 206 [128/50000]	Loss: 0.9363	LR: 0.000830
Training Epoch: 206 [128/50000]	Loss: 0.9389	LR: 0.000830
Evaluating Network.....
Test set: Epoch: 206, Average loss: 0.0108, Top1Accuracy: 0.6202, Top3Accuracy: 0.8178, Top5Accuracy: 0.8807, Time consumed:1.98s

Training Epoch: 207 [128/50000]	Loss: 0.8322	LR: 0.000808
Training Epoch: 207 [128/50000]	Loss: 1.0180	LR: 0.000808
Training Epoch: 207 [128/50000]	Loss: 0.8360	LR: 0.000808
Training Epoch: 207 [128/50000]	Loss: 0.9493	LR: 0.000808
Training Epoch: 207 [128/50000]	Loss: 0.8214	LR: 0.000808
Training Epoch: 207 [128/50000]	Loss: 0.9949	LR: 0.000808
Training Epoch: 207 [128/50000]	Loss: 0.8762	LR: 0.000808
Training Epoch: 207 [128/50000]	Loss: 0.9527	LR: 0.000808
Training Epoch: 207 [128/50000]	Loss: 1.0835	LR: 0.000808
Training Epoch: 207 [128/50000]	Loss: 0.9513	LR: 0.000808
Evaluating Network.....
Test set: Epoch: 207, Average loss: 0.0107, Top1Accuracy: 0.6218, Top3Accuracy: 0.8168, Top5Accuracy: 0.8797, Time consumed:1.85s

Training Epoch: 208 [128/50000]	Loss: 0.8972	LR: 0.000787
Training Epoch: 208 [128/50000]	Loss: 0.8273	LR: 0.000787
Training Epoch: 208 [128/50000]	Loss: 0.8819	LR: 0.000787
Training Epoch: 208 [128/50000]	Loss: 0.8719	LR: 0.000787
Training Epoch: 208 [128/50000]	Loss: 0.6407	LR: 0.000787
Training Epoch: 208 [128/50000]	Loss: 0.7412	LR: 0.000787
Training Epoch: 208 [128/50000]	Loss: 0.8338	LR: 0.000787
Training Epoch: 208 [128/50000]	Loss: 1.0086	LR: 0.000787
Training Epoch: 208 [128/50000]	Loss: 0.8638	LR: 0.000787
Training Epoch: 208 [128/50000]	Loss: 1.0484	LR: 0.000787
Evaluating Network.....
Test set: Epoch: 208, Average loss: 0.0108, Top1Accuracy: 0.6217, Top3Accuracy: 0.8189, Top5Accuracy: 0.8804, Time consumed:1.79s

Training Epoch: 209 [128/50000]	Loss: 0.9264	LR: 0.000766
Training Epoch: 209 [128/50000]	Loss: 1.0013	LR: 0.000766
Training Epoch: 209 [128/50000]	Loss: 0.8895	LR: 0.000766
Training Epoch: 209 [128/50000]	Loss: 0.6956	LR: 0.000766
Training Epoch: 209 [128/50000]	Loss: 1.0522	LR: 0.000766
Training Epoch: 209 [128/50000]	Loss: 0.9368	LR: 0.000766
Training Epoch: 209 [128/50000]	Loss: 0.8577	LR: 0.000766
Training Epoch: 209 [128/50000]	Loss: 0.7021	LR: 0.000766
Training Epoch: 209 [128/50000]	Loss: 0.8187	LR: 0.000766
Training Epoch: 209 [128/50000]	Loss: 1.0650	LR: 0.000766
Evaluating Network.....
Test set: Epoch: 209, Average loss: 0.0108, Top1Accuracy: 0.6212, Top3Accuracy: 0.8185, Top5Accuracy: 0.8804, Time consumed:1.80s

Training Epoch: 210 [128/50000]	Loss: 0.9324	LR: 0.000746
Training Epoch: 210 [128/50000]	Loss: 0.8011	LR: 0.000746
Training Epoch: 210 [128/50000]	Loss: 0.8634	LR: 0.000746
Training Epoch: 210 [128/50000]	Loss: 0.9225	LR: 0.000746
Training Epoch: 210 [128/50000]	Loss: 0.9359	LR: 0.000746
Training Epoch: 210 [128/50000]	Loss: 1.0058	LR: 0.000746
Training Epoch: 210 [128/50000]	Loss: 0.9150	LR: 0.000746
Training Epoch: 210 [128/50000]	Loss: 0.9202	LR: 0.000746
Training Epoch: 210 [128/50000]	Loss: 0.9318	LR: 0.000746
Training Epoch: 210 [128/50000]	Loss: 0.9244	LR: 0.000746
Evaluating Network.....
Test set: Epoch: 210, Average loss: 0.0109, Top1Accuracy: 0.6202, Top3Accuracy: 0.8181, Top5Accuracy: 0.8810, Time consumed:1.80s

Training Epoch: 211 [128/50000]	Loss: 0.9084	LR: 0.000726
Training Epoch: 211 [128/50000]	Loss: 0.9007	LR: 0.000726
Training Epoch: 211 [128/50000]	Loss: 0.8298	LR: 0.000726
Training Epoch: 211 [128/50000]	Loss: 1.0459	LR: 0.000726
Training Epoch: 211 [128/50000]	Loss: 0.7719	LR: 0.000726
Training Epoch: 211 [128/50000]	Loss: 1.1322	LR: 0.000726
Training Epoch: 211 [128/50000]	Loss: 0.7942	LR: 0.000726
Training Epoch: 211 [128/50000]	Loss: 1.1223	LR: 0.000726
Training Epoch: 211 [128/50000]	Loss: 0.9622	LR: 0.000726
Training Epoch: 211 [128/50000]	Loss: 0.9212	LR: 0.000726
Evaluating Network.....
Test set: Epoch: 211, Average loss: 0.0108, Top1Accuracy: 0.6221, Top3Accuracy: 0.8183, Top5Accuracy: 0.8809, Time consumed:1.79s

Training Epoch: 212 [128/50000]	Loss: 0.8455	LR: 0.000707
Training Epoch: 212 [128/50000]	Loss: 0.8101	LR: 0.000707
Training Epoch: 212 [128/50000]	Loss: 0.8758	LR: 0.000707
Training Epoch: 212 [128/50000]	Loss: 0.7444	LR: 0.000707
Training Epoch: 212 [128/50000]	Loss: 0.9220	LR: 0.000707
Training Epoch: 212 [128/50000]	Loss: 1.1032	LR: 0.000707
Training Epoch: 212 [128/50000]	Loss: 0.7525	LR: 0.000707
Training Epoch: 212 [128/50000]	Loss: 0.7879	LR: 0.000707
Training Epoch: 212 [128/50000]	Loss: 0.7830	LR: 0.000707
Training Epoch: 212 [128/50000]	Loss: 1.0344	LR: 0.000707
Evaluating Network.....
Test set: Epoch: 212, Average loss: 0.0108, Top1Accuracy: 0.6202, Top3Accuracy: 0.8171, Top5Accuracy: 0.8806, Time consumed:1.79s

Training Epoch: 213 [128/50000]	Loss: 1.0438	LR: 0.000688
Training Epoch: 213 [128/50000]	Loss: 0.9335	LR: 0.000688
Training Epoch: 213 [128/50000]	Loss: 0.8711	LR: 0.000688
Training Epoch: 213 [128/50000]	Loss: 1.1141	LR: 0.000688
Training Epoch: 213 [128/50000]	Loss: 0.8496	LR: 0.000688
Training Epoch: 213 [128/50000]	Loss: 1.0138	LR: 0.000688
Training Epoch: 213 [128/50000]	Loss: 0.8627	LR: 0.000688
Training Epoch: 213 [128/50000]	Loss: 1.2262	LR: 0.000688
Training Epoch: 213 [128/50000]	Loss: 0.6444	LR: 0.000688
Training Epoch: 213 [128/50000]	Loss: 1.0184	LR: 0.000688
Evaluating Network.....
Test set: Epoch: 213, Average loss: 0.0108, Top1Accuracy: 0.6207, Top3Accuracy: 0.8172, Top5Accuracy: 0.8800, Time consumed:1.82s

Training Epoch: 214 [128/50000]	Loss: 1.0487	LR: 0.000670
Training Epoch: 214 [128/50000]	Loss: 0.7507	LR: 0.000670
Training Epoch: 214 [128/50000]	Loss: 0.8766	LR: 0.000670
Training Epoch: 214 [128/50000]	Loss: 0.9818	LR: 0.000670
Training Epoch: 214 [128/50000]	Loss: 1.0125	LR: 0.000670
Training Epoch: 214 [128/50000]	Loss: 0.8666	LR: 0.000670
Training Epoch: 214 [128/50000]	Loss: 1.1270	LR: 0.000670
Training Epoch: 214 [128/50000]	Loss: 0.8211	LR: 0.000670
Training Epoch: 214 [128/50000]	Loss: 0.9270	LR: 0.000670
Training Epoch: 214 [128/50000]	Loss: 0.8812	LR: 0.000670
Evaluating Network.....
Test set: Epoch: 214, Average loss: 0.0108, Top1Accuracy: 0.6208, Top3Accuracy: 0.8162, Top5Accuracy: 0.8804, Time consumed:1.78s

Training Epoch: 215 [128/50000]	Loss: 0.9581	LR: 0.000652
Training Epoch: 215 [128/50000]	Loss: 0.7158	LR: 0.000652
Training Epoch: 215 [128/50000]	Loss: 0.6835	LR: 0.000652
Training Epoch: 215 [128/50000]	Loss: 0.9769	LR: 0.000652
Training Epoch: 215 [128/50000]	Loss: 0.7113	LR: 0.000652
Training Epoch: 215 [128/50000]	Loss: 0.8818	LR: 0.000652
Training Epoch: 215 [128/50000]	Loss: 0.8817	LR: 0.000652
Training Epoch: 215 [128/50000]	Loss: 0.9007	LR: 0.000652
Training Epoch: 215 [128/50000]	Loss: 0.8679	LR: 0.000652
Training Epoch: 215 [128/50000]	Loss: 1.0071	LR: 0.000652
Evaluating Network.....
Test set: Epoch: 215, Average loss: 0.0108, Top1Accuracy: 0.6211, Top3Accuracy: 0.8192, Top5Accuracy: 0.8808, Time consumed:1.78s

Training Epoch: 216 [128/50000]	Loss: 1.0383	LR: 0.000635
Training Epoch: 216 [128/50000]	Loss: 0.9245	LR: 0.000635
Training Epoch: 216 [128/50000]	Loss: 1.0024	LR: 0.000635
Training Epoch: 216 [128/50000]	Loss: 0.8654	LR: 0.000635
Training Epoch: 216 [128/50000]	Loss: 0.6860	LR: 0.000635
Training Epoch: 216 [128/50000]	Loss: 0.9176	LR: 0.000635
Training Epoch: 216 [128/50000]	Loss: 0.9171	LR: 0.000635
Training Epoch: 216 [128/50000]	Loss: 0.8137	LR: 0.000635
Training Epoch: 216 [128/50000]	Loss: 0.9489	LR: 0.000635
Training Epoch: 216 [128/50000]	Loss: 0.9369	LR: 0.000635
Evaluating Network.....
Test set: Epoch: 216, Average loss: 0.0108, Top1Accuracy: 0.6216, Top3Accuracy: 0.8167, Top5Accuracy: 0.8806, Time consumed:1.78s

Training Epoch: 217 [128/50000]	Loss: 1.0422	LR: 0.000618
Training Epoch: 217 [128/50000]	Loss: 1.0685	LR: 0.000618
Training Epoch: 217 [128/50000]	Loss: 0.8487	LR: 0.000618
Training Epoch: 217 [128/50000]	Loss: 0.8037	LR: 0.000618
Training Epoch: 217 [128/50000]	Loss: 0.9553	LR: 0.000618
Training Epoch: 217 [128/50000]	Loss: 0.9369	LR: 0.000618
Training Epoch: 217 [128/50000]	Loss: 1.0716	LR: 0.000618
Training Epoch: 217 [128/50000]	Loss: 0.9542	LR: 0.000618
Training Epoch: 217 [128/50000]	Loss: 1.0494	LR: 0.000618
Training Epoch: 217 [128/50000]	Loss: 0.8963	LR: 0.000618
Evaluating Network.....
Test set: Epoch: 217, Average loss: 0.0108, Top1Accuracy: 0.6229, Top3Accuracy: 0.8175, Top5Accuracy: 0.8809, Time consumed:1.79s

Training Epoch: 218 [128/50000]	Loss: 0.8579	LR: 0.000602
Training Epoch: 218 [128/50000]	Loss: 0.9595	LR: 0.000602
Training Epoch: 218 [128/50000]	Loss: 0.8940	LR: 0.000602
Training Epoch: 218 [128/50000]	Loss: 0.7293	LR: 0.000602
Training Epoch: 218 [128/50000]	Loss: 0.8013	LR: 0.000602
Training Epoch: 218 [128/50000]	Loss: 0.9221	LR: 0.000602
Training Epoch: 218 [128/50000]	Loss: 0.8669	LR: 0.000602
Training Epoch: 218 [128/50000]	Loss: 0.7873	LR: 0.000602
Training Epoch: 218 [128/50000]	Loss: 0.9304	LR: 0.000602
Training Epoch: 218 [128/50000]	Loss: 0.8365	LR: 0.000602
Evaluating Network.....
Test set: Epoch: 218, Average loss: 0.0108, Top1Accuracy: 0.6204, Top3Accuracy: 0.8174, Top5Accuracy: 0.8794, Time consumed:1.78s

Training Epoch: 219 [128/50000]	Loss: 1.0499	LR: 0.000586
Training Epoch: 219 [128/50000]	Loss: 0.8784	LR: 0.000586
Training Epoch: 219 [128/50000]	Loss: 0.9315	LR: 0.000586
Training Epoch: 219 [128/50000]	Loss: 1.0813	LR: 0.000586
Training Epoch: 219 [128/50000]	Loss: 0.8170	LR: 0.000586
Training Epoch: 219 [128/50000]	Loss: 0.9364	LR: 0.000586
Training Epoch: 219 [128/50000]	Loss: 0.9623	LR: 0.000586
Training Epoch: 219 [128/50000]	Loss: 1.1883	LR: 0.000586
Training Epoch: 219 [128/50000]	Loss: 0.9073	LR: 0.000586
Training Epoch: 219 [128/50000]	Loss: 0.9001	LR: 0.000586
Evaluating Network.....
Test set: Epoch: 219, Average loss: 0.0108, Top1Accuracy: 0.6218, Top3Accuracy: 0.8186, Top5Accuracy: 0.8807, Time consumed:1.79s

Training Epoch: 220 [128/50000]	Loss: 0.8845	LR: 0.000571
Training Epoch: 220 [128/50000]	Loss: 0.9201	LR: 0.000571
Training Epoch: 220 [128/50000]	Loss: 1.0049	LR: 0.000571
Training Epoch: 220 [128/50000]	Loss: 0.9445	LR: 0.000571
Training Epoch: 220 [128/50000]	Loss: 0.8171	LR: 0.000571
Training Epoch: 220 [128/50000]	Loss: 1.1729	LR: 0.000571
Training Epoch: 220 [128/50000]	Loss: 0.8254	LR: 0.000571
Training Epoch: 220 [128/50000]	Loss: 0.9042	LR: 0.000571
Training Epoch: 220 [128/50000]	Loss: 0.6987	LR: 0.000571
Training Epoch: 220 [128/50000]	Loss: 0.7693	LR: 0.000571
Evaluating Network.....
Test set: Epoch: 220, Average loss: 0.0108, Top1Accuracy: 0.6207, Top3Accuracy: 0.8174, Top5Accuracy: 0.8800, Time consumed:1.80s

Training Epoch: 221 [128/50000]	Loss: 0.9875	LR: 0.000556
Training Epoch: 221 [128/50000]	Loss: 0.7081	LR: 0.000556
Training Epoch: 221 [128/50000]	Loss: 1.0003	LR: 0.000556
Training Epoch: 221 [128/50000]	Loss: 0.8130	LR: 0.000556
Training Epoch: 221 [128/50000]	Loss: 0.7271	LR: 0.000556
Training Epoch: 221 [128/50000]	Loss: 0.9457	LR: 0.000556
Training Epoch: 221 [128/50000]	Loss: 0.8646	LR: 0.000556
Training Epoch: 221 [128/50000]	Loss: 0.9477	LR: 0.000556
Training Epoch: 221 [128/50000]	Loss: 0.9146	LR: 0.000556
Training Epoch: 221 [128/50000]	Loss: 1.0177	LR: 0.000556
Evaluating Network.....
Test set: Epoch: 221, Average loss: 0.0108, Top1Accuracy: 0.6228, Top3Accuracy: 0.8183, Top5Accuracy: 0.8802, Time consumed:1.81s

Training Epoch: 222 [128/50000]	Loss: 0.9141	LR: 0.000541
Training Epoch: 222 [128/50000]	Loss: 0.7384	LR: 0.000541
Training Epoch: 222 [128/50000]	Loss: 0.8966	LR: 0.000541
Training Epoch: 222 [128/50000]	Loss: 0.9935	LR: 0.000541
Training Epoch: 222 [128/50000]	Loss: 0.9494	LR: 0.000541
Training Epoch: 222 [128/50000]	Loss: 0.7911	LR: 0.000541
Training Epoch: 222 [128/50000]	Loss: 1.1233	LR: 0.000541
Training Epoch: 222 [128/50000]	Loss: 0.9655	LR: 0.000541
Training Epoch: 222 [128/50000]	Loss: 0.9863	LR: 0.000541
Training Epoch: 222 [128/50000]	Loss: 0.9665	LR: 0.000541
Evaluating Network.....
Test set: Epoch: 222, Average loss: 0.0108, Top1Accuracy: 0.6228, Top3Accuracy: 0.8174, Top5Accuracy: 0.8801, Time consumed:1.79s

Training Epoch: 223 [128/50000]	Loss: 1.0463	LR: 0.000527
Training Epoch: 223 [128/50000]	Loss: 0.9906	LR: 0.000527
Training Epoch: 223 [128/50000]	Loss: 0.9205	LR: 0.000527
Training Epoch: 223 [128/50000]	Loss: 0.9602	LR: 0.000527
Training Epoch: 223 [128/50000]	Loss: 1.0018	LR: 0.000527
Training Epoch: 223 [128/50000]	Loss: 0.9859	LR: 0.000527
Training Epoch: 223 [128/50000]	Loss: 0.7876	LR: 0.000527
Training Epoch: 223 [128/50000]	Loss: 0.7573	LR: 0.000527
Training Epoch: 223 [128/50000]	Loss: 0.9338	LR: 0.000527
Training Epoch: 223 [128/50000]	Loss: 0.9884	LR: 0.000527
Evaluating Network.....
Test set: Epoch: 223, Average loss: 0.0108, Top1Accuracy: 0.6205, Top3Accuracy: 0.8179, Top5Accuracy: 0.8804, Time consumed:1.78s

Training Epoch: 224 [128/50000]	Loss: 1.1310	LR: 0.000513
Training Epoch: 224 [128/50000]	Loss: 0.7598	LR: 0.000513
Training Epoch: 224 [128/50000]	Loss: 0.9618	LR: 0.000513
Training Epoch: 224 [128/50000]	Loss: 1.0510	LR: 0.000513
Training Epoch: 224 [128/50000]	Loss: 1.0250	LR: 0.000513
Training Epoch: 224 [128/50000]	Loss: 1.0145	LR: 0.000513
Training Epoch: 224 [128/50000]	Loss: 0.9665	LR: 0.000513
Training Epoch: 224 [128/50000]	Loss: 1.1173	LR: 0.000513
Training Epoch: 224 [128/50000]	Loss: 1.0239	LR: 0.000513
Training Epoch: 224 [128/50000]	Loss: 0.8805	LR: 0.000513
Evaluating Network.....
Test set: Epoch: 224, Average loss: 0.0109, Top1Accuracy: 0.6210, Top3Accuracy: 0.8191, Top5Accuracy: 0.8801, Time consumed:1.79s

Training Epoch: 225 [128/50000]	Loss: 0.8331	LR: 0.000499
Training Epoch: 225 [128/50000]	Loss: 0.9321	LR: 0.000499
Training Epoch: 225 [128/50000]	Loss: 0.9895	LR: 0.000499
Training Epoch: 225 [128/50000]	Loss: 1.0253	LR: 0.000499
Training Epoch: 225 [128/50000]	Loss: 0.9552	LR: 0.000499
Training Epoch: 225 [128/50000]	Loss: 0.8867	LR: 0.000499
Training Epoch: 225 [128/50000]	Loss: 0.9414	LR: 0.000499
Training Epoch: 225 [128/50000]	Loss: 0.9397	LR: 0.000499
Training Epoch: 225 [128/50000]	Loss: 0.9621	LR: 0.000499
Training Epoch: 225 [128/50000]	Loss: 0.6997	LR: 0.000499
Evaluating Network.....
Test set: Epoch: 225, Average loss: 0.0108, Top1Accuracy: 0.6218, Top3Accuracy: 0.8193, Top5Accuracy: 0.8813, Time consumed:1.78s

Training Epoch: 226 [128/50000]	Loss: 0.7767	LR: 0.000486
Training Epoch: 226 [128/50000]	Loss: 0.7789	LR: 0.000486
Training Epoch: 226 [128/50000]	Loss: 0.9352	LR: 0.000486
Training Epoch: 226 [128/50000]	Loss: 0.9759	LR: 0.000486
Training Epoch: 226 [128/50000]	Loss: 0.9348	LR: 0.000486
Training Epoch: 226 [128/50000]	Loss: 0.9714	LR: 0.000486
Training Epoch: 226 [128/50000]	Loss: 0.7616	LR: 0.000486
Training Epoch: 226 [128/50000]	Loss: 1.0163	LR: 0.000486
Training Epoch: 226 [128/50000]	Loss: 0.8661	LR: 0.000486
Training Epoch: 226 [128/50000]	Loss: 0.8844	LR: 0.000486
Evaluating Network.....
Test set: Epoch: 226, Average loss: 0.0108, Top1Accuracy: 0.6216, Top3Accuracy: 0.8194, Top5Accuracy: 0.8812, Time consumed:1.81s

Training Epoch: 227 [128/50000]	Loss: 0.7884	LR: 0.000473
Training Epoch: 227 [128/50000]	Loss: 0.7104	LR: 0.000473
Training Epoch: 227 [128/50000]	Loss: 0.8535	LR: 0.000473
Training Epoch: 227 [128/50000]	Loss: 0.8335	LR: 0.000473
Training Epoch: 227 [128/50000]	Loss: 0.8568	LR: 0.000473
Training Epoch: 227 [128/50000]	Loss: 0.8470	LR: 0.000473
Training Epoch: 227 [128/50000]	Loss: 1.0249	LR: 0.000473
Training Epoch: 227 [128/50000]	Loss: 0.9528	LR: 0.000473
Training Epoch: 227 [128/50000]	Loss: 1.0951	LR: 0.000473
Training Epoch: 227 [128/50000]	Loss: 0.8526	LR: 0.000473
Evaluating Network.....
Test set: Epoch: 227, Average loss: 0.0109, Top1Accuracy: 0.6198, Top3Accuracy: 0.8189, Top5Accuracy: 0.8810, Time consumed:1.79s

Training Epoch: 228 [128/50000]	Loss: 0.8302	LR: 0.000461
Training Epoch: 228 [128/50000]	Loss: 0.8719	LR: 0.000461
Training Epoch: 228 [128/50000]	Loss: 0.8538	LR: 0.000461
Training Epoch: 228 [128/50000]	Loss: 0.9749	LR: 0.000461
Training Epoch: 228 [128/50000]	Loss: 1.0963	LR: 0.000461
Training Epoch: 228 [128/50000]	Loss: 0.8495	LR: 0.000461
Training Epoch: 228 [128/50000]	Loss: 1.0162	LR: 0.000461
Training Epoch: 228 [128/50000]	Loss: 0.7743	LR: 0.000461
Training Epoch: 228 [128/50000]	Loss: 0.7993	LR: 0.000461
Training Epoch: 228 [128/50000]	Loss: 0.8683	LR: 0.000461
Evaluating Network.....
Test set: Epoch: 228, Average loss: 0.0108, Top1Accuracy: 0.6199, Top3Accuracy: 0.8186, Top5Accuracy: 0.8811, Time consumed:1.79s

Training Epoch: 229 [128/50000]	Loss: 1.0057	LR: 0.000449
Training Epoch: 229 [128/50000]	Loss: 0.9587	LR: 0.000449
Training Epoch: 229 [128/50000]	Loss: 0.9119	LR: 0.000449
Training Epoch: 229 [128/50000]	Loss: 1.1082	LR: 0.000449
Training Epoch: 229 [128/50000]	Loss: 0.8748	LR: 0.000449
Training Epoch: 229 [128/50000]	Loss: 0.9431	LR: 0.000449
Training Epoch: 229 [128/50000]	Loss: 0.8014	LR: 0.000449
Training Epoch: 229 [128/50000]	Loss: 0.8147	LR: 0.000449
Training Epoch: 229 [128/50000]	Loss: 0.7327	LR: 0.000449
Training Epoch: 229 [128/50000]	Loss: 0.9735	LR: 0.000449
Evaluating Network.....
Test set: Epoch: 229, Average loss: 0.0107, Top1Accuracy: 0.6212, Top3Accuracy: 0.8187, Top5Accuracy: 0.8813, Time consumed:1.79s

Training Epoch: 230 [128/50000]	Loss: 1.0197	LR: 0.000437
Training Epoch: 230 [128/50000]	Loss: 0.9606	LR: 0.000437
Training Epoch: 230 [128/50000]	Loss: 0.9981	LR: 0.000437
Training Epoch: 230 [128/50000]	Loss: 0.8944	LR: 0.000437
Training Epoch: 230 [128/50000]	Loss: 1.0840	LR: 0.000437
Training Epoch: 230 [128/50000]	Loss: 0.6508	LR: 0.000437
Training Epoch: 230 [128/50000]	Loss: 0.8269	LR: 0.000437
Training Epoch: 230 [128/50000]	Loss: 0.9475	LR: 0.000437
Training Epoch: 230 [128/50000]	Loss: 0.9671	LR: 0.000437
Training Epoch: 230 [128/50000]	Loss: 0.9427	LR: 0.000437
Evaluating Network.....
Test set: Epoch: 230, Average loss: 0.0109, Top1Accuracy: 0.6227, Top3Accuracy: 0.8182, Top5Accuracy: 0.8813, Time consumed:2.08s

Training Epoch: 231 [128/50000]	Loss: 0.7855	LR: 0.000425
Training Epoch: 231 [128/50000]	Loss: 0.8601	LR: 0.000425
Training Epoch: 231 [128/50000]	Loss: 1.0004	LR: 0.000425
Training Epoch: 231 [128/50000]	Loss: 0.7297	LR: 0.000425
Training Epoch: 231 [128/50000]	Loss: 0.8101	LR: 0.000425
Training Epoch: 231 [128/50000]	Loss: 0.9448	LR: 0.000425
Training Epoch: 231 [128/50000]	Loss: 0.9132	LR: 0.000425
Training Epoch: 231 [128/50000]	Loss: 0.9809	LR: 0.000425
Training Epoch: 231 [128/50000]	Loss: 0.7238	LR: 0.000425
Training Epoch: 231 [128/50000]	Loss: 0.9760	LR: 0.000425
Evaluating Network.....
Test set: Epoch: 231, Average loss: 0.0109, Top1Accuracy: 0.6218, Top3Accuracy: 0.8170, Top5Accuracy: 0.8797, Time consumed:2.18s

Training Epoch: 232 [128/50000]	Loss: 0.9923	LR: 0.000414
Training Epoch: 232 [128/50000]	Loss: 0.7802	LR: 0.000414
Training Epoch: 232 [128/50000]	Loss: 1.0599	LR: 0.000414
Training Epoch: 232 [128/50000]	Loss: 0.7293	LR: 0.000414
Training Epoch: 232 [128/50000]	Loss: 1.0748	LR: 0.000414
Training Epoch: 232 [128/50000]	Loss: 0.9980	LR: 0.000414
Training Epoch: 232 [128/50000]	Loss: 0.8494	LR: 0.000414
Training Epoch: 232 [128/50000]	Loss: 0.9476	LR: 0.000414
Training Epoch: 232 [128/50000]	Loss: 0.8108	LR: 0.000414
Training Epoch: 232 [128/50000]	Loss: 0.7682	LR: 0.000414
Evaluating Network.....
Test set: Epoch: 232, Average loss: 0.0108, Top1Accuracy: 0.6222, Top3Accuracy: 0.8177, Top5Accuracy: 0.8800, Time consumed:1.82s

Training Epoch: 233 [128/50000]	Loss: 0.9556	LR: 0.000403
Training Epoch: 233 [128/50000]	Loss: 0.8947	LR: 0.000403
Training Epoch: 233 [128/50000]	Loss: 0.9343	LR: 0.000403
Training Epoch: 233 [128/50000]	Loss: 0.8644	LR: 0.000403
Training Epoch: 233 [128/50000]	Loss: 1.0336	LR: 0.000403
Training Epoch: 233 [128/50000]	Loss: 0.9057	LR: 0.000403
Training Epoch: 233 [128/50000]	Loss: 0.8310	LR: 0.000403
Training Epoch: 233 [128/50000]	Loss: 0.8991	LR: 0.000403
Training Epoch: 233 [128/50000]	Loss: 0.9520	LR: 0.000403
Training Epoch: 233 [128/50000]	Loss: 0.9637	LR: 0.000403
Evaluating Network.....
Test set: Epoch: 233, Average loss: 0.0108, Top1Accuracy: 0.6220, Top3Accuracy: 0.8183, Top5Accuracy: 0.8801, Time consumed:1.80s

Training Epoch: 234 [128/50000]	Loss: 0.8302	LR: 0.000392
Training Epoch: 234 [128/50000]	Loss: 0.6815	LR: 0.000392
Training Epoch: 234 [128/50000]	Loss: 0.8038	LR: 0.000392
Training Epoch: 234 [128/50000]	Loss: 0.8281	LR: 0.000392
Training Epoch: 234 [128/50000]	Loss: 0.8761	LR: 0.000392
Training Epoch: 234 [128/50000]	Loss: 1.0990	LR: 0.000392
Training Epoch: 234 [128/50000]	Loss: 0.8509	LR: 0.000392
Training Epoch: 234 [128/50000]	Loss: 1.0154	LR: 0.000392
Training Epoch: 234 [128/50000]	Loss: 0.9353	LR: 0.000392
Training Epoch: 234 [128/50000]	Loss: 0.6649	LR: 0.000392
Evaluating Network.....
Test set: Epoch: 234, Average loss: 0.0108, Top1Accuracy: 0.6215, Top3Accuracy: 0.8169, Top5Accuracy: 0.8801, Time consumed:1.78s

Training Epoch: 235 [128/50000]	Loss: 0.8096	LR: 0.000382
Training Epoch: 235 [128/50000]	Loss: 0.9546	LR: 0.000382
Training Epoch: 235 [128/50000]	Loss: 0.9823	LR: 0.000382
Training Epoch: 235 [128/50000]	Loss: 0.7735	LR: 0.000382
Training Epoch: 235 [128/50000]	Loss: 0.9841	LR: 0.000382
Training Epoch: 235 [128/50000]	Loss: 1.0494	LR: 0.000382
Training Epoch: 235 [128/50000]	Loss: 0.7823	LR: 0.000382
Training Epoch: 235 [128/50000]	Loss: 0.7959	LR: 0.000382
Training Epoch: 235 [128/50000]	Loss: 0.8263	LR: 0.000382
Training Epoch: 235 [128/50000]	Loss: 0.9117	LR: 0.000382
Evaluating Network.....
Test set: Epoch: 235, Average loss: 0.0108, Top1Accuracy: 0.6213, Top3Accuracy: 0.8176, Top5Accuracy: 0.8808, Time consumed:1.80s

Training Epoch: 236 [128/50000]	Loss: 0.7545	LR: 0.000372
Training Epoch: 236 [128/50000]	Loss: 1.0143	LR: 0.000372
Training Epoch: 236 [128/50000]	Loss: 0.9099	LR: 0.000372
Training Epoch: 236 [128/50000]	Loss: 0.9518	LR: 0.000372
Training Epoch: 236 [128/50000]	Loss: 0.8087	LR: 0.000372
Training Epoch: 236 [128/50000]	Loss: 0.8250	LR: 0.000372
Training Epoch: 236 [128/50000]	Loss: 0.7510	LR: 0.000372
Training Epoch: 236 [128/50000]	Loss: 1.0316	LR: 0.000372
Training Epoch: 236 [128/50000]	Loss: 0.9214	LR: 0.000372
Training Epoch: 236 [128/50000]	Loss: 1.0044	LR: 0.000372
Evaluating Network.....
Test set: Epoch: 236, Average loss: 0.0108, Top1Accuracy: 0.6215, Top3Accuracy: 0.8185, Top5Accuracy: 0.8817, Time consumed:1.80s

Training Epoch: 237 [128/50000]	Loss: 0.9849	LR: 0.000362
Training Epoch: 237 [128/50000]	Loss: 0.9911	LR: 0.000362
Training Epoch: 237 [128/50000]	Loss: 0.9694	LR: 0.000362
Training Epoch: 237 [128/50000]	Loss: 1.1094	LR: 0.000362
Training Epoch: 237 [128/50000]	Loss: 1.0757	LR: 0.000362
Training Epoch: 237 [128/50000]	Loss: 0.9362	LR: 0.000362
Training Epoch: 237 [128/50000]	Loss: 0.8716	LR: 0.000362
Training Epoch: 237 [128/50000]	Loss: 0.9968	LR: 0.000362
Training Epoch: 237 [128/50000]	Loss: 0.9135	LR: 0.000362
Training Epoch: 237 [128/50000]	Loss: 0.8312	LR: 0.000362
Evaluating Network.....
Test set: Epoch: 237, Average loss: 0.0108, Top1Accuracy: 0.6215, Top3Accuracy: 0.8180, Top5Accuracy: 0.8807, Time consumed:1.80s

Training Epoch: 238 [128/50000]	Loss: 1.0238	LR: 0.000353
Training Epoch: 238 [128/50000]	Loss: 0.9156	LR: 0.000353
Training Epoch: 238 [128/50000]	Loss: 0.9149	LR: 0.000353
Training Epoch: 238 [128/50000]	Loss: 0.9104	LR: 0.000353
Training Epoch: 238 [128/50000]	Loss: 1.1697	LR: 0.000353
Training Epoch: 238 [128/50000]	Loss: 0.8995	LR: 0.000353
Training Epoch: 238 [128/50000]	Loss: 1.0398	LR: 0.000353
Training Epoch: 238 [128/50000]	Loss: 0.6862	LR: 0.000353
Training Epoch: 238 [128/50000]	Loss: 0.8924	LR: 0.000353
Training Epoch: 238 [128/50000]	Loss: 0.8988	LR: 0.000353
Evaluating Network.....
Test set: Epoch: 238, Average loss: 0.0108, Top1Accuracy: 0.6216, Top3Accuracy: 0.8184, Top5Accuracy: 0.8805, Time consumed:1.79s

Training Epoch: 239 [128/50000]	Loss: 1.1111	LR: 0.000343
Training Epoch: 239 [128/50000]	Loss: 0.7866	LR: 0.000343
Training Epoch: 239 [128/50000]	Loss: 0.8982	LR: 0.000343
Training Epoch: 239 [128/50000]	Loss: 0.9754	LR: 0.000343
Training Epoch: 239 [128/50000]	Loss: 0.6969	LR: 0.000343
Training Epoch: 239 [128/50000]	Loss: 1.3215	LR: 0.000343
Training Epoch: 239 [128/50000]	Loss: 0.8834	LR: 0.000343
Training Epoch: 239 [128/50000]	Loss: 0.9397	LR: 0.000343
Training Epoch: 239 [128/50000]	Loss: 1.2147	LR: 0.000343
Training Epoch: 239 [128/50000]	Loss: 0.9040	LR: 0.000343
Evaluating Network.....
Test set: Epoch: 239, Average loss: 0.0108, Top1Accuracy: 0.6217, Top3Accuracy: 0.8183, Top5Accuracy: 0.8807, Time consumed:1.80s

Training Epoch: 240 [128/50000]	Loss: 0.8454	LR: 0.000334
Training Epoch: 240 [128/50000]	Loss: 0.7907	LR: 0.000334
Training Epoch: 240 [128/50000]	Loss: 0.8111	LR: 0.000334
Training Epoch: 240 [128/50000]	Loss: 0.9290	LR: 0.000334
Training Epoch: 240 [128/50000]	Loss: 0.9444	LR: 0.000334
Training Epoch: 240 [128/50000]	Loss: 0.7943	LR: 0.000334
Training Epoch: 240 [128/50000]	Loss: 0.9457	LR: 0.000334
Training Epoch: 240 [128/50000]	Loss: 0.8939	LR: 0.000334
Training Epoch: 240 [128/50000]	Loss: 0.9425	LR: 0.000334
Training Epoch: 240 [128/50000]	Loss: 1.0010	LR: 0.000334
Evaluating Network.....
Test set: Epoch: 240, Average loss: 0.0108, Top1Accuracy: 0.6219, Top3Accuracy: 0.8194, Top5Accuracy: 0.8804, Time consumed:1.80s

Training Epoch: 241 [128/50000]	Loss: 1.0072	LR: 0.000325
Training Epoch: 241 [128/50000]	Loss: 1.0664	LR: 0.000325
Training Epoch: 241 [128/50000]	Loss: 0.9237	LR: 0.000325
Training Epoch: 241 [128/50000]	Loss: 0.8127	LR: 0.000325
Training Epoch: 241 [128/50000]	Loss: 0.9257	LR: 0.000325
Training Epoch: 241 [128/50000]	Loss: 0.8758	LR: 0.000325
Training Epoch: 241 [128/50000]	Loss: 0.9387	LR: 0.000325
Training Epoch: 241 [128/50000]	Loss: 0.8398	LR: 0.000325
Training Epoch: 241 [128/50000]	Loss: 0.8477	LR: 0.000325
Training Epoch: 241 [128/50000]	Loss: 0.8909	LR: 0.000325
Evaluating Network.....
Test set: Epoch: 241, Average loss: 0.0108, Top1Accuracy: 0.6211, Top3Accuracy: 0.8200, Top5Accuracy: 0.8809, Time consumed:1.81s

Training Epoch: 242 [128/50000]	Loss: 0.9386	LR: 0.000317
Training Epoch: 242 [128/50000]	Loss: 0.8557	LR: 0.000317
Training Epoch: 242 [128/50000]	Loss: 1.0362	LR: 0.000317
Training Epoch: 242 [128/50000]	Loss: 1.0147	LR: 0.000317
Training Epoch: 242 [128/50000]	Loss: 0.8000	LR: 0.000317
Training Epoch: 242 [128/50000]	Loss: 0.8403	LR: 0.000317
Training Epoch: 242 [128/50000]	Loss: 1.0343	LR: 0.000317
Training Epoch: 242 [128/50000]	Loss: 0.9490	LR: 0.000317
Training Epoch: 242 [128/50000]	Loss: 0.8362	LR: 0.000317
Training Epoch: 242 [128/50000]	Loss: 0.9545	LR: 0.000317
Evaluating Network.....
Test set: Epoch: 242, Average loss: 0.0108, Top1Accuracy: 0.6203, Top3Accuracy: 0.8187, Top5Accuracy: 0.8805, Time consumed:1.80s

Training Epoch: 243 [128/50000]	Loss: 0.8822	LR: 0.000308
Training Epoch: 243 [128/50000]	Loss: 0.8156	LR: 0.000308
Training Epoch: 243 [128/50000]	Loss: 1.2763	LR: 0.000308
Training Epoch: 243 [128/50000]	Loss: 0.8918	LR: 0.000308
Training Epoch: 243 [128/50000]	Loss: 1.0024	LR: 0.000308
Training Epoch: 243 [128/50000]	Loss: 0.8586	LR: 0.000308
Training Epoch: 243 [128/50000]	Loss: 0.6578	LR: 0.000308
Training Epoch: 243 [128/50000]	Loss: 0.8239	LR: 0.000308
Training Epoch: 243 [128/50000]	Loss: 0.8262	LR: 0.000308
Training Epoch: 243 [128/50000]	Loss: 0.7304	LR: 0.000308
Evaluating Network.....
Test set: Epoch: 243, Average loss: 0.0108, Top1Accuracy: 0.6205, Top3Accuracy: 0.8181, Top5Accuracy: 0.8804, Time consumed:1.78s

Training Epoch: 244 [128/50000]	Loss: 0.8299	LR: 0.000300
Training Epoch: 244 [128/50000]	Loss: 0.8833	LR: 0.000300
Training Epoch: 244 [128/50000]	Loss: 0.8060	LR: 0.000300
Training Epoch: 244 [128/50000]	Loss: 0.9349	LR: 0.000300
Training Epoch: 244 [128/50000]	Loss: 0.9502	LR: 0.000300
Training Epoch: 244 [128/50000]	Loss: 0.8749	LR: 0.000300
Training Epoch: 244 [128/50000]	Loss: 0.8552	LR: 0.000300
Training Epoch: 244 [128/50000]	Loss: 0.9608	LR: 0.000300
Training Epoch: 244 [128/50000]	Loss: 0.9370	LR: 0.000300
Training Epoch: 244 [128/50000]	Loss: 0.8102	LR: 0.000300
Evaluating Network.....
Test set: Epoch: 244, Average loss: 0.0108, Top1Accuracy: 0.6222, Top3Accuracy: 0.8205, Top5Accuracy: 0.8812, Time consumed:1.78s

Training Epoch: 245 [128/50000]	Loss: 0.9377	LR: 0.000292
Training Epoch: 245 [128/50000]	Loss: 0.8412	LR: 0.000292
Training Epoch: 245 [128/50000]	Loss: 0.8437	LR: 0.000292
Training Epoch: 245 [128/50000]	Loss: 0.9967	LR: 0.000292
Training Epoch: 245 [128/50000]	Loss: 0.7699	LR: 0.000292
Training Epoch: 245 [128/50000]	Loss: 0.9173	LR: 0.000292
Training Epoch: 245 [128/50000]	Loss: 0.9729	LR: 0.000292
Training Epoch: 245 [128/50000]	Loss: 0.8405	LR: 0.000292
Training Epoch: 245 [128/50000]	Loss: 0.8672	LR: 0.000292
Training Epoch: 245 [128/50000]	Loss: 0.7829	LR: 0.000292
Evaluating Network.....
Test set: Epoch: 245, Average loss: 0.0107, Top1Accuracy: 0.6197, Top3Accuracy: 0.8200, Top5Accuracy: 0.8805, Time consumed:1.78s

Training Epoch: 246 [128/50000]	Loss: 1.0286	LR: 0.000285
Training Epoch: 246 [128/50000]	Loss: 0.8398	LR: 0.000285
Training Epoch: 246 [128/50000]	Loss: 0.9455	LR: 0.000285
Training Epoch: 246 [128/50000]	Loss: 0.6661	LR: 0.000285
Training Epoch: 246 [128/50000]	Loss: 0.8900	LR: 0.000285
Training Epoch: 246 [128/50000]	Loss: 0.8644	LR: 0.000285
Training Epoch: 246 [128/50000]	Loss: 0.9944	LR: 0.000285
Training Epoch: 246 [128/50000]	Loss: 0.9089	LR: 0.000285
Training Epoch: 246 [128/50000]	Loss: 0.8765	LR: 0.000285
Training Epoch: 246 [128/50000]	Loss: 0.8022	LR: 0.000285
Evaluating Network.....
Test set: Epoch: 246, Average loss: 0.0108, Top1Accuracy: 0.6218, Top3Accuracy: 0.8184, Top5Accuracy: 0.8805, Time consumed:1.80s

Training Epoch: 247 [128/50000]	Loss: 0.8986	LR: 0.000277
Training Epoch: 247 [128/50000]	Loss: 0.8215	LR: 0.000277
Training Epoch: 247 [128/50000]	Loss: 0.9222	LR: 0.000277
Training Epoch: 247 [128/50000]	Loss: 0.7945	LR: 0.000277
Training Epoch: 247 [128/50000]	Loss: 0.8684	LR: 0.000277
Training Epoch: 247 [128/50000]	Loss: 0.7392	LR: 0.000277
Training Epoch: 247 [128/50000]	Loss: 0.7934	LR: 0.000277
Training Epoch: 247 [128/50000]	Loss: 0.8451	LR: 0.000277
Training Epoch: 247 [128/50000]	Loss: 0.8490	LR: 0.000277
Training Epoch: 247 [128/50000]	Loss: 0.7420	LR: 0.000277
Evaluating Network.....
Test set: Epoch: 247, Average loss: 0.0109, Top1Accuracy: 0.6201, Top3Accuracy: 0.8186, Top5Accuracy: 0.8805, Time consumed:1.81s

Training Epoch: 248 [128/50000]	Loss: 0.9843	LR: 0.000270
Training Epoch: 248 [128/50000]	Loss: 0.8989	LR: 0.000270
Training Epoch: 248 [128/50000]	Loss: 0.7928	LR: 0.000270
Training Epoch: 248 [128/50000]	Loss: 0.9020	LR: 0.000270
Training Epoch: 248 [128/50000]	Loss: 0.7432	LR: 0.000270
Training Epoch: 248 [128/50000]	Loss: 0.8991	LR: 0.000270
Training Epoch: 248 [128/50000]	Loss: 1.0046	LR: 0.000270
Training Epoch: 248 [128/50000]	Loss: 0.9575	LR: 0.000270
Training Epoch: 248 [128/50000]	Loss: 0.9243	LR: 0.000270
Training Epoch: 248 [128/50000]	Loss: 0.7994	LR: 0.000270
Evaluating Network.....
Test set: Epoch: 248, Average loss: 0.0108, Top1Accuracy: 0.6207, Top3Accuracy: 0.8182, Top5Accuracy: 0.8805, Time consumed:2.04s

Training Epoch: 249 [128/50000]	Loss: 0.8640	LR: 0.000263
Training Epoch: 249 [128/50000]	Loss: 0.8834	LR: 0.000263
Training Epoch: 249 [128/50000]	Loss: 0.8229	LR: 0.000263
Training Epoch: 249 [128/50000]	Loss: 0.9624	LR: 0.000263
Training Epoch: 249 [128/50000]	Loss: 0.7890	LR: 0.000263
Training Epoch: 249 [128/50000]	Loss: 0.8393	LR: 0.000263
Training Epoch: 249 [128/50000]	Loss: 0.9399	LR: 0.000263
Training Epoch: 249 [128/50000]	Loss: 0.7558	LR: 0.000263
Training Epoch: 249 [128/50000]	Loss: 0.9490	LR: 0.000263
Training Epoch: 249 [128/50000]	Loss: 0.7547	LR: 0.000263
Evaluating Network.....
Test set: Epoch: 249, Average loss: 0.0108, Top1Accuracy: 0.6213, Top3Accuracy: 0.8191, Top5Accuracy: 0.8807, Time consumed:1.97s

Training Epoch: 250 [128/50000]	Loss: 0.8868	LR: 0.000256
Training Epoch: 250 [128/50000]	Loss: 0.8117	LR: 0.000256
Training Epoch: 250 [128/50000]	Loss: 0.7107	LR: 0.000256
Training Epoch: 250 [128/50000]	Loss: 0.8542	LR: 0.000256
Training Epoch: 250 [128/50000]	Loss: 0.9173	LR: 0.000256
Training Epoch: 250 [128/50000]	Loss: 1.0515	LR: 0.000256
Training Epoch: 250 [128/50000]	Loss: 0.9759	LR: 0.000256
Training Epoch: 250 [128/50000]	Loss: 0.7041	LR: 0.000256
Training Epoch: 250 [128/50000]	Loss: 0.8595	LR: 0.000256
Training Epoch: 250 [128/50000]	Loss: 0.8502	LR: 0.000256
Evaluating Network.....
Test set: Epoch: 250, Average loss: 0.0108, Top1Accuracy: 0.6206, Top3Accuracy: 0.8189, Top5Accuracy: 0.8804, Time consumed:1.81s

Training Epoch: 251 [128/50000]	Loss: 0.8682	LR: 0.000249
Training Epoch: 251 [128/50000]	Loss: 0.9718	LR: 0.000249
Training Epoch: 251 [128/50000]	Loss: 0.9303	LR: 0.000249
Training Epoch: 251 [128/50000]	Loss: 0.9353	LR: 0.000249
Training Epoch: 251 [128/50000]	Loss: 0.9197	LR: 0.000249
Training Epoch: 251 [128/50000]	Loss: 0.8610	LR: 0.000249
Training Epoch: 251 [128/50000]	Loss: 0.9666	LR: 0.000249
Training Epoch: 251 [128/50000]	Loss: 0.9331	LR: 0.000249
Training Epoch: 251 [128/50000]	Loss: 0.8298	LR: 0.000249
Training Epoch: 251 [128/50000]	Loss: 0.8849	LR: 0.000249
Evaluating Network.....
Test set: Epoch: 251, Average loss: 0.0107, Top1Accuracy: 0.6208, Top3Accuracy: 0.8192, Top5Accuracy: 0.8809, Time consumed:1.78s

Training Epoch: 252 [128/50000]	Loss: 0.8021	LR: 0.000242
Training Epoch: 252 [128/50000]	Loss: 0.8762	LR: 0.000242
Training Epoch: 252 [128/50000]	Loss: 0.8670	LR: 0.000242
Training Epoch: 252 [128/50000]	Loss: 0.8294	LR: 0.000242
Training Epoch: 252 [128/50000]	Loss: 0.9840	LR: 0.000242
Training Epoch: 252 [128/50000]	Loss: 0.9788	LR: 0.000242
Training Epoch: 252 [128/50000]	Loss: 0.9287	LR: 0.000242
Training Epoch: 252 [128/50000]	Loss: 0.9266	LR: 0.000242
Training Epoch: 252 [128/50000]	Loss: 0.8921	LR: 0.000242
Training Epoch: 252 [128/50000]	Loss: 0.9789	LR: 0.000242
Evaluating Network.....
Test set: Epoch: 252, Average loss: 0.0107, Top1Accuracy: 0.6220, Top3Accuracy: 0.8184, Top5Accuracy: 0.8802, Time consumed:1.80s

Training Epoch: 253 [128/50000]	Loss: 0.7178	LR: 0.000236
Training Epoch: 253 [128/50000]	Loss: 0.8957	LR: 0.000236
Training Epoch: 253 [128/50000]	Loss: 0.8024	LR: 0.000236
Training Epoch: 253 [128/50000]	Loss: 0.9023	LR: 0.000236
Training Epoch: 253 [128/50000]	Loss: 0.7907	LR: 0.000236
Training Epoch: 253 [128/50000]	Loss: 0.8267	LR: 0.000236
Training Epoch: 253 [128/50000]	Loss: 0.8055	LR: 0.000236
Training Epoch: 253 [128/50000]	Loss: 0.8269	LR: 0.000236
Training Epoch: 253 [128/50000]	Loss: 0.8842	LR: 0.000236
Training Epoch: 253 [128/50000]	Loss: 0.9426	LR: 0.000236
Evaluating Network.....
Test set: Epoch: 253, Average loss: 0.0109, Top1Accuracy: 0.6215, Top3Accuracy: 0.8193, Top5Accuracy: 0.8802, Time consumed:1.77s

Training Epoch: 254 [128/50000]	Loss: 0.9936	LR: 0.000230
Training Epoch: 254 [128/50000]	Loss: 0.8171	LR: 0.000230
Training Epoch: 254 [128/50000]	Loss: 0.7341	LR: 0.000230
Training Epoch: 254 [128/50000]	Loss: 0.9561	LR: 0.000230
Training Epoch: 254 [128/50000]	Loss: 0.9102	LR: 0.000230
Training Epoch: 254 [128/50000]	Loss: 0.8772	LR: 0.000230
Training Epoch: 254 [128/50000]	Loss: 0.9205	LR: 0.000230
Training Epoch: 254 [128/50000]	Loss: 0.8845	LR: 0.000230
Training Epoch: 254 [128/50000]	Loss: 0.7644	LR: 0.000230
Training Epoch: 254 [128/50000]	Loss: 0.9722	LR: 0.000230
Evaluating Network.....
Test set: Epoch: 254, Average loss: 0.0108, Top1Accuracy: 0.6212, Top3Accuracy: 0.8194, Top5Accuracy: 0.8802, Time consumed:1.79s

Training Epoch: 255 [128/50000]	Loss: 0.7846	LR: 0.000224
Training Epoch: 255 [128/50000]	Loss: 0.9160	LR: 0.000224
Training Epoch: 255 [128/50000]	Loss: 0.9560	LR: 0.000224
Training Epoch: 255 [128/50000]	Loss: 0.9509	LR: 0.000224
Training Epoch: 255 [128/50000]	Loss: 0.8715	LR: 0.000224
Training Epoch: 255 [128/50000]	Loss: 0.9798	LR: 0.000224
Training Epoch: 255 [128/50000]	Loss: 0.9664	LR: 0.000224
Training Epoch: 255 [128/50000]	Loss: 0.8515	LR: 0.000224
Training Epoch: 255 [128/50000]	Loss: 0.8058	LR: 0.000224
Training Epoch: 255 [128/50000]	Loss: 0.7930	LR: 0.000224
Evaluating Network.....
Test set: Epoch: 255, Average loss: 0.0108, Top1Accuracy: 0.6209, Top3Accuracy: 0.8200, Top5Accuracy: 0.8811, Time consumed:1.78s

Training Epoch: 256 [128/50000]	Loss: 0.8558	LR: 0.000218
Training Epoch: 256 [128/50000]	Loss: 0.7319	LR: 0.000218
Training Epoch: 256 [128/50000]	Loss: 0.9681	LR: 0.000218
Training Epoch: 256 [128/50000]	Loss: 0.9299	LR: 0.000218
Training Epoch: 256 [128/50000]	Loss: 0.6519	LR: 0.000218
Training Epoch: 256 [128/50000]	Loss: 0.9377	LR: 0.000218
Training Epoch: 256 [128/50000]	Loss: 0.7997	LR: 0.000218
Training Epoch: 256 [128/50000]	Loss: 1.0266	LR: 0.000218
Training Epoch: 256 [128/50000]	Loss: 0.8437	LR: 0.000218
Training Epoch: 256 [128/50000]	Loss: 0.9012	LR: 0.000218
Evaluating Network.....
Test set: Epoch: 256, Average loss: 0.0108, Top1Accuracy: 0.6220, Top3Accuracy: 0.8174, Top5Accuracy: 0.8815, Time consumed:1.79s

Training Epoch: 257 [128/50000]	Loss: 0.6680	LR: 0.000212
Training Epoch: 257 [128/50000]	Loss: 0.7577	LR: 0.000212
Training Epoch: 257 [128/50000]	Loss: 0.9048	LR: 0.000212
Training Epoch: 257 [128/50000]	Loss: 0.7809	LR: 0.000212
Training Epoch: 257 [128/50000]	Loss: 0.9302	LR: 0.000212
Training Epoch: 257 [128/50000]	Loss: 0.8076	LR: 0.000212
Training Epoch: 257 [128/50000]	Loss: 0.8745	LR: 0.000212
Training Epoch: 257 [128/50000]	Loss: 0.9979	LR: 0.000212
Training Epoch: 257 [128/50000]	Loss: 0.8963	LR: 0.000212
Training Epoch: 257 [128/50000]	Loss: 0.9639	LR: 0.000212
Evaluating Network.....
Test set: Epoch: 257, Average loss: 0.0109, Top1Accuracy: 0.6197, Top3Accuracy: 0.8184, Top5Accuracy: 0.8819, Time consumed:1.79s

Training Epoch: 258 [128/50000]	Loss: 0.7969	LR: 0.000206
Training Epoch: 258 [128/50000]	Loss: 0.7982	LR: 0.000206
Training Epoch: 258 [128/50000]	Loss: 0.8718	LR: 0.000206
Training Epoch: 258 [128/50000]	Loss: 0.7272	LR: 0.000206
Training Epoch: 258 [128/50000]	Loss: 1.2215	LR: 0.000206
Training Epoch: 258 [128/50000]	Loss: 0.7856	LR: 0.000206
Training Epoch: 258 [128/50000]	Loss: 0.9985	LR: 0.000206
Training Epoch: 258 [128/50000]	Loss: 0.9488	LR: 0.000206
Training Epoch: 258 [128/50000]	Loss: 0.7560	LR: 0.000206
Training Epoch: 258 [128/50000]	Loss: 1.0263	LR: 0.000206
Evaluating Network.....
Test set: Epoch: 258, Average loss: 0.0108, Top1Accuracy: 0.6205, Top3Accuracy: 0.8182, Top5Accuracy: 0.8801, Time consumed:1.79s

Training Epoch: 259 [128/50000]	Loss: 0.7741	LR: 0.000201
Training Epoch: 259 [128/50000]	Loss: 0.9909	LR: 0.000201
Training Epoch: 259 [128/50000]	Loss: 0.8921	LR: 0.000201
Training Epoch: 259 [128/50000]	Loss: 0.8761	LR: 0.000201
Training Epoch: 259 [128/50000]	Loss: 0.9465	LR: 0.000201
Training Epoch: 259 [128/50000]	Loss: 0.7706	LR: 0.000201
Training Epoch: 259 [128/50000]	Loss: 0.8020	LR: 0.000201
Training Epoch: 259 [128/50000]	Loss: 1.0839	LR: 0.000201
Training Epoch: 259 [128/50000]	Loss: 1.0100	LR: 0.000201
Training Epoch: 259 [128/50000]	Loss: 0.9568	LR: 0.000201
Evaluating Network.....
Test set: Epoch: 259, Average loss: 0.0108, Top1Accuracy: 0.6208, Top3Accuracy: 0.8188, Top5Accuracy: 0.8795, Time consumed:1.81s

Training Epoch: 260 [128/50000]	Loss: 0.8511	LR: 0.000196
Training Epoch: 260 [128/50000]	Loss: 0.8458	LR: 0.000196
Training Epoch: 260 [128/50000]	Loss: 0.9145	LR: 0.000196
Training Epoch: 260 [128/50000]	Loss: 0.9871	LR: 0.000196
Training Epoch: 260 [128/50000]	Loss: 0.8642	LR: 0.000196
Training Epoch: 260 [128/50000]	Loss: 1.0149	LR: 0.000196
Training Epoch: 260 [128/50000]	Loss: 0.8074	LR: 0.000196
Training Epoch: 260 [128/50000]	Loss: 0.7859	LR: 0.000196
Training Epoch: 260 [128/50000]	Loss: 0.7037	LR: 0.000196
Training Epoch: 260 [128/50000]	Loss: 0.9041	LR: 0.000196
Evaluating Network.....
Test set: Epoch: 260, Average loss: 0.0108, Top1Accuracy: 0.6194, Top3Accuracy: 0.8190, Top5Accuracy: 0.8809, Time consumed:1.80s

Training Epoch: 261 [128/50000]	Loss: 0.8091	LR: 0.000191
Training Epoch: 261 [128/50000]	Loss: 0.7028	LR: 0.000191
Training Epoch: 261 [128/50000]	Loss: 0.8851	LR: 0.000191
Training Epoch: 261 [128/50000]	Loss: 0.9752	LR: 0.000191
Training Epoch: 261 [128/50000]	Loss: 0.8127	LR: 0.000191
Training Epoch: 261 [128/50000]	Loss: 0.8191	LR: 0.000191
Training Epoch: 261 [128/50000]	Loss: 1.0989	LR: 0.000191
Training Epoch: 261 [128/50000]	Loss: 0.7139	LR: 0.000191
Training Epoch: 261 [128/50000]	Loss: 1.1220	LR: 0.000191
Training Epoch: 261 [128/50000]	Loss: 1.0005	LR: 0.000191
Evaluating Network.....
Test set: Epoch: 261, Average loss: 0.0108, Top1Accuracy: 0.6212, Top3Accuracy: 0.8204, Top5Accuracy: 0.8805, Time consumed:1.79s

Training Epoch: 262 [128/50000]	Loss: 0.8709	LR: 0.000186
Training Epoch: 262 [128/50000]	Loss: 0.7915	LR: 0.000186
Training Epoch: 262 [128/50000]	Loss: 0.8611	LR: 0.000186
Training Epoch: 262 [128/50000]	Loss: 0.7988	LR: 0.000186
Training Epoch: 262 [128/50000]	Loss: 0.8440	LR: 0.000186
Training Epoch: 262 [128/50000]	Loss: 0.8907	LR: 0.000186
Training Epoch: 262 [128/50000]	Loss: 0.9545	LR: 0.000186
Training Epoch: 262 [128/50000]	Loss: 0.7827	LR: 0.000186
Training Epoch: 262 [128/50000]	Loss: 0.8375	LR: 0.000186
Training Epoch: 262 [128/50000]	Loss: 0.8867	LR: 0.000186
Evaluating Network.....
Test set: Epoch: 262, Average loss: 0.0108, Top1Accuracy: 0.6210, Top3Accuracy: 0.8184, Top5Accuracy: 0.8810, Time consumed:1.82s

Training Epoch: 263 [128/50000]	Loss: 0.8048	LR: 0.000181
Training Epoch: 263 [128/50000]	Loss: 0.9930	LR: 0.000181
Training Epoch: 263 [128/50000]	Loss: 0.9038	LR: 0.000181
Training Epoch: 263 [128/50000]	Loss: 0.8131	LR: 0.000181
Training Epoch: 263 [128/50000]	Loss: 1.0717	LR: 0.000181
Training Epoch: 263 [128/50000]	Loss: 0.9050	LR: 0.000181
Training Epoch: 263 [128/50000]	Loss: 0.9762	LR: 0.000181
Training Epoch: 263 [128/50000]	Loss: 0.9680	LR: 0.000181
Training Epoch: 263 [128/50000]	Loss: 0.8078	LR: 0.000181
Training Epoch: 263 [128/50000]	Loss: 0.8863	LR: 0.000181
Evaluating Network.....
Test set: Epoch: 263, Average loss: 0.0109, Top1Accuracy: 0.6204, Top3Accuracy: 0.8201, Top5Accuracy: 0.8808, Time consumed:1.79s

Training Epoch: 264 [128/50000]	Loss: 0.6381	LR: 0.000176
Training Epoch: 264 [128/50000]	Loss: 0.7873	LR: 0.000176
Training Epoch: 264 [128/50000]	Loss: 0.8046	LR: 0.000176
Training Epoch: 264 [128/50000]	Loss: 0.6642	LR: 0.000176
Training Epoch: 264 [128/50000]	Loss: 0.8426	LR: 0.000176
Training Epoch: 264 [128/50000]	Loss: 0.7009	LR: 0.000176
Training Epoch: 264 [128/50000]	Loss: 1.0560	LR: 0.000176
Training Epoch: 264 [128/50000]	Loss: 0.7937	LR: 0.000176
Training Epoch: 264 [128/50000]	Loss: 0.8088	LR: 0.000176
Training Epoch: 264 [128/50000]	Loss: 0.8846	LR: 0.000176
Evaluating Network.....
Test set: Epoch: 264, Average loss: 0.0109, Top1Accuracy: 0.6208, Top3Accuracy: 0.8185, Top5Accuracy: 0.8797, Time consumed:1.78s

Training Epoch: 265 [128/50000]	Loss: 0.7738	LR: 0.000171
Training Epoch: 265 [128/50000]	Loss: 0.8229	LR: 0.000171
Training Epoch: 265 [128/50000]	Loss: 0.8484	LR: 0.000171
Training Epoch: 265 [128/50000]	Loss: 0.9038	LR: 0.000171
Training Epoch: 265 [128/50000]	Loss: 0.8727	LR: 0.000171
Training Epoch: 265 [128/50000]	Loss: 0.8467	LR: 0.000171
Training Epoch: 265 [128/50000]	Loss: 1.0239	LR: 0.000171
Training Epoch: 265 [128/50000]	Loss: 0.7359	LR: 0.000171
Training Epoch: 265 [128/50000]	Loss: 0.9817	LR: 0.000171
Training Epoch: 265 [128/50000]	Loss: 0.8543	LR: 0.000171
Evaluating Network.....
Test set: Epoch: 265, Average loss: 0.0108, Top1Accuracy: 0.6204, Top3Accuracy: 0.8198, Top5Accuracy: 0.8806, Time consumed:1.79s

Training Epoch: 266 [128/50000]	Loss: 0.8236	LR: 0.000167
Training Epoch: 266 [128/50000]	Loss: 0.8972	LR: 0.000167
Training Epoch: 266 [128/50000]	Loss: 1.0975	LR: 0.000167
Training Epoch: 266 [128/50000]	Loss: 0.9558	LR: 0.000167
Training Epoch: 266 [128/50000]	Loss: 0.7884	LR: 0.000167
Training Epoch: 266 [128/50000]	Loss: 0.9519	LR: 0.000167
Training Epoch: 266 [128/50000]	Loss: 0.8928	LR: 0.000167
Training Epoch: 266 [128/50000]	Loss: 0.9987	LR: 0.000167
Training Epoch: 266 [128/50000]	Loss: 0.8776	LR: 0.000167
Training Epoch: 266 [128/50000]	Loss: 0.9098	LR: 0.000167
Evaluating Network.....
Test set: Epoch: 266, Average loss: 0.0108, Top1Accuracy: 0.6224, Top3Accuracy: 0.8186, Top5Accuracy: 0.8803, Time consumed:1.80s

Training Epoch: 267 [128/50000]	Loss: 0.7813	LR: 0.000162
Training Epoch: 267 [128/50000]	Loss: 0.7244	LR: 0.000162
Training Epoch: 267 [128/50000]	Loss: 0.9528	LR: 0.000162
Training Epoch: 267 [128/50000]	Loss: 0.9514	LR: 0.000162
Training Epoch: 267 [128/50000]	Loss: 0.7082	LR: 0.000162
Training Epoch: 267 [128/50000]	Loss: 1.0386	LR: 0.000162
Training Epoch: 267 [128/50000]	Loss: 1.0730	LR: 0.000162
Training Epoch: 267 [128/50000]	Loss: 0.9242	LR: 0.000162
Training Epoch: 267 [128/50000]	Loss: 0.9883	LR: 0.000162
Training Epoch: 267 [128/50000]	Loss: 0.8894	LR: 0.000162
Evaluating Network.....
Test set: Epoch: 267, Average loss: 0.0108, Top1Accuracy: 0.6209, Top3Accuracy: 0.8200, Top5Accuracy: 0.8803, Time consumed:1.79s

Training Epoch: 268 [128/50000]	Loss: 0.7772	LR: 0.000158
Training Epoch: 268 [128/50000]	Loss: 0.7897	LR: 0.000158
Training Epoch: 268 [128/50000]	Loss: 0.9866	LR: 0.000158
Training Epoch: 268 [128/50000]	Loss: 0.9405	LR: 0.000158
Training Epoch: 268 [128/50000]	Loss: 0.8558	LR: 0.000158
Training Epoch: 268 [128/50000]	Loss: 0.8695	LR: 0.000158
Training Epoch: 268 [128/50000]	Loss: 0.9506	LR: 0.000158
Training Epoch: 268 [128/50000]	Loss: 0.6649	LR: 0.000158
Training Epoch: 268 [128/50000]	Loss: 1.0545	LR: 0.000158
Training Epoch: 268 [128/50000]	Loss: 0.9864	LR: 0.000158
Evaluating Network.....
Test set: Epoch: 268, Average loss: 0.0108, Top1Accuracy: 0.6216, Top3Accuracy: 0.8188, Top5Accuracy: 0.8796, Time consumed:1.80s

Training Epoch: 269 [128/50000]	Loss: 0.7208	LR: 0.000154
Training Epoch: 269 [128/50000]	Loss: 0.8509	LR: 0.000154
Training Epoch: 269 [128/50000]	Loss: 1.0140	LR: 0.000154
Training Epoch: 269 [128/50000]	Loss: 0.8647	LR: 0.000154
Training Epoch: 269 [128/50000]	Loss: 0.7622	LR: 0.000154
Training Epoch: 269 [128/50000]	Loss: 0.9562	LR: 0.000154
Training Epoch: 269 [128/50000]	Loss: 0.9536	LR: 0.000154
Training Epoch: 269 [128/50000]	Loss: 0.9279	LR: 0.000154
Training Epoch: 269 [128/50000]	Loss: 1.0612	LR: 0.000154
Training Epoch: 269 [128/50000]	Loss: 0.9043	LR: 0.000154
Evaluating Network.....
Test set: Epoch: 269, Average loss: 0.0108, Top1Accuracy: 0.6217, Top3Accuracy: 0.8187, Top5Accuracy: 0.8810, Time consumed:1.79s

Training Epoch: 270 [128/50000]	Loss: 0.8450	LR: 0.000150
Training Epoch: 270 [128/50000]	Loss: 0.9274	LR: 0.000150
Training Epoch: 270 [128/50000]	Loss: 0.8559	LR: 0.000150
Training Epoch: 270 [128/50000]	Loss: 1.0282	LR: 0.000150
Training Epoch: 270 [128/50000]	Loss: 1.1159	LR: 0.000150
Training Epoch: 270 [128/50000]	Loss: 0.7618	LR: 0.000150
Training Epoch: 270 [128/50000]	Loss: 0.9147	LR: 0.000150
Training Epoch: 270 [128/50000]	Loss: 0.8589	LR: 0.000150
Training Epoch: 270 [128/50000]	Loss: 0.7847	LR: 0.000150
Training Epoch: 270 [128/50000]	Loss: 1.0293	LR: 0.000150
Evaluating Network.....
Test set: Epoch: 270, Average loss: 0.0109, Top1Accuracy: 0.6213, Top3Accuracy: 0.8176, Top5Accuracy: 0.8803, Time consumed:1.80s

Training Epoch: 271 [128/50000]	Loss: 0.9662	LR: 0.000146
Training Epoch: 271 [128/50000]	Loss: 0.8532	LR: 0.000146
Training Epoch: 271 [128/50000]	Loss: 0.7600	LR: 0.000146
Training Epoch: 271 [128/50000]	Loss: 0.9332	LR: 0.000146
Training Epoch: 271 [128/50000]	Loss: 0.9254	LR: 0.000146
Training Epoch: 271 [128/50000]	Loss: 0.9693	LR: 0.000146
Training Epoch: 271 [128/50000]	Loss: 0.9552	LR: 0.000146
Training Epoch: 271 [128/50000]	Loss: 0.8224	LR: 0.000146
Training Epoch: 271 [128/50000]	Loss: 1.0267	LR: 0.000146
Training Epoch: 271 [128/50000]	Loss: 0.7950	LR: 0.000146
Evaluating Network.....
Test set: Epoch: 271, Average loss: 0.0109, Top1Accuracy: 0.6210, Top3Accuracy: 0.8184, Top5Accuracy: 0.8801, Time consumed:1.80s

Training Epoch: 272 [128/50000]	Loss: 0.7226	LR: 0.000142
Training Epoch: 272 [128/50000]	Loss: 0.9066	LR: 0.000142
Training Epoch: 272 [128/50000]	Loss: 0.8904	LR: 0.000142
Training Epoch: 272 [128/50000]	Loss: 0.9869	LR: 0.000142
Training Epoch: 272 [128/50000]	Loss: 0.8326	LR: 0.000142
Training Epoch: 272 [128/50000]	Loss: 1.0875	LR: 0.000142
Training Epoch: 272 [128/50000]	Loss: 0.7032	LR: 0.000142
Training Epoch: 272 [128/50000]	Loss: 0.9513	LR: 0.000142
Training Epoch: 272 [128/50000]	Loss: 1.0648	LR: 0.000142
Training Epoch: 272 [128/50000]	Loss: 0.9961	LR: 0.000142
Evaluating Network.....
Test set: Epoch: 272, Average loss: 0.0108, Top1Accuracy: 0.6211, Top3Accuracy: 0.8189, Top5Accuracy: 0.8798, Time consumed:1.99s

Training Epoch: 273 [128/50000]	Loss: 0.8625	LR: 0.000138
Training Epoch: 273 [128/50000]	Loss: 1.0614	LR: 0.000138
Training Epoch: 273 [128/50000]	Loss: 0.9172	LR: 0.000138
Training Epoch: 273 [128/50000]	Loss: 0.9270	LR: 0.000138
Training Epoch: 273 [128/50000]	Loss: 0.9609	LR: 0.000138
Training Epoch: 273 [128/50000]	Loss: 1.0299	LR: 0.000138
Training Epoch: 273 [128/50000]	Loss: 0.8621	LR: 0.000138
Training Epoch: 273 [128/50000]	Loss: 0.7288	LR: 0.000138
Training Epoch: 273 [128/50000]	Loss: 0.9347	LR: 0.000138
Training Epoch: 273 [128/50000]	Loss: 1.0837	LR: 0.000138
Evaluating Network.....
Test set: Epoch: 273, Average loss: 0.0108, Top1Accuracy: 0.6214, Top3Accuracy: 0.8191, Top5Accuracy: 0.8801, Time consumed:1.80s

Training Epoch: 274 [128/50000]	Loss: 0.8253	LR: 0.000135
Training Epoch: 274 [128/50000]	Loss: 0.9943	LR: 0.000135
Training Epoch: 274 [128/50000]	Loss: 0.9293	LR: 0.000135
Training Epoch: 274 [128/50000]	Loss: 0.8010	LR: 0.000135
Training Epoch: 274 [128/50000]	Loss: 0.8937	LR: 0.000135
Training Epoch: 274 [128/50000]	Loss: 0.9414	LR: 0.000135
Training Epoch: 274 [128/50000]	Loss: 0.8107	LR: 0.000135
Training Epoch: 274 [128/50000]	Loss: 0.6829	LR: 0.000135
Training Epoch: 274 [128/50000]	Loss: 1.0108	LR: 0.000135
Training Epoch: 274 [128/50000]	Loss: 1.0337	LR: 0.000135
Evaluating Network.....
Test set: Epoch: 274, Average loss: 0.0108, Top1Accuracy: 0.6213, Top3Accuracy: 0.8182, Top5Accuracy: 0.8795, Time consumed:1.81s

Training Epoch: 275 [128/50000]	Loss: 0.9505	LR: 0.000131
Training Epoch: 275 [128/50000]	Loss: 0.9828	LR: 0.000131
Training Epoch: 275 [128/50000]	Loss: 0.7955	LR: 0.000131
Training Epoch: 275 [128/50000]	Loss: 0.8892	LR: 0.000131
Training Epoch: 275 [128/50000]	Loss: 0.8208	LR: 0.000131
Training Epoch: 275 [128/50000]	Loss: 0.8539	LR: 0.000131
Training Epoch: 275 [128/50000]	Loss: 0.8091	LR: 0.000131
Training Epoch: 275 [128/50000]	Loss: 0.7700	LR: 0.000131
Training Epoch: 275 [128/50000]	Loss: 0.7934	LR: 0.000131
Training Epoch: 275 [128/50000]	Loss: 0.9254	LR: 0.000131
Evaluating Network.....
Test set: Epoch: 275, Average loss: 0.0109, Top1Accuracy: 0.6211, Top3Accuracy: 0.8183, Top5Accuracy: 0.8808, Time consumed:1.78s

Training Epoch: 276 [128/50000]	Loss: 0.8661	LR: 0.000128
Training Epoch: 276 [128/50000]	Loss: 0.7330	LR: 0.000128
Training Epoch: 276 [128/50000]	Loss: 0.9009	LR: 0.000128
Training Epoch: 276 [128/50000]	Loss: 0.9986	LR: 0.000128
Training Epoch: 276 [128/50000]	Loss: 0.7479	LR: 0.000128
Training Epoch: 276 [128/50000]	Loss: 0.8666	LR: 0.000128
Training Epoch: 276 [128/50000]	Loss: 0.9371	LR: 0.000128
Training Epoch: 276 [128/50000]	Loss: 0.9069	LR: 0.000128
Training Epoch: 276 [128/50000]	Loss: 0.9929	LR: 0.000128
Training Epoch: 276 [128/50000]	Loss: 0.7123	LR: 0.000128
Evaluating Network.....
Test set: Epoch: 276, Average loss: 0.0109, Top1Accuracy: 0.6211, Top3Accuracy: 0.8198, Top5Accuracy: 0.8806, Time consumed:1.81s

Training Epoch: 277 [128/50000]	Loss: 1.0347	LR: 0.000124
Training Epoch: 277 [128/50000]	Loss: 0.7856	LR: 0.000124
Training Epoch: 277 [128/50000]	Loss: 0.8454	LR: 0.000124
Training Epoch: 277 [128/50000]	Loss: 0.9053	LR: 0.000124
Training Epoch: 277 [128/50000]	Loss: 0.9923	LR: 0.000124
Training Epoch: 277 [128/50000]	Loss: 0.7706	LR: 0.000124
Training Epoch: 277 [128/50000]	Loss: 0.8869	LR: 0.000124
Training Epoch: 277 [128/50000]	Loss: 0.9747	LR: 0.000124
Training Epoch: 277 [128/50000]	Loss: 0.7749	LR: 0.000124
Training Epoch: 277 [128/50000]	Loss: 0.7587	LR: 0.000124
Evaluating Network.....
Test set: Epoch: 277, Average loss: 0.0108, Top1Accuracy: 0.6219, Top3Accuracy: 0.8188, Top5Accuracy: 0.8800, Time consumed:1.79s

Training Epoch: 278 [128/50000]	Loss: 0.8343	LR: 0.000121
Training Epoch: 278 [128/50000]	Loss: 0.8204	LR: 0.000121
Training Epoch: 278 [128/50000]	Loss: 1.0409	LR: 0.000121
Training Epoch: 278 [128/50000]	Loss: 1.0216	LR: 0.000121
Training Epoch: 278 [128/50000]	Loss: 0.8996	LR: 0.000121
Training Epoch: 278 [128/50000]	Loss: 0.8960	LR: 0.000121
Training Epoch: 278 [128/50000]	Loss: 0.9276	LR: 0.000121
Training Epoch: 278 [128/50000]	Loss: 0.8015	LR: 0.000121
Training Epoch: 278 [128/50000]	Loss: 0.7428	LR: 0.000121
Training Epoch: 278 [128/50000]	Loss: 0.7419	LR: 0.000121
Evaluating Network.....
Test set: Epoch: 278, Average loss: 0.0108, Top1Accuracy: 0.6218, Top3Accuracy: 0.8198, Top5Accuracy: 0.8792, Time consumed:1.81s

Training Epoch: 279 [128/50000]	Loss: 1.0568	LR: 0.000118
Training Epoch: 279 [128/50000]	Loss: 1.0106	LR: 0.000118
Training Epoch: 279 [128/50000]	Loss: 1.0602	LR: 0.000118
Training Epoch: 279 [128/50000]	Loss: 0.8472	LR: 0.000118
Training Epoch: 279 [128/50000]	Loss: 0.8016	LR: 0.000118
Training Epoch: 279 [128/50000]	Loss: 0.8303	LR: 0.000118
Training Epoch: 279 [128/50000]	Loss: 0.8607	LR: 0.000118
Training Epoch: 279 [128/50000]	Loss: 0.7575	LR: 0.000118
Training Epoch: 279 [128/50000]	Loss: 0.9059	LR: 0.000118
Training Epoch: 279 [128/50000]	Loss: 0.9042	LR: 0.000118
Evaluating Network.....
Test set: Epoch: 279, Average loss: 0.0108, Top1Accuracy: 0.6215, Top3Accuracy: 0.8191, Top5Accuracy: 0.8809, Time consumed:1.79s

Training Epoch: 280 [128/50000]	Loss: 0.8451	LR: 0.000115
Training Epoch: 280 [128/50000]	Loss: 0.9072	LR: 0.000115
Training Epoch: 280 [128/50000]	Loss: 0.9165	LR: 0.000115
Training Epoch: 280 [128/50000]	Loss: 1.0276	LR: 0.000115
Training Epoch: 280 [128/50000]	Loss: 0.9112	LR: 0.000115
Training Epoch: 280 [128/50000]	Loss: 0.8000	LR: 0.000115
Training Epoch: 280 [128/50000]	Loss: 0.9783	LR: 0.000115
Training Epoch: 280 [128/50000]	Loss: 0.9460	LR: 0.000115
Training Epoch: 280 [128/50000]	Loss: 0.9450	LR: 0.000115
Training Epoch: 280 [128/50000]	Loss: 0.8384	LR: 0.000115
Evaluating Network.....
Test set: Epoch: 280, Average loss: 0.0109, Top1Accuracy: 0.6206, Top3Accuracy: 0.8192, Top5Accuracy: 0.8807, Time consumed:1.79s

Training Epoch: 281 [128/50000]	Loss: 0.9891	LR: 0.000112
Training Epoch: 281 [128/50000]	Loss: 0.8130	LR: 0.000112
Training Epoch: 281 [128/50000]	Loss: 0.8070	LR: 0.000112
Training Epoch: 281 [128/50000]	Loss: 0.9691	LR: 0.000112
Training Epoch: 281 [128/50000]	Loss: 0.8937	LR: 0.000112
Training Epoch: 281 [128/50000]	Loss: 0.8231	LR: 0.000112
Training Epoch: 281 [128/50000]	Loss: 0.8644	LR: 0.000112
Training Epoch: 281 [128/50000]	Loss: 1.0426	LR: 0.000112
Training Epoch: 281 [128/50000]	Loss: 0.8113	LR: 0.000112
Training Epoch: 281 [128/50000]	Loss: 0.9934	LR: 0.000112
Evaluating Network.....
Test set: Epoch: 281, Average loss: 0.0108, Top1Accuracy: 0.6203, Top3Accuracy: 0.8197, Top5Accuracy: 0.8798, Time consumed:1.78s

Training Epoch: 282 [128/50000]	Loss: 0.7602	LR: 0.000109
Training Epoch: 282 [128/50000]	Loss: 0.7117	LR: 0.000109
Training Epoch: 282 [128/50000]	Loss: 0.7803	LR: 0.000109
Training Epoch: 282 [128/50000]	Loss: 1.1586	LR: 0.000109
Training Epoch: 282 [128/50000]	Loss: 0.8705	LR: 0.000109
Training Epoch: 282 [128/50000]	Loss: 0.8866	LR: 0.000109
Training Epoch: 282 [128/50000]	Loss: 0.9424	LR: 0.000109
Training Epoch: 282 [128/50000]	Loss: 0.8026	LR: 0.000109
Training Epoch: 282 [128/50000]	Loss: 0.7953	LR: 0.000109
Training Epoch: 282 [128/50000]	Loss: 0.9574	LR: 0.000109
Evaluating Network.....
Test set: Epoch: 282, Average loss: 0.0108, Top1Accuracy: 0.6227, Top3Accuracy: 0.8195, Top5Accuracy: 0.8797, Time consumed:1.79s

Training Epoch: 283 [128/50000]	Loss: 0.8087	LR: 0.000106
Training Epoch: 283 [128/50000]	Loss: 1.0345	LR: 0.000106
Training Epoch: 283 [128/50000]	Loss: 0.8649	LR: 0.000106
Training Epoch: 283 [128/50000]	Loss: 1.0096	LR: 0.000106
Training Epoch: 283 [128/50000]	Loss: 0.7436	LR: 0.000106
Training Epoch: 283 [128/50000]	Loss: 1.0049	LR: 0.000106
Training Epoch: 283 [128/50000]	Loss: 1.0228	LR: 0.000106
Training Epoch: 283 [128/50000]	Loss: 0.8716	LR: 0.000106
Training Epoch: 283 [128/50000]	Loss: 0.8968	LR: 0.000106
Training Epoch: 283 [128/50000]	Loss: 0.6964	LR: 0.000106
Evaluating Network.....
Test set: Epoch: 283, Average loss: 0.0108, Top1Accuracy: 0.6220, Top3Accuracy: 0.8184, Top5Accuracy: 0.8807, Time consumed:1.80s

Training Epoch: 284 [128/50000]	Loss: 0.9045	LR: 0.000103
Training Epoch: 284 [128/50000]	Loss: 0.6923	LR: 0.000103
Training Epoch: 284 [128/50000]	Loss: 0.9164	LR: 0.000103
Training Epoch: 284 [128/50000]	Loss: 0.7929	LR: 0.000103
Training Epoch: 284 [128/50000]	Loss: 0.9074	LR: 0.000103
Training Epoch: 284 [128/50000]	Loss: 1.0012	LR: 0.000103
Training Epoch: 284 [128/50000]	Loss: 0.8128	LR: 0.000103
Training Epoch: 284 [128/50000]	Loss: 0.8170	LR: 0.000103
Training Epoch: 284 [128/50000]	Loss: 0.6256	LR: 0.000103
Training Epoch: 284 [128/50000]	Loss: 0.9417	LR: 0.000103
Evaluating Network.....
Test set: Epoch: 284, Average loss: 0.0108, Top1Accuracy: 0.6212, Top3Accuracy: 0.8177, Top5Accuracy: 0.8799, Time consumed:1.78s

Training Epoch: 285 [128/50000]	Loss: 1.0377	LR: 0.000100
Training Epoch: 285 [128/50000]	Loss: 0.7144	LR: 0.000100
Training Epoch: 285 [128/50000]	Loss: 0.9834	LR: 0.000100
Training Epoch: 285 [128/50000]	Loss: 1.1608	LR: 0.000100
Training Epoch: 285 [128/50000]	Loss: 0.7501	LR: 0.000100
Training Epoch: 285 [128/50000]	Loss: 0.8314	LR: 0.000100
Training Epoch: 285 [128/50000]	Loss: 0.8091	LR: 0.000100
Training Epoch: 285 [128/50000]	Loss: 0.7091	LR: 0.000100
Training Epoch: 285 [128/50000]	Loss: 0.8949	LR: 0.000100
Training Epoch: 285 [128/50000]	Loss: 0.9840	LR: 0.000100
Evaluating Network.....
Test set: Epoch: 285, Average loss: 0.0108, Top1Accuracy: 0.6214, Top3Accuracy: 0.8189, Top5Accuracy: 0.8795, Time consumed:1.81s

Training Epoch: 286 [128/50000]	Loss: 0.8251	LR: 0.000098
Training Epoch: 286 [128/50000]	Loss: 1.0344	LR: 0.000098
Training Epoch: 286 [128/50000]	Loss: 0.8629	LR: 0.000098
Training Epoch: 286 [128/50000]	Loss: 0.8090	LR: 0.000098
Training Epoch: 286 [128/50000]	Loss: 1.0455	LR: 0.000098
Training Epoch: 286 [128/50000]	Loss: 0.8751	LR: 0.000098
Training Epoch: 286 [128/50000]	Loss: 1.0438	LR: 0.000098
Training Epoch: 286 [128/50000]	Loss: 1.0295	LR: 0.000098
Training Epoch: 286 [128/50000]	Loss: 0.9952	LR: 0.000098
Training Epoch: 286 [128/50000]	Loss: 0.8534	LR: 0.000098
Evaluating Network.....
Test set: Epoch: 286, Average loss: 0.0109, Top1Accuracy: 0.6226, Top3Accuracy: 0.8191, Top5Accuracy: 0.8799, Time consumed:1.78s

Training Epoch: 287 [128/50000]	Loss: 0.8892	LR: 0.000095
Training Epoch: 287 [128/50000]	Loss: 1.0106	LR: 0.000095
Training Epoch: 287 [128/50000]	Loss: 0.8680	LR: 0.000095
Training Epoch: 287 [128/50000]	Loss: 1.1178	LR: 0.000095
Training Epoch: 287 [128/50000]	Loss: 1.0147	LR: 0.000095
Training Epoch: 287 [128/50000]	Loss: 1.0440	LR: 0.000095
Training Epoch: 287 [128/50000]	Loss: 1.0755	LR: 0.000095
Training Epoch: 287 [128/50000]	Loss: 0.7174	LR: 0.000095
Training Epoch: 287 [128/50000]	Loss: 0.9722	LR: 0.000095
Training Epoch: 287 [128/50000]	Loss: 0.5965	LR: 0.000095
Evaluating Network.....
Test set: Epoch: 287, Average loss: 0.0109, Top1Accuracy: 0.6208, Top3Accuracy: 0.8186, Top5Accuracy: 0.8798, Time consumed:1.80s

Training Epoch: 288 [128/50000]	Loss: 0.9579	LR: 0.000093
Training Epoch: 288 [128/50000]	Loss: 0.8752	LR: 0.000093
Training Epoch: 288 [128/50000]	Loss: 0.9300	LR: 0.000093
Training Epoch: 288 [128/50000]	Loss: 0.7514	LR: 0.000093
Training Epoch: 288 [128/50000]	Loss: 0.8179	LR: 0.000093
Training Epoch: 288 [128/50000]	Loss: 0.9355	LR: 0.000093
Training Epoch: 288 [128/50000]	Loss: 0.7664	LR: 0.000093
Training Epoch: 288 [128/50000]	Loss: 1.1268	LR: 0.000093
Training Epoch: 288 [128/50000]	Loss: 0.8564	LR: 0.000093
Training Epoch: 288 [128/50000]	Loss: 0.9371	LR: 0.000093
Evaluating Network.....
Test set: Epoch: 288, Average loss: 0.0108, Top1Accuracy: 0.6218, Top3Accuracy: 0.8189, Top5Accuracy: 0.8794, Time consumed:1.80s

Training Epoch: 289 [128/50000]	Loss: 0.8786	LR: 0.000090
Training Epoch: 289 [128/50000]	Loss: 0.9164	LR: 0.000090
Training Epoch: 289 [128/50000]	Loss: 0.7883	LR: 0.000090
Training Epoch: 289 [128/50000]	Loss: 0.9369	LR: 0.000090
Training Epoch: 289 [128/50000]	Loss: 0.9924	LR: 0.000090
Training Epoch: 289 [128/50000]	Loss: 0.8680	LR: 0.000090
Training Epoch: 289 [128/50000]	Loss: 0.9141	LR: 0.000090
Training Epoch: 289 [128/50000]	Loss: 0.7887	LR: 0.000090
Training Epoch: 289 [128/50000]	Loss: 0.9334	LR: 0.000090
Training Epoch: 289 [128/50000]	Loss: 0.8093	LR: 0.000090
Evaluating Network.....
Test set: Epoch: 289, Average loss: 0.0108, Top1Accuracy: 0.6239, Top3Accuracy: 0.8190, Top5Accuracy: 0.8797, Time consumed:1.97s

Training Epoch: 290 [128/50000]	Loss: 0.8914	LR: 0.000088
Training Epoch: 290 [128/50000]	Loss: 0.9963	LR: 0.000088
Training Epoch: 290 [128/50000]	Loss: 0.8186	LR: 0.000088
Training Epoch: 290 [128/50000]	Loss: 0.9987	LR: 0.000088
Training Epoch: 290 [128/50000]	Loss: 0.9454	LR: 0.000088
Training Epoch: 290 [128/50000]	Loss: 0.7999	LR: 0.000088
Training Epoch: 290 [128/50000]	Loss: 0.7326	LR: 0.000088
Training Epoch: 290 [128/50000]	Loss: 0.9614	LR: 0.000088
Training Epoch: 290 [128/50000]	Loss: 0.9095	LR: 0.000088
Training Epoch: 290 [128/50000]	Loss: 0.8716	LR: 0.000088
Evaluating Network.....
Test set: Epoch: 290, Average loss: 0.0108, Top1Accuracy: 0.6225, Top3Accuracy: 0.8188, Top5Accuracy: 0.8802, Time consumed:1.80s

Training Epoch: 291 [128/50000]	Loss: 0.9550	LR: 0.000085
Training Epoch: 291 [128/50000]	Loss: 0.8092	LR: 0.000085
Training Epoch: 291 [128/50000]	Loss: 0.8807	LR: 0.000085
Training Epoch: 291 [128/50000]	Loss: 0.9449	LR: 0.000085
Training Epoch: 291 [128/50000]	Loss: 1.1347	LR: 0.000085
Training Epoch: 291 [128/50000]	Loss: 0.8933	LR: 0.000085
Training Epoch: 291 [128/50000]	Loss: 0.7975	LR: 0.000085
Training Epoch: 291 [128/50000]	Loss: 0.9129	LR: 0.000085
Training Epoch: 291 [128/50000]	Loss: 0.9990	LR: 0.000085
Training Epoch: 291 [128/50000]	Loss: 0.9503	LR: 0.000085
Evaluating Network.....
Test set: Epoch: 291, Average loss: 0.0109, Top1Accuracy: 0.6221, Top3Accuracy: 0.8182, Top5Accuracy: 0.8799, Time consumed:1.79s

Training Epoch: 292 [128/50000]	Loss: 0.9252	LR: 0.000083
Training Epoch: 292 [128/50000]	Loss: 0.8450	LR: 0.000083
Training Epoch: 292 [128/50000]	Loss: 0.9623	LR: 0.000083
Training Epoch: 292 [128/50000]	Loss: 0.8962	LR: 0.000083
Training Epoch: 292 [128/50000]	Loss: 0.8020	LR: 0.000083
Training Epoch: 292 [128/50000]	Loss: 0.8530	LR: 0.000083
Training Epoch: 292 [128/50000]	Loss: 0.7492	LR: 0.000083
Training Epoch: 292 [128/50000]	Loss: 0.9904	LR: 0.000083
Training Epoch: 292 [128/50000]	Loss: 0.7118	LR: 0.000083
Training Epoch: 292 [128/50000]	Loss: 0.9289	LR: 0.000083
Evaluating Network.....
Test set: Epoch: 292, Average loss: 0.0109, Top1Accuracy: 0.6231, Top3Accuracy: 0.8188, Top5Accuracy: 0.8796, Time consumed:1.80s

Training Epoch: 293 [128/50000]	Loss: 1.0227	LR: 0.000081
Training Epoch: 293 [128/50000]	Loss: 0.9121	LR: 0.000081
Training Epoch: 293 [128/50000]	Loss: 0.8363	LR: 0.000081
Training Epoch: 293 [128/50000]	Loss: 0.9268	LR: 0.000081
Training Epoch: 293 [128/50000]	Loss: 0.7775	LR: 0.000081
Training Epoch: 293 [128/50000]	Loss: 0.8134	LR: 0.000081
Training Epoch: 293 [128/50000]	Loss: 0.9103	LR: 0.000081
Training Epoch: 293 [128/50000]	Loss: 0.8920	LR: 0.000081
Training Epoch: 293 [128/50000]	Loss: 0.7651	LR: 0.000081
Training Epoch: 293 [128/50000]	Loss: 0.6180	LR: 0.000081
Evaluating Network.....
Test set: Epoch: 293, Average loss: 0.0108, Top1Accuracy: 0.6228, Top3Accuracy: 0.8188, Top5Accuracy: 0.8796, Time consumed:1.80s

Training Epoch: 294 [128/50000]	Loss: 0.8488	LR: 0.000079
Training Epoch: 294 [128/50000]	Loss: 0.8691	LR: 0.000079
Training Epoch: 294 [128/50000]	Loss: 0.8533	LR: 0.000079
Training Epoch: 294 [128/50000]	Loss: 0.9698	LR: 0.000079
Training Epoch: 294 [128/50000]	Loss: 0.7561	LR: 0.000079
Training Epoch: 294 [128/50000]	Loss: 0.8991	LR: 0.000079
Training Epoch: 294 [128/50000]	Loss: 0.8034	LR: 0.000079
Training Epoch: 294 [128/50000]	Loss: 0.7669	LR: 0.000079
Training Epoch: 294 [128/50000]	Loss: 0.7843	LR: 0.000079
Training Epoch: 294 [128/50000]	Loss: 0.9861	LR: 0.000079
Evaluating Network.....
Test set: Epoch: 294, Average loss: 0.0108, Top1Accuracy: 0.6220, Top3Accuracy: 0.8189, Top5Accuracy: 0.8794, Time consumed:1.81s

Training Epoch: 295 [128/50000]	Loss: 1.0174	LR: 0.000077
Training Epoch: 295 [128/50000]	Loss: 0.9047	LR: 0.000077
Training Epoch: 295 [128/50000]	Loss: 0.9548	LR: 0.000077
Training Epoch: 295 [128/50000]	Loss: 0.8879	LR: 0.000077
Training Epoch: 295 [128/50000]	Loss: 0.7527	LR: 0.000077
Training Epoch: 295 [128/50000]	Loss: 0.8487	LR: 0.000077
Training Epoch: 295 [128/50000]	Loss: 0.9884	LR: 0.000077
Training Epoch: 295 [128/50000]	Loss: 0.7746	LR: 0.000077
Training Epoch: 295 [128/50000]	Loss: 1.1719	LR: 0.000077
Training Epoch: 295 [128/50000]	Loss: 1.1640	LR: 0.000077
Evaluating Network.....
Test set: Epoch: 295, Average loss: 0.0108, Top1Accuracy: 0.6231, Top3Accuracy: 0.8199, Top5Accuracy: 0.8801, Time consumed:1.79s

Training Epoch: 296 [128/50000]	Loss: 0.8864	LR: 0.000075
Training Epoch: 296 [128/50000]	Loss: 0.7217	LR: 0.000075
Training Epoch: 296 [128/50000]	Loss: 0.9075	LR: 0.000075
Training Epoch: 296 [128/50000]	Loss: 0.8686	LR: 0.000075
Training Epoch: 296 [128/50000]	Loss: 0.8023	LR: 0.000075
Training Epoch: 296 [128/50000]	Loss: 0.8858	LR: 0.000075
Training Epoch: 296 [128/50000]	Loss: 0.8450	LR: 0.000075
Training Epoch: 296 [128/50000]	Loss: 0.8531	LR: 0.000075
Training Epoch: 296 [128/50000]	Loss: 0.9636	LR: 0.000075
Training Epoch: 296 [128/50000]	Loss: 0.7976	LR: 0.000075
Evaluating Network.....
Test set: Epoch: 296, Average loss: 0.0109, Top1Accuracy: 0.6210, Top3Accuracy: 0.8195, Top5Accuracy: 0.8792, Time consumed:1.80s

Training Epoch: 297 [128/50000]	Loss: 0.9979	LR: 0.000073
Training Epoch: 297 [128/50000]	Loss: 0.9700	LR: 0.000073
Training Epoch: 297 [128/50000]	Loss: 0.8946	LR: 0.000073
Training Epoch: 297 [128/50000]	Loss: 1.0196	LR: 0.000073
Training Epoch: 297 [128/50000]	Loss: 0.7849	LR: 0.000073
Training Epoch: 297 [128/50000]	Loss: 0.8304	LR: 0.000073
Training Epoch: 297 [128/50000]	Loss: 0.7896	LR: 0.000073
Training Epoch: 297 [128/50000]	Loss: 0.7733	LR: 0.000073
Training Epoch: 297 [128/50000]	Loss: 0.8571	LR: 0.000073
Training Epoch: 297 [128/50000]	Loss: 0.8726	LR: 0.000073
Evaluating Network.....
Test set: Epoch: 297, Average loss: 0.0108, Top1Accuracy: 0.6222, Top3Accuracy: 0.8199, Top5Accuracy: 0.8792, Time consumed:1.80s

Training Epoch: 298 [128/50000]	Loss: 0.6882	LR: 0.000071
Training Epoch: 298 [128/50000]	Loss: 0.9694	LR: 0.000071
Training Epoch: 298 [128/50000]	Loss: 0.8841	LR: 0.000071
Training Epoch: 298 [128/50000]	Loss: 1.0992	LR: 0.000071
Training Epoch: 298 [128/50000]	Loss: 0.6918	LR: 0.000071
Training Epoch: 298 [128/50000]	Loss: 0.8700	LR: 0.000071
Training Epoch: 298 [128/50000]	Loss: 0.8596	LR: 0.000071
Training Epoch: 298 [128/50000]	Loss: 0.8943	LR: 0.000071
Training Epoch: 298 [128/50000]	Loss: 0.8596	LR: 0.000071
Training Epoch: 298 [128/50000]	Loss: 0.9125	LR: 0.000071
Evaluating Network.....
Test set: Epoch: 298, Average loss: 0.0108, Top1Accuracy: 0.6215, Top3Accuracy: 0.8187, Top5Accuracy: 0.8802, Time consumed:1.79s

Training Epoch: 299 [128/50000]	Loss: 0.8478	LR: 0.000069
Training Epoch: 299 [128/50000]	Loss: 0.8640	LR: 0.000069
Training Epoch: 299 [128/50000]	Loss: 0.9082	LR: 0.000069
Training Epoch: 299 [128/50000]	Loss: 0.7820	LR: 0.000069
Training Epoch: 299 [128/50000]	Loss: 0.8682	LR: 0.000069
Training Epoch: 299 [128/50000]	Loss: 0.7161	LR: 0.000069
Training Epoch: 299 [128/50000]	Loss: 0.7197	LR: 0.000069
Training Epoch: 299 [128/50000]	Loss: 1.0262	LR: 0.000069
Training Epoch: 299 [128/50000]	Loss: 0.9749	LR: 0.000069
Training Epoch: 299 [128/50000]	Loss: 0.7900	LR: 0.000069
Evaluating Network.....
Test set: Epoch: 299, Average loss: 0.0108, Top1Accuracy: 0.6219, Top3Accuracy: 0.8208, Top5Accuracy: 0.8798, Time consumed:1.78s

Training Epoch: 300 [128/50000]	Loss: 0.9571	LR: 0.000067
Training Epoch: 300 [128/50000]	Loss: 0.8743	LR: 0.000067
Training Epoch: 300 [128/50000]	Loss: 0.9936	LR: 0.000067
Training Epoch: 300 [128/50000]	Loss: 1.1869	LR: 0.000067
Training Epoch: 300 [128/50000]	Loss: 0.7309	LR: 0.000067
Training Epoch: 300 [128/50000]	Loss: 0.9924	LR: 0.000067
Training Epoch: 300 [128/50000]	Loss: 0.9201	LR: 0.000067
Training Epoch: 300 [128/50000]	Loss: 0.7964	LR: 0.000067
Training Epoch: 300 [128/50000]	Loss: 0.8085	LR: 0.000067
Training Epoch: 300 [128/50000]	Loss: 0.8999	LR: 0.000067
Evaluating Network.....
Test set: Epoch: 300, Average loss: 0.0108, Top1Accuracy: 0.6209, Top3Accuracy: 0.8191, Top5Accuracy: 0.8797, Time consumed:1.79s

Training Epoch: 301 [128/50000]	Loss: 0.8412	LR: 0.000065
Training Epoch: 301 [128/50000]	Loss: 0.9523	LR: 0.000065
Training Epoch: 301 [128/50000]	Loss: 0.8433	LR: 0.000065
Training Epoch: 301 [128/50000]	Loss: 0.9903	LR: 0.000065
Training Epoch: 301 [128/50000]	Loss: 0.9307	LR: 0.000065
Training Epoch: 301 [128/50000]	Loss: 0.7189	LR: 0.000065
Training Epoch: 301 [128/50000]	Loss: 0.9874	LR: 0.000065
Training Epoch: 301 [128/50000]	Loss: 0.8658	LR: 0.000065
Training Epoch: 301 [128/50000]	Loss: 0.8087	LR: 0.000065
Training Epoch: 301 [128/50000]	Loss: 0.8075	LR: 0.000065
Evaluating Network.....
Test set: Epoch: 301, Average loss: 0.0108, Top1Accuracy: 0.6206, Top3Accuracy: 0.8191, Top5Accuracy: 0.8797, Time consumed:1.79s

Training Epoch: 302 [128/50000]	Loss: 1.0612	LR: 0.000064
Training Epoch: 302 [128/50000]	Loss: 0.8795	LR: 0.000064
Training Epoch: 302 [128/50000]	Loss: 0.8964	LR: 0.000064
Training Epoch: 302 [128/50000]	Loss: 0.8917	LR: 0.000064
Training Epoch: 302 [128/50000]	Loss: 0.8500	LR: 0.000064
Training Epoch: 302 [128/50000]	Loss: 1.0155	LR: 0.000064
Training Epoch: 302 [128/50000]	Loss: 0.7180	LR: 0.000064
Training Epoch: 302 [128/50000]	Loss: 0.8255	LR: 0.000064
Training Epoch: 302 [128/50000]	Loss: 1.0355	LR: 0.000064
Training Epoch: 302 [128/50000]	Loss: 0.8226	LR: 0.000064
Evaluating Network.....
Test set: Epoch: 302, Average loss: 0.0108, Top1Accuracy: 0.6224, Top3Accuracy: 0.8185, Top5Accuracy: 0.8808, Time consumed:1.80s

Training Epoch: 303 [128/50000]	Loss: 0.7739	LR: 0.000062
Training Epoch: 303 [128/50000]	Loss: 0.8708	LR: 0.000062
Training Epoch: 303 [128/50000]	Loss: 0.9209	LR: 0.000062
Training Epoch: 303 [128/50000]	Loss: 0.9702	LR: 0.000062
Training Epoch: 303 [128/50000]	Loss: 0.7693	LR: 0.000062
Training Epoch: 303 [128/50000]	Loss: 0.8509	LR: 0.000062
Training Epoch: 303 [128/50000]	Loss: 0.9751	LR: 0.000062
Training Epoch: 303 [128/50000]	Loss: 0.7235	LR: 0.000062
Training Epoch: 303 [128/50000]	Loss: 0.7273	LR: 0.000062
Training Epoch: 303 [128/50000]	Loss: 0.8584	LR: 0.000062
Evaluating Network.....
Test set: Epoch: 303, Average loss: 0.0108, Top1Accuracy: 0.6221, Top3Accuracy: 0.8180, Top5Accuracy: 0.8803, Time consumed:1.79s

Training Epoch: 304 [128/50000]	Loss: 1.0158	LR: 0.000060
Training Epoch: 304 [128/50000]	Loss: 1.0250	LR: 0.000060
Training Epoch: 304 [128/50000]	Loss: 0.8003	LR: 0.000060
Training Epoch: 304 [128/50000]	Loss: 0.8017	LR: 0.000060
Training Epoch: 304 [128/50000]	Loss: 0.9940	LR: 0.000060
Training Epoch: 304 [128/50000]	Loss: 0.9715	LR: 0.000060
Training Epoch: 304 [128/50000]	Loss: 1.0087	LR: 0.000060
Training Epoch: 304 [128/50000]	Loss: 0.7853	LR: 0.000060
Training Epoch: 304 [128/50000]	Loss: 0.9029	LR: 0.000060
Training Epoch: 304 [128/50000]	Loss: 0.9370	LR: 0.000060
Evaluating Network.....
Test set: Epoch: 304, Average loss: 0.0108, Top1Accuracy: 0.6212, Top3Accuracy: 0.8179, Top5Accuracy: 0.8798, Time consumed:1.79s

Training Epoch: 305 [128/50000]	Loss: 1.0419	LR: 0.000059
Training Epoch: 305 [128/50000]	Loss: 0.9901	LR: 0.000059
Training Epoch: 305 [128/50000]	Loss: 0.8828	LR: 0.000059
Training Epoch: 305 [128/50000]	Loss: 0.9748	LR: 0.000059
Training Epoch: 305 [128/50000]	Loss: 1.0110	LR: 0.000059
Training Epoch: 305 [128/50000]	Loss: 0.9784	LR: 0.000059
Training Epoch: 305 [128/50000]	Loss: 1.0360	LR: 0.000059
Training Epoch: 305 [128/50000]	Loss: 0.8448	LR: 0.000059
Training Epoch: 305 [128/50000]	Loss: 0.7612	LR: 0.000059
Training Epoch: 305 [128/50000]	Loss: 0.8078	LR: 0.000059
Evaluating Network.....
Test set: Epoch: 305, Average loss: 0.0108, Top1Accuracy: 0.6221, Top3Accuracy: 0.8192, Top5Accuracy: 0.8799, Time consumed:1.79s

Training Epoch: 306 [128/50000]	Loss: 0.9652	LR: 0.000057
Training Epoch: 306 [128/50000]	Loss: 0.9044	LR: 0.000057
Training Epoch: 306 [128/50000]	Loss: 0.9235	LR: 0.000057
Training Epoch: 306 [128/50000]	Loss: 0.8114	LR: 0.000057
Training Epoch: 306 [128/50000]	Loss: 0.9929	LR: 0.000057
Training Epoch: 306 [128/50000]	Loss: 1.0458	LR: 0.000057
Training Epoch: 306 [128/50000]	Loss: 0.8403	LR: 0.000057
Training Epoch: 306 [128/50000]	Loss: 0.8758	LR: 0.000057
Training Epoch: 306 [128/50000]	Loss: 0.9044	LR: 0.000057
Training Epoch: 306 [128/50000]	Loss: 0.9684	LR: 0.000057
Evaluating Network.....
Test set: Epoch: 306, Average loss: 0.0108, Top1Accuracy: 0.6230, Top3Accuracy: 0.8194, Top5Accuracy: 0.8798, Time consumed:1.80s

Training Epoch: 307 [128/50000]	Loss: 0.8999	LR: 0.000056
Training Epoch: 307 [128/50000]	Loss: 1.2163	LR: 0.000056
Training Epoch: 307 [128/50000]	Loss: 0.8319	LR: 0.000056
Training Epoch: 307 [128/50000]	Loss: 0.9116	LR: 0.000056
Training Epoch: 307 [128/50000]	Loss: 1.0571	LR: 0.000056
Training Epoch: 307 [128/50000]	Loss: 1.1042	LR: 0.000056
Training Epoch: 307 [128/50000]	Loss: 0.9443	LR: 0.000056
Training Epoch: 307 [128/50000]	Loss: 0.8391	LR: 0.000056
Training Epoch: 307 [128/50000]	Loss: 0.8013	LR: 0.000056
Training Epoch: 307 [128/50000]	Loss: 0.8677	LR: 0.000056
Evaluating Network.....
Test set: Epoch: 307, Average loss: 0.0109, Top1Accuracy: 0.6215, Top3Accuracy: 0.8177, Top5Accuracy: 0.8800, Time consumed:1.77s

Training Epoch: 308 [128/50000]	Loss: 0.8125	LR: 0.000054
Training Epoch: 308 [128/50000]	Loss: 0.8473	LR: 0.000054
Training Epoch: 308 [128/50000]	Loss: 0.7671	LR: 0.000054
Training Epoch: 308 [128/50000]	Loss: 0.7488	LR: 0.000054
Training Epoch: 308 [128/50000]	Loss: 0.8493	LR: 0.000054
Training Epoch: 308 [128/50000]	Loss: 0.7634	LR: 0.000054
Training Epoch: 308 [128/50000]	Loss: 0.7705	LR: 0.000054
Training Epoch: 308 [128/50000]	Loss: 0.8725	LR: 0.000054
Training Epoch: 308 [128/50000]	Loss: 0.8060	LR: 0.000054
Training Epoch: 308 [128/50000]	Loss: 0.8149	LR: 0.000054
Evaluating Network.....
Test set: Epoch: 308, Average loss: 0.0108, Top1Accuracy: 0.6230, Top3Accuracy: 0.8184, Top5Accuracy: 0.8794, Time consumed:1.79s

Training Epoch: 309 [128/50000]	Loss: 0.7690	LR: 0.000053
Training Epoch: 309 [128/50000]	Loss: 0.6974	LR: 0.000053
Training Epoch: 309 [128/50000]	Loss: 0.9588	LR: 0.000053
Training Epoch: 309 [128/50000]	Loss: 0.8770	LR: 0.000053
Training Epoch: 309 [128/50000]	Loss: 0.8768	LR: 0.000053
Training Epoch: 309 [128/50000]	Loss: 0.7213	LR: 0.000053
Training Epoch: 309 [128/50000]	Loss: 0.8656	LR: 0.000053
Training Epoch: 309 [128/50000]	Loss: 0.8469	LR: 0.000053
Training Epoch: 309 [128/50000]	Loss: 0.9599	LR: 0.000053
Training Epoch: 309 [128/50000]	Loss: 0.6970	LR: 0.000053
Evaluating Network.....
Test set: Epoch: 309, Average loss: 0.0109, Top1Accuracy: 0.6206, Top3Accuracy: 0.8181, Top5Accuracy: 0.8783, Time consumed:1.79s

Training Epoch: 310 [128/50000]	Loss: 0.9581	LR: 0.000051
Training Epoch: 310 [128/50000]	Loss: 0.8976	LR: 0.000051
Training Epoch: 310 [128/50000]	Loss: 0.8525	LR: 0.000051
Training Epoch: 310 [128/50000]	Loss: 0.9734	LR: 0.000051
Training Epoch: 310 [128/50000]	Loss: 0.8733	LR: 0.000051
Training Epoch: 310 [128/50000]	Loss: 0.7765	LR: 0.000051
Training Epoch: 310 [128/50000]	Loss: 0.9418	LR: 0.000051
Training Epoch: 310 [128/50000]	Loss: 0.9336	LR: 0.000051
Training Epoch: 310 [128/50000]	Loss: 1.0223	LR: 0.000051
Training Epoch: 310 [128/50000]	Loss: 0.8014	LR: 0.000051
Evaluating Network.....
Test set: Epoch: 310, Average loss: 0.0108, Top1Accuracy: 0.6222, Top3Accuracy: 0.8182, Top5Accuracy: 0.8797, Time consumed:1.78s

Training Epoch: 311 [128/50000]	Loss: 0.8779	LR: 0.000050
Training Epoch: 311 [128/50000]	Loss: 0.7982	LR: 0.000050
Training Epoch: 311 [128/50000]	Loss: 0.6435	LR: 0.000050
Training Epoch: 311 [128/50000]	Loss: 0.7098	LR: 0.000050
Training Epoch: 311 [128/50000]	Loss: 0.8328	LR: 0.000050
Training Epoch: 311 [128/50000]	Loss: 0.8642	LR: 0.000050
Training Epoch: 311 [128/50000]	Loss: 0.9663	LR: 0.000050
Training Epoch: 311 [128/50000]	Loss: 0.8562	LR: 0.000050
Training Epoch: 311 [128/50000]	Loss: 0.8665	LR: 0.000050
Training Epoch: 311 [128/50000]	Loss: 0.8312	LR: 0.000050
Evaluating Network.....
Test set: Epoch: 311, Average loss: 0.0109, Top1Accuracy: 0.6235, Top3Accuracy: 0.8199, Top5Accuracy: 0.8791, Time consumed:1.81s

Training Epoch: 312 [128/50000]	Loss: 0.7758	LR: 0.000049
Training Epoch: 312 [128/50000]	Loss: 0.6852	LR: 0.000049
Training Epoch: 312 [128/50000]	Loss: 1.0415	LR: 0.000049
Training Epoch: 312 [128/50000]	Loss: 0.8770	LR: 0.000049
Training Epoch: 312 [128/50000]	Loss: 0.8310	LR: 0.000049
Training Epoch: 312 [128/50000]	Loss: 1.0096	LR: 0.000049
Training Epoch: 312 [128/50000]	Loss: 0.7333	LR: 0.000049
Training Epoch: 312 [128/50000]	Loss: 0.7666	LR: 0.000049
Training Epoch: 312 [128/50000]	Loss: 0.9136	LR: 0.000049
Training Epoch: 312 [128/50000]	Loss: 0.7586	LR: 0.000049
Evaluating Network.....
Test set: Epoch: 312, Average loss: 0.0109, Top1Accuracy: 0.6215, Top3Accuracy: 0.8183, Top5Accuracy: 0.8799, Time consumed:1.80s

Training Epoch: 313 [128/50000]	Loss: 0.8200	LR: 0.000047
Training Epoch: 313 [128/50000]	Loss: 0.8134	LR: 0.000047
Training Epoch: 313 [128/50000]	Loss: 0.8340	LR: 0.000047
Training Epoch: 313 [128/50000]	Loss: 0.7313	LR: 0.000047
Training Epoch: 313 [128/50000]	Loss: 0.9376	LR: 0.000047
Training Epoch: 313 [128/50000]	Loss: 0.7337	LR: 0.000047
Training Epoch: 313 [128/50000]	Loss: 0.9597	LR: 0.000047
Training Epoch: 313 [128/50000]	Loss: 1.1296	LR: 0.000047
Training Epoch: 313 [128/50000]	Loss: 0.8255	LR: 0.000047
Training Epoch: 313 [128/50000]	Loss: 0.9604	LR: 0.000047
Evaluating Network.....
Test set: Epoch: 313, Average loss: 0.0108, Top1Accuracy: 0.6232, Top3Accuracy: 0.8200, Top5Accuracy: 0.8803, Time consumed:1.78s

Training Epoch: 314 [128/50000]	Loss: 1.0915	LR: 0.000046
Training Epoch: 314 [128/50000]	Loss: 0.8171	LR: 0.000046
Training Epoch: 314 [128/50000]	Loss: 0.9056	LR: 0.000046
Training Epoch: 314 [128/50000]	Loss: 0.7911	LR: 0.000046
Training Epoch: 314 [128/50000]	Loss: 0.8066	LR: 0.000046
Training Epoch: 314 [128/50000]	Loss: 0.9969	LR: 0.000046
Training Epoch: 314 [128/50000]	Loss: 0.8939	LR: 0.000046
Training Epoch: 314 [128/50000]	Loss: 0.8654	LR: 0.000046
Training Epoch: 314 [128/50000]	Loss: 0.8302	LR: 0.000046
Training Epoch: 314 [128/50000]	Loss: 0.8454	LR: 0.000046
Evaluating Network.....
Test set: Epoch: 314, Average loss: 0.0109, Top1Accuracy: 0.6222, Top3Accuracy: 0.8182, Top5Accuracy: 0.8793, Time consumed:1.78s

Training Epoch: 315 [128/50000]	Loss: 0.8767	LR: 0.000045
Training Epoch: 315 [128/50000]	Loss: 0.7910	LR: 0.000045
Training Epoch: 315 [128/50000]	Loss: 1.0026	LR: 0.000045
Training Epoch: 315 [128/50000]	Loss: 0.8840	LR: 0.000045
Training Epoch: 315 [128/50000]	Loss: 0.9350	LR: 0.000045
Training Epoch: 315 [128/50000]	Loss: 0.8993	LR: 0.000045
Training Epoch: 315 [128/50000]	Loss: 1.0291	LR: 0.000045
Training Epoch: 315 [128/50000]	Loss: 0.8844	LR: 0.000045
Training Epoch: 315 [128/50000]	Loss: 0.9335	LR: 0.000045
Training Epoch: 315 [128/50000]	Loss: 0.9757	LR: 0.000045
Evaluating Network.....
Test set: Epoch: 315, Average loss: 0.0108, Top1Accuracy: 0.6220, Top3Accuracy: 0.8191, Top5Accuracy: 0.8795, Time consumed:1.81s

Training Epoch: 316 [128/50000]	Loss: 0.9524	LR: 0.000044
Training Epoch: 316 [128/50000]	Loss: 0.7985	LR: 0.000044
Training Epoch: 316 [128/50000]	Loss: 0.8850	LR: 0.000044
Training Epoch: 316 [128/50000]	Loss: 0.9616	LR: 0.000044
Training Epoch: 316 [128/50000]	Loss: 0.8736	LR: 0.000044
Training Epoch: 316 [128/50000]	Loss: 0.8622	LR: 0.000044
Training Epoch: 316 [128/50000]	Loss: 0.9887	LR: 0.000044
Training Epoch: 316 [128/50000]	Loss: 0.8281	LR: 0.000044
Training Epoch: 316 [128/50000]	Loss: 0.8631	LR: 0.000044
Training Epoch: 316 [128/50000]	Loss: 0.8703	LR: 0.000044
Evaluating Network.....
Test set: Epoch: 316, Average loss: 0.0108, Top1Accuracy: 0.6217, Top3Accuracy: 0.8174, Top5Accuracy: 0.8790, Time consumed:1.80s

Training Epoch: 317 [128/50000]	Loss: 0.7753	LR: 0.000043
Training Epoch: 317 [128/50000]	Loss: 1.1050	LR: 0.000043
Training Epoch: 317 [128/50000]	Loss: 0.9641	LR: 0.000043
Training Epoch: 317 [128/50000]	Loss: 0.8479	LR: 0.000043
Training Epoch: 317 [128/50000]	Loss: 0.9741	LR: 0.000043
Training Epoch: 317 [128/50000]	Loss: 0.9015	LR: 0.000043
Training Epoch: 317 [128/50000]	Loss: 0.8685	LR: 0.000043
Training Epoch: 317 [128/50000]	Loss: 0.6834	LR: 0.000043
Training Epoch: 317 [128/50000]	Loss: 0.8596	LR: 0.000043
Training Epoch: 317 [128/50000]	Loss: 0.9483	LR: 0.000043
Evaluating Network.....
Test set: Epoch: 317, Average loss: 0.0109, Top1Accuracy: 0.6232, Top3Accuracy: 0.8199, Top5Accuracy: 0.8802, Time consumed:1.79s

Training Epoch: 318 [128/50000]	Loss: 0.9379	LR: 0.000041
Training Epoch: 318 [128/50000]	Loss: 0.7645	LR: 0.000041
Training Epoch: 318 [128/50000]	Loss: 0.9140	LR: 0.000041
Training Epoch: 318 [128/50000]	Loss: 0.8246	LR: 0.000041
Training Epoch: 318 [128/50000]	Loss: 0.9289	LR: 0.000041
Training Epoch: 318 [128/50000]	Loss: 1.1349	LR: 0.000041
Training Epoch: 318 [128/50000]	Loss: 0.8591	LR: 0.000041
Training Epoch: 318 [128/50000]	Loss: 1.0114	LR: 0.000041
Training Epoch: 318 [128/50000]	Loss: 0.8700	LR: 0.000041
Training Epoch: 318 [128/50000]	Loss: 0.9473	LR: 0.000041
Evaluating Network.....
Test set: Epoch: 318, Average loss: 0.0108, Top1Accuracy: 0.6218, Top3Accuracy: 0.8190, Top5Accuracy: 0.8806, Time consumed:1.79s

Training Epoch: 319 [128/50000]	Loss: 0.7669	LR: 0.000040
Training Epoch: 319 [128/50000]	Loss: 0.8747	LR: 0.000040
Training Epoch: 319 [128/50000]	Loss: 1.0619	LR: 0.000040
Training Epoch: 319 [128/50000]	Loss: 0.7568	LR: 0.000040
Training Epoch: 319 [128/50000]	Loss: 0.6578	LR: 0.000040
Training Epoch: 319 [128/50000]	Loss: 0.9803	LR: 0.000040
Training Epoch: 319 [128/50000]	Loss: 0.8899	LR: 0.000040
Training Epoch: 319 [128/50000]	Loss: 0.8993	LR: 0.000040
Training Epoch: 319 [128/50000]	Loss: 0.8091	LR: 0.000040
Training Epoch: 319 [128/50000]	Loss: 1.0641	LR: 0.000040
Evaluating Network.....
Test set: Epoch: 319, Average loss: 0.0110, Top1Accuracy: 0.6236, Top3Accuracy: 0.8169, Top5Accuracy: 0.8786, Time consumed:1.78s

Training Epoch: 320 [128/50000]	Loss: 0.8182	LR: 0.000039
Training Epoch: 320 [128/50000]	Loss: 0.8837	LR: 0.000039
Training Epoch: 320 [128/50000]	Loss: 1.0972	LR: 0.000039
Training Epoch: 320 [128/50000]	Loss: 0.8368	LR: 0.000039
Training Epoch: 320 [128/50000]	Loss: 0.8895	LR: 0.000039
Training Epoch: 320 [128/50000]	Loss: 0.9564	LR: 0.000039
Training Epoch: 320 [128/50000]	Loss: 0.9548	LR: 0.000039
Training Epoch: 320 [128/50000]	Loss: 0.9197	LR: 0.000039
Training Epoch: 320 [128/50000]	Loss: 0.7189	LR: 0.000039
Training Epoch: 320 [128/50000]	Loss: 0.9753	LR: 0.000039
Evaluating Network.....
Test set: Epoch: 320, Average loss: 0.0108, Top1Accuracy: 0.6214, Top3Accuracy: 0.8184, Top5Accuracy: 0.8796, Time consumed:1.81s

Training Epoch: 321 [128/50000]	Loss: 0.9324	LR: 0.000038
Training Epoch: 321 [128/50000]	Loss: 0.8882	LR: 0.000038
Training Epoch: 321 [128/50000]	Loss: 0.8808	LR: 0.000038
Training Epoch: 321 [128/50000]	Loss: 1.0946	LR: 0.000038
Training Epoch: 321 [128/50000]	Loss: 0.8402	LR: 0.000038
Training Epoch: 321 [128/50000]	Loss: 0.9511	LR: 0.000038
Training Epoch: 321 [128/50000]	Loss: 0.8432	LR: 0.000038
Training Epoch: 321 [128/50000]	Loss: 0.8753	LR: 0.000038
Training Epoch: 321 [128/50000]	Loss: 0.8957	LR: 0.000038
Training Epoch: 321 [128/50000]	Loss: 0.7577	LR: 0.000038
Evaluating Network.....
Test set: Epoch: 321, Average loss: 0.0108, Top1Accuracy: 0.6230, Top3Accuracy: 0.8188, Top5Accuracy: 0.8804, Time consumed:1.77s

Training Epoch: 322 [128/50000]	Loss: 0.8284	LR: 0.000037
Training Epoch: 322 [128/50000]	Loss: 0.9388	LR: 0.000037
Training Epoch: 322 [128/50000]	Loss: 0.9582	LR: 0.000037
Training Epoch: 322 [128/50000]	Loss: 0.8173	LR: 0.000037
Training Epoch: 322 [128/50000]	Loss: 0.6795	LR: 0.000037
Training Epoch: 322 [128/50000]	Loss: 0.8749	LR: 0.000037
Training Epoch: 322 [128/50000]	Loss: 0.8502	LR: 0.000037
Training Epoch: 322 [128/50000]	Loss: 0.9280	LR: 0.000037
Training Epoch: 322 [128/50000]	Loss: 0.9981	LR: 0.000037
Training Epoch: 322 [128/50000]	Loss: 1.0662	LR: 0.000037
Evaluating Network.....
Test set: Epoch: 322, Average loss: 0.0108, Top1Accuracy: 0.6218, Top3Accuracy: 0.8181, Top5Accuracy: 0.8797, Time consumed:1.80s

Training Epoch: 323 [128/50000]	Loss: 0.9081	LR: 0.000036
Training Epoch: 323 [128/50000]	Loss: 1.0744	LR: 0.000036
Training Epoch: 323 [128/50000]	Loss: 0.8542	LR: 0.000036
Training Epoch: 323 [128/50000]	Loss: 0.8297	LR: 0.000036
Training Epoch: 323 [128/50000]	Loss: 0.9477	LR: 0.000036
Training Epoch: 323 [128/50000]	Loss: 0.7011	LR: 0.000036
Training Epoch: 323 [128/50000]	Loss: 0.8237	LR: 0.000036
Training Epoch: 323 [128/50000]	Loss: 1.0488	LR: 0.000036
Training Epoch: 323 [128/50000]	Loss: 0.8414	LR: 0.000036
Training Epoch: 323 [128/50000]	Loss: 0.9600	LR: 0.000036
Evaluating Network.....
Test set: Epoch: 323, Average loss: 0.0108, Top1Accuracy: 0.6216, Top3Accuracy: 0.8193, Top5Accuracy: 0.8791, Time consumed:1.79s

Training Epoch: 324 [128/50000]	Loss: 0.7793	LR: 0.000035
Training Epoch: 324 [128/50000]	Loss: 1.0158	LR: 0.000035
Training Epoch: 324 [128/50000]	Loss: 0.8428	LR: 0.000035
Training Epoch: 324 [128/50000]	Loss: 0.8998	LR: 0.000035
Training Epoch: 324 [128/50000]	Loss: 1.0206	LR: 0.000035
Training Epoch: 324 [128/50000]	Loss: 1.0205	LR: 0.000035
Training Epoch: 324 [128/50000]	Loss: 1.0327	LR: 0.000035
Training Epoch: 324 [128/50000]	Loss: 0.8958	LR: 0.000035
Training Epoch: 324 [128/50000]	Loss: 0.9278	LR: 0.000035
Training Epoch: 324 [128/50000]	Loss: 1.0726	LR: 0.000035
Evaluating Network.....
Test set: Epoch: 324, Average loss: 0.0108, Top1Accuracy: 0.6220, Top3Accuracy: 0.8197, Top5Accuracy: 0.8791, Time consumed:2.07s

Training Epoch: 325 [128/50000]	Loss: 0.7446	LR: 0.000034
Training Epoch: 325 [128/50000]	Loss: 0.9528	LR: 0.000034
Training Epoch: 325 [128/50000]	Loss: 0.8119	LR: 0.000034
Training Epoch: 325 [128/50000]	Loss: 0.9723	LR: 0.000034
Training Epoch: 325 [128/50000]	Loss: 0.9103	LR: 0.000034
Training Epoch: 325 [128/50000]	Loss: 0.7447	LR: 0.000034
Training Epoch: 325 [128/50000]	Loss: 0.8827	LR: 0.000034
Training Epoch: 325 [128/50000]	Loss: 0.8724	LR: 0.000034
Training Epoch: 325 [128/50000]	Loss: 0.9209	LR: 0.000034
Training Epoch: 325 [128/50000]	Loss: 0.9751	LR: 0.000034
Evaluating Network.....
Test set: Epoch: 325, Average loss: 0.0108, Top1Accuracy: 0.6212, Top3Accuracy: 0.8195, Top5Accuracy: 0.8797, Time consumed:1.80s

Training Epoch: 326 [128/50000]	Loss: 0.8088	LR: 0.000033
Training Epoch: 326 [128/50000]	Loss: 0.8663	LR: 0.000033
Training Epoch: 326 [128/50000]	Loss: 0.9408	LR: 0.000033
Training Epoch: 326 [128/50000]	Loss: 0.8288	LR: 0.000033
Training Epoch: 326 [128/50000]	Loss: 0.8720	LR: 0.000033
Training Epoch: 326 [128/50000]	Loss: 0.9497	LR: 0.000033
Training Epoch: 326 [128/50000]	Loss: 1.1326	LR: 0.000033
Training Epoch: 326 [128/50000]	Loss: 0.8438	LR: 0.000033
Training Epoch: 326 [128/50000]	Loss: 0.8123	LR: 0.000033
Training Epoch: 326 [128/50000]	Loss: 0.9653	LR: 0.000033
Evaluating Network.....
Test set: Epoch: 326, Average loss: 0.0108, Top1Accuracy: 0.6230, Top3Accuracy: 0.8204, Top5Accuracy: 0.8798, Time consumed:1.78s

Training Epoch: 327 [128/50000]	Loss: 0.8464	LR: 0.000033
Training Epoch: 327 [128/50000]	Loss: 0.9579	LR: 0.000033
Training Epoch: 327 [128/50000]	Loss: 0.7970	LR: 0.000033
Training Epoch: 327 [128/50000]	Loss: 1.0388	LR: 0.000033
Training Epoch: 327 [128/50000]	Loss: 0.8041	LR: 0.000033
Training Epoch: 327 [128/50000]	Loss: 0.9017	LR: 0.000033
Training Epoch: 327 [128/50000]	Loss: 0.9820	LR: 0.000033
Training Epoch: 327 [128/50000]	Loss: 0.8389	LR: 0.000033
Training Epoch: 327 [128/50000]	Loss: 0.8996	LR: 0.000033
Training Epoch: 327 [128/50000]	Loss: 0.9327	LR: 0.000033
Evaluating Network.....
Test set: Epoch: 327, Average loss: 0.0108, Top1Accuracy: 0.6219, Top3Accuracy: 0.8191, Top5Accuracy: 0.8796, Time consumed:1.80s

Training Epoch: 328 [128/50000]	Loss: 0.8422	LR: 0.000032
Training Epoch: 328 [128/50000]	Loss: 0.8675	LR: 0.000032
Training Epoch: 328 [128/50000]	Loss: 0.9353	LR: 0.000032
Training Epoch: 328 [128/50000]	Loss: 1.0596	LR: 0.000032
Training Epoch: 328 [128/50000]	Loss: 0.8161	LR: 0.000032
Training Epoch: 328 [128/50000]	Loss: 0.8312	LR: 0.000032
Training Epoch: 328 [128/50000]	Loss: 0.9773	LR: 0.000032
Training Epoch: 328 [128/50000]	Loss: 0.9730	LR: 0.000032
Training Epoch: 328 [128/50000]	Loss: 0.8646	LR: 0.000032
Training Epoch: 328 [128/50000]	Loss: 0.9544	LR: 0.000032
Evaluating Network.....
Test set: Epoch: 328, Average loss: 0.0108, Top1Accuracy: 0.6220, Top3Accuracy: 0.8183, Top5Accuracy: 0.8794, Time consumed:1.81s

Training Epoch: 329 [128/50000]	Loss: 1.1368	LR: 0.000031
Training Epoch: 329 [128/50000]	Loss: 0.7651	LR: 0.000031
Training Epoch: 329 [128/50000]	Loss: 0.7654	LR: 0.000031
Training Epoch: 329 [128/50000]	Loss: 1.0466	LR: 0.000031
Training Epoch: 329 [128/50000]	Loss: 0.7580	LR: 0.000031
Training Epoch: 329 [128/50000]	Loss: 0.8531	LR: 0.000031
Training Epoch: 329 [128/50000]	Loss: 0.7232	LR: 0.000031
Training Epoch: 329 [128/50000]	Loss: 0.7233	LR: 0.000031
Training Epoch: 329 [128/50000]	Loss: 0.7144	LR: 0.000031
Training Epoch: 329 [128/50000]	Loss: 1.1146	LR: 0.000031
Evaluating Network.....
Test set: Epoch: 329, Average loss: 0.0108, Top1Accuracy: 0.6221, Top3Accuracy: 0.8193, Top5Accuracy: 0.8792, Time consumed:1.79s

Training Epoch: 330 [128/50000]	Loss: 0.7226	LR: 0.000030
Training Epoch: 330 [128/50000]	Loss: 0.8320	LR: 0.000030
Training Epoch: 330 [128/50000]	Loss: 0.7919	LR: 0.000030
Training Epoch: 330 [128/50000]	Loss: 0.9040	LR: 0.000030
Training Epoch: 330 [128/50000]	Loss: 0.9485	LR: 0.000030
Training Epoch: 330 [128/50000]	Loss: 1.0952	LR: 0.000030
Training Epoch: 330 [128/50000]	Loss: 0.8119	LR: 0.000030
Training Epoch: 330 [128/50000]	Loss: 0.7893	LR: 0.000030
Training Epoch: 330 [128/50000]	Loss: 0.9920	LR: 0.000030
Training Epoch: 330 [128/50000]	Loss: 0.7370	LR: 0.000030
Evaluating Network.....
Test set: Epoch: 330, Average loss: 0.0109, Top1Accuracy: 0.6214, Top3Accuracy: 0.8195, Top5Accuracy: 0.8804, Time consumed:1.78s

Training Epoch: 331 [128/50000]	Loss: 0.8518	LR: 0.000029
Training Epoch: 331 [128/50000]	Loss: 0.7974	LR: 0.000029
Training Epoch: 331 [128/50000]	Loss: 0.9233	LR: 0.000029
Training Epoch: 331 [128/50000]	Loss: 0.8601	LR: 0.000029
Training Epoch: 331 [128/50000]	Loss: 0.9048	LR: 0.000029
Training Epoch: 331 [128/50000]	Loss: 0.8149	LR: 0.000029
Training Epoch: 331 [128/50000]	Loss: 0.9104	LR: 0.000029
Training Epoch: 331 [128/50000]	Loss: 0.8565	LR: 0.000029
Training Epoch: 331 [128/50000]	Loss: 0.7965	LR: 0.000029
Training Epoch: 331 [128/50000]	Loss: 0.9470	LR: 0.000029
Evaluating Network.....
Test set: Epoch: 331, Average loss: 0.0108, Top1Accuracy: 0.6215, Top3Accuracy: 0.8205, Top5Accuracy: 0.8807, Time consumed:1.78s

Training Epoch: 332 [128/50000]	Loss: 0.8853	LR: 0.000029
Training Epoch: 332 [128/50000]	Loss: 0.9335	LR: 0.000029
Training Epoch: 332 [128/50000]	Loss: 1.1188	LR: 0.000029
Training Epoch: 332 [128/50000]	Loss: 0.8482	LR: 0.000029
Training Epoch: 332 [128/50000]	Loss: 0.7996	LR: 0.000029
Training Epoch: 332 [128/50000]	Loss: 0.8843	LR: 0.000029
Training Epoch: 332 [128/50000]	Loss: 0.8296	LR: 0.000029
Training Epoch: 332 [128/50000]	Loss: 0.7734	LR: 0.000029
Training Epoch: 332 [128/50000]	Loss: 0.7825	LR: 0.000029
Training Epoch: 332 [128/50000]	Loss: 0.8023	LR: 0.000029
Evaluating Network.....
Test set: Epoch: 332, Average loss: 0.0108, Top1Accuracy: 0.6223, Top3Accuracy: 0.8195, Top5Accuracy: 0.8803, Time consumed:1.79s

Training Epoch: 333 [128/50000]	Loss: 0.9145	LR: 0.000028
Training Epoch: 333 [128/50000]	Loss: 0.7186	LR: 0.000028
Training Epoch: 333 [128/50000]	Loss: 0.9446	LR: 0.000028
Training Epoch: 333 [128/50000]	Loss: 0.8989	LR: 0.000028
Training Epoch: 333 [128/50000]	Loss: 0.9257	LR: 0.000028
Training Epoch: 333 [128/50000]	Loss: 0.7219	LR: 0.000028
Training Epoch: 333 [128/50000]	Loss: 0.9353	LR: 0.000028
Training Epoch: 333 [128/50000]	Loss: 0.8088	LR: 0.000028
Training Epoch: 333 [128/50000]	Loss: 0.8420	LR: 0.000028
Training Epoch: 333 [128/50000]	Loss: 0.8909	LR: 0.000028
Evaluating Network.....
Test set: Epoch: 333, Average loss: 0.0108, Top1Accuracy: 0.6207, Top3Accuracy: 0.8185, Top5Accuracy: 0.8804, Time consumed:1.79s

Training Epoch: 334 [128/50000]	Loss: 0.7314	LR: 0.000027
Training Epoch: 334 [128/50000]	Loss: 0.7990	LR: 0.000027
Training Epoch: 334 [128/50000]	Loss: 0.8434	LR: 0.000027
Training Epoch: 334 [128/50000]	Loss: 1.0899	LR: 0.000027
Training Epoch: 334 [128/50000]	Loss: 0.8691	LR: 0.000027
Training Epoch: 334 [128/50000]	Loss: 0.7157	LR: 0.000027
Training Epoch: 334 [128/50000]	Loss: 0.7348	LR: 0.000027
Training Epoch: 334 [128/50000]	Loss: 0.8953	LR: 0.000027
Training Epoch: 334 [128/50000]	Loss: 0.6814	LR: 0.000027
Training Epoch: 334 [128/50000]	Loss: 0.9503	LR: 0.000027
Evaluating Network.....
Test set: Epoch: 334, Average loss: 0.0109, Top1Accuracy: 0.6205, Top3Accuracy: 0.8172, Top5Accuracy: 0.8790, Time consumed:1.80s

Training Epoch: 335 [128/50000]	Loss: 0.9511	LR: 0.000026
Training Epoch: 335 [128/50000]	Loss: 0.8423	LR: 0.000026
Training Epoch: 335 [128/50000]	Loss: 0.9176	LR: 0.000026
Training Epoch: 335 [128/50000]	Loss: 0.9557	LR: 0.000026
Training Epoch: 335 [128/50000]	Loss: 0.8638	LR: 0.000026
Training Epoch: 335 [128/50000]	Loss: 0.8261	LR: 0.000026
Training Epoch: 335 [128/50000]	Loss: 1.1389	LR: 0.000026
Training Epoch: 335 [128/50000]	Loss: 0.8981	LR: 0.000026
Training Epoch: 335 [128/50000]	Loss: 0.7953	LR: 0.000026
Training Epoch: 335 [128/50000]	Loss: 0.8667	LR: 0.000026
Evaluating Network.....
Test set: Epoch: 335, Average loss: 0.0108, Top1Accuracy: 0.6211, Top3Accuracy: 0.8199, Top5Accuracy: 0.8804, Time consumed:1.78s

Training Epoch: 336 [128/50000]	Loss: 0.9014	LR: 0.000026
Training Epoch: 336 [128/50000]	Loss: 0.9105	LR: 0.000026
Training Epoch: 336 [128/50000]	Loss: 0.8324	LR: 0.000026
Training Epoch: 336 [128/50000]	Loss: 0.7817	LR: 0.000026
Training Epoch: 336 [128/50000]	Loss: 0.7882	LR: 0.000026
Training Epoch: 336 [128/50000]	Loss: 0.8949	LR: 0.000026
Training Epoch: 336 [128/50000]	Loss: 0.7546	LR: 0.000026
Training Epoch: 336 [128/50000]	Loss: 1.0577	LR: 0.000026
Training Epoch: 336 [128/50000]	Loss: 1.1284	LR: 0.000026
Training Epoch: 336 [128/50000]	Loss: 0.5999	LR: 0.000026
Evaluating Network.....
Test set: Epoch: 336, Average loss: 0.0108, Top1Accuracy: 0.6207, Top3Accuracy: 0.8186, Top5Accuracy: 0.8794, Time consumed:1.80s

Training Epoch: 337 [128/50000]	Loss: 0.8937	LR: 0.000025
Training Epoch: 337 [128/50000]	Loss: 0.7660	LR: 0.000025
Training Epoch: 337 [128/50000]	Loss: 0.8466	LR: 0.000025
Training Epoch: 337 [128/50000]	Loss: 0.6963	LR: 0.000025
Training Epoch: 337 [128/50000]	Loss: 0.6067	LR: 0.000025
Training Epoch: 337 [128/50000]	Loss: 0.8919	LR: 0.000025
Training Epoch: 337 [128/50000]	Loss: 0.8748	LR: 0.000025
Training Epoch: 337 [128/50000]	Loss: 0.7185	LR: 0.000025
Training Epoch: 337 [128/50000]	Loss: 0.9441	LR: 0.000025
Training Epoch: 337 [128/50000]	Loss: 0.8141	LR: 0.000025
Evaluating Network.....
Test set: Epoch: 337, Average loss: 0.0109, Top1Accuracy: 0.6227, Top3Accuracy: 0.8184, Top5Accuracy: 0.8804, Time consumed:1.79s

Training Epoch: 338 [128/50000]	Loss: 1.0409	LR: 0.000024
Training Epoch: 338 [128/50000]	Loss: 0.9873	LR: 0.000024
Training Epoch: 338 [128/50000]	Loss: 0.9097	LR: 0.000024
Training Epoch: 338 [128/50000]	Loss: 1.0032	LR: 0.000024
Training Epoch: 338 [128/50000]	Loss: 1.0836	LR: 0.000024
Training Epoch: 338 [128/50000]	Loss: 0.9694	LR: 0.000024
Training Epoch: 338 [128/50000]	Loss: 0.8807	LR: 0.000024
Training Epoch: 338 [128/50000]	Loss: 0.9610	LR: 0.000024
Training Epoch: 338 [128/50000]	Loss: 0.9020	LR: 0.000024
Training Epoch: 338 [128/50000]	Loss: 0.9910	LR: 0.000024
Evaluating Network.....
Test set: Epoch: 338, Average loss: 0.0109, Top1Accuracy: 0.6210, Top3Accuracy: 0.8187, Top5Accuracy: 0.8788, Time consumed:1.80s

Training Epoch: 339 [128/50000]	Loss: 0.8339	LR: 0.000024
Training Epoch: 339 [128/50000]	Loss: 0.8205	LR: 0.000024
Training Epoch: 339 [128/50000]	Loss: 0.8173	LR: 0.000024
Training Epoch: 339 [128/50000]	Loss: 0.9073	LR: 0.000024
Training Epoch: 339 [128/50000]	Loss: 0.8069	LR: 0.000024
Training Epoch: 339 [128/50000]	Loss: 0.9421	LR: 0.000024
Training Epoch: 339 [128/50000]	Loss: 0.7764	LR: 0.000024
Training Epoch: 339 [128/50000]	Loss: 1.1235	LR: 0.000024
Training Epoch: 339 [128/50000]	Loss: 0.9528	LR: 0.000024
Training Epoch: 339 [128/50000]	Loss: 0.9492	LR: 0.000024
Evaluating Network.....
Test set: Epoch: 339, Average loss: 0.0108, Top1Accuracy: 0.6228, Top3Accuracy: 0.8195, Top5Accuracy: 0.8800, Time consumed:1.78s

Training Epoch: 340 [128/50000]	Loss: 0.8635	LR: 0.000023
Training Epoch: 340 [128/50000]	Loss: 0.8795	LR: 0.000023
Training Epoch: 340 [128/50000]	Loss: 0.8301	LR: 0.000023
Training Epoch: 340 [128/50000]	Loss: 0.8223	LR: 0.000023
Training Epoch: 340 [128/50000]	Loss: 0.8692	LR: 0.000023
Training Epoch: 340 [128/50000]	Loss: 0.6356	LR: 0.000023
Training Epoch: 340 [128/50000]	Loss: 0.7987	LR: 0.000023
Training Epoch: 340 [128/50000]	Loss: 1.0673	LR: 0.000023
Training Epoch: 340 [128/50000]	Loss: 1.1120	LR: 0.000023
Training Epoch: 340 [128/50000]	Loss: 0.8906	LR: 0.000023
Evaluating Network.....
Test set: Epoch: 340, Average loss: 0.0109, Top1Accuracy: 0.6218, Top3Accuracy: 0.8183, Top5Accuracy: 0.8817, Time consumed:1.79s

Training Epoch: 341 [128/50000]	Loss: 0.8690	LR: 0.000022
Training Epoch: 341 [128/50000]	Loss: 0.9670	LR: 0.000022
Training Epoch: 341 [128/50000]	Loss: 0.7910	LR: 0.000022
Training Epoch: 341 [128/50000]	Loss: 0.7862	LR: 0.000022
Training Epoch: 341 [128/50000]	Loss: 0.7241	LR: 0.000022
Training Epoch: 341 [128/50000]	Loss: 0.9443	LR: 0.000022
Training Epoch: 341 [128/50000]	Loss: 0.8542	LR: 0.000022
Training Epoch: 341 [128/50000]	Loss: 0.7541	LR: 0.000022
Training Epoch: 341 [128/50000]	Loss: 0.8495	LR: 0.000022
Training Epoch: 341 [128/50000]	Loss: 0.8146	LR: 0.000022
Evaluating Network.....
Test set: Epoch: 341, Average loss: 0.0108, Top1Accuracy: 0.6207, Top3Accuracy: 0.8193, Top5Accuracy: 0.8808, Time consumed:1.79s

Training Epoch: 342 [128/50000]	Loss: 0.7920	LR: 0.000022
Training Epoch: 342 [128/50000]	Loss: 0.9920	LR: 0.000022
Training Epoch: 342 [128/50000]	Loss: 0.8222	LR: 0.000022
Training Epoch: 342 [128/50000]	Loss: 0.7661	LR: 0.000022
Training Epoch: 342 [128/50000]	Loss: 0.7124	LR: 0.000022
Training Epoch: 342 [128/50000]	Loss: 1.0885	LR: 0.000022
Training Epoch: 342 [128/50000]	Loss: 0.8405	LR: 0.000022
Training Epoch: 342 [128/50000]	Loss: 1.1069	LR: 0.000022
Training Epoch: 342 [128/50000]	Loss: 0.8381	LR: 0.000022
Training Epoch: 342 [128/50000]	Loss: 1.1535	LR: 0.000022
Evaluating Network.....
Test set: Epoch: 342, Average loss: 0.0108, Top1Accuracy: 0.6222, Top3Accuracy: 0.8192, Top5Accuracy: 0.8807, Time consumed:1.80s

Training Epoch: 343 [128/50000]	Loss: 0.9596	LR: 0.000021
Training Epoch: 343 [128/50000]	Loss: 0.6644	LR: 0.000021
Training Epoch: 343 [128/50000]	Loss: 0.9200	LR: 0.000021
Training Epoch: 343 [128/50000]	Loss: 0.8890	LR: 0.000021
Training Epoch: 343 [128/50000]	Loss: 0.7599	LR: 0.000021
Training Epoch: 343 [128/50000]	Loss: 0.8395	LR: 0.000021
Training Epoch: 343 [128/50000]	Loss: 0.9203	LR: 0.000021
Training Epoch: 343 [128/50000]	Loss: 0.7665	LR: 0.000021
Training Epoch: 343 [128/50000]	Loss: 0.8544	LR: 0.000021
Training Epoch: 343 [128/50000]	Loss: 0.8309	LR: 0.000021
Evaluating Network.....
Test set: Epoch: 343, Average loss: 0.0108, Top1Accuracy: 0.6219, Top3Accuracy: 0.8181, Top5Accuracy: 0.8795, Time consumed:1.78s

Training Epoch: 344 [128/50000]	Loss: 0.9224	LR: 0.000021
Training Epoch: 344 [128/50000]	Loss: 0.9269	LR: 0.000021
Training Epoch: 344 [128/50000]	Loss: 0.7977	LR: 0.000021
Training Epoch: 344 [128/50000]	Loss: 0.8748	LR: 0.000021
Training Epoch: 344 [128/50000]	Loss: 0.7741	LR: 0.000021
Training Epoch: 344 [128/50000]	Loss: 0.8129	LR: 0.000021
Training Epoch: 344 [128/50000]	Loss: 0.7931	LR: 0.000021
Training Epoch: 344 [128/50000]	Loss: 0.8159	LR: 0.000021
Training Epoch: 344 [128/50000]	Loss: 0.7888	LR: 0.000021
Training Epoch: 344 [128/50000]	Loss: 0.7996	LR: 0.000021
Evaluating Network.....
Test set: Epoch: 344, Average loss: 0.0108, Top1Accuracy: 0.6228, Top3Accuracy: 0.8192, Top5Accuracy: 0.8800, Time consumed:1.79s

Training Epoch: 345 [128/50000]	Loss: 1.0480	LR: 0.000020
Training Epoch: 345 [128/50000]	Loss: 0.9471	LR: 0.000020
Training Epoch: 345 [128/50000]	Loss: 0.9996	LR: 0.000020
Training Epoch: 345 [128/50000]	Loss: 0.8330	LR: 0.000020
Training Epoch: 345 [128/50000]	Loss: 0.8829	LR: 0.000020
Training Epoch: 345 [128/50000]	Loss: 0.9347	LR: 0.000020
Training Epoch: 345 [128/50000]	Loss: 0.8871	LR: 0.000020
Training Epoch: 345 [128/50000]	Loss: 0.8446	LR: 0.000020
Training Epoch: 345 [128/50000]	Loss: 0.7619	LR: 0.000020
Training Epoch: 345 [128/50000]	Loss: 0.6247	LR: 0.000020
Evaluating Network.....
Test set: Epoch: 345, Average loss: 0.0108, Top1Accuracy: 0.6230, Top3Accuracy: 0.8185, Top5Accuracy: 0.8803, Time consumed:1.80s

Training Epoch: 346 [128/50000]	Loss: 0.8733	LR: 0.000020
Training Epoch: 346 [128/50000]	Loss: 1.1124	LR: 0.000020
Training Epoch: 346 [128/50000]	Loss: 0.9011	LR: 0.000020
Training Epoch: 346 [128/50000]	Loss: 0.8629	LR: 0.000020
Training Epoch: 346 [128/50000]	Loss: 0.7711	LR: 0.000020
Training Epoch: 346 [128/50000]	Loss: 1.0035	LR: 0.000020
Training Epoch: 346 [128/50000]	Loss: 0.9000	LR: 0.000020
Training Epoch: 346 [128/50000]	Loss: 1.0218	LR: 0.000020
Training Epoch: 346 [128/50000]	Loss: 0.8790	LR: 0.000020
Training Epoch: 346 [128/50000]	Loss: 0.8176	LR: 0.000020
Evaluating Network.....
Test set: Epoch: 346, Average loss: 0.0108, Top1Accuracy: 0.6227, Top3Accuracy: 0.8182, Top5Accuracy: 0.8793, Time consumed:1.78s

Training Epoch: 347 [128/50000]	Loss: 0.8546	LR: 0.000019
Training Epoch: 347 [128/50000]	Loss: 0.7284	LR: 0.000019
Training Epoch: 347 [128/50000]	Loss: 0.8350	LR: 0.000019
Training Epoch: 347 [128/50000]	Loss: 0.8444	LR: 0.000019
Training Epoch: 347 [128/50000]	Loss: 0.8584	LR: 0.000019
Training Epoch: 347 [128/50000]	Loss: 0.9907	LR: 0.000019
Training Epoch: 347 [128/50000]	Loss: 1.0151	LR: 0.000019
Training Epoch: 347 [128/50000]	Loss: 0.8252	LR: 0.000019
Training Epoch: 347 [128/50000]	Loss: 0.7924	LR: 0.000019
Training Epoch: 347 [128/50000]	Loss: 0.8712	LR: 0.000019
Evaluating Network.....
Test set: Epoch: 347, Average loss: 0.0108, Top1Accuracy: 0.6211, Top3Accuracy: 0.8189, Top5Accuracy: 0.8802, Time consumed:1.80s

Training Epoch: 348 [128/50000]	Loss: 0.9798	LR: 0.000019
Training Epoch: 348 [128/50000]	Loss: 1.0156	LR: 0.000019
Training Epoch: 348 [128/50000]	Loss: 0.9377	LR: 0.000019
Training Epoch: 348 [128/50000]	Loss: 1.0543	LR: 0.000019
Training Epoch: 348 [128/50000]	Loss: 0.8346	LR: 0.000019
Training Epoch: 348 [128/50000]	Loss: 0.9672	LR: 0.000019
Training Epoch: 348 [128/50000]	Loss: 0.9105	LR: 0.000019
Training Epoch: 348 [128/50000]	Loss: 0.9994	LR: 0.000019
Training Epoch: 348 [128/50000]	Loss: 0.9180	LR: 0.000019
Training Epoch: 348 [128/50000]	Loss: 0.7799	LR: 0.000019
Evaluating Network.....
Test set: Epoch: 348, Average loss: 0.0109, Top1Accuracy: 0.6219, Top3Accuracy: 0.8181, Top5Accuracy: 0.8798, Time consumed:1.79s

Training Epoch: 349 [128/50000]	Loss: 0.8958	LR: 0.000018
Training Epoch: 349 [128/50000]	Loss: 0.8541	LR: 0.000018
Training Epoch: 349 [128/50000]	Loss: 0.8869	LR: 0.000018
Training Epoch: 349 [128/50000]	Loss: 0.8799	LR: 0.000018
Training Epoch: 349 [128/50000]	Loss: 0.7689	LR: 0.000018
Training Epoch: 349 [128/50000]	Loss: 0.8281	LR: 0.000018
Training Epoch: 349 [128/50000]	Loss: 0.9034	LR: 0.000018
Training Epoch: 349 [128/50000]	Loss: 0.8491	LR: 0.000018
Training Epoch: 349 [128/50000]	Loss: 0.9753	LR: 0.000018
Training Epoch: 349 [128/50000]	Loss: 0.8144	LR: 0.000018
Evaluating Network.....
Test set: Epoch: 349, Average loss: 0.0109, Top1Accuracy: 0.6222, Top3Accuracy: 0.8187, Top5Accuracy: 0.8793, Time consumed:1.80s

Training Epoch: 350 [128/50000]	Loss: 0.8274	LR: 0.000018
Training Epoch: 350 [128/50000]	Loss: 0.7704	LR: 0.000018
Training Epoch: 350 [128/50000]	Loss: 0.8890	LR: 0.000018
Training Epoch: 350 [128/50000]	Loss: 0.9151	LR: 0.000018
Training Epoch: 350 [128/50000]	Loss: 1.1712	LR: 0.000018
Training Epoch: 350 [128/50000]	Loss: 0.8220	LR: 0.000018
Training Epoch: 350 [128/50000]	Loss: 0.8939	LR: 0.000018
Training Epoch: 350 [128/50000]	Loss: 0.8618	LR: 0.000018
Training Epoch: 350 [128/50000]	Loss: 0.9404	LR: 0.000018
Training Epoch: 350 [128/50000]	Loss: 0.8204	LR: 0.000018
Evaluating Network.....
Test set: Epoch: 350, Average loss: 0.0108, Top1Accuracy: 0.6222, Top3Accuracy: 0.8202, Top5Accuracy: 0.8796, Time consumed:1.80s

Training Epoch: 351 [128/50000]	Loss: 0.9752	LR: 0.000017
Training Epoch: 351 [128/50000]	Loss: 0.8281	LR: 0.000017
Training Epoch: 351 [128/50000]	Loss: 0.8580	LR: 0.000017
Training Epoch: 351 [128/50000]	Loss: 0.9804	LR: 0.000017
Training Epoch: 351 [128/50000]	Loss: 0.8198	LR: 0.000017
Training Epoch: 351 [128/50000]	Loss: 0.7879	LR: 0.000017
Training Epoch: 351 [128/50000]	Loss: 0.9831	LR: 0.000017
Training Epoch: 351 [128/50000]	Loss: 0.7837	LR: 0.000017
Training Epoch: 351 [128/50000]	Loss: 0.8827	LR: 0.000017
Training Epoch: 351 [128/50000]	Loss: 0.9745	LR: 0.000017
Evaluating Network.....
Test set: Epoch: 351, Average loss: 0.0109, Top1Accuracy: 0.6225, Top3Accuracy: 0.8194, Top5Accuracy: 0.8792, Time consumed:1.78s

Training Epoch: 352 [128/50000]	Loss: 0.8794	LR: 0.000017
Training Epoch: 352 [128/50000]	Loss: 0.8657	LR: 0.000017
Training Epoch: 352 [128/50000]	Loss: 0.9501	LR: 0.000017
Training Epoch: 352 [128/50000]	Loss: 0.9241	LR: 0.000017
Training Epoch: 352 [128/50000]	Loss: 0.9716	LR: 0.000017
Training Epoch: 352 [128/50000]	Loss: 0.9235	LR: 0.000017
Training Epoch: 352 [128/50000]	Loss: 0.8960	LR: 0.000017
Training Epoch: 352 [128/50000]	Loss: 0.9466	LR: 0.000017
Training Epoch: 352 [128/50000]	Loss: 0.8577	LR: 0.000017
Training Epoch: 352 [128/50000]	Loss: 0.9912	LR: 0.000017
Evaluating Network.....
Test set: Epoch: 352, Average loss: 0.0109, Top1Accuracy: 0.6219, Top3Accuracy: 0.8194, Top5Accuracy: 0.8803, Time consumed:1.79s

Training Epoch: 353 [128/50000]	Loss: 0.8938	LR: 0.000016
Training Epoch: 353 [128/50000]	Loss: 0.7219	LR: 0.000016
Training Epoch: 353 [128/50000]	Loss: 0.9618	LR: 0.000016
Training Epoch: 353 [128/50000]	Loss: 0.7894	LR: 0.000016
Training Epoch: 353 [128/50000]	Loss: 0.7837	LR: 0.000016
Training Epoch: 353 [128/50000]	Loss: 0.6741	LR: 0.000016
Training Epoch: 353 [128/50000]	Loss: 1.0745	LR: 0.000016
Training Epoch: 353 [128/50000]	Loss: 0.5999	LR: 0.000016
Training Epoch: 353 [128/50000]	Loss: 0.9957	LR: 0.000016
Training Epoch: 353 [128/50000]	Loss: 0.8666	LR: 0.000016
Evaluating Network.....
Test set: Epoch: 353, Average loss: 0.0108, Top1Accuracy: 0.6221, Top3Accuracy: 0.8170, Top5Accuracy: 0.8793, Time consumed:1.79s

Training Epoch: 354 [128/50000]	Loss: 0.7913	LR: 0.000016
Training Epoch: 354 [128/50000]	Loss: 1.0780	LR: 0.000016
Training Epoch: 354 [128/50000]	Loss: 0.8365	LR: 0.000016
Training Epoch: 354 [128/50000]	Loss: 1.0509	LR: 0.000016
Training Epoch: 354 [128/50000]	Loss: 0.7724	LR: 0.000016
Training Epoch: 354 [128/50000]	Loss: 0.8700	LR: 0.000016
Training Epoch: 354 [128/50000]	Loss: 1.0178	LR: 0.000016
Training Epoch: 354 [128/50000]	Loss: 0.8737	LR: 0.000016
Training Epoch: 354 [128/50000]	Loss: 0.9591	LR: 0.000016
Training Epoch: 354 [128/50000]	Loss: 0.9718	LR: 0.000016
Evaluating Network.....
Test set: Epoch: 354, Average loss: 0.0108, Top1Accuracy: 0.6217, Top3Accuracy: 0.8188, Top5Accuracy: 0.8804, Time consumed:1.78s

Training Epoch: 355 [128/50000]	Loss: 0.8768	LR: 0.000015
Training Epoch: 355 [128/50000]	Loss: 0.8219	LR: 0.000015
Training Epoch: 355 [128/50000]	Loss: 0.9342	LR: 0.000015
Training Epoch: 355 [128/50000]	Loss: 1.0234	LR: 0.000015
Training Epoch: 355 [128/50000]	Loss: 0.7249	LR: 0.000015
Training Epoch: 355 [128/50000]	Loss: 0.6893	LR: 0.000015
Training Epoch: 355 [128/50000]	Loss: 0.9942	LR: 0.000015
Training Epoch: 355 [128/50000]	Loss: 0.7762	LR: 0.000015
Training Epoch: 355 [128/50000]	Loss: 1.0149	LR: 0.000015
Training Epoch: 355 [128/50000]	Loss: 0.9186	LR: 0.000015
Evaluating Network.....
Test set: Epoch: 355, Average loss: 0.0108, Top1Accuracy: 0.6227, Top3Accuracy: 0.8194, Top5Accuracy: 0.8794, Time consumed:1.78s

Training Epoch: 356 [128/50000]	Loss: 0.7931	LR: 0.000015
Training Epoch: 356 [128/50000]	Loss: 0.7606	LR: 0.000015
Training Epoch: 356 [128/50000]	Loss: 0.8957	LR: 0.000015
Training Epoch: 356 [128/50000]	Loss: 0.8985	LR: 0.000015
Training Epoch: 356 [128/50000]	Loss: 0.8107	LR: 0.000015
Training Epoch: 356 [128/50000]	Loss: 0.7960	LR: 0.000015
Training Epoch: 356 [128/50000]	Loss: 0.9419	LR: 0.000015
Training Epoch: 356 [128/50000]	Loss: 0.9316	LR: 0.000015
Training Epoch: 356 [128/50000]	Loss: 0.9212	LR: 0.000015
Training Epoch: 356 [128/50000]	Loss: 0.8473	LR: 0.000015
Evaluating Network.....
Test set: Epoch: 356, Average loss: 0.0108, Top1Accuracy: 0.6203, Top3Accuracy: 0.8188, Top5Accuracy: 0.8788, Time consumed:1.80s

Training Epoch: 357 [128/50000]	Loss: 0.7928	LR: 0.000015
Training Epoch: 357 [128/50000]	Loss: 0.7914	LR: 0.000015
Training Epoch: 357 [128/50000]	Loss: 0.9340	LR: 0.000015
Training Epoch: 357 [128/50000]	Loss: 0.8267	LR: 0.000015
Training Epoch: 357 [128/50000]	Loss: 0.8317	LR: 0.000015
Training Epoch: 357 [128/50000]	Loss: 0.9889	LR: 0.000015
Training Epoch: 357 [128/50000]	Loss: 0.8592	LR: 0.000015
Training Epoch: 357 [128/50000]	Loss: 0.9063	LR: 0.000015
Training Epoch: 357 [128/50000]	Loss: 0.8470	LR: 0.000015
Training Epoch: 357 [128/50000]	Loss: 1.0616	LR: 0.000015
Evaluating Network.....
Test set: Epoch: 357, Average loss: 0.0108, Top1Accuracy: 0.6222, Top3Accuracy: 0.8185, Top5Accuracy: 0.8793, Time consumed:1.79s

Training Epoch: 358 [128/50000]	Loss: 0.8614	LR: 0.000014
Training Epoch: 358 [128/50000]	Loss: 0.8428	LR: 0.000014
Training Epoch: 358 [128/50000]	Loss: 0.9921	LR: 0.000014
Training Epoch: 358 [128/50000]	Loss: 0.8360	LR: 0.000014
Training Epoch: 358 [128/50000]	Loss: 0.9251	LR: 0.000014
Training Epoch: 358 [128/50000]	Loss: 1.0790	LR: 0.000014
Training Epoch: 358 [128/50000]	Loss: 1.0327	LR: 0.000014
Training Epoch: 358 [128/50000]	Loss: 0.8486	LR: 0.000014
Training Epoch: 358 [128/50000]	Loss: 1.0137	LR: 0.000014
Training Epoch: 358 [128/50000]	Loss: 0.9483	LR: 0.000014
Evaluating Network.....
Test set: Epoch: 358, Average loss: 0.0108, Top1Accuracy: 0.6220, Top3Accuracy: 0.8193, Top5Accuracy: 0.8799, Time consumed:1.79s

Training Epoch: 359 [128/50000]	Loss: 0.7246	LR: 0.000014
Training Epoch: 359 [128/50000]	Loss: 1.0287	LR: 0.000014
Training Epoch: 359 [128/50000]	Loss: 0.8118	LR: 0.000014
Training Epoch: 359 [128/50000]	Loss: 0.8514	LR: 0.000014
Training Epoch: 359 [128/50000]	Loss: 0.8385	LR: 0.000014
Training Epoch: 359 [128/50000]	Loss: 0.9050	LR: 0.000014
Training Epoch: 359 [128/50000]	Loss: 0.7552	LR: 0.000014
Training Epoch: 359 [128/50000]	Loss: 0.8906	LR: 0.000014
Training Epoch: 359 [128/50000]	Loss: 0.7319	LR: 0.000014
Training Epoch: 359 [128/50000]	Loss: 1.0405	LR: 0.000014
Evaluating Network.....
Test set: Epoch: 359, Average loss: 0.0108, Top1Accuracy: 0.6212, Top3Accuracy: 0.8183, Top5Accuracy: 0.8801, Time consumed:1.80s

Training Epoch: 360 [128/50000]	Loss: 1.0726	LR: 0.000013
Training Epoch: 360 [128/50000]	Loss: 0.8069	LR: 0.000013
Training Epoch: 360 [128/50000]	Loss: 0.9888	LR: 0.000013
Training Epoch: 360 [128/50000]	Loss: 0.8152	LR: 0.000013
Training Epoch: 360 [128/50000]	Loss: 0.8833	LR: 0.000013
Training Epoch: 360 [128/50000]	Loss: 1.0717	LR: 0.000013
Training Epoch: 360 [128/50000]	Loss: 0.8370	LR: 0.000013
Training Epoch: 360 [128/50000]	Loss: 0.9289	LR: 0.000013
Training Epoch: 360 [128/50000]	Loss: 0.8637	LR: 0.000013
Training Epoch: 360 [128/50000]	Loss: 0.8546	LR: 0.000013
Evaluating Network.....
Test set: Epoch: 360, Average loss: 0.0109, Top1Accuracy: 0.6210, Top3Accuracy: 0.8173, Top5Accuracy: 0.8806, Time consumed:1.79s

Training Epoch: 361 [128/50000]	Loss: 0.8633	LR: 0.000013
Training Epoch: 361 [128/50000]	Loss: 0.8800	LR: 0.000013
Training Epoch: 361 [128/50000]	Loss: 0.7041	LR: 0.000013
Training Epoch: 361 [128/50000]	Loss: 1.0279	LR: 0.000013
Training Epoch: 361 [128/50000]	Loss: 0.8872	LR: 0.000013
Training Epoch: 361 [128/50000]	Loss: 1.0833	LR: 0.000013
Training Epoch: 361 [128/50000]	Loss: 0.9830	LR: 0.000013
Training Epoch: 361 [128/50000]	Loss: 0.7827	LR: 0.000013
Training Epoch: 361 [128/50000]	Loss: 0.8713	LR: 0.000013
Training Epoch: 361 [128/50000]	Loss: 0.9529	LR: 0.000013
Evaluating Network.....
Test set: Epoch: 361, Average loss: 0.0109, Top1Accuracy: 0.6226, Top3Accuracy: 0.8198, Top5Accuracy: 0.8803, Time consumed:1.80s

Training Epoch: 362 [128/50000]	Loss: 0.7436	LR: 0.000013
Training Epoch: 362 [128/50000]	Loss: 0.9343	LR: 0.000013
Training Epoch: 362 [128/50000]	Loss: 0.8064	LR: 0.000013
Training Epoch: 362 [128/50000]	Loss: 0.8314	LR: 0.000013
Training Epoch: 362 [128/50000]	Loss: 0.8098	LR: 0.000013
Training Epoch: 362 [128/50000]	Loss: 0.7715	LR: 0.000013
Training Epoch: 362 [128/50000]	Loss: 0.8869	LR: 0.000013
Training Epoch: 362 [128/50000]	Loss: 0.7963	LR: 0.000013
Training Epoch: 362 [128/50000]	Loss: 0.8562	LR: 0.000013
Training Epoch: 362 [128/50000]	Loss: 0.8507	LR: 0.000013
Evaluating Network.....
Test set: Epoch: 362, Average loss: 0.0109, Top1Accuracy: 0.6211, Top3Accuracy: 0.8187, Top5Accuracy: 0.8792, Time consumed:1.79s

Training Epoch: 363 [128/50000]	Loss: 0.9126	LR: 0.000012
Training Epoch: 363 [128/50000]	Loss: 0.8972	LR: 0.000012
Training Epoch: 363 [128/50000]	Loss: 0.8296	LR: 0.000012
Training Epoch: 363 [128/50000]	Loss: 0.7413	LR: 0.000012
Training Epoch: 363 [128/50000]	Loss: 0.8147	LR: 0.000012
Training Epoch: 363 [128/50000]	Loss: 0.7114	LR: 0.000012
Training Epoch: 363 [128/50000]	Loss: 1.0468	LR: 0.000012
Training Epoch: 363 [128/50000]	Loss: 0.7763	LR: 0.000012
Training Epoch: 363 [128/50000]	Loss: 0.8836	LR: 0.000012
Training Epoch: 363 [128/50000]	Loss: 0.8389	LR: 0.000012
Evaluating Network.....
Test set: Epoch: 363, Average loss: 0.0108, Top1Accuracy: 0.6220, Top3Accuracy: 0.8189, Top5Accuracy: 0.8806, Time consumed:1.80s

Training Epoch: 364 [128/50000]	Loss: 1.0172	LR: 0.000012
Training Epoch: 364 [128/50000]	Loss: 0.7814	LR: 0.000012
Training Epoch: 364 [128/50000]	Loss: 0.8593	LR: 0.000012
Training Epoch: 364 [128/50000]	Loss: 0.8060	LR: 0.000012
Training Epoch: 364 [128/50000]	Loss: 0.7630	LR: 0.000012
Training Epoch: 364 [128/50000]	Loss: 0.8530	LR: 0.000012
Training Epoch: 364 [128/50000]	Loss: 1.1934	LR: 0.000012
Training Epoch: 364 [128/50000]	Loss: 0.8837	LR: 0.000012
Training Epoch: 364 [128/50000]	Loss: 0.7914	LR: 0.000012
Training Epoch: 364 [128/50000]	Loss: 0.7465	LR: 0.000012
Evaluating Network.....
Test set: Epoch: 364, Average loss: 0.0109, Top1Accuracy: 0.6220, Top3Accuracy: 0.8174, Top5Accuracy: 0.8792, Time consumed:1.77s

Training Epoch: 365 [128/50000]	Loss: 1.1648	LR: 0.000012
Training Epoch: 365 [128/50000]	Loss: 0.9380	LR: 0.000012
Training Epoch: 365 [128/50000]	Loss: 0.8625	LR: 0.000012
Training Epoch: 365 [128/50000]	Loss: 0.6591	LR: 0.000012
Training Epoch: 365 [128/50000]	Loss: 1.1041	LR: 0.000012
Training Epoch: 365 [128/50000]	Loss: 0.9626	LR: 0.000012
Training Epoch: 365 [128/50000]	Loss: 0.8471	LR: 0.000012
Training Epoch: 365 [128/50000]	Loss: 0.9715	LR: 0.000012
Training Epoch: 365 [128/50000]	Loss: 1.0754	LR: 0.000012
Training Epoch: 365 [128/50000]	Loss: 0.9155	LR: 0.000012
Evaluating Network.....
Test set: Epoch: 365, Average loss: 0.0108, Top1Accuracy: 0.6220, Top3Accuracy: 0.8189, Top5Accuracy: 0.8787, Time consumed:1.78s

Training Epoch: 366 [128/50000]	Loss: 0.7522	LR: 0.000011
Training Epoch: 366 [128/50000]	Loss: 0.9096	LR: 0.000011
Training Epoch: 366 [128/50000]	Loss: 0.9877	LR: 0.000011
Training Epoch: 366 [128/50000]	Loss: 1.0420	LR: 0.000011
Training Epoch: 366 [128/50000]	Loss: 0.8387	LR: 0.000011
Training Epoch: 366 [128/50000]	Loss: 0.7456	LR: 0.000011
Training Epoch: 366 [128/50000]	Loss: 1.0888	LR: 0.000011
Training Epoch: 366 [128/50000]	Loss: 0.8113	LR: 0.000011
Training Epoch: 366 [128/50000]	Loss: 1.0130	LR: 0.000011
Training Epoch: 366 [128/50000]	Loss: 0.7572	LR: 0.000011
Evaluating Network.....
Test set: Epoch: 366, Average loss: 0.0108, Top1Accuracy: 0.6227, Top3Accuracy: 0.8197, Top5Accuracy: 0.8796, Time consumed:1.80s

Training Epoch: 367 [128/50000]	Loss: 0.9377	LR: 0.000011
Training Epoch: 367 [128/50000]	Loss: 0.8944	LR: 0.000011
Training Epoch: 367 [128/50000]	Loss: 0.9185	LR: 0.000011
Training Epoch: 367 [128/50000]	Loss: 0.9473	LR: 0.000011
Training Epoch: 367 [128/50000]	Loss: 0.8802	LR: 0.000011
Training Epoch: 367 [128/50000]	Loss: 0.7911	LR: 0.000011
Training Epoch: 367 [128/50000]	Loss: 0.8933	LR: 0.000011
Training Epoch: 367 [128/50000]	Loss: 0.9055	LR: 0.000011
Training Epoch: 367 [128/50000]	Loss: 0.9261	LR: 0.000011
Training Epoch: 367 [128/50000]	Loss: 0.8259	LR: 0.000011
Evaluating Network.....
Test set: Epoch: 367, Average loss: 0.0108, Top1Accuracy: 0.6215, Top3Accuracy: 0.8192, Top5Accuracy: 0.8798, Time consumed:1.80s

Training Epoch: 368 [128/50000]	Loss: 0.7900	LR: 0.000011
Training Epoch: 368 [128/50000]	Loss: 0.7687	LR: 0.000011
Training Epoch: 368 [128/50000]	Loss: 1.1100	LR: 0.000011
Training Epoch: 368 [128/50000]	Loss: 0.9566	LR: 0.000011
Training Epoch: 368 [128/50000]	Loss: 0.8652	LR: 0.000011
Training Epoch: 368 [128/50000]	Loss: 1.0596	LR: 0.000011
Training Epoch: 368 [128/50000]	Loss: 0.8591	LR: 0.000011
Training Epoch: 368 [128/50000]	Loss: 0.9457	LR: 0.000011
Training Epoch: 368 [128/50000]	Loss: 0.8297	LR: 0.000011
Training Epoch: 368 [128/50000]	Loss: 0.7817	LR: 0.000011
Evaluating Network.....
Test set: Epoch: 368, Average loss: 0.0108, Top1Accuracy: 0.6219, Top3Accuracy: 0.8192, Top5Accuracy: 0.8796, Time consumed:1.78s

Training Epoch: 369 [128/50000]	Loss: 1.2705	LR: 0.000011
Training Epoch: 369 [128/50000]	Loss: 0.9219	LR: 0.000011
Training Epoch: 369 [128/50000]	Loss: 0.9798	LR: 0.000011
Training Epoch: 369 [128/50000]	Loss: 0.9186	LR: 0.000011
Training Epoch: 369 [128/50000]	Loss: 0.8478	LR: 0.000011
Training Epoch: 369 [128/50000]	Loss: 0.7435	LR: 0.000011
Training Epoch: 369 [128/50000]	Loss: 0.8771	LR: 0.000011
Training Epoch: 369 [128/50000]	Loss: 0.9084	LR: 0.000011
Training Epoch: 369 [128/50000]	Loss: 0.9687	LR: 0.000011
Training Epoch: 369 [128/50000]	Loss: 0.7990	LR: 0.000011
Evaluating Network.....
Test set: Epoch: 369, Average loss: 0.0108, Top1Accuracy: 0.6225, Top3Accuracy: 0.8187, Top5Accuracy: 0.8804, Time consumed:1.79s

Training Epoch: 370 [128/50000]	Loss: 0.6929	LR: 0.000010
Training Epoch: 370 [128/50000]	Loss: 0.9291	LR: 0.000010
Training Epoch: 370 [128/50000]	Loss: 0.8874	LR: 0.000010
Training Epoch: 370 [128/50000]	Loss: 0.8759	LR: 0.000010
Training Epoch: 370 [128/50000]	Loss: 0.8840	LR: 0.000010
Training Epoch: 370 [128/50000]	Loss: 0.7837	LR: 0.000010
Training Epoch: 370 [128/50000]	Loss: 0.8395	LR: 0.000010
Training Epoch: 370 [128/50000]	Loss: 0.9428	LR: 0.000010
Training Epoch: 370 [128/50000]	Loss: 0.9158	LR: 0.000010
Training Epoch: 370 [128/50000]	Loss: 0.9385	LR: 0.000010
Evaluating Network.....
Test set: Epoch: 370, Average loss: 0.0109, Top1Accuracy: 0.6219, Top3Accuracy: 0.8174, Top5Accuracy: 0.8796, Time consumed:1.77s

Training Epoch: 371 [128/50000]	Loss: 1.1700	LR: 0.000010
Training Epoch: 371 [128/50000]	Loss: 0.8466	LR: 0.000010
Training Epoch: 371 [128/50000]	Loss: 1.0021	LR: 0.000010
Training Epoch: 371 [128/50000]	Loss: 0.9902	LR: 0.000010
Training Epoch: 371 [128/50000]	Loss: 0.9546	LR: 0.000010
Training Epoch: 371 [128/50000]	Loss: 0.7492	LR: 0.000010
Training Epoch: 371 [128/50000]	Loss: 0.7944	LR: 0.000010
Training Epoch: 371 [128/50000]	Loss: 0.9916	LR: 0.000010
Training Epoch: 371 [128/50000]	Loss: 0.8305	LR: 0.000010
Training Epoch: 371 [128/50000]	Loss: 0.8677	LR: 0.000010
Evaluating Network.....
Test set: Epoch: 371, Average loss: 0.0108, Top1Accuracy: 0.6222, Top3Accuracy: 0.8179, Top5Accuracy: 0.8795, Time consumed:1.78s

Training Epoch: 372 [128/50000]	Loss: 0.7373	LR: 0.000010
Training Epoch: 372 [128/50000]	Loss: 0.9358	LR: 0.000010
Training Epoch: 372 [128/50000]	Loss: 1.0780	LR: 0.000010
Training Epoch: 372 [128/50000]	Loss: 0.6616	LR: 0.000010
Training Epoch: 372 [128/50000]	Loss: 0.8643	LR: 0.000010
Training Epoch: 372 [128/50000]	Loss: 0.7635	LR: 0.000010
Training Epoch: 372 [128/50000]	Loss: 0.8985	LR: 0.000010
Training Epoch: 372 [128/50000]	Loss: 1.0383	LR: 0.000010
Training Epoch: 372 [128/50000]	Loss: 0.7656	LR: 0.000010
Training Epoch: 372 [128/50000]	Loss: 0.7651	LR: 0.000010
Evaluating Network.....
Test set: Epoch: 372, Average loss: 0.0109, Top1Accuracy: 0.6218, Top3Accuracy: 0.8171, Top5Accuracy: 0.8802, Time consumed:1.79s

Training Epoch: 373 [128/50000]	Loss: 0.9134	LR: 0.000010
Training Epoch: 373 [128/50000]	Loss: 0.8825	LR: 0.000010
Training Epoch: 373 [128/50000]	Loss: 0.7209	LR: 0.000010
Training Epoch: 373 [128/50000]	Loss: 0.9320	LR: 0.000010
Training Epoch: 373 [128/50000]	Loss: 0.8224	LR: 0.000010
Training Epoch: 373 [128/50000]	Loss: 0.9842	LR: 0.000010
Training Epoch: 373 [128/50000]	Loss: 0.8143	LR: 0.000010
Training Epoch: 373 [128/50000]	Loss: 0.8981	LR: 0.000010
Training Epoch: 373 [128/50000]	Loss: 0.8117	LR: 0.000010
Training Epoch: 373 [128/50000]	Loss: 0.9515	LR: 0.000010
Evaluating Network.....
Test set: Epoch: 373, Average loss: 0.0108, Top1Accuracy: 0.6209, Top3Accuracy: 0.8180, Top5Accuracy: 0.8799, Time consumed:1.80s

Training Epoch: 374 [128/50000]	Loss: 0.7465	LR: 0.000009
Training Epoch: 374 [128/50000]	Loss: 0.9239	LR: 0.000009
Training Epoch: 374 [128/50000]	Loss: 0.6898	LR: 0.000009
Training Epoch: 374 [128/50000]	Loss: 0.8326	LR: 0.000009
Training Epoch: 374 [128/50000]	Loss: 0.7596	LR: 0.000009
Training Epoch: 374 [128/50000]	Loss: 0.9677	LR: 0.000009
Training Epoch: 374 [128/50000]	Loss: 0.7551	LR: 0.000009
Training Epoch: 374 [128/50000]	Loss: 0.8390	LR: 0.000009
Training Epoch: 374 [128/50000]	Loss: 0.9886	LR: 0.000009
Training Epoch: 374 [128/50000]	Loss: 0.9279	LR: 0.000009
Evaluating Network.....
Test set: Epoch: 374, Average loss: 0.0109, Top1Accuracy: 0.6215, Top3Accuracy: 0.8181, Top5Accuracy: 0.8798, Time consumed:1.79s

Training Epoch: 375 [128/50000]	Loss: 0.9812	LR: 0.000009
Training Epoch: 375 [128/50000]	Loss: 0.8378	LR: 0.000009
Training Epoch: 375 [128/50000]	Loss: 0.8460	LR: 0.000009
Training Epoch: 375 [128/50000]	Loss: 0.8202	LR: 0.000009
Training Epoch: 375 [128/50000]	Loss: 0.9328	LR: 0.000009
Training Epoch: 375 [128/50000]	Loss: 0.9008	LR: 0.000009
Training Epoch: 375 [128/50000]	Loss: 0.7982	LR: 0.000009
Training Epoch: 375 [128/50000]	Loss: 0.7390	LR: 0.000009
Training Epoch: 375 [128/50000]	Loss: 1.0583	LR: 0.000009
Training Epoch: 375 [128/50000]	Loss: 0.9115	LR: 0.000009
Evaluating Network.....
Test set: Epoch: 375, Average loss: 0.0109, Top1Accuracy: 0.6224, Top3Accuracy: 0.8183, Top5Accuracy: 0.8800, Time consumed:1.80s

Training Epoch: 376 [128/50000]	Loss: 0.6359	LR: 0.000009
Training Epoch: 376 [128/50000]	Loss: 0.8797	LR: 0.000009
Training Epoch: 376 [128/50000]	Loss: 0.9112	LR: 0.000009
Training Epoch: 376 [128/50000]	Loss: 0.9333	LR: 0.000009
Training Epoch: 376 [128/50000]	Loss: 0.9006	LR: 0.000009
Training Epoch: 376 [128/50000]	Loss: 0.8416	LR: 0.000009
Training Epoch: 376 [128/50000]	Loss: 0.8232	LR: 0.000009
Training Epoch: 376 [128/50000]	Loss: 1.1163	LR: 0.000009
Training Epoch: 376 [128/50000]	Loss: 0.7677	LR: 0.000009
Training Epoch: 376 [128/50000]	Loss: 0.9581	LR: 0.000009
Evaluating Network.....
Test set: Epoch: 376, Average loss: 0.0108, Top1Accuracy: 0.6210, Top3Accuracy: 0.8183, Top5Accuracy: 0.8795, Time consumed:1.79s

Training Epoch: 377 [128/50000]	Loss: 0.7677	LR: 0.000009
Training Epoch: 377 [128/50000]	Loss: 0.7649	LR: 0.000009
Training Epoch: 377 [128/50000]	Loss: 0.8909	LR: 0.000009
Training Epoch: 377 [128/50000]	Loss: 1.0127	LR: 0.000009
Training Epoch: 377 [128/50000]	Loss: 0.8856	LR: 0.000009
Training Epoch: 377 [128/50000]	Loss: 0.8840	LR: 0.000009
Training Epoch: 377 [128/50000]	Loss: 0.8144	LR: 0.000009
Training Epoch: 377 [128/50000]	Loss: 1.0090	LR: 0.000009
Training Epoch: 377 [128/50000]	Loss: 1.0133	LR: 0.000009
Training Epoch: 377 [128/50000]	Loss: 0.8892	LR: 0.000009
Evaluating Network.....
Test set: Epoch: 377, Average loss: 0.0109, Top1Accuracy: 0.6222, Top3Accuracy: 0.8192, Top5Accuracy: 0.8812, Time consumed:1.79s

Training Epoch: 378 [128/50000]	Loss: 0.9836	LR: 0.000008
Training Epoch: 378 [128/50000]	Loss: 0.9000	LR: 0.000008
Training Epoch: 378 [128/50000]	Loss: 0.9445	LR: 0.000008
Training Epoch: 378 [128/50000]	Loss: 0.8466	LR: 0.000008
Training Epoch: 378 [128/50000]	Loss: 1.1246	LR: 0.000008
Training Epoch: 378 [128/50000]	Loss: 0.7490	LR: 0.000008
Training Epoch: 378 [128/50000]	Loss: 0.7334	LR: 0.000008
Training Epoch: 378 [128/50000]	Loss: 0.9479	LR: 0.000008
Training Epoch: 378 [128/50000]	Loss: 0.8278	LR: 0.000008
Training Epoch: 378 [128/50000]	Loss: 0.8647	LR: 0.000008
Evaluating Network.....
Test set: Epoch: 378, Average loss: 0.0108, Top1Accuracy: 0.6226, Top3Accuracy: 0.8190, Top5Accuracy: 0.8789, Time consumed:1.80s

Training Epoch: 379 [128/50000]	Loss: 0.9731	LR: 0.000008
Training Epoch: 379 [128/50000]	Loss: 0.9192	LR: 0.000008
Training Epoch: 379 [128/50000]	Loss: 0.7860	LR: 0.000008
Training Epoch: 379 [128/50000]	Loss: 0.9275	LR: 0.000008
Training Epoch: 379 [128/50000]	Loss: 0.6593	LR: 0.000008
Training Epoch: 379 [128/50000]	Loss: 0.9524	LR: 0.000008
Training Epoch: 379 [128/50000]	Loss: 0.8339	LR: 0.000008
Training Epoch: 379 [128/50000]	Loss: 0.9524	LR: 0.000008
Training Epoch: 379 [128/50000]	Loss: 0.8752	LR: 0.000008
Training Epoch: 379 [128/50000]	Loss: 0.7577	LR: 0.000008
Evaluating Network.....
Test set: Epoch: 379, Average loss: 0.0109, Top1Accuracy: 0.6228, Top3Accuracy: 0.8189, Top5Accuracy: 0.8795, Time consumed:1.78s

Training Epoch: 380 [128/50000]	Loss: 0.8716	LR: 0.000008
Training Epoch: 380 [128/50000]	Loss: 0.8451	LR: 0.000008
Training Epoch: 380 [128/50000]	Loss: 0.8389	LR: 0.000008
Training Epoch: 380 [128/50000]	Loss: 0.7787	LR: 0.000008
Training Epoch: 380 [128/50000]	Loss: 0.9234	LR: 0.000008
Training Epoch: 380 [128/50000]	Loss: 0.8764	LR: 0.000008
Training Epoch: 380 [128/50000]	Loss: 0.7984	LR: 0.000008
Training Epoch: 380 [128/50000]	Loss: 0.9270	LR: 0.000008
Training Epoch: 380 [128/50000]	Loss: 1.0246	LR: 0.000008
Training Epoch: 380 [128/50000]	Loss: 0.8498	LR: 0.000008
Evaluating Network.....
Test set: Epoch: 380, Average loss: 0.0108, Top1Accuracy: 0.6218, Top3Accuracy: 0.8187, Top5Accuracy: 0.8793, Time consumed:1.79s

Training Epoch: 381 [128/50000]	Loss: 0.8869	LR: 0.000008
Training Epoch: 381 [128/50000]	Loss: 0.7830	LR: 0.000008
Training Epoch: 381 [128/50000]	Loss: 0.9483	LR: 0.000008
Training Epoch: 381 [128/50000]	Loss: 0.9187	LR: 0.000008
Training Epoch: 381 [128/50000]	Loss: 1.0009	LR: 0.000008
Training Epoch: 381 [128/50000]	Loss: 0.6813	LR: 0.000008
Training Epoch: 381 [128/50000]	Loss: 0.7784	LR: 0.000008
Training Epoch: 381 [128/50000]	Loss: 1.0178	LR: 0.000008
Training Epoch: 381 [128/50000]	Loss: 0.9820	LR: 0.000008
Training Epoch: 381 [128/50000]	Loss: 0.8060	LR: 0.000008
Evaluating Network.....
Test set: Epoch: 381, Average loss: 0.0108, Top1Accuracy: 0.6234, Top3Accuracy: 0.8195, Top5Accuracy: 0.8808, Time consumed:1.79s

Training Epoch: 382 [128/50000]	Loss: 0.8965	LR: 0.000007
Training Epoch: 382 [128/50000]	Loss: 0.7389	LR: 0.000007
Training Epoch: 382 [128/50000]	Loss: 0.8602	LR: 0.000007
Training Epoch: 382 [128/50000]	Loss: 0.9156	LR: 0.000007
Training Epoch: 382 [128/50000]	Loss: 0.7671	LR: 0.000007
Training Epoch: 382 [128/50000]	Loss: 0.9904	LR: 0.000007
Training Epoch: 382 [128/50000]	Loss: 0.7692	LR: 0.000007
Training Epoch: 382 [128/50000]	Loss: 0.7833	LR: 0.000007
Training Epoch: 382 [128/50000]	Loss: 0.9159	LR: 0.000007
Training Epoch: 382 [128/50000]	Loss: 0.8957	LR: 0.000007
Evaluating Network.....
Test set: Epoch: 382, Average loss: 0.0108, Top1Accuracy: 0.6223, Top3Accuracy: 0.8189, Top5Accuracy: 0.8801, Time consumed:1.79s

Training Epoch: 383 [128/50000]	Loss: 0.9913	LR: 0.000007
Training Epoch: 383 [128/50000]	Loss: 0.8624	LR: 0.000007
Training Epoch: 383 [128/50000]	Loss: 0.9751	LR: 0.000007
Training Epoch: 383 [128/50000]	Loss: 0.8630	LR: 0.000007
Training Epoch: 383 [128/50000]	Loss: 0.8913	LR: 0.000007
Training Epoch: 383 [128/50000]	Loss: 0.7952	LR: 0.000007
Training Epoch: 383 [128/50000]	Loss: 0.7990	LR: 0.000007
Training Epoch: 383 [128/50000]	Loss: 0.7128	LR: 0.000007
Training Epoch: 383 [128/50000]	Loss: 0.9259	LR: 0.000007
Training Epoch: 383 [128/50000]	Loss: 0.9695	LR: 0.000007
Evaluating Network.....
Test set: Epoch: 383, Average loss: 0.0109, Top1Accuracy: 0.6219, Top3Accuracy: 0.8197, Top5Accuracy: 0.8791, Time consumed:1.79s

Training Epoch: 384 [128/50000]	Loss: 0.9833	LR: 0.000007
Training Epoch: 384 [128/50000]	Loss: 0.8064	LR: 0.000007
Training Epoch: 384 [128/50000]	Loss: 0.8906	LR: 0.000007
Training Epoch: 384 [128/50000]	Loss: 1.0340	LR: 0.000007
Training Epoch: 384 [128/50000]	Loss: 0.6871	LR: 0.000007
Training Epoch: 384 [128/50000]	Loss: 0.8595	LR: 0.000007
Training Epoch: 384 [128/50000]	Loss: 1.0589	LR: 0.000007
Training Epoch: 384 [128/50000]	Loss: 0.8931	LR: 0.000007
Training Epoch: 384 [128/50000]	Loss: 1.1422	LR: 0.000007
Training Epoch: 384 [128/50000]	Loss: 0.7783	LR: 0.000007
Evaluating Network.....
Test set: Epoch: 384, Average loss: 0.0108, Top1Accuracy: 0.6210, Top3Accuracy: 0.8186, Top5Accuracy: 0.8798, Time consumed:1.79s

Training Epoch: 385 [128/50000]	Loss: 0.6858	LR: 0.000007
Training Epoch: 385 [128/50000]	Loss: 0.7910	LR: 0.000007
Training Epoch: 385 [128/50000]	Loss: 0.9259	LR: 0.000007
Training Epoch: 385 [128/50000]	Loss: 1.1219	LR: 0.000007
Training Epoch: 385 [128/50000]	Loss: 0.8460	LR: 0.000007
Training Epoch: 385 [128/50000]	Loss: 0.8097	LR: 0.000007
Training Epoch: 385 [128/50000]	Loss: 0.8697	LR: 0.000007
Training Epoch: 385 [128/50000]	Loss: 0.8255	LR: 0.000007
Training Epoch: 385 [128/50000]	Loss: 0.8854	LR: 0.000007
Training Epoch: 385 [128/50000]	Loss: 0.7132	LR: 0.000007
Evaluating Network.....
Test set: Epoch: 385, Average loss: 0.0108, Top1Accuracy: 0.6217, Top3Accuracy: 0.8181, Top5Accuracy: 0.8794, Time consumed:1.81s

Training Epoch: 386 [128/50000]	Loss: 1.0134	LR: 0.000007
Training Epoch: 386 [128/50000]	Loss: 0.8728	LR: 0.000007
Training Epoch: 386 [128/50000]	Loss: 0.9107	LR: 0.000007
Training Epoch: 386 [128/50000]	Loss: 0.9396	LR: 0.000007
Training Epoch: 386 [128/50000]	Loss: 0.8865	LR: 0.000007
Training Epoch: 386 [128/50000]	Loss: 0.7646	LR: 0.000007
Training Epoch: 386 [128/50000]	Loss: 0.7935	LR: 0.000007
Training Epoch: 386 [128/50000]	Loss: 0.8409	LR: 0.000007
Training Epoch: 386 [128/50000]	Loss: 0.9528	LR: 0.000007
Training Epoch: 386 [128/50000]	Loss: 0.7643	LR: 0.000007
Evaluating Network.....
Test set: Epoch: 386, Average loss: 0.0109, Top1Accuracy: 0.6224, Top3Accuracy: 0.8190, Top5Accuracy: 0.8799, Time consumed:1.80s

Training Epoch: 387 [128/50000]	Loss: 0.8715	LR: 0.000007
Training Epoch: 387 [128/50000]	Loss: 0.8954	LR: 0.000007
Training Epoch: 387 [128/50000]	Loss: 0.8734	LR: 0.000007
Training Epoch: 387 [128/50000]	Loss: 0.8753	LR: 0.000007
Training Epoch: 387 [128/50000]	Loss: 0.8175	LR: 0.000007
Training Epoch: 387 [128/50000]	Loss: 0.7753	LR: 0.000007
Training Epoch: 387 [128/50000]	Loss: 1.0169	LR: 0.000007
Training Epoch: 387 [128/50000]	Loss: 0.8193	LR: 0.000007
Training Epoch: 387 [128/50000]	Loss: 0.9673	LR: 0.000007
Training Epoch: 387 [128/50000]	Loss: 0.7769	LR: 0.000007
Evaluating Network.....
Test set: Epoch: 387, Average loss: 0.0108, Top1Accuracy: 0.6235, Top3Accuracy: 0.8198, Top5Accuracy: 0.8796, Time consumed:1.76s

Training Epoch: 388 [128/50000]	Loss: 0.8519	LR: 0.000006
Training Epoch: 388 [128/50000]	Loss: 0.9866	LR: 0.000006
Training Epoch: 388 [128/50000]	Loss: 0.8593	LR: 0.000006
Training Epoch: 388 [128/50000]	Loss: 0.7314	LR: 0.000006
Training Epoch: 388 [128/50000]	Loss: 0.8148	LR: 0.000006
Training Epoch: 388 [128/50000]	Loss: 1.0698	LR: 0.000006
Training Epoch: 388 [128/50000]	Loss: 0.7921	LR: 0.000006
Training Epoch: 388 [128/50000]	Loss: 0.9737	LR: 0.000006
Training Epoch: 388 [128/50000]	Loss: 0.9895	LR: 0.000006
Training Epoch: 388 [128/50000]	Loss: 0.7468	LR: 0.000006
Evaluating Network.....
Test set: Epoch: 388, Average loss: 0.0108, Top1Accuracy: 0.6214, Top3Accuracy: 0.8193, Top5Accuracy: 0.8794, Time consumed:1.79s

Training Epoch: 389 [128/50000]	Loss: 1.0817	LR: 0.000006
Training Epoch: 389 [128/50000]	Loss: 0.7916	LR: 0.000006
Training Epoch: 389 [128/50000]	Loss: 0.9227	LR: 0.000006
Training Epoch: 389 [128/50000]	Loss: 0.9536	LR: 0.000006
Training Epoch: 389 [128/50000]	Loss: 0.9765	LR: 0.000006
Training Epoch: 389 [128/50000]	Loss: 0.8431	LR: 0.000006
Training Epoch: 389 [128/50000]	Loss: 0.8649	LR: 0.000006
Training Epoch: 389 [128/50000]	Loss: 0.9406	LR: 0.000006
Training Epoch: 389 [128/50000]	Loss: 0.9090	LR: 0.000006
Training Epoch: 389 [128/50000]	Loss: 0.8376	LR: 0.000006
Evaluating Network.....
Test set: Epoch: 389, Average loss: 0.0109, Top1Accuracy: 0.6222, Top3Accuracy: 0.8186, Top5Accuracy: 0.8797, Time consumed:1.78s

Training Epoch: 390 [128/50000]	Loss: 0.7335	LR: 0.000006
Training Epoch: 390 [128/50000]	Loss: 0.8663	LR: 0.000006
Training Epoch: 390 [128/50000]	Loss: 0.8957	LR: 0.000006
Training Epoch: 390 [128/50000]	Loss: 0.7925	LR: 0.000006
Training Epoch: 390 [128/50000]	Loss: 0.8489	LR: 0.000006
Training Epoch: 390 [128/50000]	Loss: 0.7674	LR: 0.000006
Training Epoch: 390 [128/50000]	Loss: 0.9349	LR: 0.000006
Training Epoch: 390 [128/50000]	Loss: 0.8304	LR: 0.000006
Training Epoch: 390 [128/50000]	Loss: 0.8362	LR: 0.000006
Training Epoch: 390 [128/50000]	Loss: 0.8771	LR: 0.000006
Evaluating Network.....
Test set: Epoch: 390, Average loss: 0.0108, Top1Accuracy: 0.6207, Top3Accuracy: 0.8187, Top5Accuracy: 0.8794, Time consumed:1.79s

Training Epoch: 391 [128/50000]	Loss: 0.9067	LR: 0.000006
Training Epoch: 391 [128/50000]	Loss: 1.0504	LR: 0.000006
Training Epoch: 391 [128/50000]	Loss: 0.8551	LR: 0.000006
Training Epoch: 391 [128/50000]	Loss: 0.9156	LR: 0.000006
Training Epoch: 391 [128/50000]	Loss: 0.9641	LR: 0.000006
Training Epoch: 391 [128/50000]	Loss: 0.9281	LR: 0.000006
Training Epoch: 391 [128/50000]	Loss: 1.0056	LR: 0.000006
Training Epoch: 391 [128/50000]	Loss: 0.9430	LR: 0.000006
Training Epoch: 391 [128/50000]	Loss: 0.9551	LR: 0.000006
Training Epoch: 391 [128/50000]	Loss: 1.0379	LR: 0.000006
Evaluating Network.....
Test set: Epoch: 391, Average loss: 0.0108, Top1Accuracy: 0.6228, Top3Accuracy: 0.8179, Top5Accuracy: 0.8810, Time consumed:1.79s

Training Epoch: 392 [128/50000]	Loss: 0.8645	LR: 0.000006
Training Epoch: 392 [128/50000]	Loss: 0.8357	LR: 0.000006
Training Epoch: 392 [128/50000]	Loss: 0.9411	LR: 0.000006
Training Epoch: 392 [128/50000]	Loss: 0.9199	LR: 0.000006
Training Epoch: 392 [128/50000]	Loss: 0.8924	LR: 0.000006
Training Epoch: 392 [128/50000]	Loss: 0.9183	LR: 0.000006
Training Epoch: 392 [128/50000]	Loss: 0.8220	LR: 0.000006
Training Epoch: 392 [128/50000]	Loss: 0.7905	LR: 0.000006
Training Epoch: 392 [128/50000]	Loss: 0.8035	LR: 0.000006
Training Epoch: 392 [128/50000]	Loss: 0.7671	LR: 0.000006
Evaluating Network.....
Test set: Epoch: 392, Average loss: 0.0108, Top1Accuracy: 0.6218, Top3Accuracy: 0.8186, Top5Accuracy: 0.8800, Time consumed:1.78s

Training Epoch: 393 [128/50000]	Loss: 0.8196	LR: 0.000006
Training Epoch: 393 [128/50000]	Loss: 0.8050	LR: 0.000006
Training Epoch: 393 [128/50000]	Loss: 0.7954	LR: 0.000006
Training Epoch: 393 [128/50000]	Loss: 0.7885	LR: 0.000006
Training Epoch: 393 [128/50000]	Loss: 0.8969	LR: 0.000006
Training Epoch: 393 [128/50000]	Loss: 0.9261	LR: 0.000006
Training Epoch: 393 [128/50000]	Loss: 0.7813	LR: 0.000006
Training Epoch: 393 [128/50000]	Loss: 0.7895	LR: 0.000006
Training Epoch: 393 [128/50000]	Loss: 0.9590	LR: 0.000006
Training Epoch: 393 [128/50000]	Loss: 0.9792	LR: 0.000006
Evaluating Network.....
Test set: Epoch: 393, Average loss: 0.0108, Top1Accuracy: 0.6223, Top3Accuracy: 0.8182, Top5Accuracy: 0.8797, Time consumed:1.79s

Training Epoch: 394 [128/50000]	Loss: 0.8442	LR: 0.000005
Training Epoch: 394 [128/50000]	Loss: 0.7893	LR: 0.000005
Training Epoch: 394 [128/50000]	Loss: 0.7869	LR: 0.000005
Training Epoch: 394 [128/50000]	Loss: 0.8097	LR: 0.000005
Training Epoch: 394 [128/50000]	Loss: 0.7545	LR: 0.000005
Training Epoch: 394 [128/50000]	Loss: 0.8879	LR: 0.000005
Training Epoch: 394 [128/50000]	Loss: 0.9200	LR: 0.000005
Training Epoch: 394 [128/50000]	Loss: 0.9189	LR: 0.000005
Training Epoch: 394 [128/50000]	Loss: 0.7374	LR: 0.000005
Training Epoch: 394 [128/50000]	Loss: 0.8469	LR: 0.000005
Evaluating Network.....
Test set: Epoch: 394, Average loss: 0.0109, Top1Accuracy: 0.6227, Top3Accuracy: 0.8195, Top5Accuracy: 0.8792, Time consumed:1.78s

Training Epoch: 395 [128/50000]	Loss: 1.0709	LR: 0.000005
Training Epoch: 395 [128/50000]	Loss: 0.9929	LR: 0.000005
Training Epoch: 395 [128/50000]	Loss: 0.7913	LR: 0.000005
Training Epoch: 395 [128/50000]	Loss: 0.8369	LR: 0.000005
Training Epoch: 395 [128/50000]	Loss: 0.8993	LR: 0.000005
Training Epoch: 395 [128/50000]	Loss: 0.9525	LR: 0.000005
Training Epoch: 395 [128/50000]	Loss: 0.9609	LR: 0.000005
Training Epoch: 395 [128/50000]	Loss: 0.8956	LR: 0.000005
Training Epoch: 395 [128/50000]	Loss: 0.9185	LR: 0.000005
Training Epoch: 395 [128/50000]	Loss: 0.9068	LR: 0.000005
Evaluating Network.....
Test set: Epoch: 395, Average loss: 0.0108, Top1Accuracy: 0.6229, Top3Accuracy: 0.8190, Top5Accuracy: 0.8807, Time consumed:1.94s

Training Epoch: 396 [128/50000]	Loss: 0.9662	LR: 0.000005
Training Epoch: 396 [128/50000]	Loss: 0.9290	LR: 0.000005
Training Epoch: 396 [128/50000]	Loss: 0.8965	LR: 0.000005
Training Epoch: 396 [128/50000]	Loss: 0.9161	LR: 0.000005
Training Epoch: 396 [128/50000]	Loss: 0.7973	LR: 0.000005
Training Epoch: 396 [128/50000]	Loss: 0.8444	LR: 0.000005
Training Epoch: 396 [128/50000]	Loss: 0.9358	LR: 0.000005
Training Epoch: 396 [128/50000]	Loss: 0.9088	LR: 0.000005
Training Epoch: 396 [128/50000]	Loss: 0.6221	LR: 0.000005
Training Epoch: 396 [128/50000]	Loss: 1.0786	LR: 0.000005
Evaluating Network.....
Test set: Epoch: 396, Average loss: 0.0108, Top1Accuracy: 0.6222, Top3Accuracy: 0.8202, Top5Accuracy: 0.8800, Time consumed:1.81s

Training Epoch: 397 [128/50000]	Loss: 0.8165	LR: 0.000005
Training Epoch: 397 [128/50000]	Loss: 1.0666	LR: 0.000005
Training Epoch: 397 [128/50000]	Loss: 1.0053	LR: 0.000005
Training Epoch: 397 [128/50000]	Loss: 0.8628	LR: 0.000005
Training Epoch: 397 [128/50000]	Loss: 0.8657	LR: 0.000005
Training Epoch: 397 [128/50000]	Loss: 0.7573	LR: 0.000005
Training Epoch: 397 [128/50000]	Loss: 1.0344	LR: 0.000005
Training Epoch: 397 [128/50000]	Loss: 1.2818	LR: 0.000005
Training Epoch: 397 [128/50000]	Loss: 0.8027	LR: 0.000005
Training Epoch: 397 [128/50000]	Loss: 0.7870	LR: 0.000005
Evaluating Network.....
Test set: Epoch: 397, Average loss: 0.0108, Top1Accuracy: 0.6219, Top3Accuracy: 0.8187, Top5Accuracy: 0.8797, Time consumed:1.77s

Training Epoch: 398 [128/50000]	Loss: 0.9738	LR: 0.000005
Training Epoch: 398 [128/50000]	Loss: 0.8485	LR: 0.000005
Training Epoch: 398 [128/50000]	Loss: 0.9329	LR: 0.000005
Training Epoch: 398 [128/50000]	Loss: 0.7879	LR: 0.000005
Training Epoch: 398 [128/50000]	Loss: 0.9948	LR: 0.000005
Training Epoch: 398 [128/50000]	Loss: 1.0425	LR: 0.000005
Training Epoch: 398 [128/50000]	Loss: 0.8636	LR: 0.000005
Training Epoch: 398 [128/50000]	Loss: 0.7915	LR: 0.000005
Training Epoch: 398 [128/50000]	Loss: 0.9033	LR: 0.000005
Training Epoch: 398 [128/50000]	Loss: 0.9544	LR: 0.000005
Evaluating Network.....
Test set: Epoch: 398, Average loss: 0.0108, Top1Accuracy: 0.6210, Top3Accuracy: 0.8181, Top5Accuracy: 0.8802, Time consumed:1.78s

Training Epoch: 399 [128/50000]	Loss: 0.7780	LR: 0.000005
Training Epoch: 399 [128/50000]	Loss: 1.0047	LR: 0.000005
Training Epoch: 399 [128/50000]	Loss: 0.8661	LR: 0.000005
Training Epoch: 399 [128/50000]	Loss: 0.8797	LR: 0.000005
Training Epoch: 399 [128/50000]	Loss: 0.8605	LR: 0.000005
Training Epoch: 399 [128/50000]	Loss: 0.7991	LR: 0.000005
Training Epoch: 399 [128/50000]	Loss: 1.0282	LR: 0.000005
Training Epoch: 399 [128/50000]	Loss: 0.8239	LR: 0.000005
Training Epoch: 399 [128/50000]	Loss: 0.7999	LR: 0.000005
Training Epoch: 399 [128/50000]	Loss: 1.1003	LR: 0.000005
Evaluating Network.....
Test set: Epoch: 399, Average loss: 0.0109, Top1Accuracy: 0.6226, Top3Accuracy: 0.8188, Top5Accuracy: 0.8792, Time consumed:1.79s

Training Epoch: 400 [128/50000]	Loss: 0.9823	LR: 0.000005
Training Epoch: 400 [128/50000]	Loss: 0.9439	LR: 0.000005
Training Epoch: 400 [128/50000]	Loss: 0.9630	LR: 0.000005
Training Epoch: 400 [128/50000]	Loss: 1.0412	LR: 0.000005
Training Epoch: 400 [128/50000]	Loss: 0.9740	LR: 0.000005
Training Epoch: 400 [128/50000]	Loss: 0.8099	LR: 0.000005
Training Epoch: 400 [128/50000]	Loss: 0.8643	LR: 0.000005
Training Epoch: 400 [128/50000]	Loss: 0.9550	LR: 0.000005
Training Epoch: 400 [128/50000]	Loss: 0.7671	LR: 0.000005
Training Epoch: 400 [128/50000]	Loss: 0.9500	LR: 0.000005
Evaluating Network.....
Test set: Epoch: 400, Average loss: 0.0109, Top1Accuracy: 0.6221, Top3Accuracy: 0.8173, Top5Accuracy: 0.8798, Time consumed:1.79s

