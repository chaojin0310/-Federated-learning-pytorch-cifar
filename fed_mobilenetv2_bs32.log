Files already downloaded and verified
Files already downloaded and verified
Training Epoch: 1 [32/50000]	Loss: 4.6422	LR: 0.200000
Training Epoch: 1 [32/50000]	Loss: 4.6848	LR: 0.200000
Training Epoch: 1 [32/50000]	Loss: 4.6902	LR: 0.200000
Training Epoch: 1 [32/50000]	Loss: 4.6447	LR: 0.200000
Training Epoch: 1 [32/50000]	Loss: 4.6679	LR: 0.200000
Training Epoch: 1 [32/50000]	Loss: 4.6423	LR: 0.200000
Training Epoch: 1 [32/50000]	Loss: 4.5706	LR: 0.200000
Training Epoch: 1 [32/50000]	Loss: 4.6301	LR: 0.200000
Training Epoch: 1 [32/50000]	Loss: 4.6874	LR: 0.200000
Training Epoch: 1 [32/50000]	Loss: 4.6491	LR: 0.200000
Evaluating Network.....
Test set: Epoch: 1, Average loss: 0.1442, Top1Accuracy: 0.0100, Top3Accuracy: 0.0300, Top5Accuracy: 0.0500, Time consumed:2.67s

Training Epoch: 2 [32/50000]	Loss: 4.6108	LR: 0.194720
Training Epoch: 2 [32/50000]	Loss: 4.6149	LR: 0.194720
Training Epoch: 2 [32/50000]	Loss: 4.5967	LR: 0.194720
Training Epoch: 2 [32/50000]	Loss: 4.5820	LR: 0.194720
Training Epoch: 2 [32/50000]	Loss: 4.5982	LR: 0.194720
Training Epoch: 2 [32/50000]	Loss: 4.6071	LR: 0.194720
Training Epoch: 2 [32/50000]	Loss: 4.6136	LR: 0.194720
Training Epoch: 2 [32/50000]	Loss: 4.5978	LR: 0.194720
Training Epoch: 2 [32/50000]	Loss: 4.6228	LR: 0.194720
Training Epoch: 2 [32/50000]	Loss: 4.6072	LR: 0.194720
Evaluating Network.....
Test set: Epoch: 2, Average loss: 0.1442, Top1Accuracy: 0.0100, Top3Accuracy: 0.0300, Top5Accuracy: 0.0500, Time consumed:2.68s

Training Epoch: 3 [32/50000]	Loss: 4.5884	LR: 0.189579
Training Epoch: 3 [32/50000]	Loss: 4.5829	LR: 0.189579
Training Epoch: 3 [32/50000]	Loss: 4.5997	LR: 0.189579
Training Epoch: 3 [32/50000]	Loss: 4.6034	LR: 0.189579
Training Epoch: 3 [32/50000]	Loss: 4.5980	LR: 0.189579
Training Epoch: 3 [32/50000]	Loss: 4.5956	LR: 0.189579
Training Epoch: 3 [32/50000]	Loss: 4.6008	LR: 0.189579
Training Epoch: 3 [32/50000]	Loss: 4.6050	LR: 0.189579
Training Epoch: 3 [32/50000]	Loss: 4.6076	LR: 0.189579
Training Epoch: 3 [32/50000]	Loss: 4.6097	LR: 0.189579
Evaluating Network.....
Test set: Epoch: 3, Average loss: 0.1443, Top1Accuracy: 0.0100, Top3Accuracy: 0.0300, Top5Accuracy: 0.0500, Time consumed:2.73s

Training Epoch: 4 [32/50000]	Loss: 4.5434	LR: 0.184574
Training Epoch: 4 [32/50000]	Loss: 4.5827	LR: 0.184574
Training Epoch: 4 [32/50000]	Loss: 4.5323	LR: 0.184574
Training Epoch: 4 [32/50000]	Loss: 4.4712	LR: 0.184574
Training Epoch: 4 [32/50000]	Loss: 4.4855	LR: 0.184574
Training Epoch: 4 [32/50000]	Loss: 4.4921	LR: 0.184574
Training Epoch: 4 [32/50000]	Loss: 4.5340	LR: 0.184574
Training Epoch: 4 [32/50000]	Loss: 4.4618	LR: 0.184574
Training Epoch: 4 [32/50000]	Loss: 4.4815	LR: 0.184574
Training Epoch: 4 [32/50000]	Loss: 4.5559	LR: 0.184574
Evaluating Network.....
Test set: Epoch: 4, Average loss: 0.1449, Top1Accuracy: 0.0100, Top3Accuracy: 0.0303, Top5Accuracy: 0.0500, Time consumed:2.70s

Training Epoch: 5 [32/50000]	Loss: 4.5716	LR: 0.179702
Training Epoch: 5 [32/50000]	Loss: 4.3893	LR: 0.179702
Training Epoch: 5 [32/50000]	Loss: 4.4117	LR: 0.179702
Training Epoch: 5 [32/50000]	Loss: 4.1857	LR: 0.179702
Training Epoch: 5 [32/50000]	Loss: 4.3052	LR: 0.179702
Training Epoch: 5 [32/50000]	Loss: 4.2392	LR: 0.179702
Training Epoch: 5 [32/50000]	Loss: 4.3772	LR: 0.179702
Training Epoch: 5 [32/50000]	Loss: 4.2720	LR: 0.179702
Training Epoch: 5 [32/50000]	Loss: 4.2416	LR: 0.179702
Training Epoch: 5 [32/50000]	Loss: 4.2472	LR: 0.179702
Evaluating Network.....
Test set: Epoch: 5, Average loss: 0.1443, Top1Accuracy: 0.0114, Top3Accuracy: 0.0363, Top5Accuracy: 0.0606, Time consumed:2.64s

Training Epoch: 6 [32/50000]	Loss: 4.0957	LR: 0.174958
Training Epoch: 6 [32/50000]	Loss: 4.3039	LR: 0.174958
Training Epoch: 6 [32/50000]	Loss: 4.3408	LR: 0.174958
Training Epoch: 6 [32/50000]	Loss: 4.2699	LR: 0.174958
Training Epoch: 6 [32/50000]	Loss: 4.3081	LR: 0.174958
Training Epoch: 6 [32/50000]	Loss: 4.1272	LR: 0.174958
Training Epoch: 6 [32/50000]	Loss: 4.1379	LR: 0.174958
Training Epoch: 6 [32/50000]	Loss: 4.3123	LR: 0.174958
Training Epoch: 6 [32/50000]	Loss: 4.1061	LR: 0.174958
Training Epoch: 6 [32/50000]	Loss: 4.0861	LR: 0.174958
Evaluating Network.....
Test set: Epoch: 6, Average loss: 0.1425, Top1Accuracy: 0.0234, Top3Accuracy: 0.0643, Top5Accuracy: 0.1044, Time consumed:2.65s

Training Epoch: 7 [32/50000]	Loss: 4.2089	LR: 0.170339
Training Epoch: 7 [32/50000]	Loss: 4.1704	LR: 0.170339
Training Epoch: 7 [32/50000]	Loss: 4.4453	LR: 0.170339
Training Epoch: 7 [32/50000]	Loss: 4.0209	LR: 0.170339
Training Epoch: 7 [32/50000]	Loss: 3.8032	LR: 0.170339
Training Epoch: 7 [32/50000]	Loss: 4.2956	LR: 0.170339
Training Epoch: 7 [32/50000]	Loss: 3.9978	LR: 0.170339
Training Epoch: 7 [32/50000]	Loss: 4.0321	LR: 0.170339
Training Epoch: 7 [32/50000]	Loss: 4.2368	LR: 0.170339
Training Epoch: 7 [32/50000]	Loss: 4.2890	LR: 0.170339
Evaluating Network.....
Test set: Epoch: 7, Average loss: 0.1405, Top1Accuracy: 0.0279, Top3Accuracy: 0.0767, Top5Accuracy: 0.1216, Time consumed:2.69s

Training Epoch: 8 [32/50000]	Loss: 4.0892	LR: 0.165842
Training Epoch: 8 [32/50000]	Loss: 4.2377	LR: 0.165842
Training Epoch: 8 [32/50000]	Loss: 4.2318	LR: 0.165842
Training Epoch: 8 [32/50000]	Loss: 4.1438	LR: 0.165842
Training Epoch: 8 [32/50000]	Loss: 4.3662	LR: 0.165842
Training Epoch: 8 [32/50000]	Loss: 4.2126	LR: 0.165842
Training Epoch: 8 [32/50000]	Loss: 4.1225	LR: 0.165842
Training Epoch: 8 [32/50000]	Loss: 4.0828	LR: 0.165842
Training Epoch: 8 [32/50000]	Loss: 4.2031	LR: 0.165842
Training Epoch: 8 [32/50000]	Loss: 4.1611	LR: 0.165842
Evaluating Network.....
Test set: Epoch: 8, Average loss: 0.1395, Top1Accuracy: 0.0289, Top3Accuracy: 0.0904, Top5Accuracy: 0.1407, Time consumed:2.71s

Training Epoch: 9 [32/50000]	Loss: 4.3033	LR: 0.161464
Training Epoch: 9 [32/50000]	Loss: 4.0684	LR: 0.161464
Training Epoch: 9 [32/50000]	Loss: 4.1530	LR: 0.161464
Training Epoch: 9 [32/50000]	Loss: 4.0603	LR: 0.161464
Training Epoch: 9 [32/50000]	Loss: 3.9042	LR: 0.161464
Training Epoch: 9 [32/50000]	Loss: 4.1241	LR: 0.161464
Training Epoch: 9 [32/50000]	Loss: 4.2859	LR: 0.161464
Training Epoch: 9 [32/50000]	Loss: 3.9601	LR: 0.161464
Training Epoch: 9 [32/50000]	Loss: 4.0787	LR: 0.161464
Training Epoch: 9 [32/50000]	Loss: 3.8685	LR: 0.161464
Evaluating Network.....
Test set: Epoch: 9, Average loss: 0.1376, Top1Accuracy: 0.0365, Top3Accuracy: 0.0971, Top5Accuracy: 0.1431, Time consumed:2.68s

Training Epoch: 10 [32/50000]	Loss: 4.1405	LR: 0.157201
Training Epoch: 10 [32/50000]	Loss: 4.2389	LR: 0.157201
Training Epoch: 10 [32/50000]	Loss: 4.0887	LR: 0.157201
Training Epoch: 10 [32/50000]	Loss: 4.1791	LR: 0.157201
Training Epoch: 10 [32/50000]	Loss: 4.0432	LR: 0.157201
Training Epoch: 10 [32/50000]	Loss: 4.0505	LR: 0.157201
Training Epoch: 10 [32/50000]	Loss: 4.1621	LR: 0.157201
Training Epoch: 10 [32/50000]	Loss: 4.1297	LR: 0.157201
Training Epoch: 10 [32/50000]	Loss: 4.1746	LR: 0.157201
Training Epoch: 10 [32/50000]	Loss: 3.9163	LR: 0.157201
Evaluating Network.....
Test set: Epoch: 10, Average loss: 0.1357, Top1Accuracy: 0.0357, Top3Accuracy: 0.0990, Top5Accuracy: 0.1508, Time consumed:3.18s

Training Epoch: 11 [32/50000]	Loss: 3.9282	LR: 0.153051
Training Epoch: 11 [32/50000]	Loss: 3.8184	LR: 0.153051
Training Epoch: 11 [32/50000]	Loss: 3.9988	LR: 0.153051
Training Epoch: 11 [32/50000]	Loss: 4.1625	LR: 0.153051
Training Epoch: 11 [32/50000]	Loss: 4.0323	LR: 0.153051
Training Epoch: 11 [32/50000]	Loss: 3.9776	LR: 0.153051
Training Epoch: 11 [32/50000]	Loss: 4.1994	LR: 0.153051
Training Epoch: 11 [32/50000]	Loss: 4.1037	LR: 0.153051
Training Epoch: 11 [32/50000]	Loss: 4.1228	LR: 0.153051
Training Epoch: 11 [32/50000]	Loss: 4.1147	LR: 0.153051
Evaluating Network.....
Test set: Epoch: 11, Average loss: 0.1360, Top1Accuracy: 0.0358, Top3Accuracy: 0.1059, Top5Accuracy: 0.1609, Time consumed:2.70s

Training Epoch: 12 [32/50000]	Loss: 4.1814	LR: 0.149010
Training Epoch: 12 [32/50000]	Loss: 3.9408	LR: 0.149010
Training Epoch: 12 [32/50000]	Loss: 3.9063	LR: 0.149010
Training Epoch: 12 [32/50000]	Loss: 3.9556	LR: 0.149010
Training Epoch: 12 [32/50000]	Loss: 4.2209	LR: 0.149010
Training Epoch: 12 [32/50000]	Loss: 4.0573	LR: 0.149010
Training Epoch: 12 [32/50000]	Loss: 3.6791	LR: 0.149010
Training Epoch: 12 [32/50000]	Loss: 3.8471	LR: 0.149010
Training Epoch: 12 [32/50000]	Loss: 3.8868	LR: 0.149010
Training Epoch: 12 [32/50000]	Loss: 4.2289	LR: 0.149010
Evaluating Network.....
Test set: Epoch: 12, Average loss: 0.1331, Top1Accuracy: 0.0437, Top3Accuracy: 0.1123, Top5Accuracy: 0.1682, Time consumed:2.80s

Training Epoch: 13 [32/50000]	Loss: 4.0741	LR: 0.145076
Training Epoch: 13 [32/50000]	Loss: 3.6935	LR: 0.145076
Training Epoch: 13 [32/50000]	Loss: 4.1798	LR: 0.145076
Training Epoch: 13 [32/50000]	Loss: 4.1336	LR: 0.145076
Training Epoch: 13 [32/50000]	Loss: 4.0992	LR: 0.145076
Training Epoch: 13 [32/50000]	Loss: 3.8862	LR: 0.145076
Training Epoch: 13 [32/50000]	Loss: 3.9024	LR: 0.145076
Training Epoch: 13 [32/50000]	Loss: 3.7684	LR: 0.145076
Training Epoch: 13 [32/50000]	Loss: 4.0069	LR: 0.145076
Training Epoch: 13 [32/50000]	Loss: 4.0352	LR: 0.145076
Evaluating Network.....
Test set: Epoch: 13, Average loss: 0.1335, Top1Accuracy: 0.0391, Top3Accuracy: 0.1031, Top5Accuracy: 0.1579, Time consumed:2.68s

Training Epoch: 14 [32/50000]	Loss: 3.9694	LR: 0.141246
Training Epoch: 14 [32/50000]	Loss: 3.8306	LR: 0.141246
Training Epoch: 14 [32/50000]	Loss: 4.0359	LR: 0.141246
Training Epoch: 14 [32/50000]	Loss: 3.8869	LR: 0.141246
Training Epoch: 14 [32/50000]	Loss: 3.9118	LR: 0.141246
Training Epoch: 14 [32/50000]	Loss: 3.9975	LR: 0.141246
Training Epoch: 14 [32/50000]	Loss: 4.1732	LR: 0.141246
Training Epoch: 14 [32/50000]	Loss: 3.9803	LR: 0.141246
Training Epoch: 14 [32/50000]	Loss: 3.7652	LR: 0.141246
Training Epoch: 14 [32/50000]	Loss: 4.0633	LR: 0.141246
Evaluating Network.....
Test set: Epoch: 14, Average loss: 0.1324, Top1Accuracy: 0.0374, Top3Accuracy: 0.1017, Top5Accuracy: 0.1643, Time consumed:2.73s

Training Epoch: 15 [32/50000]	Loss: 4.0490	LR: 0.137517
Training Epoch: 15 [32/50000]	Loss: 4.0856	LR: 0.137517
Training Epoch: 15 [32/50000]	Loss: 4.0303	LR: 0.137517
Training Epoch: 15 [32/50000]	Loss: 3.9616	LR: 0.137517
Training Epoch: 15 [32/50000]	Loss: 3.8071	LR: 0.137517
Training Epoch: 15 [32/50000]	Loss: 4.2064	LR: 0.137517
Training Epoch: 15 [32/50000]	Loss: 3.6477	LR: 0.137517
Training Epoch: 15 [32/50000]	Loss: 4.0881	LR: 0.137517
Training Epoch: 15 [32/50000]	Loss: 3.9702	LR: 0.137517
Training Epoch: 15 [32/50000]	Loss: 4.0190	LR: 0.137517
Evaluating Network.....
Test set: Epoch: 15, Average loss: 0.1305, Top1Accuracy: 0.0472, Top3Accuracy: 0.1180, Top5Accuracy: 0.1820, Time consumed:2.60s

Training Epoch: 16 [32/50000]	Loss: 3.8294	LR: 0.133887
Training Epoch: 16 [32/50000]	Loss: 3.8980	LR: 0.133887
Training Epoch: 16 [32/50000]	Loss: 3.9332	LR: 0.133887
Training Epoch: 16 [32/50000]	Loss: 3.7305	LR: 0.133887
Training Epoch: 16 [32/50000]	Loss: 3.9825	LR: 0.133887
Training Epoch: 16 [32/50000]	Loss: 3.9357	LR: 0.133887
Training Epoch: 16 [32/50000]	Loss: 3.9970	LR: 0.133887
Training Epoch: 16 [32/50000]	Loss: 4.0412	LR: 0.133887
Training Epoch: 16 [32/50000]	Loss: 4.1495	LR: 0.133887
Training Epoch: 16 [32/50000]	Loss: 3.9835	LR: 0.133887
Evaluating Network.....
Test set: Epoch: 16, Average loss: 0.1348, Top1Accuracy: 0.0382, Top3Accuracy: 0.0989, Top5Accuracy: 0.1521, Time consumed:2.69s

Training Epoch: 17 [32/50000]	Loss: 3.9177	LR: 0.130352
Training Epoch: 17 [32/50000]	Loss: 3.7779	LR: 0.130352
Training Epoch: 17 [32/50000]	Loss: 3.7645	LR: 0.130352
Training Epoch: 17 [32/50000]	Loss: 3.9596	LR: 0.130352
Training Epoch: 17 [32/50000]	Loss: 4.0438	LR: 0.130352
Training Epoch: 17 [32/50000]	Loss: 4.0338	LR: 0.130352
Training Epoch: 17 [32/50000]	Loss: 4.0119	LR: 0.130352
Training Epoch: 17 [32/50000]	Loss: 3.9114	LR: 0.130352
Training Epoch: 17 [32/50000]	Loss: 4.1941	LR: 0.130352
Training Epoch: 17 [32/50000]	Loss: 3.8586	LR: 0.130352
Evaluating Network.....
Test set: Epoch: 17, Average loss: 0.1345, Top1Accuracy: 0.0317, Top3Accuracy: 0.0940, Top5Accuracy: 0.1476, Time consumed:2.76s

Training Epoch: 18 [32/50000]	Loss: 3.7930	LR: 0.126911
Training Epoch: 18 [32/50000]	Loss: 3.8713	LR: 0.126911
Training Epoch: 18 [32/50000]	Loss: 3.5981	LR: 0.126911
Training Epoch: 18 [32/50000]	Loss: 3.9955	LR: 0.126911
Training Epoch: 18 [32/50000]	Loss: 3.9330	LR: 0.126911
Training Epoch: 18 [32/50000]	Loss: 4.1061	LR: 0.126911
Training Epoch: 18 [32/50000]	Loss: 3.9927	LR: 0.126911
Training Epoch: 18 [32/50000]	Loss: 3.8412	LR: 0.126911
Training Epoch: 18 [32/50000]	Loss: 4.1281	LR: 0.126911
Training Epoch: 18 [32/50000]	Loss: 3.6859	LR: 0.126911
Evaluating Network.....
Test set: Epoch: 18, Average loss: 0.1360, Top1Accuracy: 0.0291, Top3Accuracy: 0.0890, Top5Accuracy: 0.1366, Time consumed:2.77s

Training Epoch: 19 [32/50000]	Loss: 3.9759	LR: 0.123561
Training Epoch: 19 [32/50000]	Loss: 3.6854	LR: 0.123561
Training Epoch: 19 [32/50000]	Loss: 4.2626	LR: 0.123561
Training Epoch: 19 [32/50000]	Loss: 4.0313	LR: 0.123561
Training Epoch: 19 [32/50000]	Loss: 3.8238	LR: 0.123561
Training Epoch: 19 [32/50000]	Loss: 4.0561	LR: 0.123561
Training Epoch: 19 [32/50000]	Loss: 3.6682	LR: 0.123561
Training Epoch: 19 [32/50000]	Loss: 4.1973	LR: 0.123561
Training Epoch: 19 [32/50000]	Loss: 3.8082	LR: 0.123561
Training Epoch: 19 [32/50000]	Loss: 4.0206	LR: 0.123561
Evaluating Network.....
Test set: Epoch: 19, Average loss: 0.1334, Top1Accuracy: 0.0425, Top3Accuracy: 0.1046, Top5Accuracy: 0.1604, Time consumed:2.69s

Training Epoch: 20 [32/50000]	Loss: 3.8448	LR: 0.120299
Training Epoch: 20 [32/50000]	Loss: 3.6748	LR: 0.120299
Training Epoch: 20 [32/50000]	Loss: 3.4818	LR: 0.120299
Training Epoch: 20 [32/50000]	Loss: 3.7931	LR: 0.120299
Training Epoch: 20 [32/50000]	Loss: 3.9573	LR: 0.120299
Training Epoch: 20 [32/50000]	Loss: 3.6612	LR: 0.120299
Training Epoch: 20 [32/50000]	Loss: 3.9940	LR: 0.120299
Training Epoch: 20 [32/50000]	Loss: 4.1089	LR: 0.120299
Training Epoch: 20 [32/50000]	Loss: 3.9296	LR: 0.120299
Training Epoch: 20 [32/50000]	Loss: 3.7709	LR: 0.120299
Evaluating Network.....
Test set: Epoch: 20, Average loss: 0.1288, Top1Accuracy: 0.0555, Top3Accuracy: 0.1435, Top5Accuracy: 0.2112, Time consumed:2.75s

Training Epoch: 21 [32/50000]	Loss: 4.1773	LR: 0.117123
Training Epoch: 21 [32/50000]	Loss: 4.0061	LR: 0.117123
Training Epoch: 21 [32/50000]	Loss: 3.8559	LR: 0.117123
Training Epoch: 21 [32/50000]	Loss: 4.0159	LR: 0.117123
Training Epoch: 21 [32/50000]	Loss: 4.0161	LR: 0.117123
Training Epoch: 21 [32/50000]	Loss: 3.6920	LR: 0.117123
Training Epoch: 21 [32/50000]	Loss: 3.8839	LR: 0.117123
Training Epoch: 21 [32/50000]	Loss: 3.6122	LR: 0.117123
Training Epoch: 21 [32/50000]	Loss: 3.8825	LR: 0.117123
Training Epoch: 21 [32/50000]	Loss: 3.8400	LR: 0.117123
Evaluating Network.....
Test set: Epoch: 21, Average loss: 0.1264, Top1Accuracy: 0.0636, Top3Accuracy: 0.1568, Top5Accuracy: 0.2281, Time consumed:2.68s

Training Epoch: 22 [32/50000]	Loss: 3.6766	LR: 0.114031
Training Epoch: 22 [32/50000]	Loss: 4.0043	LR: 0.114031
Training Epoch: 22 [32/50000]	Loss: 4.0077	LR: 0.114031
Training Epoch: 22 [32/50000]	Loss: 3.7936	LR: 0.114031
Training Epoch: 22 [32/50000]	Loss: 3.8816	LR: 0.114031
Training Epoch: 22 [32/50000]	Loss: 3.9257	LR: 0.114031
Training Epoch: 22 [32/50000]	Loss: 3.7375	LR: 0.114031
Training Epoch: 22 [32/50000]	Loss: 3.8975	LR: 0.114031
Training Epoch: 22 [32/50000]	Loss: 3.6762	LR: 0.114031
Training Epoch: 22 [32/50000]	Loss: 3.8578	LR: 0.114031
Evaluating Network.....
Test set: Epoch: 22, Average loss: 0.1242, Top1Accuracy: 0.0775, Top3Accuracy: 0.1771, Top5Accuracy: 0.2537, Time consumed:2.65s

Training Epoch: 23 [32/50000]	Loss: 4.1051	LR: 0.111020
Training Epoch: 23 [32/50000]	Loss: 4.1758	LR: 0.111020
Training Epoch: 23 [32/50000]	Loss: 3.7712	LR: 0.111020
Training Epoch: 23 [32/50000]	Loss: 3.7644	LR: 0.111020
Training Epoch: 23 [32/50000]	Loss: 3.6958	LR: 0.111020
Training Epoch: 23 [32/50000]	Loss: 3.9701	LR: 0.111020
Training Epoch: 23 [32/50000]	Loss: 3.5429	LR: 0.111020
Training Epoch: 23 [32/50000]	Loss: 3.8824	LR: 0.111020
Training Epoch: 23 [32/50000]	Loss: 3.6143	LR: 0.111020
Training Epoch: 23 [32/50000]	Loss: 3.9884	LR: 0.111020
Evaluating Network.....
Test set: Epoch: 23, Average loss: 0.1269, Top1Accuracy: 0.0667, Top3Accuracy: 0.1570, Top5Accuracy: 0.2281, Time consumed:2.64s

Training Epoch: 24 [32/50000]	Loss: 3.5362	LR: 0.108089
Training Epoch: 24 [32/50000]	Loss: 3.8520	LR: 0.108089
Training Epoch: 24 [32/50000]	Loss: 3.8778	LR: 0.108089
Training Epoch: 24 [32/50000]	Loss: 3.9867	LR: 0.108089
Training Epoch: 24 [32/50000]	Loss: 3.8316	LR: 0.108089
Training Epoch: 24 [32/50000]	Loss: 3.8692	LR: 0.108089
Training Epoch: 24 [32/50000]	Loss: 3.8165	LR: 0.108089
Training Epoch: 24 [32/50000]	Loss: 3.8822	LR: 0.108089
Training Epoch: 24 [32/50000]	Loss: 3.7037	LR: 0.108089
Training Epoch: 24 [32/50000]	Loss: 3.9333	LR: 0.108089
Evaluating Network.....
Test set: Epoch: 24, Average loss: 0.1251, Top1Accuracy: 0.0736, Top3Accuracy: 0.1701, Top5Accuracy: 0.2451, Time consumed:2.66s

Training Epoch: 25 [32/50000]	Loss: 3.7622	LR: 0.105236
Training Epoch: 25 [32/50000]	Loss: 3.8199	LR: 0.105236
Training Epoch: 25 [32/50000]	Loss: 3.5698	LR: 0.105236
Training Epoch: 25 [32/50000]	Loss: 3.6936	LR: 0.105236
Training Epoch: 25 [32/50000]	Loss: 3.6975	LR: 0.105236
Training Epoch: 25 [32/50000]	Loss: 3.8741	LR: 0.105236
Training Epoch: 25 [32/50000]	Loss: 3.8370	LR: 0.105236
Training Epoch: 25 [32/50000]	Loss: 4.0601	LR: 0.105236
Training Epoch: 25 [32/50000]	Loss: 3.8744	LR: 0.105236
Training Epoch: 25 [32/50000]	Loss: 3.8012	LR: 0.105236
Evaluating Network.....
Test set: Epoch: 25, Average loss: 0.1241, Top1Accuracy: 0.0787, Top3Accuracy: 0.1778, Top5Accuracy: 0.2526, Time consumed:2.67s

Training Epoch: 26 [32/50000]	Loss: 4.0908	LR: 0.102458
Training Epoch: 26 [32/50000]	Loss: 3.3805	LR: 0.102458
Training Epoch: 26 [32/50000]	Loss: 3.9718	LR: 0.102458
Training Epoch: 26 [32/50000]	Loss: 3.8087	LR: 0.102458
Training Epoch: 26 [32/50000]	Loss: 3.9967	LR: 0.102458
Training Epoch: 26 [32/50000]	Loss: 3.9148	LR: 0.102458
Training Epoch: 26 [32/50000]	Loss: 3.9872	LR: 0.102458
Training Epoch: 26 [32/50000]	Loss: 3.8830	LR: 0.102458
Training Epoch: 26 [32/50000]	Loss: 3.9982	LR: 0.102458
Training Epoch: 26 [32/50000]	Loss: 3.7549	LR: 0.102458
Evaluating Network.....
Test set: Epoch: 26, Average loss: 0.1231, Top1Accuracy: 0.0835, Top3Accuracy: 0.1891, Top5Accuracy: 0.2689, Time consumed:2.78s

Training Epoch: 27 [32/50000]	Loss: 3.5219	LR: 0.099753
Training Epoch: 27 [32/50000]	Loss: 4.0660	LR: 0.099753
Training Epoch: 27 [32/50000]	Loss: 3.7293	LR: 0.099753
Training Epoch: 27 [32/50000]	Loss: 3.7457	LR: 0.099753
Training Epoch: 27 [32/50000]	Loss: 3.7830	LR: 0.099753
Training Epoch: 27 [32/50000]	Loss: 4.0053	LR: 0.099753
Training Epoch: 27 [32/50000]	Loss: 3.4950	LR: 0.099753
Training Epoch: 27 [32/50000]	Loss: 3.8620	LR: 0.099753
Training Epoch: 27 [32/50000]	Loss: 3.7693	LR: 0.099753
Training Epoch: 27 [32/50000]	Loss: 3.9158	LR: 0.099753
Evaluating Network.....
Test set: Epoch: 27, Average loss: 0.1230, Top1Accuracy: 0.0885, Top3Accuracy: 0.1920, Top5Accuracy: 0.2708, Time consumed:2.71s

Training Epoch: 28 [32/50000]	Loss: 3.5345	LR: 0.097119
Training Epoch: 28 [32/50000]	Loss: 3.6117	LR: 0.097119
Training Epoch: 28 [32/50000]	Loss: 3.9493	LR: 0.097119
Training Epoch: 28 [32/50000]	Loss: 3.5804	LR: 0.097119
Training Epoch: 28 [32/50000]	Loss: 4.0256	LR: 0.097119
Training Epoch: 28 [32/50000]	Loss: 3.8213	LR: 0.097119
Training Epoch: 28 [32/50000]	Loss: 3.7555	LR: 0.097119
Training Epoch: 28 [32/50000]	Loss: 3.7255	LR: 0.097119
Training Epoch: 28 [32/50000]	Loss: 3.8693	LR: 0.097119
Training Epoch: 28 [32/50000]	Loss: 4.0740	LR: 0.097119
Evaluating Network.....
Test set: Epoch: 28, Average loss: 0.1201, Top1Accuracy: 0.0938, Top3Accuracy: 0.2200, Top5Accuracy: 0.3015, Time consumed:2.93s

Training Epoch: 29 [32/50000]	Loss: 3.6980	LR: 0.094555
Training Epoch: 29 [32/50000]	Loss: 4.0240	LR: 0.094555
Training Epoch: 29 [32/50000]	Loss: 3.3436	LR: 0.094555
Training Epoch: 29 [32/50000]	Loss: 3.5129	LR: 0.094555
Training Epoch: 29 [32/50000]	Loss: 3.6582	LR: 0.094555
Training Epoch: 29 [32/50000]	Loss: 3.7768	LR: 0.094555
Training Epoch: 29 [32/50000]	Loss: 3.5889	LR: 0.094555
Training Epoch: 29 [32/50000]	Loss: 3.3187	LR: 0.094555
Training Epoch: 29 [32/50000]	Loss: 3.7435	LR: 0.094555
Training Epoch: 29 [32/50000]	Loss: 3.6281	LR: 0.094555
Evaluating Network.....
Test set: Epoch: 29, Average loss: 0.1203, Top1Accuracy: 0.0929, Top3Accuracy: 0.2137, Top5Accuracy: 0.2981, Time consumed:2.70s

Training Epoch: 30 [32/50000]	Loss: 3.3747	LR: 0.092059
Training Epoch: 30 [32/50000]	Loss: 3.6800	LR: 0.092059
Training Epoch: 30 [32/50000]	Loss: 3.8051	LR: 0.092059
Training Epoch: 30 [32/50000]	Loss: 3.6585	LR: 0.092059
Training Epoch: 30 [32/50000]	Loss: 3.4284	LR: 0.092059
Training Epoch: 30 [32/50000]	Loss: 3.8245	LR: 0.092059
Training Epoch: 30 [32/50000]	Loss: 3.6641	LR: 0.092059
Training Epoch: 30 [32/50000]	Loss: 3.4008	LR: 0.092059
Training Epoch: 30 [32/50000]	Loss: 3.8494	LR: 0.092059
Training Epoch: 30 [32/50000]	Loss: 3.3687	LR: 0.092059
Evaluating Network.....
Test set: Epoch: 30, Average loss: 0.1210, Top1Accuracy: 0.0897, Top3Accuracy: 0.2088, Top5Accuracy: 0.2868, Time consumed:2.65s

Training Epoch: 31 [32/50000]	Loss: 4.0794	LR: 0.089629
Training Epoch: 31 [32/50000]	Loss: 3.6364	LR: 0.089629
Training Epoch: 31 [32/50000]	Loss: 3.5719	LR: 0.089629
Training Epoch: 31 [32/50000]	Loss: 3.7726	LR: 0.089629
Training Epoch: 31 [32/50000]	Loss: 3.8259	LR: 0.089629
Training Epoch: 31 [32/50000]	Loss: 3.5943	LR: 0.089629
Training Epoch: 31 [32/50000]	Loss: 3.4943	LR: 0.089629
Training Epoch: 31 [32/50000]	Loss: 3.8528	LR: 0.089629
Training Epoch: 31 [32/50000]	Loss: 3.5440	LR: 0.089629
Training Epoch: 31 [32/50000]	Loss: 3.3590	LR: 0.089629
Evaluating Network.....
Test set: Epoch: 31, Average loss: 0.1210, Top1Accuracy: 0.0940, Top3Accuracy: 0.2084, Top5Accuracy: 0.2932, Time consumed:2.61s

Training Epoch: 32 [32/50000]	Loss: 3.7268	LR: 0.087262
Training Epoch: 32 [32/50000]	Loss: 3.5350	LR: 0.087262
Training Epoch: 32 [32/50000]	Loss: 3.4907	LR: 0.087262
Training Epoch: 32 [32/50000]	Loss: 3.7478	LR: 0.087262
Training Epoch: 32 [32/50000]	Loss: 3.5429	LR: 0.087262
Training Epoch: 32 [32/50000]	Loss: 3.7983	LR: 0.087262
Training Epoch: 32 [32/50000]	Loss: 3.9174	LR: 0.087262
Training Epoch: 32 [32/50000]	Loss: 3.7825	LR: 0.087262
Training Epoch: 32 [32/50000]	Loss: 3.9395	LR: 0.087262
Training Epoch: 32 [32/50000]	Loss: 3.5183	LR: 0.087262
Evaluating Network.....
Test set: Epoch: 32, Average loss: 0.1191, Top1Accuracy: 0.1012, Top3Accuracy: 0.2239, Top5Accuracy: 0.3111, Time consumed:2.65s

Training Epoch: 33 [32/50000]	Loss: 3.6228	LR: 0.084959
Training Epoch: 33 [32/50000]	Loss: 3.5154	LR: 0.084959
Training Epoch: 33 [32/50000]	Loss: 3.8585	LR: 0.084959
Training Epoch: 33 [32/50000]	Loss: 3.5611	LR: 0.084959
Training Epoch: 33 [32/50000]	Loss: 3.5233	LR: 0.084959
Training Epoch: 33 [32/50000]	Loss: 3.4040	LR: 0.084959
Training Epoch: 33 [32/50000]	Loss: 3.5960	LR: 0.084959
Training Epoch: 33 [32/50000]	Loss: 3.6965	LR: 0.084959
Training Epoch: 33 [32/50000]	Loss: 4.3029	LR: 0.084959
Training Epoch: 33 [32/50000]	Loss: 3.6202	LR: 0.084959
Evaluating Network.....
Test set: Epoch: 33, Average loss: 0.1188, Top1Accuracy: 0.1047, Top3Accuracy: 0.2288, Top5Accuracy: 0.3143, Time consumed:2.72s

Training Epoch: 34 [32/50000]	Loss: 3.3585	LR: 0.082716
Training Epoch: 34 [32/50000]	Loss: 3.5562	LR: 0.082716
Training Epoch: 34 [32/50000]	Loss: 3.7269	LR: 0.082716
Training Epoch: 34 [32/50000]	Loss: 3.7311	LR: 0.082716
Training Epoch: 34 [32/50000]	Loss: 3.5662	LR: 0.082716
Training Epoch: 34 [32/50000]	Loss: 3.6180	LR: 0.082716
Training Epoch: 34 [32/50000]	Loss: 3.4628	LR: 0.082716
Training Epoch: 34 [32/50000]	Loss: 3.8171	LR: 0.082716
Training Epoch: 34 [32/50000]	Loss: 3.3020	LR: 0.082716
Training Epoch: 34 [32/50000]	Loss: 3.9156	LR: 0.082716
Evaluating Network.....
Test set: Epoch: 34, Average loss: 0.1183, Top1Accuracy: 0.1067, Top3Accuracy: 0.2302, Top5Accuracy: 0.3202, Time consumed:3.36s

Training Epoch: 35 [32/50000]	Loss: 4.0379	LR: 0.080532
Training Epoch: 35 [32/50000]	Loss: 3.8346	LR: 0.080532
Training Epoch: 35 [32/50000]	Loss: 3.4430	LR: 0.080532
Training Epoch: 35 [32/50000]	Loss: 3.8965	LR: 0.080532
Training Epoch: 35 [32/50000]	Loss: 3.6436	LR: 0.080532
Training Epoch: 35 [32/50000]	Loss: 3.5230	LR: 0.080532
Training Epoch: 35 [32/50000]	Loss: 3.3454	LR: 0.080532
Training Epoch: 35 [32/50000]	Loss: 3.4108	LR: 0.080532
Training Epoch: 35 [32/50000]	Loss: 3.4651	LR: 0.080532
Training Epoch: 35 [32/50000]	Loss: 3.7790	LR: 0.080532
Evaluating Network.....
Test set: Epoch: 35, Average loss: 0.1167, Top1Accuracy: 0.1098, Top3Accuracy: 0.2439, Top5Accuracy: 0.3372, Time consumed:2.62s

Training Epoch: 36 [32/50000]	Loss: 3.3016	LR: 0.078406
Training Epoch: 36 [32/50000]	Loss: 3.9624	LR: 0.078406
Training Epoch: 36 [32/50000]	Loss: 3.8635	LR: 0.078406
Training Epoch: 36 [32/50000]	Loss: 3.4550	LR: 0.078406
Training Epoch: 36 [32/50000]	Loss: 3.3891	LR: 0.078406
Training Epoch: 36 [32/50000]	Loss: 3.5788	LR: 0.078406
Training Epoch: 36 [32/50000]	Loss: 3.4864	LR: 0.078406
Training Epoch: 36 [32/50000]	Loss: 4.0126	LR: 0.078406
Training Epoch: 36 [32/50000]	Loss: 4.0837	LR: 0.078406
Training Epoch: 36 [32/50000]	Loss: 3.7999	LR: 0.078406
Evaluating Network.....
Test set: Epoch: 36, Average loss: 0.1155, Top1Accuracy: 0.1168, Top3Accuracy: 0.2535, Top5Accuracy: 0.3430, Time consumed:2.66s

Training Epoch: 37 [32/50000]	Loss: 3.7560	LR: 0.076336
Training Epoch: 37 [32/50000]	Loss: 3.4131	LR: 0.076336
Training Epoch: 37 [32/50000]	Loss: 3.5524	LR: 0.076336
Training Epoch: 37 [32/50000]	Loss: 3.6156	LR: 0.076336
Training Epoch: 37 [32/50000]	Loss: 3.7546	LR: 0.076336
Training Epoch: 37 [32/50000]	Loss: 3.3485	LR: 0.076336
Training Epoch: 37 [32/50000]	Loss: 3.6816	LR: 0.076336
Training Epoch: 37 [32/50000]	Loss: 3.7694	LR: 0.076336
Training Epoch: 37 [32/50000]	Loss: 3.6705	LR: 0.076336
Training Epoch: 37 [32/50000]	Loss: 3.5822	LR: 0.076336
Evaluating Network.....
Test set: Epoch: 37, Average loss: 0.1157, Top1Accuracy: 0.1147, Top3Accuracy: 0.2540, Top5Accuracy: 0.3477, Time consumed:2.67s

Training Epoch: 38 [32/50000]	Loss: 3.4949	LR: 0.074321
Training Epoch: 38 [32/50000]	Loss: 3.5934	LR: 0.074321
Training Epoch: 38 [32/50000]	Loss: 3.4154	LR: 0.074321
Training Epoch: 38 [32/50000]	Loss: 3.4125	LR: 0.074321
Training Epoch: 38 [32/50000]	Loss: 3.8616	LR: 0.074321
Training Epoch: 38 [32/50000]	Loss: 3.4004	LR: 0.074321
Training Epoch: 38 [32/50000]	Loss: 3.4374	LR: 0.074321
Training Epoch: 38 [32/50000]	Loss: 3.4962	LR: 0.074321
Training Epoch: 38 [32/50000]	Loss: 3.5339	LR: 0.074321
Training Epoch: 38 [32/50000]	Loss: 3.9248	LR: 0.074321
Evaluating Network.....
Test set: Epoch: 38, Average loss: 0.1147, Top1Accuracy: 0.1207, Top3Accuracy: 0.2676, Top5Accuracy: 0.3565, Time consumed:2.63s

Training Epoch: 39 [32/50000]	Loss: 3.4520	LR: 0.072359
Training Epoch: 39 [32/50000]	Loss: 3.2739	LR: 0.072359
Training Epoch: 39 [32/50000]	Loss: 3.6418	LR: 0.072359
Training Epoch: 39 [32/50000]	Loss: 3.7718	LR: 0.072359
Training Epoch: 39 [32/50000]	Loss: 3.7440	LR: 0.072359
Training Epoch: 39 [32/50000]	Loss: 3.6417	LR: 0.072359
Training Epoch: 39 [32/50000]	Loss: 3.5346	LR: 0.072359
Training Epoch: 39 [32/50000]	Loss: 3.6197	LR: 0.072359
Training Epoch: 39 [32/50000]	Loss: 3.7888	LR: 0.072359
Training Epoch: 39 [32/50000]	Loss: 3.5661	LR: 0.072359
Evaluating Network.....
Test set: Epoch: 39, Average loss: 0.1136, Top1Accuracy: 0.1247, Top3Accuracy: 0.2721, Top5Accuracy: 0.3668, Time consumed:2.66s

Training Epoch: 40 [32/50000]	Loss: 3.4339	LR: 0.070449
Training Epoch: 40 [32/50000]	Loss: 3.5751	LR: 0.070449
Training Epoch: 40 [32/50000]	Loss: 3.5997	LR: 0.070449
Training Epoch: 40 [32/50000]	Loss: 3.4314	LR: 0.070449
Training Epoch: 40 [32/50000]	Loss: 3.4843	LR: 0.070449
Training Epoch: 40 [32/50000]	Loss: 3.2509	LR: 0.070449
Training Epoch: 40 [32/50000]	Loss: 3.2104	LR: 0.070449
Training Epoch: 40 [32/50000]	Loss: 3.2855	LR: 0.070449
Training Epoch: 40 [32/50000]	Loss: 3.6664	LR: 0.070449
Training Epoch: 40 [32/50000]	Loss: 3.7162	LR: 0.070449
Evaluating Network.....
Test set: Epoch: 40, Average loss: 0.1134, Top1Accuracy: 0.1316, Top3Accuracy: 0.2789, Top5Accuracy: 0.3666, Time consumed:2.70s

Training Epoch: 41 [32/50000]	Loss: 3.8526	LR: 0.068589
Training Epoch: 41 [32/50000]	Loss: 3.6602	LR: 0.068589
Training Epoch: 41 [32/50000]	Loss: 3.3931	LR: 0.068589
Training Epoch: 41 [32/50000]	Loss: 3.6019	LR: 0.068589
Training Epoch: 41 [32/50000]	Loss: 3.3371	LR: 0.068589
Training Epoch: 41 [32/50000]	Loss: 3.3352	LR: 0.068589
Training Epoch: 41 [32/50000]	Loss: 3.4524	LR: 0.068589
Training Epoch: 41 [32/50000]	Loss: 4.0458	LR: 0.068589
Training Epoch: 41 [32/50000]	Loss: 3.3152	LR: 0.068589
Training Epoch: 41 [32/50000]	Loss: 3.6559	LR: 0.068589
Evaluating Network.....
Test set: Epoch: 41, Average loss: 0.1119, Top1Accuracy: 0.1366, Top3Accuracy: 0.2862, Top5Accuracy: 0.3815, Time consumed:2.60s

Training Epoch: 42 [32/50000]	Loss: 3.5344	LR: 0.066778
Training Epoch: 42 [32/50000]	Loss: 3.7335	LR: 0.066778
Training Epoch: 42 [32/50000]	Loss: 3.5031	LR: 0.066778
Training Epoch: 42 [32/50000]	Loss: 4.1378	LR: 0.066778
Training Epoch: 42 [32/50000]	Loss: 3.6970	LR: 0.066778
Training Epoch: 42 [32/50000]	Loss: 3.5561	LR: 0.066778
Training Epoch: 42 [32/50000]	Loss: 3.3062	LR: 0.066778
Training Epoch: 42 [32/50000]	Loss: 3.1713	LR: 0.066778
Training Epoch: 42 [32/50000]	Loss: 3.0078	LR: 0.066778
Training Epoch: 42 [32/50000]	Loss: 3.5438	LR: 0.066778
Evaluating Network.....
Test set: Epoch: 42, Average loss: 0.1111, Top1Accuracy: 0.1425, Top3Accuracy: 0.2998, Top5Accuracy: 0.3911, Time consumed:2.65s

Training Epoch: 43 [32/50000]	Loss: 3.4562	LR: 0.065015
Training Epoch: 43 [32/50000]	Loss: 3.3234	LR: 0.065015
Training Epoch: 43 [32/50000]	Loss: 3.7577	LR: 0.065015
Training Epoch: 43 [32/50000]	Loss: 3.7845	LR: 0.065015
Training Epoch: 43 [32/50000]	Loss: 3.5124	LR: 0.065015
Training Epoch: 43 [32/50000]	Loss: 3.3508	LR: 0.065015
Training Epoch: 43 [32/50000]	Loss: 3.4006	LR: 0.065015
Training Epoch: 43 [32/50000]	Loss: 3.2510	LR: 0.065015
Training Epoch: 43 [32/50000]	Loss: 3.1354	LR: 0.065015
Training Epoch: 43 [32/50000]	Loss: 3.1025	LR: 0.065015
Evaluating Network.....
Test set: Epoch: 43, Average loss: 0.1110, Top1Accuracy: 0.1389, Top3Accuracy: 0.2951, Top5Accuracy: 0.3910, Time consumed:2.83s

Training Epoch: 44 [32/50000]	Loss: 3.3839	LR: 0.063299
Training Epoch: 44 [32/50000]	Loss: 3.4326	LR: 0.063299
Training Epoch: 44 [32/50000]	Loss: 3.4133	LR: 0.063299
Training Epoch: 44 [32/50000]	Loss: 3.3430	LR: 0.063299
Training Epoch: 44 [32/50000]	Loss: 3.3912	LR: 0.063299
Training Epoch: 44 [32/50000]	Loss: 3.4376	LR: 0.063299
Training Epoch: 44 [32/50000]	Loss: 3.1909	LR: 0.063299
Training Epoch: 44 [32/50000]	Loss: 3.8084	LR: 0.063299
Training Epoch: 44 [32/50000]	Loss: 3.6146	LR: 0.063299
Training Epoch: 44 [32/50000]	Loss: 3.5666	LR: 0.063299
Evaluating Network.....
Test set: Epoch: 44, Average loss: 0.1104, Top1Accuracy: 0.1468, Top3Accuracy: 0.2978, Top5Accuracy: 0.3943, Time consumed:2.64s

Training Epoch: 45 [32/50000]	Loss: 3.3854	LR: 0.061628
Training Epoch: 45 [32/50000]	Loss: 3.2276	LR: 0.061628
Training Epoch: 45 [32/50000]	Loss: 4.4423	LR: 0.061628
Training Epoch: 45 [32/50000]	Loss: 3.2724	LR: 0.061628
Training Epoch: 45 [32/50000]	Loss: 3.9859	LR: 0.061628
Training Epoch: 45 [32/50000]	Loss: 3.4619	LR: 0.061628
Training Epoch: 45 [32/50000]	Loss: 3.3210	LR: 0.061628
Training Epoch: 45 [32/50000]	Loss: 3.8404	LR: 0.061628
Training Epoch: 45 [32/50000]	Loss: 3.1755	LR: 0.061628
Training Epoch: 45 [32/50000]	Loss: 3.5545	LR: 0.061628
Evaluating Network.....
Test set: Epoch: 45, Average loss: 0.1107, Top1Accuracy: 0.1437, Top3Accuracy: 0.2947, Top5Accuracy: 0.3933, Time consumed:2.64s

Training Epoch: 46 [32/50000]	Loss: 3.0600	LR: 0.060001
Training Epoch: 46 [32/50000]	Loss: 3.2782	LR: 0.060001
Training Epoch: 46 [32/50000]	Loss: 3.3806	LR: 0.060001
Training Epoch: 46 [32/50000]	Loss: 3.1494	LR: 0.060001
Training Epoch: 46 [32/50000]	Loss: 3.3433	LR: 0.060001
Training Epoch: 46 [32/50000]	Loss: 3.4064	LR: 0.060001
Training Epoch: 46 [32/50000]	Loss: 3.3242	LR: 0.060001
Training Epoch: 46 [32/50000]	Loss: 3.2973	LR: 0.060001
Training Epoch: 46 [32/50000]	Loss: 3.2965	LR: 0.060001
Training Epoch: 46 [32/50000]	Loss: 3.2766	LR: 0.060001
Evaluating Network.....
Test set: Epoch: 46, Average loss: 0.1103, Top1Accuracy: 0.1498, Top3Accuracy: 0.3001, Top5Accuracy: 0.3967, Time consumed:2.68s

Training Epoch: 47 [32/50000]	Loss: 3.9362	LR: 0.058417
Training Epoch: 47 [32/50000]	Loss: 3.2111	LR: 0.058417
Training Epoch: 47 [32/50000]	Loss: 3.7268	LR: 0.058417
Training Epoch: 47 [32/50000]	Loss: 3.4284	LR: 0.058417
Training Epoch: 47 [32/50000]	Loss: 3.3202	LR: 0.058417
Training Epoch: 47 [32/50000]	Loss: 3.3113	LR: 0.058417
Training Epoch: 47 [32/50000]	Loss: 3.5427	LR: 0.058417
Training Epoch: 47 [32/50000]	Loss: 3.4386	LR: 0.058417
Training Epoch: 47 [32/50000]	Loss: 3.0397	LR: 0.058417
Training Epoch: 47 [32/50000]	Loss: 3.6709	LR: 0.058417
Evaluating Network.....
Test set: Epoch: 47, Average loss: 0.1096, Top1Accuracy: 0.1462, Top3Accuracy: 0.3006, Top5Accuracy: 0.4016, Time consumed:2.68s

Training Epoch: 48 [32/50000]	Loss: 3.2680	LR: 0.056874
Training Epoch: 48 [32/50000]	Loss: 3.5745	LR: 0.056874
Training Epoch: 48 [32/50000]	Loss: 3.0143	LR: 0.056874
Training Epoch: 48 [32/50000]	Loss: 3.4962	LR: 0.056874
Training Epoch: 48 [32/50000]	Loss: 3.2905	LR: 0.056874
Training Epoch: 48 [32/50000]	Loss: 3.4175	LR: 0.056874
Training Epoch: 48 [32/50000]	Loss: 3.2464	LR: 0.056874
Training Epoch: 48 [32/50000]	Loss: 3.4288	LR: 0.056874
Training Epoch: 48 [32/50000]	Loss: 3.3063	LR: 0.056874
Training Epoch: 48 [32/50000]	Loss: 3.3822	LR: 0.056874
Evaluating Network.....
Test set: Epoch: 48, Average loss: 0.1095, Top1Accuracy: 0.1474, Top3Accuracy: 0.3036, Top5Accuracy: 0.4016, Time consumed:2.67s

Training Epoch: 49 [32/50000]	Loss: 2.8357	LR: 0.055373
Training Epoch: 49 [32/50000]	Loss: 3.1295	LR: 0.055373
Training Epoch: 49 [32/50000]	Loss: 3.7211	LR: 0.055373
Training Epoch: 49 [32/50000]	Loss: 2.9196	LR: 0.055373
Training Epoch: 49 [32/50000]	Loss: 3.2445	LR: 0.055373
Training Epoch: 49 [32/50000]	Loss: 3.3852	LR: 0.055373
Training Epoch: 49 [32/50000]	Loss: 3.6726	LR: 0.055373
Training Epoch: 49 [32/50000]	Loss: 3.1765	LR: 0.055373
Training Epoch: 49 [32/50000]	Loss: 3.0516	LR: 0.055373
Training Epoch: 49 [32/50000]	Loss: 3.5654	LR: 0.055373
Evaluating Network.....
Test set: Epoch: 49, Average loss: 0.1084, Top1Accuracy: 0.1549, Top3Accuracy: 0.3109, Top5Accuracy: 0.4151, Time consumed:2.68s

Training Epoch: 50 [32/50000]	Loss: 3.4485	LR: 0.053911
Training Epoch: 50 [32/50000]	Loss: 3.3281	LR: 0.053911
Training Epoch: 50 [32/50000]	Loss: 3.5516	LR: 0.053911
Training Epoch: 50 [32/50000]	Loss: 2.9952	LR: 0.053911
Training Epoch: 50 [32/50000]	Loss: 3.4547	LR: 0.053911
Training Epoch: 50 [32/50000]	Loss: 3.5055	LR: 0.053911
Training Epoch: 50 [32/50000]	Loss: 3.4730	LR: 0.053911
Training Epoch: 50 [32/50000]	Loss: 3.3337	LR: 0.053911
Training Epoch: 50 [32/50000]	Loss: 3.1222	LR: 0.053911
Training Epoch: 50 [32/50000]	Loss: 3.8610	LR: 0.053911
Evaluating Network.....
Test set: Epoch: 50, Average loss: 0.1050, Top1Accuracy: 0.1716, Top3Accuracy: 0.3452, Top5Accuracy: 0.4489, Time consumed:2.59s

Training Epoch: 51 [32/50000]	Loss: 2.9263	LR: 0.052488
Training Epoch: 51 [32/50000]	Loss: 3.2816	LR: 0.052488
Training Epoch: 51 [32/50000]	Loss: 3.1657	LR: 0.052488
Training Epoch: 51 [32/50000]	Loss: 3.0704	LR: 0.052488
Training Epoch: 51 [32/50000]	Loss: 2.8720	LR: 0.052488
Training Epoch: 51 [32/50000]	Loss: 3.1241	LR: 0.052488
Training Epoch: 51 [32/50000]	Loss: 3.5405	LR: 0.052488
Training Epoch: 51 [32/50000]	Loss: 3.0695	LR: 0.052488
Training Epoch: 51 [32/50000]	Loss: 3.3645	LR: 0.052488
Training Epoch: 51 [32/50000]	Loss: 2.8330	LR: 0.052488
Evaluating Network.....
Test set: Epoch: 51, Average loss: 0.1069, Top1Accuracy: 0.1620, Top3Accuracy: 0.3285, Top5Accuracy: 0.4326, Time consumed:2.67s

Training Epoch: 52 [32/50000]	Loss: 3.4251	LR: 0.051102
Training Epoch: 52 [32/50000]	Loss: 3.0131	LR: 0.051102
Training Epoch: 52 [32/50000]	Loss: 3.5954	LR: 0.051102
Training Epoch: 52 [32/50000]	Loss: 3.2698	LR: 0.051102
Training Epoch: 52 [32/50000]	Loss: 3.6854	LR: 0.051102
Training Epoch: 52 [32/50000]	Loss: 3.0243	LR: 0.051102
Training Epoch: 52 [32/50000]	Loss: 3.0128	LR: 0.051102
Training Epoch: 52 [32/50000]	Loss: 3.3027	LR: 0.051102
Training Epoch: 52 [32/50000]	Loss: 3.5788	LR: 0.051102
Training Epoch: 52 [32/50000]	Loss: 3.0722	LR: 0.051102
Evaluating Network.....
Test set: Epoch: 52, Average loss: 0.1060, Top1Accuracy: 0.1665, Top3Accuracy: 0.3325, Top5Accuracy: 0.4345, Time consumed:2.60s

Training Epoch: 53 [32/50000]	Loss: 3.1513	LR: 0.049753
Training Epoch: 53 [32/50000]	Loss: 3.1960	LR: 0.049753
Training Epoch: 53 [32/50000]	Loss: 2.9978	LR: 0.049753
Training Epoch: 53 [32/50000]	Loss: 3.6741	LR: 0.049753
Training Epoch: 53 [32/50000]	Loss: 3.2879	LR: 0.049753
Training Epoch: 53 [32/50000]	Loss: 3.2286	LR: 0.049753
Training Epoch: 53 [32/50000]	Loss: 3.6608	LR: 0.049753
Training Epoch: 53 [32/50000]	Loss: 3.4205	LR: 0.049753
Training Epoch: 53 [32/50000]	Loss: 3.1692	LR: 0.049753
Training Epoch: 53 [32/50000]	Loss: 2.9897	LR: 0.049753
Evaluating Network.....
Test set: Epoch: 53, Average loss: 0.1046, Top1Accuracy: 0.1789, Top3Accuracy: 0.3509, Top5Accuracy: 0.4552, Time consumed:2.74s

Training Epoch: 54 [32/50000]	Loss: 3.3742	LR: 0.048440
Training Epoch: 54 [32/50000]	Loss: 3.0778	LR: 0.048440
Training Epoch: 54 [32/50000]	Loss: 3.1727	LR: 0.048440
Training Epoch: 54 [32/50000]	Loss: 3.4432	LR: 0.048440
Training Epoch: 54 [32/50000]	Loss: 3.3994	LR: 0.048440
Training Epoch: 54 [32/50000]	Loss: 3.4908	LR: 0.048440
Training Epoch: 54 [32/50000]	Loss: 3.0911	LR: 0.048440
Training Epoch: 54 [32/50000]	Loss: 2.9901	LR: 0.048440
Training Epoch: 54 [32/50000]	Loss: 3.6414	LR: 0.048440
Training Epoch: 54 [32/50000]	Loss: 3.1406	LR: 0.048440
Evaluating Network.....
Test set: Epoch: 54, Average loss: 0.1019, Top1Accuracy: 0.1917, Top3Accuracy: 0.3716, Top5Accuracy: 0.4782, Time consumed:2.62s

Training Epoch: 55 [32/50000]	Loss: 3.1662	LR: 0.047161
Training Epoch: 55 [32/50000]	Loss: 3.3422	LR: 0.047161
Training Epoch: 55 [32/50000]	Loss: 2.9735	LR: 0.047161
Training Epoch: 55 [32/50000]	Loss: 3.0972	LR: 0.047161
Training Epoch: 55 [32/50000]	Loss: 2.9504	LR: 0.047161
Training Epoch: 55 [32/50000]	Loss: 3.1057	LR: 0.047161
Training Epoch: 55 [32/50000]	Loss: 3.1755	LR: 0.047161
Training Epoch: 55 [32/50000]	Loss: 2.9278	LR: 0.047161
Training Epoch: 55 [32/50000]	Loss: 3.4790	LR: 0.047161
Training Epoch: 55 [32/50000]	Loss: 3.0348	LR: 0.047161
Evaluating Network.....
Test set: Epoch: 55, Average loss: 0.1027, Top1Accuracy: 0.1891, Top3Accuracy: 0.3667, Top5Accuracy: 0.4699, Time consumed:2.62s

Training Epoch: 56 [32/50000]	Loss: 3.4195	LR: 0.045916
Training Epoch: 56 [32/50000]	Loss: 3.1000	LR: 0.045916
Training Epoch: 56 [32/50000]	Loss: 3.7270	LR: 0.045916
Training Epoch: 56 [32/50000]	Loss: 3.2176	LR: 0.045916
Training Epoch: 56 [32/50000]	Loss: 2.7416	LR: 0.045916
Training Epoch: 56 [32/50000]	Loss: 2.9822	LR: 0.045916
Training Epoch: 56 [32/50000]	Loss: 2.9489	LR: 0.045916
Training Epoch: 56 [32/50000]	Loss: 3.3055	LR: 0.045916
Training Epoch: 56 [32/50000]	Loss: 2.8810	LR: 0.045916
Training Epoch: 56 [32/50000]	Loss: 3.8385	LR: 0.045916
Evaluating Network.....
Test set: Epoch: 56, Average loss: 0.1011, Top1Accuracy: 0.1976, Top3Accuracy: 0.3793, Top5Accuracy: 0.4867, Time consumed:2.72s

Training Epoch: 57 [32/50000]	Loss: 3.1500	LR: 0.044704
Training Epoch: 57 [32/50000]	Loss: 2.7506	LR: 0.044704
Training Epoch: 57 [32/50000]	Loss: 3.6510	LR: 0.044704
Training Epoch: 57 [32/50000]	Loss: 3.4068	LR: 0.044704
Training Epoch: 57 [32/50000]	Loss: 2.5729	LR: 0.044704
Training Epoch: 57 [32/50000]	Loss: 2.6163	LR: 0.044704
Training Epoch: 57 [32/50000]	Loss: 3.2251	LR: 0.044704
Training Epoch: 57 [32/50000]	Loss: 2.9249	LR: 0.044704
Training Epoch: 57 [32/50000]	Loss: 3.1395	LR: 0.044704
Training Epoch: 57 [32/50000]	Loss: 3.2789	LR: 0.044704
Evaluating Network.....
Test set: Epoch: 57, Average loss: 0.1000, Top1Accuracy: 0.2021, Top3Accuracy: 0.3873, Top5Accuracy: 0.4947, Time consumed:2.68s

Training Epoch: 58 [32/50000]	Loss: 3.0380	LR: 0.043523
Training Epoch: 58 [32/50000]	Loss: 2.9523	LR: 0.043523
Training Epoch: 58 [32/50000]	Loss: 3.2059	LR: 0.043523
Training Epoch: 58 [32/50000]	Loss: 2.8919	LR: 0.043523
Training Epoch: 58 [32/50000]	Loss: 2.8744	LR: 0.043523
Training Epoch: 58 [32/50000]	Loss: 2.9134	LR: 0.043523
Training Epoch: 58 [32/50000]	Loss: 2.8097	LR: 0.043523
Training Epoch: 58 [32/50000]	Loss: 3.3902	LR: 0.043523
Training Epoch: 58 [32/50000]	Loss: 3.2965	LR: 0.043523
Training Epoch: 58 [32/50000]	Loss: 3.2670	LR: 0.043523
Evaluating Network.....
Test set: Epoch: 58, Average loss: 0.0993, Top1Accuracy: 0.2054, Top3Accuracy: 0.3934, Top5Accuracy: 0.5034, Time consumed:2.78s

Training Epoch: 59 [32/50000]	Loss: 3.2972	LR: 0.042374
Training Epoch: 59 [32/50000]	Loss: 3.0331	LR: 0.042374
Training Epoch: 59 [32/50000]	Loss: 3.1181	LR: 0.042374
Training Epoch: 59 [32/50000]	Loss: 2.8154	LR: 0.042374
Training Epoch: 59 [32/50000]	Loss: 3.1547	LR: 0.042374
Training Epoch: 59 [32/50000]	Loss: 3.1998	LR: 0.042374
Training Epoch: 59 [32/50000]	Loss: 3.6926	LR: 0.042374
Training Epoch: 59 [32/50000]	Loss: 3.0707	LR: 0.042374
Training Epoch: 59 [32/50000]	Loss: 2.8806	LR: 0.042374
Training Epoch: 59 [32/50000]	Loss: 3.1374	LR: 0.042374
Evaluating Network.....
Test set: Epoch: 59, Average loss: 0.0987, Top1Accuracy: 0.2095, Top3Accuracy: 0.3979, Top5Accuracy: 0.5099, Time consumed:2.73s

Training Epoch: 60 [32/50000]	Loss: 2.8023	LR: 0.041256
Training Epoch: 60 [32/50000]	Loss: 2.8512	LR: 0.041256
Training Epoch: 60 [32/50000]	Loss: 2.9526	LR: 0.041256
Training Epoch: 60 [32/50000]	Loss: 3.0688	LR: 0.041256
Training Epoch: 60 [32/50000]	Loss: 2.7688	LR: 0.041256
Training Epoch: 60 [32/50000]	Loss: 3.0959	LR: 0.041256
Training Epoch: 60 [32/50000]	Loss: 2.9777	LR: 0.041256
Training Epoch: 60 [32/50000]	Loss: 3.0675	LR: 0.041256
Training Epoch: 60 [32/50000]	Loss: 2.7347	LR: 0.041256
Training Epoch: 60 [32/50000]	Loss: 3.4632	LR: 0.041256
Evaluating Network.....
Test set: Epoch: 60, Average loss: 0.0975, Top1Accuracy: 0.2145, Top3Accuracy: 0.4121, Top5Accuracy: 0.5181, Time consumed:2.66s

Training Epoch: 61 [32/50000]	Loss: 3.5382	LR: 0.040166
Training Epoch: 61 [32/50000]	Loss: 2.9617	LR: 0.040166
Training Epoch: 61 [32/50000]	Loss: 3.4040	LR: 0.040166
Training Epoch: 61 [32/50000]	Loss: 3.1925	LR: 0.040166
Training Epoch: 61 [32/50000]	Loss: 3.4080	LR: 0.040166
Training Epoch: 61 [32/50000]	Loss: 3.0824	LR: 0.040166
Training Epoch: 61 [32/50000]	Loss: 3.4146	LR: 0.040166
Training Epoch: 61 [32/50000]	Loss: 3.3577	LR: 0.040166
Training Epoch: 61 [32/50000]	Loss: 3.0774	LR: 0.040166
Training Epoch: 61 [32/50000]	Loss: 3.1766	LR: 0.040166
Evaluating Network.....
Test set: Epoch: 61, Average loss: 0.0973, Top1Accuracy: 0.2196, Top3Accuracy: 0.4109, Top5Accuracy: 0.5186, Time consumed:2.67s

Training Epoch: 62 [32/50000]	Loss: 2.6959	LR: 0.039106
Training Epoch: 62 [32/50000]	Loss: 2.9996	LR: 0.039106
Training Epoch: 62 [32/50000]	Loss: 2.8679	LR: 0.039106
Training Epoch: 62 [32/50000]	Loss: 2.9970	LR: 0.039106
Training Epoch: 62 [32/50000]	Loss: 3.0059	LR: 0.039106
Training Epoch: 62 [32/50000]	Loss: 2.5996	LR: 0.039106
Training Epoch: 62 [32/50000]	Loss: 3.3662	LR: 0.039106
Training Epoch: 62 [32/50000]	Loss: 3.1970	LR: 0.039106
Training Epoch: 62 [32/50000]	Loss: 2.9541	LR: 0.039106
Training Epoch: 62 [32/50000]	Loss: 2.7958	LR: 0.039106
Evaluating Network.....
Test set: Epoch: 62, Average loss: 0.0972, Top1Accuracy: 0.2282, Top3Accuracy: 0.4212, Top5Accuracy: 0.5230, Time consumed:2.69s

Training Epoch: 63 [32/50000]	Loss: 3.2499	LR: 0.038074
Training Epoch: 63 [32/50000]	Loss: 3.1206	LR: 0.038074
Training Epoch: 63 [32/50000]	Loss: 2.7910	LR: 0.038074
Training Epoch: 63 [32/50000]	Loss: 3.2605	LR: 0.038074
Training Epoch: 63 [32/50000]	Loss: 3.3244	LR: 0.038074
Training Epoch: 63 [32/50000]	Loss: 3.2255	LR: 0.038074
Training Epoch: 63 [32/50000]	Loss: 3.2521	LR: 0.038074
Training Epoch: 63 [32/50000]	Loss: 3.6884	LR: 0.038074
Training Epoch: 63 [32/50000]	Loss: 3.1218	LR: 0.038074
Training Epoch: 63 [32/50000]	Loss: 2.9500	LR: 0.038074
Evaluating Network.....
Test set: Epoch: 63, Average loss: 0.0973, Top1Accuracy: 0.2228, Top3Accuracy: 0.4140, Top5Accuracy: 0.5200, Time consumed:2.80s

Training Epoch: 64 [32/50000]	Loss: 3.0540	LR: 0.037069
Training Epoch: 64 [32/50000]	Loss: 2.9252	LR: 0.037069
Training Epoch: 64 [32/50000]	Loss: 3.1333	LR: 0.037069
Training Epoch: 64 [32/50000]	Loss: 2.6774	LR: 0.037069
Training Epoch: 64 [32/50000]	Loss: 2.9643	LR: 0.037069
Training Epoch: 64 [32/50000]	Loss: 2.9316	LR: 0.037069
Training Epoch: 64 [32/50000]	Loss: 2.6750	LR: 0.037069
Training Epoch: 64 [32/50000]	Loss: 3.1552	LR: 0.037069
Training Epoch: 64 [32/50000]	Loss: 3.1859	LR: 0.037069
Training Epoch: 64 [32/50000]	Loss: 3.4569	LR: 0.037069
Evaluating Network.....
Test set: Epoch: 64, Average loss: 0.0956, Top1Accuracy: 0.2311, Top3Accuracy: 0.4302, Top5Accuracy: 0.5320, Time consumed:2.69s

Training Epoch: 65 [32/50000]	Loss: 2.8923	LR: 0.036090
Training Epoch: 65 [32/50000]	Loss: 3.0780	LR: 0.036090
Training Epoch: 65 [32/50000]	Loss: 3.4452	LR: 0.036090
Training Epoch: 65 [32/50000]	Loss: 3.0370	LR: 0.036090
Training Epoch: 65 [32/50000]	Loss: 2.8714	LR: 0.036090
Training Epoch: 65 [32/50000]	Loss: 3.0399	LR: 0.036090
Training Epoch: 65 [32/50000]	Loss: 2.7796	LR: 0.036090
Training Epoch: 65 [32/50000]	Loss: 3.2468	LR: 0.036090
Training Epoch: 65 [32/50000]	Loss: 3.3234	LR: 0.036090
Training Epoch: 65 [32/50000]	Loss: 3.0566	LR: 0.036090
Evaluating Network.....
Test set: Epoch: 65, Average loss: 0.0953, Top1Accuracy: 0.2360, Top3Accuracy: 0.4315, Top5Accuracy: 0.5341, Time consumed:2.69s

Training Epoch: 66 [32/50000]	Loss: 3.4131	LR: 0.035137
Training Epoch: 66 [32/50000]	Loss: 3.1913	LR: 0.035137
Training Epoch: 66 [32/50000]	Loss: 2.9503	LR: 0.035137
Training Epoch: 66 [32/50000]	Loss: 3.3414	LR: 0.035137
Training Epoch: 66 [32/50000]	Loss: 3.2368	LR: 0.035137
Training Epoch: 66 [32/50000]	Loss: 3.0874	LR: 0.035137
Training Epoch: 66 [32/50000]	Loss: 3.0831	LR: 0.035137
Training Epoch: 66 [32/50000]	Loss: 3.2518	LR: 0.035137
Training Epoch: 66 [32/50000]	Loss: 2.8371	LR: 0.035137
Training Epoch: 66 [32/50000]	Loss: 3.1642	LR: 0.035137
Evaluating Network.....
Test set: Epoch: 66, Average loss: 0.0947, Top1Accuracy: 0.2330, Top3Accuracy: 0.4299, Top5Accuracy: 0.5385, Time consumed:3.21s

Training Epoch: 67 [32/50000]	Loss: 3.2154	LR: 0.034210
Training Epoch: 67 [32/50000]	Loss: 2.9245	LR: 0.034210
Training Epoch: 67 [32/50000]	Loss: 3.1700	LR: 0.034210
Training Epoch: 67 [32/50000]	Loss: 2.7563	LR: 0.034210
Training Epoch: 67 [32/50000]	Loss: 3.1052	LR: 0.034210
Training Epoch: 67 [32/50000]	Loss: 2.9261	LR: 0.034210
Training Epoch: 67 [32/50000]	Loss: 2.8200	LR: 0.034210
Training Epoch: 67 [32/50000]	Loss: 3.0919	LR: 0.034210
Training Epoch: 67 [32/50000]	Loss: 3.1479	LR: 0.034210
Training Epoch: 67 [32/50000]	Loss: 3.3073	LR: 0.034210
Evaluating Network.....
Test set: Epoch: 67, Average loss: 0.0942, Top1Accuracy: 0.2399, Top3Accuracy: 0.4346, Top5Accuracy: 0.5450, Time consumed:2.70s

Training Epoch: 68 [32/50000]	Loss: 3.1203	LR: 0.033306
Training Epoch: 68 [32/50000]	Loss: 3.4357	LR: 0.033306
Training Epoch: 68 [32/50000]	Loss: 2.9050	LR: 0.033306
Training Epoch: 68 [32/50000]	Loss: 2.5371	LR: 0.033306
Training Epoch: 68 [32/50000]	Loss: 3.1216	LR: 0.033306
Training Epoch: 68 [32/50000]	Loss: 2.9288	LR: 0.033306
Training Epoch: 68 [32/50000]	Loss: 3.2427	LR: 0.033306
Training Epoch: 68 [32/50000]	Loss: 3.1436	LR: 0.033306
Training Epoch: 68 [32/50000]	Loss: 2.8678	LR: 0.033306
Training Epoch: 68 [32/50000]	Loss: 3.3360	LR: 0.033306
Evaluating Network.....
Test set: Epoch: 68, Average loss: 0.0925, Top1Accuracy: 0.2470, Top3Accuracy: 0.4518, Top5Accuracy: 0.5576, Time consumed:2.73s

Training Epoch: 69 [32/50000]	Loss: 2.7292	LR: 0.032427
Training Epoch: 69 [32/50000]	Loss: 3.3143	LR: 0.032427
Training Epoch: 69 [32/50000]	Loss: 3.1821	LR: 0.032427
Training Epoch: 69 [32/50000]	Loss: 3.6743	LR: 0.032427
Training Epoch: 69 [32/50000]	Loss: 3.1875	LR: 0.032427
Training Epoch: 69 [32/50000]	Loss: 3.0916	LR: 0.032427
Training Epoch: 69 [32/50000]	Loss: 2.6968	LR: 0.032427
Training Epoch: 69 [32/50000]	Loss: 2.7393	LR: 0.032427
Training Epoch: 69 [32/50000]	Loss: 3.2256	LR: 0.032427
Training Epoch: 69 [32/50000]	Loss: 3.0593	LR: 0.032427
Evaluating Network.....
Test set: Epoch: 69, Average loss: 0.0921, Top1Accuracy: 0.2480, Top3Accuracy: 0.4549, Top5Accuracy: 0.5643, Time consumed:2.68s

Training Epoch: 70 [32/50000]	Loss: 2.8043	LR: 0.031571
Training Epoch: 70 [32/50000]	Loss: 2.6656	LR: 0.031571
Training Epoch: 70 [32/50000]	Loss: 2.6101	LR: 0.031571
Training Epoch: 70 [32/50000]	Loss: 3.4032	LR: 0.031571
Training Epoch: 70 [32/50000]	Loss: 3.0586	LR: 0.031571
Training Epoch: 70 [32/50000]	Loss: 2.9818	LR: 0.031571
Training Epoch: 70 [32/50000]	Loss: 2.8146	LR: 0.031571
Training Epoch: 70 [32/50000]	Loss: 2.7862	LR: 0.031571
Training Epoch: 70 [32/50000]	Loss: 3.1226	LR: 0.031571
Training Epoch: 70 [32/50000]	Loss: 2.9749	LR: 0.031571
Evaluating Network.....
Test set: Epoch: 70, Average loss: 0.0922, Top1Accuracy: 0.2477, Top3Accuracy: 0.4514, Top5Accuracy: 0.5615, Time consumed:2.66s

Training Epoch: 71 [32/50000]	Loss: 3.0153	LR: 0.030738
Training Epoch: 71 [32/50000]	Loss: 2.5240	LR: 0.030738
Training Epoch: 71 [32/50000]	Loss: 3.0291	LR: 0.030738
Training Epoch: 71 [32/50000]	Loss: 2.7912	LR: 0.030738
Training Epoch: 71 [32/50000]	Loss: 2.7536	LR: 0.030738
Training Epoch: 71 [32/50000]	Loss: 2.8667	LR: 0.030738
Training Epoch: 71 [32/50000]	Loss: 2.9841	LR: 0.030738
Training Epoch: 71 [32/50000]	Loss: 2.6290	LR: 0.030738
Training Epoch: 71 [32/50000]	Loss: 3.0439	LR: 0.030738
Training Epoch: 71 [32/50000]	Loss: 3.3995	LR: 0.030738
Evaluating Network.....
Test set: Epoch: 71, Average loss: 0.0902, Top1Accuracy: 0.2594, Top3Accuracy: 0.4705, Top5Accuracy: 0.5781, Time consumed:2.71s

Training Epoch: 72 [32/50000]	Loss: 2.7782	LR: 0.029926
Training Epoch: 72 [32/50000]	Loss: 3.0644	LR: 0.029926
Training Epoch: 72 [32/50000]	Loss: 2.8284	LR: 0.029926
Training Epoch: 72 [32/50000]	Loss: 2.8838	LR: 0.029926
Training Epoch: 72 [32/50000]	Loss: 3.1140	LR: 0.029926
Training Epoch: 72 [32/50000]	Loss: 2.9600	LR: 0.029926
Training Epoch: 72 [32/50000]	Loss: 2.5553	LR: 0.029926
Training Epoch: 72 [32/50000]	Loss: 2.9491	LR: 0.029926
Training Epoch: 72 [32/50000]	Loss: 3.0145	LR: 0.029926
Training Epoch: 72 [32/50000]	Loss: 3.1741	LR: 0.029926
Evaluating Network.....
Test set: Epoch: 72, Average loss: 0.0908, Top1Accuracy: 0.2555, Top3Accuracy: 0.4639, Top5Accuracy: 0.5705, Time consumed:2.77s

Training Epoch: 73 [32/50000]	Loss: 3.3713	LR: 0.029136
Training Epoch: 73 [32/50000]	Loss: 2.6509	LR: 0.029136
Training Epoch: 73 [32/50000]	Loss: 3.2410	LR: 0.029136
Training Epoch: 73 [32/50000]	Loss: 2.2681	LR: 0.029136
Training Epoch: 73 [32/50000]	Loss: 3.1311	LR: 0.029136
Training Epoch: 73 [32/50000]	Loss: 2.7955	LR: 0.029136
Training Epoch: 73 [32/50000]	Loss: 2.8621	LR: 0.029136
Training Epoch: 73 [32/50000]	Loss: 2.6053	LR: 0.029136
Training Epoch: 73 [32/50000]	Loss: 2.5953	LR: 0.029136
Training Epoch: 73 [32/50000]	Loss: 3.2796	LR: 0.029136
Evaluating Network.....
Test set: Epoch: 73, Average loss: 0.0903, Top1Accuracy: 0.2560, Top3Accuracy: 0.4705, Top5Accuracy: 0.5766, Time consumed:2.78s

Training Epoch: 74 [32/50000]	Loss: 3.0687	LR: 0.028367
Training Epoch: 74 [32/50000]	Loss: 3.1819	LR: 0.028367
Training Epoch: 74 [32/50000]	Loss: 2.7517	LR: 0.028367
Training Epoch: 74 [32/50000]	Loss: 2.7302	LR: 0.028367
Training Epoch: 74 [32/50000]	Loss: 2.9613	LR: 0.028367
Training Epoch: 74 [32/50000]	Loss: 3.6276	LR: 0.028367
Training Epoch: 74 [32/50000]	Loss: 2.7730	LR: 0.028367
Training Epoch: 74 [32/50000]	Loss: 3.0502	LR: 0.028367
Training Epoch: 74 [32/50000]	Loss: 2.9340	LR: 0.028367
Training Epoch: 74 [32/50000]	Loss: 2.7622	LR: 0.028367
Evaluating Network.....
Test set: Epoch: 74, Average loss: 0.0877, Top1Accuracy: 0.2742, Top3Accuracy: 0.4880, Top5Accuracy: 0.5961, Time consumed:2.68s

Training Epoch: 75 [32/50000]	Loss: 2.4649	LR: 0.027618
Training Epoch: 75 [32/50000]	Loss: 2.8597	LR: 0.027618
Training Epoch: 75 [32/50000]	Loss: 2.6047	LR: 0.027618
Training Epoch: 75 [32/50000]	Loss: 3.1486	LR: 0.027618
Training Epoch: 75 [32/50000]	Loss: 3.3712	LR: 0.027618
Training Epoch: 75 [32/50000]	Loss: 2.9066	LR: 0.027618
Training Epoch: 75 [32/50000]	Loss: 2.5575	LR: 0.027618
Training Epoch: 75 [32/50000]	Loss: 2.3668	LR: 0.027618
Training Epoch: 75 [32/50000]	Loss: 3.1946	LR: 0.027618
Training Epoch: 75 [32/50000]	Loss: 2.9590	LR: 0.027618
Evaluating Network.....
Test set: Epoch: 75, Average loss: 0.0870, Top1Accuracy: 0.2792, Top3Accuracy: 0.4949, Top5Accuracy: 0.5999, Time consumed:2.72s

Training Epoch: 76 [32/50000]	Loss: 3.4517	LR: 0.026889
Training Epoch: 76 [32/50000]	Loss: 2.6280	LR: 0.026889
Training Epoch: 76 [32/50000]	Loss: 2.9971	LR: 0.026889
Training Epoch: 76 [32/50000]	Loss: 2.6518	LR: 0.026889
Training Epoch: 76 [32/50000]	Loss: 2.7469	LR: 0.026889
Training Epoch: 76 [32/50000]	Loss: 2.3125	LR: 0.026889
Training Epoch: 76 [32/50000]	Loss: 3.0360	LR: 0.026889
Training Epoch: 76 [32/50000]	Loss: 2.5701	LR: 0.026889
Training Epoch: 76 [32/50000]	Loss: 2.6735	LR: 0.026889
Training Epoch: 76 [32/50000]	Loss: 2.7079	LR: 0.026889
Evaluating Network.....
Test set: Epoch: 76, Average loss: 0.0880, Top1Accuracy: 0.2735, Top3Accuracy: 0.4870, Top5Accuracy: 0.5983, Time consumed:2.70s

Training Epoch: 77 [32/50000]	Loss: 2.3271	LR: 0.026179
Training Epoch: 77 [32/50000]	Loss: 3.1041	LR: 0.026179
Training Epoch: 77 [32/50000]	Loss: 2.7550	LR: 0.026179
Training Epoch: 77 [32/50000]	Loss: 2.9346	LR: 0.026179
Training Epoch: 77 [32/50000]	Loss: 2.6980	LR: 0.026179
Training Epoch: 77 [32/50000]	Loss: 2.7586	LR: 0.026179
Training Epoch: 77 [32/50000]	Loss: 2.7554	LR: 0.026179
Training Epoch: 77 [32/50000]	Loss: 2.7499	LR: 0.026179
Training Epoch: 77 [32/50000]	Loss: 2.5170	LR: 0.026179
Training Epoch: 77 [32/50000]	Loss: 3.0187	LR: 0.026179
Evaluating Network.....
Test set: Epoch: 77, Average loss: 0.0855, Top1Accuracy: 0.2834, Top3Accuracy: 0.5074, Top5Accuracy: 0.6147, Time consumed:2.70s

Training Epoch: 78 [32/50000]	Loss: 2.2198	LR: 0.025488
Training Epoch: 78 [32/50000]	Loss: 2.4895	LR: 0.025488
Training Epoch: 78 [32/50000]	Loss: 2.9435	LR: 0.025488
Training Epoch: 78 [32/50000]	Loss: 2.6708	LR: 0.025488
Training Epoch: 78 [32/50000]	Loss: 2.8358	LR: 0.025488
Training Epoch: 78 [32/50000]	Loss: 3.0564	LR: 0.025488
Training Epoch: 78 [32/50000]	Loss: 3.1134	LR: 0.025488
Training Epoch: 78 [32/50000]	Loss: 2.4672	LR: 0.025488
Training Epoch: 78 [32/50000]	Loss: 2.7055	LR: 0.025488
Training Epoch: 78 [32/50000]	Loss: 2.7850	LR: 0.025488
Evaluating Network.....
Test set: Epoch: 78, Average loss: 0.0848, Top1Accuracy: 0.2902, Top3Accuracy: 0.5121, Top5Accuracy: 0.6220, Time consumed:2.65s

Training Epoch: 79 [32/50000]	Loss: 2.7558	LR: 0.024815
Training Epoch: 79 [32/50000]	Loss: 2.7758	LR: 0.024815
Training Epoch: 79 [32/50000]	Loss: 2.8567	LR: 0.024815
Training Epoch: 79 [32/50000]	Loss: 2.2867	LR: 0.024815
Training Epoch: 79 [32/50000]	Loss: 3.2554	LR: 0.024815
Training Epoch: 79 [32/50000]	Loss: 3.1939	LR: 0.024815
Training Epoch: 79 [32/50000]	Loss: 2.9195	LR: 0.024815
Training Epoch: 79 [32/50000]	Loss: 2.7001	LR: 0.024815
Training Epoch: 79 [32/50000]	Loss: 2.6851	LR: 0.024815
Training Epoch: 79 [32/50000]	Loss: 2.8137	LR: 0.024815
Evaluating Network.....
Test set: Epoch: 79, Average loss: 0.0848, Top1Accuracy: 0.2891, Top3Accuracy: 0.5075, Top5Accuracy: 0.6131, Time consumed:2.68s

Training Epoch: 80 [32/50000]	Loss: 2.5924	LR: 0.024160
Training Epoch: 80 [32/50000]	Loss: 2.5878	LR: 0.024160
Training Epoch: 80 [32/50000]	Loss: 2.2830	LR: 0.024160
Training Epoch: 80 [32/50000]	Loss: 2.7146	LR: 0.024160
Training Epoch: 80 [32/50000]	Loss: 2.6923	LR: 0.024160
Training Epoch: 80 [32/50000]	Loss: 2.7102	LR: 0.024160
Training Epoch: 80 [32/50000]	Loss: 2.6326	LR: 0.024160
Training Epoch: 80 [32/50000]	Loss: 2.9337	LR: 0.024160
Training Epoch: 80 [32/50000]	Loss: 2.4058	LR: 0.024160
Training Epoch: 80 [32/50000]	Loss: 2.7331	LR: 0.024160
Evaluating Network.....
Test set: Epoch: 80, Average loss: 0.0838, Top1Accuracy: 0.2975, Top3Accuracy: 0.5209, Top5Accuracy: 0.6276, Time consumed:2.64s

Training Epoch: 81 [32/50000]	Loss: 2.7333	LR: 0.023522
Training Epoch: 81 [32/50000]	Loss: 2.2975	LR: 0.023522
Training Epoch: 81 [32/50000]	Loss: 2.6348	LR: 0.023522
Training Epoch: 81 [32/50000]	Loss: 2.9562	LR: 0.023522
Training Epoch: 81 [32/50000]	Loss: 2.9121	LR: 0.023522
Training Epoch: 81 [32/50000]	Loss: 2.7774	LR: 0.023522
Training Epoch: 81 [32/50000]	Loss: 2.7014	LR: 0.023522
Training Epoch: 81 [32/50000]	Loss: 3.0219	LR: 0.023522
Training Epoch: 81 [32/50000]	Loss: 2.6510	LR: 0.023522
Training Epoch: 81 [32/50000]	Loss: 2.6748	LR: 0.023522
Evaluating Network.....
Test set: Epoch: 81, Average loss: 0.0836, Top1Accuracy: 0.2981, Top3Accuracy: 0.5178, Top5Accuracy: 0.6226, Time consumed:2.70s

Training Epoch: 82 [32/50000]	Loss: 2.4482	LR: 0.022901
Training Epoch: 82 [32/50000]	Loss: 2.7951	LR: 0.022901
Training Epoch: 82 [32/50000]	Loss: 2.9972	LR: 0.022901
Training Epoch: 82 [32/50000]	Loss: 2.6177	LR: 0.022901
Training Epoch: 82 [32/50000]	Loss: 2.9964	LR: 0.022901
Training Epoch: 82 [32/50000]	Loss: 2.8530	LR: 0.022901
Training Epoch: 82 [32/50000]	Loss: 2.9459	LR: 0.022901
Training Epoch: 82 [32/50000]	Loss: 2.9827	LR: 0.022901
Training Epoch: 82 [32/50000]	Loss: 2.9881	LR: 0.022901
Training Epoch: 82 [32/50000]	Loss: 2.7431	LR: 0.022901
Evaluating Network.....
Test set: Epoch: 82, Average loss: 0.0829, Top1Accuracy: 0.3014, Top3Accuracy: 0.5249, Top5Accuracy: 0.6357, Time consumed:2.70s

Training Epoch: 83 [32/50000]	Loss: 2.4855	LR: 0.022296
Training Epoch: 83 [32/50000]	Loss: 2.6940	LR: 0.022296
Training Epoch: 83 [32/50000]	Loss: 2.8741	LR: 0.022296
Training Epoch: 83 [32/50000]	Loss: 2.7074	LR: 0.022296
Training Epoch: 83 [32/50000]	Loss: 2.6251	LR: 0.022296
Training Epoch: 83 [32/50000]	Loss: 2.6072	LR: 0.022296
Training Epoch: 83 [32/50000]	Loss: 2.4961	LR: 0.022296
Training Epoch: 83 [32/50000]	Loss: 2.0073	LR: 0.022296
Training Epoch: 83 [32/50000]	Loss: 2.9112	LR: 0.022296
Training Epoch: 83 [32/50000]	Loss: 3.1081	LR: 0.022296
Evaluating Network.....
Test set: Epoch: 83, Average loss: 0.0821, Top1Accuracy: 0.3063, Top3Accuracy: 0.5339, Top5Accuracy: 0.6407, Time consumed:2.88s

Training Epoch: 84 [32/50000]	Loss: 2.9843	LR: 0.021708
Training Epoch: 84 [32/50000]	Loss: 2.4867	LR: 0.021708
Training Epoch: 84 [32/50000]	Loss: 2.3619	LR: 0.021708
Training Epoch: 84 [32/50000]	Loss: 2.5145	LR: 0.021708
Training Epoch: 84 [32/50000]	Loss: 3.0660	LR: 0.021708
Training Epoch: 84 [32/50000]	Loss: 2.7332	LR: 0.021708
Training Epoch: 84 [32/50000]	Loss: 2.4576	LR: 0.021708
Training Epoch: 84 [32/50000]	Loss: 3.0835	LR: 0.021708
Training Epoch: 84 [32/50000]	Loss: 2.2439	LR: 0.021708
Training Epoch: 84 [32/50000]	Loss: 2.2004	LR: 0.021708
Evaluating Network.....
Test set: Epoch: 84, Average loss: 0.0806, Top1Accuracy: 0.3188, Top3Accuracy: 0.5458, Top5Accuracy: 0.6518, Time consumed:2.70s

Training Epoch: 85 [32/50000]	Loss: 2.4252	LR: 0.021135
Training Epoch: 85 [32/50000]	Loss: 2.1681	LR: 0.021135
Training Epoch: 85 [32/50000]	Loss: 2.2976	LR: 0.021135
Training Epoch: 85 [32/50000]	Loss: 2.0529	LR: 0.021135
Training Epoch: 85 [32/50000]	Loss: 2.9480	LR: 0.021135
Training Epoch: 85 [32/50000]	Loss: 2.4158	LR: 0.021135
Training Epoch: 85 [32/50000]	Loss: 2.2881	LR: 0.021135
Training Epoch: 85 [32/50000]	Loss: 2.5685	LR: 0.021135
Training Epoch: 85 [32/50000]	Loss: 2.2927	LR: 0.021135
Training Epoch: 85 [32/50000]	Loss: 2.5294	LR: 0.021135
Evaluating Network.....
Test set: Epoch: 85, Average loss: 0.0804, Top1Accuracy: 0.3225, Top3Accuracy: 0.5471, Top5Accuracy: 0.6543, Time consumed:2.76s

Training Epoch: 86 [32/50000]	Loss: 2.5222	LR: 0.020577
Training Epoch: 86 [32/50000]	Loss: 2.8293	LR: 0.020577
Training Epoch: 86 [32/50000]	Loss: 2.5191	LR: 0.020577
Training Epoch: 86 [32/50000]	Loss: 1.8440	LR: 0.020577
Training Epoch: 86 [32/50000]	Loss: 2.3115	LR: 0.020577
Training Epoch: 86 [32/50000]	Loss: 2.4616	LR: 0.020577
Training Epoch: 86 [32/50000]	Loss: 2.6476	LR: 0.020577
Training Epoch: 86 [32/50000]	Loss: 2.3666	LR: 0.020577
Training Epoch: 86 [32/50000]	Loss: 2.0723	LR: 0.020577
Training Epoch: 86 [32/50000]	Loss: 2.4660	LR: 0.020577
Evaluating Network.....
Test set: Epoch: 86, Average loss: 0.0779, Top1Accuracy: 0.3332, Top3Accuracy: 0.5640, Top5Accuracy: 0.6736, Time consumed:2.70s

Training Epoch: 87 [32/50000]	Loss: 2.5359	LR: 0.020034
Training Epoch: 87 [32/50000]	Loss: 2.8944	LR: 0.020034
Training Epoch: 87 [32/50000]	Loss: 2.2273	LR: 0.020034
Training Epoch: 87 [32/50000]	Loss: 2.3827	LR: 0.020034
Training Epoch: 87 [32/50000]	Loss: 2.4131	LR: 0.020034
Training Epoch: 87 [32/50000]	Loss: 2.7324	LR: 0.020034
Training Epoch: 87 [32/50000]	Loss: 2.7365	LR: 0.020034
Training Epoch: 87 [32/50000]	Loss: 2.5354	LR: 0.020034
Training Epoch: 87 [32/50000]	Loss: 2.4314	LR: 0.020034
Training Epoch: 87 [32/50000]	Loss: 2.4389	LR: 0.020034
Evaluating Network.....
Test set: Epoch: 87, Average loss: 0.0776, Top1Accuracy: 0.3404, Top3Accuracy: 0.5691, Top5Accuracy: 0.6758, Time consumed:2.70s

Training Epoch: 88 [32/50000]	Loss: 2.6214	LR: 0.019505
Training Epoch: 88 [32/50000]	Loss: 2.8211	LR: 0.019505
Training Epoch: 88 [32/50000]	Loss: 2.3711	LR: 0.019505
Training Epoch: 88 [32/50000]	Loss: 2.4851	LR: 0.019505
Training Epoch: 88 [32/50000]	Loss: 2.5078	LR: 0.019505
Training Epoch: 88 [32/50000]	Loss: 2.3373	LR: 0.019505
Training Epoch: 88 [32/50000]	Loss: 2.5152	LR: 0.019505
Training Epoch: 88 [32/50000]	Loss: 2.6455	LR: 0.019505
Training Epoch: 88 [32/50000]	Loss: 3.0417	LR: 0.019505
Training Epoch: 88 [32/50000]	Loss: 2.1160	LR: 0.019505
Evaluating Network.....
Test set: Epoch: 88, Average loss: 0.0768, Top1Accuracy: 0.3442, Top3Accuracy: 0.5745, Top5Accuracy: 0.6811, Time consumed:2.74s

Training Epoch: 89 [32/50000]	Loss: 2.4494	LR: 0.018990
Training Epoch: 89 [32/50000]	Loss: 2.4434	LR: 0.018990
Training Epoch: 89 [32/50000]	Loss: 2.6613	LR: 0.018990
Training Epoch: 89 [32/50000]	Loss: 2.2589	LR: 0.018990
Training Epoch: 89 [32/50000]	Loss: 2.4768	LR: 0.018990
Training Epoch: 89 [32/50000]	Loss: 2.3073	LR: 0.018990
Training Epoch: 89 [32/50000]	Loss: 2.5458	LR: 0.018990
Training Epoch: 89 [32/50000]	Loss: 2.4046	LR: 0.018990
Training Epoch: 89 [32/50000]	Loss: 2.5775	LR: 0.018990
Training Epoch: 89 [32/50000]	Loss: 2.6102	LR: 0.018990
Evaluating Network.....
Test set: Epoch: 89, Average loss: 0.0773, Top1Accuracy: 0.3397, Top3Accuracy: 0.5675, Top5Accuracy: 0.6779, Time consumed:2.69s

Training Epoch: 90 [32/50000]	Loss: 2.3248	LR: 0.018488
Training Epoch: 90 [32/50000]	Loss: 2.6708	LR: 0.018488
Training Epoch: 90 [32/50000]	Loss: 2.6986	LR: 0.018488
Training Epoch: 90 [32/50000]	Loss: 2.5165	LR: 0.018488
Training Epoch: 90 [32/50000]	Loss: 2.2276	LR: 0.018488
Training Epoch: 90 [32/50000]	Loss: 2.5002	LR: 0.018488
Training Epoch: 90 [32/50000]	Loss: 2.5537	LR: 0.018488
Training Epoch: 90 [32/50000]	Loss: 2.1640	LR: 0.018488
Training Epoch: 90 [32/50000]	Loss: 2.3711	LR: 0.018488
Training Epoch: 90 [32/50000]	Loss: 2.5111	LR: 0.018488
Evaluating Network.....
Test set: Epoch: 90, Average loss: 0.0769, Top1Accuracy: 0.3432, Top3Accuracy: 0.5660, Top5Accuracy: 0.6794, Time consumed:2.74s

Training Epoch: 91 [32/50000]	Loss: 2.9491	LR: 0.018000
Training Epoch: 91 [32/50000]	Loss: 2.1757	LR: 0.018000
Training Epoch: 91 [32/50000]	Loss: 2.5768	LR: 0.018000
Training Epoch: 91 [32/50000]	Loss: 2.2093	LR: 0.018000
Training Epoch: 91 [32/50000]	Loss: 2.1666	LR: 0.018000
Training Epoch: 91 [32/50000]	Loss: 2.5458	LR: 0.018000
Training Epoch: 91 [32/50000]	Loss: 2.3437	LR: 0.018000
Training Epoch: 91 [32/50000]	Loss: 2.8111	LR: 0.018000
Training Epoch: 91 [32/50000]	Loss: 2.3649	LR: 0.018000
Training Epoch: 91 [32/50000]	Loss: 2.2460	LR: 0.018000
Evaluating Network.....
Test set: Epoch: 91, Average loss: 0.0761, Top1Accuracy: 0.3544, Top3Accuracy: 0.5790, Top5Accuracy: 0.6829, Time consumed:2.84s

Training Epoch: 92 [32/50000]	Loss: 2.5004	LR: 0.017525
Training Epoch: 92 [32/50000]	Loss: 2.6386	LR: 0.017525
Training Epoch: 92 [32/50000]	Loss: 2.8668	LR: 0.017525
Training Epoch: 92 [32/50000]	Loss: 2.8366	LR: 0.017525
Training Epoch: 92 [32/50000]	Loss: 2.5741	LR: 0.017525
Training Epoch: 92 [32/50000]	Loss: 2.4987	LR: 0.017525
Training Epoch: 92 [32/50000]	Loss: 2.5008	LR: 0.017525
Training Epoch: 92 [32/50000]	Loss: 2.7110	LR: 0.017525
Training Epoch: 92 [32/50000]	Loss: 2.3498	LR: 0.017525
Training Epoch: 92 [32/50000]	Loss: 2.3066	LR: 0.017525
Evaluating Network.....
Test set: Epoch: 92, Average loss: 0.0752, Top1Accuracy: 0.3522, Top3Accuracy: 0.5817, Top5Accuracy: 0.6920, Time consumed:2.72s

Training Epoch: 93 [32/50000]	Loss: 2.4469	LR: 0.017062
Training Epoch: 93 [32/50000]	Loss: 3.0662	LR: 0.017062
Training Epoch: 93 [32/50000]	Loss: 2.1094	LR: 0.017062
Training Epoch: 93 [32/50000]	Loss: 2.5619	LR: 0.017062
Training Epoch: 93 [32/50000]	Loss: 2.4782	LR: 0.017062
Training Epoch: 93 [32/50000]	Loss: 2.6547	LR: 0.017062
Training Epoch: 93 [32/50000]	Loss: 2.8314	LR: 0.017062
Training Epoch: 93 [32/50000]	Loss: 2.6371	LR: 0.017062
Training Epoch: 93 [32/50000]	Loss: 2.5123	LR: 0.017062
Training Epoch: 93 [32/50000]	Loss: 2.1620	LR: 0.017062
Evaluating Network.....
Test set: Epoch: 93, Average loss: 0.0747, Top1Accuracy: 0.3600, Top3Accuracy: 0.5869, Top5Accuracy: 0.6945, Time consumed:2.70s

Training Epoch: 94 [32/50000]	Loss: 2.5931	LR: 0.016612
Training Epoch: 94 [32/50000]	Loss: 2.4643	LR: 0.016612
Training Epoch: 94 [32/50000]	Loss: 2.5325	LR: 0.016612
Training Epoch: 94 [32/50000]	Loss: 2.3581	LR: 0.016612
Training Epoch: 94 [32/50000]	Loss: 3.1243	LR: 0.016612
Training Epoch: 94 [32/50000]	Loss: 2.1128	LR: 0.016612
Training Epoch: 94 [32/50000]	Loss: 2.1491	LR: 0.016612
Training Epoch: 94 [32/50000]	Loss: 2.3067	LR: 0.016612
Training Epoch: 94 [32/50000]	Loss: 2.4793	LR: 0.016612
Training Epoch: 94 [32/50000]	Loss: 1.9133	LR: 0.016612
Evaluating Network.....
Test set: Epoch: 94, Average loss: 0.0743, Top1Accuracy: 0.3601, Top3Accuracy: 0.5943, Top5Accuracy: 0.6973, Time consumed:2.68s

Training Epoch: 95 [32/50000]	Loss: 2.3355	LR: 0.016173
Training Epoch: 95 [32/50000]	Loss: 2.5714	LR: 0.016173
Training Epoch: 95 [32/50000]	Loss: 2.2040	LR: 0.016173
Training Epoch: 95 [32/50000]	Loss: 2.7992	LR: 0.016173
Training Epoch: 95 [32/50000]	Loss: 2.9410	LR: 0.016173
Training Epoch: 95 [32/50000]	Loss: 2.0912	LR: 0.016173
Training Epoch: 95 [32/50000]	Loss: 2.5262	LR: 0.016173
Training Epoch: 95 [32/50000]	Loss: 2.1562	LR: 0.016173
Training Epoch: 95 [32/50000]	Loss: 2.1219	LR: 0.016173
Training Epoch: 95 [32/50000]	Loss: 2.1782	LR: 0.016173
Evaluating Network.....
Test set: Epoch: 95, Average loss: 0.0727, Top1Accuracy: 0.3703, Top3Accuracy: 0.6003, Top5Accuracy: 0.7070, Time consumed:2.67s

Training Epoch: 96 [32/50000]	Loss: 2.2509	LR: 0.015746
Training Epoch: 96 [32/50000]	Loss: 1.9312	LR: 0.015746
Training Epoch: 96 [32/50000]	Loss: 2.2256	LR: 0.015746
Training Epoch: 96 [32/50000]	Loss: 2.8219	LR: 0.015746
Training Epoch: 96 [32/50000]	Loss: 3.1529	LR: 0.015746
Training Epoch: 96 [32/50000]	Loss: 2.2983	LR: 0.015746
Training Epoch: 96 [32/50000]	Loss: 3.0900	LR: 0.015746
Training Epoch: 96 [32/50000]	Loss: 2.1976	LR: 0.015746
Training Epoch: 96 [32/50000]	Loss: 2.7203	LR: 0.015746
Training Epoch: 96 [32/50000]	Loss: 2.4205	LR: 0.015746
Evaluating Network.....
Test set: Epoch: 96, Average loss: 0.0725, Top1Accuracy: 0.3717, Top3Accuracy: 0.6050, Top5Accuracy: 0.7099, Time consumed:2.71s

Training Epoch: 97 [32/50000]	Loss: 2.4473	LR: 0.015331
Training Epoch: 97 [32/50000]	Loss: 2.1582	LR: 0.015331
Training Epoch: 97 [32/50000]	Loss: 2.1796	LR: 0.015331
Training Epoch: 97 [32/50000]	Loss: 1.8441	LR: 0.015331
Training Epoch: 97 [32/50000]	Loss: 2.5458	LR: 0.015331
Training Epoch: 97 [32/50000]	Loss: 2.3199	LR: 0.015331
Training Epoch: 97 [32/50000]	Loss: 2.2283	LR: 0.015331
Training Epoch: 97 [32/50000]	Loss: 2.1431	LR: 0.015331
Training Epoch: 97 [32/50000]	Loss: 2.2826	LR: 0.015331
Training Epoch: 97 [32/50000]	Loss: 2.0068	LR: 0.015331
Evaluating Network.....
Test set: Epoch: 97, Average loss: 0.0725, Top1Accuracy: 0.3729, Top3Accuracy: 0.6059, Top5Accuracy: 0.7099, Time consumed:2.80s

Training Epoch: 98 [32/50000]	Loss: 2.2273	LR: 0.014926
Training Epoch: 98 [32/50000]	Loss: 2.1836	LR: 0.014926
Training Epoch: 98 [32/50000]	Loss: 2.4104	LR: 0.014926
Training Epoch: 98 [32/50000]	Loss: 1.9177	LR: 0.014926
Training Epoch: 98 [32/50000]	Loss: 2.6626	LR: 0.014926
Training Epoch: 98 [32/50000]	Loss: 2.0088	LR: 0.014926
Training Epoch: 98 [32/50000]	Loss: 2.0111	LR: 0.014926
Training Epoch: 98 [32/50000]	Loss: 2.5656	LR: 0.014926
Training Epoch: 98 [32/50000]	Loss: 2.0696	LR: 0.014926
Training Epoch: 98 [32/50000]	Loss: 2.7581	LR: 0.014926
Evaluating Network.....
Test set: Epoch: 98, Average loss: 0.0713, Top1Accuracy: 0.3824, Top3Accuracy: 0.6151, Top5Accuracy: 0.7177, Time consumed:2.67s

Training Epoch: 99 [32/50000]	Loss: 2.3766	LR: 0.014532
Training Epoch: 99 [32/50000]	Loss: 2.2699	LR: 0.014532
Training Epoch: 99 [32/50000]	Loss: 2.5519	LR: 0.014532
Training Epoch: 99 [32/50000]	Loss: 1.9688	LR: 0.014532
Training Epoch: 99 [32/50000]	Loss: 2.2968	LR: 0.014532
Training Epoch: 99 [32/50000]	Loss: 2.1321	LR: 0.014532
Training Epoch: 99 [32/50000]	Loss: 2.1059	LR: 0.014532
Training Epoch: 99 [32/50000]	Loss: 2.8374	LR: 0.014532
Training Epoch: 99 [32/50000]	Loss: 2.4871	LR: 0.014532
Training Epoch: 99 [32/50000]	Loss: 2.7778	LR: 0.014532
Evaluating Network.....
Test set: Epoch: 99, Average loss: 0.0706, Top1Accuracy: 0.3886, Top3Accuracy: 0.6178, Top5Accuracy: 0.7199, Time consumed:2.67s

Training Epoch: 100 [32/50000]	Loss: 2.9371	LR: 0.014148
Training Epoch: 100 [32/50000]	Loss: 2.0257	LR: 0.014148
Training Epoch: 100 [32/50000]	Loss: 2.3489	LR: 0.014148
Training Epoch: 100 [32/50000]	Loss: 2.4419	LR: 0.014148
Training Epoch: 100 [32/50000]	Loss: 2.0568	LR: 0.014148
Training Epoch: 100 [32/50000]	Loss: 2.5522	LR: 0.014148
Training Epoch: 100 [32/50000]	Loss: 2.3208	LR: 0.014148
Training Epoch: 100 [32/50000]	Loss: 2.5370	LR: 0.014148
Training Epoch: 100 [32/50000]	Loss: 1.9981	LR: 0.014148
Training Epoch: 100 [32/50000]	Loss: 1.8954	LR: 0.014148
Evaluating Network.....
Test set: Epoch: 100, Average loss: 0.0701, Top1Accuracy: 0.3888, Top3Accuracy: 0.6269, Top5Accuracy: 0.7259, Time consumed:2.73s

Training Epoch: 101 [32/50000]	Loss: 2.4668	LR: 0.013775
Training Epoch: 101 [32/50000]	Loss: 2.5207	LR: 0.013775
Training Epoch: 101 [32/50000]	Loss: 2.0482	LR: 0.013775
Training Epoch: 101 [32/50000]	Loss: 1.9259	LR: 0.013775
Training Epoch: 101 [32/50000]	Loss: 2.2320	LR: 0.013775
Training Epoch: 101 [32/50000]	Loss: 2.1027	LR: 0.013775
Training Epoch: 101 [32/50000]	Loss: 2.3220	LR: 0.013775
Training Epoch: 101 [32/50000]	Loss: 2.1097	LR: 0.013775
Training Epoch: 101 [32/50000]	Loss: 1.8002	LR: 0.013775
Training Epoch: 101 [32/50000]	Loss: 2.1859	LR: 0.013775
Evaluating Network.....
Test set: Epoch: 101, Average loss: 0.0700, Top1Accuracy: 0.3948, Top3Accuracy: 0.6219, Top5Accuracy: 0.7269, Time consumed:2.65s

Training Epoch: 102 [32/50000]	Loss: 2.3002	LR: 0.013411
Training Epoch: 102 [32/50000]	Loss: 2.6654	LR: 0.013411
Training Epoch: 102 [32/50000]	Loss: 2.1330	LR: 0.013411
Training Epoch: 102 [32/50000]	Loss: 2.5913	LR: 0.013411
Training Epoch: 102 [32/50000]	Loss: 2.6166	LR: 0.013411
Training Epoch: 102 [32/50000]	Loss: 2.2680	LR: 0.013411
Training Epoch: 102 [32/50000]	Loss: 2.5747	LR: 0.013411
Training Epoch: 102 [32/50000]	Loss: 2.4372	LR: 0.013411
Training Epoch: 102 [32/50000]	Loss: 2.0824	LR: 0.013411
Training Epoch: 102 [32/50000]	Loss: 2.6033	LR: 0.013411
Evaluating Network.....
Test set: Epoch: 102, Average loss: 0.0696, Top1Accuracy: 0.3956, Top3Accuracy: 0.6293, Top5Accuracy: 0.7296, Time consumed:2.71s

Training Epoch: 103 [32/50000]	Loss: 2.1433	LR: 0.013057
Training Epoch: 103 [32/50000]	Loss: 2.5580	LR: 0.013057
Training Epoch: 103 [32/50000]	Loss: 2.4227	LR: 0.013057
Training Epoch: 103 [32/50000]	Loss: 2.1451	LR: 0.013057
Training Epoch: 103 [32/50000]	Loss: 2.2500	LR: 0.013057
Training Epoch: 103 [32/50000]	Loss: 2.4956	LR: 0.013057
Training Epoch: 103 [32/50000]	Loss: 2.3268	LR: 0.013057
Training Epoch: 103 [32/50000]	Loss: 2.6360	LR: 0.013057
Training Epoch: 103 [32/50000]	Loss: 2.5630	LR: 0.013057
Training Epoch: 103 [32/50000]	Loss: 2.6397	LR: 0.013057
Evaluating Network.....
Test set: Epoch: 103, Average loss: 0.0690, Top1Accuracy: 0.4009, Top3Accuracy: 0.6315, Top5Accuracy: 0.7339, Time consumed:2.75s

Training Epoch: 104 [32/50000]	Loss: 2.1183	LR: 0.012712
Training Epoch: 104 [32/50000]	Loss: 2.3949	LR: 0.012712
Training Epoch: 104 [32/50000]	Loss: 2.2731	LR: 0.012712
Training Epoch: 104 [32/50000]	Loss: 2.1892	LR: 0.012712
Training Epoch: 104 [32/50000]	Loss: 2.2104	LR: 0.012712
Training Epoch: 104 [32/50000]	Loss: 2.3703	LR: 0.012712
Training Epoch: 104 [32/50000]	Loss: 3.1533	LR: 0.012712
Training Epoch: 104 [32/50000]	Loss: 2.2820	LR: 0.012712
Training Epoch: 104 [32/50000]	Loss: 2.3095	LR: 0.012712
Training Epoch: 104 [32/50000]	Loss: 2.2891	LR: 0.012712
Evaluating Network.....
Test set: Epoch: 104, Average loss: 0.0678, Top1Accuracy: 0.4095, Top3Accuracy: 0.6418, Top5Accuracy: 0.7408, Time consumed:2.71s

Training Epoch: 105 [32/50000]	Loss: 1.9622	LR: 0.012377
Training Epoch: 105 [32/50000]	Loss: 1.8349	LR: 0.012377
Training Epoch: 105 [32/50000]	Loss: 2.8882	LR: 0.012377
Training Epoch: 105 [32/50000]	Loss: 2.2647	LR: 0.012377
Training Epoch: 105 [32/50000]	Loss: 2.1906	LR: 0.012377
Training Epoch: 105 [32/50000]	Loss: 2.6294	LR: 0.012377
Training Epoch: 105 [32/50000]	Loss: 2.4964	LR: 0.012377
Training Epoch: 105 [32/50000]	Loss: 2.1561	LR: 0.012377
Training Epoch: 105 [32/50000]	Loss: 2.2913	LR: 0.012377
Training Epoch: 105 [32/50000]	Loss: 2.1718	LR: 0.012377
Evaluating Network.....
Test set: Epoch: 105, Average loss: 0.0676, Top1Accuracy: 0.4166, Top3Accuracy: 0.6444, Top5Accuracy: 0.7405, Time consumed:2.65s

Training Epoch: 106 [32/50000]	Loss: 2.1946	LR: 0.012050
Training Epoch: 106 [32/50000]	Loss: 2.3209	LR: 0.012050
Training Epoch: 106 [32/50000]	Loss: 2.7277	LR: 0.012050
Training Epoch: 106 [32/50000]	Loss: 2.5750	LR: 0.012050
Training Epoch: 106 [32/50000]	Loss: 1.6878	LR: 0.012050
Training Epoch: 106 [32/50000]	Loss: 2.1589	LR: 0.012050
Training Epoch: 106 [32/50000]	Loss: 2.2988	LR: 0.012050
Training Epoch: 106 [32/50000]	Loss: 2.8870	LR: 0.012050
Training Epoch: 106 [32/50000]	Loss: 2.6604	LR: 0.012050
Training Epoch: 106 [32/50000]	Loss: 2.4099	LR: 0.012050
Evaluating Network.....
Test set: Epoch: 106, Average loss: 0.0670, Top1Accuracy: 0.4170, Top3Accuracy: 0.6449, Top5Accuracy: 0.7470, Time consumed:2.62s

Training Epoch: 107 [32/50000]	Loss: 2.3931	LR: 0.011732
Training Epoch: 107 [32/50000]	Loss: 1.8795	LR: 0.011732
Training Epoch: 107 [32/50000]	Loss: 1.9050	LR: 0.011732
Training Epoch: 107 [32/50000]	Loss: 2.4571	LR: 0.011732
Training Epoch: 107 [32/50000]	Loss: 2.2265	LR: 0.011732
Training Epoch: 107 [32/50000]	Loss: 2.3150	LR: 0.011732
Training Epoch: 107 [32/50000]	Loss: 2.1217	LR: 0.011732
Training Epoch: 107 [32/50000]	Loss: 2.7113	LR: 0.011732
Training Epoch: 107 [32/50000]	Loss: 1.9721	LR: 0.011732
Training Epoch: 107 [32/50000]	Loss: 2.6105	LR: 0.011732
Evaluating Network.....
Test set: Epoch: 107, Average loss: 0.0666, Top1Accuracy: 0.4200, Top3Accuracy: 0.6493, Top5Accuracy: 0.7496, Time consumed:2.66s

Training Epoch: 108 [32/50000]	Loss: 1.9790	LR: 0.011422
Training Epoch: 108 [32/50000]	Loss: 1.8566	LR: 0.011422
Training Epoch: 108 [32/50000]	Loss: 2.0995	LR: 0.011422
Training Epoch: 108 [32/50000]	Loss: 2.1290	LR: 0.011422
Training Epoch: 108 [32/50000]	Loss: 1.9958	LR: 0.011422
Training Epoch: 108 [32/50000]	Loss: 1.9523	LR: 0.011422
Training Epoch: 108 [32/50000]	Loss: 2.1424	LR: 0.011422
Training Epoch: 108 [32/50000]	Loss: 1.8801	LR: 0.011422
Training Epoch: 108 [32/50000]	Loss: 1.9443	LR: 0.011422
Training Epoch: 108 [32/50000]	Loss: 2.3698	LR: 0.011422
Evaluating Network.....
Test set: Epoch: 108, Average loss: 0.0664, Top1Accuracy: 0.4213, Top3Accuracy: 0.6499, Top5Accuracy: 0.7495, Time consumed:2.78s

Training Epoch: 109 [32/50000]	Loss: 2.1427	LR: 0.011121
Training Epoch: 109 [32/50000]	Loss: 2.1466	LR: 0.011121
Training Epoch: 109 [32/50000]	Loss: 2.4574	LR: 0.011121
Training Epoch: 109 [32/50000]	Loss: 2.5587	LR: 0.011121
Training Epoch: 109 [32/50000]	Loss: 2.2530	LR: 0.011121
Training Epoch: 109 [32/50000]	Loss: 2.3149	LR: 0.011121
Training Epoch: 109 [32/50000]	Loss: 2.2975	LR: 0.011121
Training Epoch: 109 [32/50000]	Loss: 2.7205	LR: 0.011121
Training Epoch: 109 [32/50000]	Loss: 1.9599	LR: 0.011121
Training Epoch: 109 [32/50000]	Loss: 1.5094	LR: 0.011121
Evaluating Network.....
Test set: Epoch: 109, Average loss: 0.0654, Top1Accuracy: 0.4283, Top3Accuracy: 0.6606, Top5Accuracy: 0.7557, Time consumed:2.67s

Training Epoch: 110 [32/50000]	Loss: 2.1068	LR: 0.010827
Training Epoch: 110 [32/50000]	Loss: 2.1122	LR: 0.010827
Training Epoch: 110 [32/50000]	Loss: 2.4134	LR: 0.010827
Training Epoch: 110 [32/50000]	Loss: 1.6844	LR: 0.010827
Training Epoch: 110 [32/50000]	Loss: 2.5692	LR: 0.010827
Training Epoch: 110 [32/50000]	Loss: 2.2069	LR: 0.010827
Training Epoch: 110 [32/50000]	Loss: 2.0403	LR: 0.010827
Training Epoch: 110 [32/50000]	Loss: 2.5035	LR: 0.010827
Training Epoch: 110 [32/50000]	Loss: 2.6737	LR: 0.010827
Training Epoch: 110 [32/50000]	Loss: 2.0583	LR: 0.010827
Evaluating Network.....
Test set: Epoch: 110, Average loss: 0.0650, Top1Accuracy: 0.4310, Top3Accuracy: 0.6582, Top5Accuracy: 0.7554, Time consumed:2.70s

Training Epoch: 111 [32/50000]	Loss: 2.1792	LR: 0.010541
Training Epoch: 111 [32/50000]	Loss: 1.7006	LR: 0.010541
Training Epoch: 111 [32/50000]	Loss: 2.1667	LR: 0.010541
Training Epoch: 111 [32/50000]	Loss: 1.9867	LR: 0.010541
Training Epoch: 111 [32/50000]	Loss: 2.0443	LR: 0.010541
Training Epoch: 111 [32/50000]	Loss: 1.8458	LR: 0.010541
Training Epoch: 111 [32/50000]	Loss: 2.7440	LR: 0.010541
Training Epoch: 111 [32/50000]	Loss: 2.1809	LR: 0.010541
Training Epoch: 111 [32/50000]	Loss: 2.1807	LR: 0.010541
Training Epoch: 111 [32/50000]	Loss: 2.3078	LR: 0.010541
Evaluating Network.....
Test set: Epoch: 111, Average loss: 0.0647, Top1Accuracy: 0.4324, Top3Accuracy: 0.6659, Top5Accuracy: 0.7578, Time consumed:2.71s

Training Epoch: 112 [32/50000]	Loss: 2.3644	LR: 0.010263
Training Epoch: 112 [32/50000]	Loss: 2.3706	LR: 0.010263
Training Epoch: 112 [32/50000]	Loss: 1.8581	LR: 0.010263
Training Epoch: 112 [32/50000]	Loss: 1.9691	LR: 0.010263
Training Epoch: 112 [32/50000]	Loss: 2.2820	LR: 0.010263
Training Epoch: 112 [32/50000]	Loss: 2.0972	LR: 0.010263
Training Epoch: 112 [32/50000]	Loss: 2.2870	LR: 0.010263
Training Epoch: 112 [32/50000]	Loss: 1.9735	LR: 0.010263
Training Epoch: 112 [32/50000]	Loss: 2.0447	LR: 0.010263
Training Epoch: 112 [32/50000]	Loss: 1.8857	LR: 0.010263
Evaluating Network.....
Test set: Epoch: 112, Average loss: 0.0643, Top1Accuracy: 0.4362, Top3Accuracy: 0.6649, Top5Accuracy: 0.7608, Time consumed:2.71s

Training Epoch: 113 [32/50000]	Loss: 2.0222	LR: 0.009992
Training Epoch: 113 [32/50000]	Loss: 1.8090	LR: 0.009992
Training Epoch: 113 [32/50000]	Loss: 2.2581	LR: 0.009992
Training Epoch: 113 [32/50000]	Loss: 2.3779	LR: 0.009992
Training Epoch: 113 [32/50000]	Loss: 2.2956	LR: 0.009992
Training Epoch: 113 [32/50000]	Loss: 2.5679	LR: 0.009992
Training Epoch: 113 [32/50000]	Loss: 2.1522	LR: 0.009992
Training Epoch: 113 [32/50000]	Loss: 2.3100	LR: 0.009992
Training Epoch: 113 [32/50000]	Loss: 2.3467	LR: 0.009992
Training Epoch: 113 [32/50000]	Loss: 2.5321	LR: 0.009992
Evaluating Network.....
Test set: Epoch: 113, Average loss: 0.0638, Top1Accuracy: 0.4392, Top3Accuracy: 0.6698, Top5Accuracy: 0.7674, Time consumed:2.74s

Training Epoch: 114 [32/50000]	Loss: 2.3010	LR: 0.009728
Training Epoch: 114 [32/50000]	Loss: 2.3161	LR: 0.009728
Training Epoch: 114 [32/50000]	Loss: 1.9287	LR: 0.009728
Training Epoch: 114 [32/50000]	Loss: 2.4692	LR: 0.009728
Training Epoch: 114 [32/50000]	Loss: 1.9872	LR: 0.009728
Training Epoch: 114 [32/50000]	Loss: 2.0637	LR: 0.009728
Training Epoch: 114 [32/50000]	Loss: 2.4044	LR: 0.009728
Training Epoch: 114 [32/50000]	Loss: 2.4905	LR: 0.009728
Training Epoch: 114 [32/50000]	Loss: 1.9204	LR: 0.009728
Training Epoch: 114 [32/50000]	Loss: 2.0455	LR: 0.009728
Evaluating Network.....
Test set: Epoch: 114, Average loss: 0.0633, Top1Accuracy: 0.4413, Top3Accuracy: 0.6746, Top5Accuracy: 0.7704, Time consumed:2.62s

Training Epoch: 115 [32/50000]	Loss: 1.8115	LR: 0.009471
Training Epoch: 115 [32/50000]	Loss: 2.3923	LR: 0.009471
Training Epoch: 115 [32/50000]	Loss: 1.9423	LR: 0.009471
Training Epoch: 115 [32/50000]	Loss: 2.2544	LR: 0.009471
Training Epoch: 115 [32/50000]	Loss: 2.2668	LR: 0.009471
Training Epoch: 115 [32/50000]	Loss: 1.8074	LR: 0.009471
Training Epoch: 115 [32/50000]	Loss: 2.3441	LR: 0.009471
Training Epoch: 115 [32/50000]	Loss: 2.1943	LR: 0.009471
Training Epoch: 115 [32/50000]	Loss: 2.0803	LR: 0.009471
Training Epoch: 115 [32/50000]	Loss: 2.4202	LR: 0.009471
Evaluating Network.....
Test set: Epoch: 115, Average loss: 0.0635, Top1Accuracy: 0.4430, Top3Accuracy: 0.6735, Top5Accuracy: 0.7683, Time consumed:3.52s

Training Epoch: 116 [32/50000]	Loss: 1.8853	LR: 0.009221
Training Epoch: 116 [32/50000]	Loss: 1.8463	LR: 0.009221
Training Epoch: 116 [32/50000]	Loss: 2.4115	LR: 0.009221
Training Epoch: 116 [32/50000]	Loss: 2.3930	LR: 0.009221
Training Epoch: 116 [32/50000]	Loss: 2.2342	LR: 0.009221
Training Epoch: 116 [32/50000]	Loss: 1.9949	LR: 0.009221
Training Epoch: 116 [32/50000]	Loss: 2.3823	LR: 0.009221
Training Epoch: 116 [32/50000]	Loss: 2.2023	LR: 0.009221
Training Epoch: 116 [32/50000]	Loss: 1.6908	LR: 0.009221
Training Epoch: 116 [32/50000]	Loss: 1.6700	LR: 0.009221
Evaluating Network.....
Test set: Epoch: 116, Average loss: 0.0627, Top1Accuracy: 0.4472, Top3Accuracy: 0.6795, Top5Accuracy: 0.7743, Time consumed:2.69s

Training Epoch: 117 [32/50000]	Loss: 2.4008	LR: 0.008978
Training Epoch: 117 [32/50000]	Loss: 2.0142	LR: 0.008978
Training Epoch: 117 [32/50000]	Loss: 1.7128	LR: 0.008978
Training Epoch: 117 [32/50000]	Loss: 1.9595	LR: 0.008978
Training Epoch: 117 [32/50000]	Loss: 1.9501	LR: 0.008978
Training Epoch: 117 [32/50000]	Loss: 2.2724	LR: 0.008978
Training Epoch: 117 [32/50000]	Loss: 1.9146	LR: 0.008978
Training Epoch: 117 [32/50000]	Loss: 2.4995	LR: 0.008978
Training Epoch: 117 [32/50000]	Loss: 1.7955	LR: 0.008978
Training Epoch: 117 [32/50000]	Loss: 2.0781	LR: 0.008978
Evaluating Network.....
Test set: Epoch: 117, Average loss: 0.0628, Top1Accuracy: 0.4475, Top3Accuracy: 0.6762, Top5Accuracy: 0.7733, Time consumed:2.89s

Training Epoch: 118 [32/50000]	Loss: 1.8473	LR: 0.008741
Training Epoch: 118 [32/50000]	Loss: 1.5847	LR: 0.008741
Training Epoch: 118 [32/50000]	Loss: 2.1733	LR: 0.008741
Training Epoch: 118 [32/50000]	Loss: 1.6812	LR: 0.008741
Training Epoch: 118 [32/50000]	Loss: 1.7538	LR: 0.008741
Training Epoch: 118 [32/50000]	Loss: 1.9179	LR: 0.008741
Training Epoch: 118 [32/50000]	Loss: 1.9936	LR: 0.008741
Training Epoch: 118 [32/50000]	Loss: 2.0358	LR: 0.008741
Training Epoch: 118 [32/50000]	Loss: 1.8624	LR: 0.008741
Training Epoch: 118 [32/50000]	Loss: 2.0712	LR: 0.008741
Evaluating Network.....
Test set: Epoch: 118, Average loss: 0.0618, Top1Accuracy: 0.4531, Top3Accuracy: 0.6832, Top5Accuracy: 0.7765, Time consumed:2.68s

Training Epoch: 119 [32/50000]	Loss: 2.2080	LR: 0.008510
Training Epoch: 119 [32/50000]	Loss: 2.3799	LR: 0.008510
Training Epoch: 119 [32/50000]	Loss: 2.0438	LR: 0.008510
Training Epoch: 119 [32/50000]	Loss: 2.3236	LR: 0.008510
Training Epoch: 119 [32/50000]	Loss: 1.9324	LR: 0.008510
Training Epoch: 119 [32/50000]	Loss: 1.8629	LR: 0.008510
Training Epoch: 119 [32/50000]	Loss: 2.1877	LR: 0.008510
Training Epoch: 119 [32/50000]	Loss: 2.5094	LR: 0.008510
Training Epoch: 119 [32/50000]	Loss: 2.2980	LR: 0.008510
Training Epoch: 119 [32/50000]	Loss: 2.0124	LR: 0.008510
Evaluating Network.....
Test set: Epoch: 119, Average loss: 0.0616, Top1Accuracy: 0.4595, Top3Accuracy: 0.6856, Top5Accuracy: 0.7776, Time consumed:2.62s

Training Epoch: 120 [32/50000]	Loss: 1.8444	LR: 0.008285
Training Epoch: 120 [32/50000]	Loss: 2.0283	LR: 0.008285
Training Epoch: 120 [32/50000]	Loss: 1.6847	LR: 0.008285
Training Epoch: 120 [32/50000]	Loss: 1.8459	LR: 0.008285
Training Epoch: 120 [32/50000]	Loss: 2.1939	LR: 0.008285
Training Epoch: 120 [32/50000]	Loss: 1.7112	LR: 0.008285
Training Epoch: 120 [32/50000]	Loss: 2.3455	LR: 0.008285
Training Epoch: 120 [32/50000]	Loss: 2.0273	LR: 0.008285
Training Epoch: 120 [32/50000]	Loss: 1.7236	LR: 0.008285
Training Epoch: 120 [32/50000]	Loss: 2.0805	LR: 0.008285
Evaluating Network.....
Test set: Epoch: 120, Average loss: 0.0613, Top1Accuracy: 0.4595, Top3Accuracy: 0.6844, Top5Accuracy: 0.7805, Time consumed:2.73s

Training Epoch: 121 [32/50000]	Loss: 1.9248	LR: 0.008067
Training Epoch: 121 [32/50000]	Loss: 2.4100	LR: 0.008067
Training Epoch: 121 [32/50000]	Loss: 1.9106	LR: 0.008067
Training Epoch: 121 [32/50000]	Loss: 2.2747	LR: 0.008067
Training Epoch: 121 [32/50000]	Loss: 1.7065	LR: 0.008067
Training Epoch: 121 [32/50000]	Loss: 2.3390	LR: 0.008067
Training Epoch: 121 [32/50000]	Loss: 2.0681	LR: 0.008067
Training Epoch: 121 [32/50000]	Loss: 2.2204	LR: 0.008067
Training Epoch: 121 [32/50000]	Loss: 1.9329	LR: 0.008067
Training Epoch: 121 [32/50000]	Loss: 2.4426	LR: 0.008067
Evaluating Network.....
Test set: Epoch: 121, Average loss: 0.0614, Top1Accuracy: 0.4586, Top3Accuracy: 0.6875, Top5Accuracy: 0.7811, Time consumed:2.64s

Training Epoch: 122 [32/50000]	Loss: 1.6863	LR: 0.007854
Training Epoch: 122 [32/50000]	Loss: 1.7282	LR: 0.007854
Training Epoch: 122 [32/50000]	Loss: 2.2263	LR: 0.007854
Training Epoch: 122 [32/50000]	Loss: 2.4579	LR: 0.007854
Training Epoch: 122 [32/50000]	Loss: 2.3242	LR: 0.007854
Training Epoch: 122 [32/50000]	Loss: 2.3057	LR: 0.007854
Training Epoch: 122 [32/50000]	Loss: 1.8172	LR: 0.007854
Training Epoch: 122 [32/50000]	Loss: 2.0245	LR: 0.007854
Training Epoch: 122 [32/50000]	Loss: 2.2623	LR: 0.007854
Training Epoch: 122 [32/50000]	Loss: 1.7803	LR: 0.007854
Evaluating Network.....
Test set: Epoch: 122, Average loss: 0.0610, Top1Accuracy: 0.4641, Top3Accuracy: 0.6880, Top5Accuracy: 0.7847, Time consumed:2.80s

Training Epoch: 123 [32/50000]	Loss: 1.9079	LR: 0.007646
Training Epoch: 123 [32/50000]	Loss: 2.2437	LR: 0.007646
Training Epoch: 123 [32/50000]	Loss: 2.1091	LR: 0.007646
Training Epoch: 123 [32/50000]	Loss: 2.2666	LR: 0.007646
Training Epoch: 123 [32/50000]	Loss: 2.5268	LR: 0.007646
Training Epoch: 123 [32/50000]	Loss: 2.3295	LR: 0.007646
Training Epoch: 123 [32/50000]	Loss: 2.1947	LR: 0.007646
Training Epoch: 123 [32/50000]	Loss: 1.7875	LR: 0.007646
Training Epoch: 123 [32/50000]	Loss: 2.1711	LR: 0.007646
Training Epoch: 123 [32/50000]	Loss: 1.9935	LR: 0.007646
Evaluating Network.....
Test set: Epoch: 123, Average loss: 0.0604, Top1Accuracy: 0.4661, Top3Accuracy: 0.6936, Top5Accuracy: 0.7856, Time consumed:2.64s

Training Epoch: 124 [32/50000]	Loss: 1.8143	LR: 0.007445
Training Epoch: 124 [32/50000]	Loss: 1.4381	LR: 0.007445
Training Epoch: 124 [32/50000]	Loss: 2.1996	LR: 0.007445
Training Epoch: 124 [32/50000]	Loss: 2.3335	LR: 0.007445
Training Epoch: 124 [32/50000]	Loss: 1.7545	LR: 0.007445
Training Epoch: 124 [32/50000]	Loss: 1.9798	LR: 0.007445
Training Epoch: 124 [32/50000]	Loss: 1.9782	LR: 0.007445
Training Epoch: 124 [32/50000]	Loss: 2.0374	LR: 0.007445
Training Epoch: 124 [32/50000]	Loss: 1.6992	LR: 0.007445
Training Epoch: 124 [32/50000]	Loss: 2.0312	LR: 0.007445
Evaluating Network.....
Test set: Epoch: 124, Average loss: 0.0601, Top1Accuracy: 0.4685, Top3Accuracy: 0.6964, Top5Accuracy: 0.7871, Time consumed:2.66s

Training Epoch: 125 [32/50000]	Loss: 2.1951	LR: 0.007248
Training Epoch: 125 [32/50000]	Loss: 1.9204	LR: 0.007248
Training Epoch: 125 [32/50000]	Loss: 2.2623	LR: 0.007248
Training Epoch: 125 [32/50000]	Loss: 1.9806	LR: 0.007248
Training Epoch: 125 [32/50000]	Loss: 2.3173	LR: 0.007248
Training Epoch: 125 [32/50000]	Loss: 1.9818	LR: 0.007248
Training Epoch: 125 [32/50000]	Loss: 1.4669	LR: 0.007248
Training Epoch: 125 [32/50000]	Loss: 1.6591	LR: 0.007248
Training Epoch: 125 [32/50000]	Loss: 1.8065	LR: 0.007248
Training Epoch: 125 [32/50000]	Loss: 2.0744	LR: 0.007248
Evaluating Network.....
Test set: Epoch: 125, Average loss: 0.0594, Top1Accuracy: 0.4750, Top3Accuracy: 0.7022, Top5Accuracy: 0.7912, Time consumed:2.73s

Training Epoch: 126 [32/50000]	Loss: 2.1969	LR: 0.007057
Training Epoch: 126 [32/50000]	Loss: 1.9226	LR: 0.007057
Training Epoch: 126 [32/50000]	Loss: 2.0567	LR: 0.007057
Training Epoch: 126 [32/50000]	Loss: 1.8906	LR: 0.007057
Training Epoch: 126 [32/50000]	Loss: 1.9644	LR: 0.007057
Training Epoch: 126 [32/50000]	Loss: 2.4259	LR: 0.007057
Training Epoch: 126 [32/50000]	Loss: 1.6441	LR: 0.007057
Training Epoch: 126 [32/50000]	Loss: 1.8801	LR: 0.007057
Training Epoch: 126 [32/50000]	Loss: 1.9466	LR: 0.007057
Training Epoch: 126 [32/50000]	Loss: 2.4027	LR: 0.007057
Evaluating Network.....
Test set: Epoch: 126, Average loss: 0.0595, Top1Accuracy: 0.4743, Top3Accuracy: 0.7010, Top5Accuracy: 0.7916, Time consumed:2.68s

Training Epoch: 127 [32/50000]	Loss: 2.0104	LR: 0.006870
Training Epoch: 127 [32/50000]	Loss: 2.1284	LR: 0.006870
Training Epoch: 127 [32/50000]	Loss: 1.8878	LR: 0.006870
Training Epoch: 127 [32/50000]	Loss: 1.4588	LR: 0.006870
Training Epoch: 127 [32/50000]	Loss: 1.7237	LR: 0.006870
Training Epoch: 127 [32/50000]	Loss: 2.7414	LR: 0.006870
Training Epoch: 127 [32/50000]	Loss: 1.8083	LR: 0.006870
Training Epoch: 127 [32/50000]	Loss: 1.9236	LR: 0.006870
Training Epoch: 127 [32/50000]	Loss: 2.0652	LR: 0.006870
Training Epoch: 127 [32/50000]	Loss: 1.9495	LR: 0.006870
Evaluating Network.....
Test set: Epoch: 127, Average loss: 0.0592, Top1Accuracy: 0.4771, Top3Accuracy: 0.7014, Top5Accuracy: 0.7920, Time consumed:2.71s

Training Epoch: 128 [32/50000]	Loss: 2.3390	LR: 0.006689
Training Epoch: 128 [32/50000]	Loss: 1.6341	LR: 0.006689
Training Epoch: 128 [32/50000]	Loss: 1.8927	LR: 0.006689
Training Epoch: 128 [32/50000]	Loss: 1.9464	LR: 0.006689
Training Epoch: 128 [32/50000]	Loss: 1.8578	LR: 0.006689
Training Epoch: 128 [32/50000]	Loss: 2.2415	LR: 0.006689
Training Epoch: 128 [32/50000]	Loss: 2.4738	LR: 0.006689
Training Epoch: 128 [32/50000]	Loss: 2.5213	LR: 0.006689
Training Epoch: 128 [32/50000]	Loss: 2.1826	LR: 0.006689
Training Epoch: 128 [32/50000]	Loss: 1.8787	LR: 0.006689
Evaluating Network.....
Test set: Epoch: 128, Average loss: 0.0590, Top1Accuracy: 0.4745, Top3Accuracy: 0.7033, Top5Accuracy: 0.7930, Time consumed:2.67s

Training Epoch: 129 [32/50000]	Loss: 1.7675	LR: 0.006512
Training Epoch: 129 [32/50000]	Loss: 2.1136	LR: 0.006512
Training Epoch: 129 [32/50000]	Loss: 1.6967	LR: 0.006512
Training Epoch: 129 [32/50000]	Loss: 1.9695	LR: 0.006512
Training Epoch: 129 [32/50000]	Loss: 2.1115	LR: 0.006512
Training Epoch: 129 [32/50000]	Loss: 2.0443	LR: 0.006512
Training Epoch: 129 [32/50000]	Loss: 1.6793	LR: 0.006512
Training Epoch: 129 [32/50000]	Loss: 1.7358	LR: 0.006512
Training Epoch: 129 [32/50000]	Loss: 2.1545	LR: 0.006512
Training Epoch: 129 [32/50000]	Loss: 1.7660	LR: 0.006512
Evaluating Network.....
Test set: Epoch: 129, Average loss: 0.0587, Top1Accuracy: 0.4803, Top3Accuracy: 0.7051, Top5Accuracy: 0.7954, Time consumed:2.76s

Training Epoch: 130 [32/50000]	Loss: 2.1769	LR: 0.006340
Training Epoch: 130 [32/50000]	Loss: 1.9554	LR: 0.006340
Training Epoch: 130 [32/50000]	Loss: 1.9259	LR: 0.006340
Training Epoch: 130 [32/50000]	Loss: 2.1094	LR: 0.006340
Training Epoch: 130 [32/50000]	Loss: 1.9696	LR: 0.006340
Training Epoch: 130 [32/50000]	Loss: 1.6269	LR: 0.006340
Training Epoch: 130 [32/50000]	Loss: 2.0131	LR: 0.006340
Training Epoch: 130 [32/50000]	Loss: 1.6619	LR: 0.006340
Training Epoch: 130 [32/50000]	Loss: 1.7962	LR: 0.006340
Training Epoch: 130 [32/50000]	Loss: 2.1651	LR: 0.006340
Evaluating Network.....
Test set: Epoch: 130, Average loss: 0.0581, Top1Accuracy: 0.4837, Top3Accuracy: 0.7121, Top5Accuracy: 0.7997, Time consumed:2.72s

Training Epoch: 131 [32/50000]	Loss: 2.0658	LR: 0.006173
Training Epoch: 131 [32/50000]	Loss: 2.0507	LR: 0.006173
Training Epoch: 131 [32/50000]	Loss: 2.2279	LR: 0.006173
Training Epoch: 131 [32/50000]	Loss: 2.1326	LR: 0.006173
Training Epoch: 131 [32/50000]	Loss: 1.8519	LR: 0.006173
Training Epoch: 131 [32/50000]	Loss: 2.1977	LR: 0.006173
Training Epoch: 131 [32/50000]	Loss: 1.9692	LR: 0.006173
Training Epoch: 131 [32/50000]	Loss: 1.9877	LR: 0.006173
Training Epoch: 131 [32/50000]	Loss: 2.5548	LR: 0.006173
Training Epoch: 131 [32/50000]	Loss: 2.0898	LR: 0.006173
Evaluating Network.....
Test set: Epoch: 131, Average loss: 0.0582, Top1Accuracy: 0.4863, Top3Accuracy: 0.7088, Top5Accuracy: 0.7973, Time consumed:2.72s

Training Epoch: 132 [32/50000]	Loss: 2.0929	LR: 0.006010
Training Epoch: 132 [32/50000]	Loss: 1.8913	LR: 0.006010
Training Epoch: 132 [32/50000]	Loss: 2.2948	LR: 0.006010
Training Epoch: 132 [32/50000]	Loss: 1.4732	LR: 0.006010
Training Epoch: 132 [32/50000]	Loss: 2.0324	LR: 0.006010
Training Epoch: 132 [32/50000]	Loss: 2.3092	LR: 0.006010
Training Epoch: 132 [32/50000]	Loss: 1.8611	LR: 0.006010
Training Epoch: 132 [32/50000]	Loss: 2.3163	LR: 0.006010
Training Epoch: 132 [32/50000]	Loss: 1.7637	LR: 0.006010
Training Epoch: 132 [32/50000]	Loss: 2.5725	LR: 0.006010
Evaluating Network.....
Test set: Epoch: 132, Average loss: 0.0581, Top1Accuracy: 0.4852, Top3Accuracy: 0.7075, Top5Accuracy: 0.7989, Time consumed:2.65s

Training Epoch: 133 [32/50000]	Loss: 1.6647	LR: 0.005851
Training Epoch: 133 [32/50000]	Loss: 1.8818	LR: 0.005851
Training Epoch: 133 [32/50000]	Loss: 2.2664	LR: 0.005851
Training Epoch: 133 [32/50000]	Loss: 2.0409	LR: 0.005851
Training Epoch: 133 [32/50000]	Loss: 2.4037	LR: 0.005851
Training Epoch: 133 [32/50000]	Loss: 2.2167	LR: 0.005851
Training Epoch: 133 [32/50000]	Loss: 1.7527	LR: 0.005851
Training Epoch: 133 [32/50000]	Loss: 2.2660	LR: 0.005851
Training Epoch: 133 [32/50000]	Loss: 1.5136	LR: 0.005851
Training Epoch: 133 [32/50000]	Loss: 2.3174	LR: 0.005851
Evaluating Network.....
Test set: Epoch: 133, Average loss: 0.0576, Top1Accuracy: 0.4881, Top3Accuracy: 0.7137, Top5Accuracy: 0.8019, Time consumed:2.69s

Training Epoch: 134 [32/50000]	Loss: 2.5628	LR: 0.005697
Training Epoch: 134 [32/50000]	Loss: 1.9252	LR: 0.005697
Training Epoch: 134 [32/50000]	Loss: 1.8282	LR: 0.005697
Training Epoch: 134 [32/50000]	Loss: 2.1269	LR: 0.005697
Training Epoch: 134 [32/50000]	Loss: 1.9184	LR: 0.005697
Training Epoch: 134 [32/50000]	Loss: 2.0233	LR: 0.005697
Training Epoch: 134 [32/50000]	Loss: 1.7262	LR: 0.005697
Training Epoch: 134 [32/50000]	Loss: 1.8211	LR: 0.005697
Training Epoch: 134 [32/50000]	Loss: 1.8592	LR: 0.005697
Training Epoch: 134 [32/50000]	Loss: 1.5277	LR: 0.005697
Evaluating Network.....
Test set: Epoch: 134, Average loss: 0.0571, Top1Accuracy: 0.4916, Top3Accuracy: 0.7178, Top5Accuracy: 0.8039, Time consumed:2.74s

Training Epoch: 135 [32/50000]	Loss: 1.8128	LR: 0.005547
Training Epoch: 135 [32/50000]	Loss: 1.3475	LR: 0.005547
Training Epoch: 135 [32/50000]	Loss: 2.1102	LR: 0.005547
Training Epoch: 135 [32/50000]	Loss: 2.3998	LR: 0.005547
Training Epoch: 135 [32/50000]	Loss: 1.7367	LR: 0.005547
Training Epoch: 135 [32/50000]	Loss: 1.9359	LR: 0.005547
Training Epoch: 135 [32/50000]	Loss: 1.8294	LR: 0.005547
Training Epoch: 135 [32/50000]	Loss: 2.3055	LR: 0.005547
Training Epoch: 135 [32/50000]	Loss: 1.9837	LR: 0.005547
Training Epoch: 135 [32/50000]	Loss: 2.0267	LR: 0.005547
Evaluating Network.....
Test set: Epoch: 135, Average loss: 0.0572, Top1Accuracy: 0.4879, Top3Accuracy: 0.7176, Top5Accuracy: 0.8031, Time consumed:2.73s

Training Epoch: 136 [32/50000]	Loss: 1.9407	LR: 0.005400
Training Epoch: 136 [32/50000]	Loss: 2.2652	LR: 0.005400
Training Epoch: 136 [32/50000]	Loss: 1.8524	LR: 0.005400
Training Epoch: 136 [32/50000]	Loss: 1.7085	LR: 0.005400
Training Epoch: 136 [32/50000]	Loss: 1.9174	LR: 0.005400
Training Epoch: 136 [32/50000]	Loss: 2.2257	LR: 0.005400
Training Epoch: 136 [32/50000]	Loss: 1.7496	LR: 0.005400
Training Epoch: 136 [32/50000]	Loss: 2.0989	LR: 0.005400
Training Epoch: 136 [32/50000]	Loss: 1.9584	LR: 0.005400
Training Epoch: 136 [32/50000]	Loss: 1.9862	LR: 0.005400
Evaluating Network.....
Test set: Epoch: 136, Average loss: 0.0566, Top1Accuracy: 0.4984, Top3Accuracy: 0.7199, Top5Accuracy: 0.8069, Time consumed:2.99s

Training Epoch: 137 [32/50000]	Loss: 1.6695	LR: 0.005258
Training Epoch: 137 [32/50000]	Loss: 1.7799	LR: 0.005258
Training Epoch: 137 [32/50000]	Loss: 1.5628	LR: 0.005258
Training Epoch: 137 [32/50000]	Loss: 1.6353	LR: 0.005258
Training Epoch: 137 [32/50000]	Loss: 1.7230	LR: 0.005258
Training Epoch: 137 [32/50000]	Loss: 2.1590	LR: 0.005258
Training Epoch: 137 [32/50000]	Loss: 1.9547	LR: 0.005258
Training Epoch: 137 [32/50000]	Loss: 1.7039	LR: 0.005258
Training Epoch: 137 [32/50000]	Loss: 2.0729	LR: 0.005258
Training Epoch: 137 [32/50000]	Loss: 2.3042	LR: 0.005258
Evaluating Network.....
Test set: Epoch: 137, Average loss: 0.0569, Top1Accuracy: 0.4943, Top3Accuracy: 0.7150, Top5Accuracy: 0.8043, Time consumed:2.68s

Training Epoch: 138 [32/50000]	Loss: 1.9291	LR: 0.005119
Training Epoch: 138 [32/50000]	Loss: 2.0053	LR: 0.005119
Training Epoch: 138 [32/50000]	Loss: 1.8968	LR: 0.005119
Training Epoch: 138 [32/50000]	Loss: 2.2843	LR: 0.005119
Training Epoch: 138 [32/50000]	Loss: 2.4303	LR: 0.005119
Training Epoch: 138 [32/50000]	Loss: 1.8675	LR: 0.005119
Training Epoch: 138 [32/50000]	Loss: 2.6749	LR: 0.005119
Training Epoch: 138 [32/50000]	Loss: 1.6689	LR: 0.005119
Training Epoch: 138 [32/50000]	Loss: 1.4954	LR: 0.005119
Training Epoch: 138 [32/50000]	Loss: 2.1212	LR: 0.005119
Evaluating Network.....
Test set: Epoch: 138, Average loss: 0.0563, Top1Accuracy: 0.4995, Top3Accuracy: 0.7213, Top5Accuracy: 0.8088, Time consumed:2.67s

Training Epoch: 139 [32/50000]	Loss: 1.5081	LR: 0.004984
Training Epoch: 139 [32/50000]	Loss: 1.7844	LR: 0.004984
Training Epoch: 139 [32/50000]	Loss: 1.7183	LR: 0.004984
Training Epoch: 139 [32/50000]	Loss: 1.7853	LR: 0.004984
Training Epoch: 139 [32/50000]	Loss: 1.8561	LR: 0.004984
Training Epoch: 139 [32/50000]	Loss: 1.6338	LR: 0.004984
Training Epoch: 139 [32/50000]	Loss: 1.9833	LR: 0.004984
Training Epoch: 139 [32/50000]	Loss: 1.9880	LR: 0.004984
Training Epoch: 139 [32/50000]	Loss: 1.9098	LR: 0.004984
Training Epoch: 139 [32/50000]	Loss: 1.8078	LR: 0.004984
Evaluating Network.....
Test set: Epoch: 139, Average loss: 0.0562, Top1Accuracy: 0.4989, Top3Accuracy: 0.7240, Top5Accuracy: 0.8104, Time consumed:2.72s

Training Epoch: 140 [32/50000]	Loss: 1.7851	LR: 0.004852
Training Epoch: 140 [32/50000]	Loss: 1.8119	LR: 0.004852
Training Epoch: 140 [32/50000]	Loss: 1.7544	LR: 0.004852
Training Epoch: 140 [32/50000]	Loss: 2.5077	LR: 0.004852
Training Epoch: 140 [32/50000]	Loss: 2.0859	LR: 0.004852
Training Epoch: 140 [32/50000]	Loss: 1.9423	LR: 0.004852
Training Epoch: 140 [32/50000]	Loss: 1.7187	LR: 0.004852
Training Epoch: 140 [32/50000]	Loss: 2.2238	LR: 0.004852
Training Epoch: 140 [32/50000]	Loss: 2.2619	LR: 0.004852
Training Epoch: 140 [32/50000]	Loss: 1.6909	LR: 0.004852
Evaluating Network.....
Test set: Epoch: 140, Average loss: 0.0559, Top1Accuracy: 0.5075, Top3Accuracy: 0.7260, Top5Accuracy: 0.8128, Time consumed:2.73s

Training Epoch: 141 [32/50000]	Loss: 1.8772	LR: 0.004724
Training Epoch: 141 [32/50000]	Loss: 1.8374	LR: 0.004724
Training Epoch: 141 [32/50000]	Loss: 2.0292	LR: 0.004724
Training Epoch: 141 [32/50000]	Loss: 1.5533	LR: 0.004724
Training Epoch: 141 [32/50000]	Loss: 2.0752	LR: 0.004724
Training Epoch: 141 [32/50000]	Loss: 1.2815	LR: 0.004724
Training Epoch: 141 [32/50000]	Loss: 1.9905	LR: 0.004724
Training Epoch: 141 [32/50000]	Loss: 2.1011	LR: 0.004724
Training Epoch: 141 [32/50000]	Loss: 1.6223	LR: 0.004724
Training Epoch: 141 [32/50000]	Loss: 1.9919	LR: 0.004724
Evaluating Network.....
Test set: Epoch: 141, Average loss: 0.0558, Top1Accuracy: 0.5040, Top3Accuracy: 0.7251, Top5Accuracy: 0.8132, Time consumed:2.68s

Training Epoch: 142 [32/50000]	Loss: 1.7678	LR: 0.004599
Training Epoch: 142 [32/50000]	Loss: 2.8826	LR: 0.004599
Training Epoch: 142 [32/50000]	Loss: 1.4886	LR: 0.004599
Training Epoch: 142 [32/50000]	Loss: 1.8446	LR: 0.004599
Training Epoch: 142 [32/50000]	Loss: 1.8249	LR: 0.004599
Training Epoch: 142 [32/50000]	Loss: 1.8997	LR: 0.004599
Training Epoch: 142 [32/50000]	Loss: 1.8244	LR: 0.004599
Training Epoch: 142 [32/50000]	Loss: 1.8309	LR: 0.004599
Training Epoch: 142 [32/50000]	Loss: 1.8492	LR: 0.004599
Training Epoch: 142 [32/50000]	Loss: 2.1603	LR: 0.004599
Evaluating Network.....
Test set: Epoch: 142, Average loss: 0.0554, Top1Accuracy: 0.5068, Top3Accuracy: 0.7278, Top5Accuracy: 0.8142, Time consumed:2.65s

Training Epoch: 143 [32/50000]	Loss: 1.7792	LR: 0.004478
Training Epoch: 143 [32/50000]	Loss: 1.9174	LR: 0.004478
Training Epoch: 143 [32/50000]	Loss: 1.3505	LR: 0.004478
Training Epoch: 143 [32/50000]	Loss: 1.9163	LR: 0.004478
Training Epoch: 143 [32/50000]	Loss: 1.5786	LR: 0.004478
Training Epoch: 143 [32/50000]	Loss: 1.4398	LR: 0.004478
Training Epoch: 143 [32/50000]	Loss: 1.7171	LR: 0.004478
Training Epoch: 143 [32/50000]	Loss: 2.2384	LR: 0.004478
Training Epoch: 143 [32/50000]	Loss: 1.6158	LR: 0.004478
Training Epoch: 143 [32/50000]	Loss: 1.5389	LR: 0.004478
Evaluating Network.....
Test set: Epoch: 143, Average loss: 0.0555, Top1Accuracy: 0.5057, Top3Accuracy: 0.7248, Top5Accuracy: 0.8155, Time consumed:2.68s

Training Epoch: 144 [32/50000]	Loss: 1.6433	LR: 0.004360
Training Epoch: 144 [32/50000]	Loss: 2.1372	LR: 0.004360
Training Epoch: 144 [32/50000]	Loss: 1.8002	LR: 0.004360
Training Epoch: 144 [32/50000]	Loss: 1.7701	LR: 0.004360
Training Epoch: 144 [32/50000]	Loss: 2.0467	LR: 0.004360
Training Epoch: 144 [32/50000]	Loss: 1.9073	LR: 0.004360
Training Epoch: 144 [32/50000]	Loss: 2.0296	LR: 0.004360
Training Epoch: 144 [32/50000]	Loss: 1.9571	LR: 0.004360
Training Epoch: 144 [32/50000]	Loss: 1.6932	LR: 0.004360
Training Epoch: 144 [32/50000]	Loss: 2.1356	LR: 0.004360
Evaluating Network.....
Test set: Epoch: 144, Average loss: 0.0552, Top1Accuracy: 0.5054, Top3Accuracy: 0.7341, Top5Accuracy: 0.8156, Time consumed:2.68s

Training Epoch: 145 [32/50000]	Loss: 1.8541	LR: 0.004245
Training Epoch: 145 [32/50000]	Loss: 1.9060	LR: 0.004245
Training Epoch: 145 [32/50000]	Loss: 2.2976	LR: 0.004245
Training Epoch: 145 [32/50000]	Loss: 1.5382	LR: 0.004245
Training Epoch: 145 [32/50000]	Loss: 1.6467	LR: 0.004245
Training Epoch: 145 [32/50000]	Loss: 1.4859	LR: 0.004245
Training Epoch: 145 [32/50000]	Loss: 1.3748	LR: 0.004245
Training Epoch: 145 [32/50000]	Loss: 2.3229	LR: 0.004245
Training Epoch: 145 [32/50000]	Loss: 1.7732	LR: 0.004245
Training Epoch: 145 [32/50000]	Loss: 1.6658	LR: 0.004245
Evaluating Network.....
Test set: Epoch: 145, Average loss: 0.0550, Top1Accuracy: 0.5097, Top3Accuracy: 0.7324, Top5Accuracy: 0.8152, Time consumed:2.69s

Training Epoch: 146 [32/50000]	Loss: 1.7960	LR: 0.004132
Training Epoch: 146 [32/50000]	Loss: 1.7265	LR: 0.004132
Training Epoch: 146 [32/50000]	Loss: 2.0364	LR: 0.004132
Training Epoch: 146 [32/50000]	Loss: 2.2621	LR: 0.004132
Training Epoch: 146 [32/50000]	Loss: 2.1175	LR: 0.004132
Training Epoch: 146 [32/50000]	Loss: 1.8403	LR: 0.004132
Training Epoch: 146 [32/50000]	Loss: 2.0828	LR: 0.004132
Training Epoch: 146 [32/50000]	Loss: 1.8837	LR: 0.004132
Training Epoch: 146 [32/50000]	Loss: 2.1329	LR: 0.004132
Training Epoch: 146 [32/50000]	Loss: 2.0181	LR: 0.004132
Evaluating Network.....
Test set: Epoch: 146, Average loss: 0.0546, Top1Accuracy: 0.5159, Top3Accuracy: 0.7360, Top5Accuracy: 0.8183, Time consumed:2.95s

Training Epoch: 147 [32/50000]	Loss: 1.7309	LR: 0.004023
Training Epoch: 147 [32/50000]	Loss: 1.5738	LR: 0.004023
Training Epoch: 147 [32/50000]	Loss: 1.7837	LR: 0.004023
Training Epoch: 147 [32/50000]	Loss: 1.8080	LR: 0.004023
Training Epoch: 147 [32/50000]	Loss: 1.9009	LR: 0.004023
Training Epoch: 147 [32/50000]	Loss: 2.0275	LR: 0.004023
Training Epoch: 147 [32/50000]	Loss: 1.9004	LR: 0.004023
Training Epoch: 147 [32/50000]	Loss: 1.3331	LR: 0.004023
Training Epoch: 147 [32/50000]	Loss: 1.6208	LR: 0.004023
Training Epoch: 147 [32/50000]	Loss: 1.7498	LR: 0.004023
Evaluating Network.....
Test set: Epoch: 147, Average loss: 0.0546, Top1Accuracy: 0.5156, Top3Accuracy: 0.7349, Top5Accuracy: 0.8182, Time consumed:2.99s

Training Epoch: 148 [32/50000]	Loss: 1.8755	LR: 0.003917
Training Epoch: 148 [32/50000]	Loss: 2.2020	LR: 0.003917
Training Epoch: 148 [32/50000]	Loss: 1.6470	LR: 0.003917
Training Epoch: 148 [32/50000]	Loss: 1.9993	LR: 0.003917
Training Epoch: 148 [32/50000]	Loss: 1.8546	LR: 0.003917
Training Epoch: 148 [32/50000]	Loss: 2.1086	LR: 0.003917
Training Epoch: 148 [32/50000]	Loss: 2.0511	LR: 0.003917
Training Epoch: 148 [32/50000]	Loss: 1.9409	LR: 0.003917
Training Epoch: 148 [32/50000]	Loss: 1.6451	LR: 0.003917
Training Epoch: 148 [32/50000]	Loss: 2.1635	LR: 0.003917
Evaluating Network.....
Test set: Epoch: 148, Average loss: 0.0543, Top1Accuracy: 0.5155, Top3Accuracy: 0.7393, Top5Accuracy: 0.8211, Time consumed:2.70s

Training Epoch: 149 [32/50000]	Loss: 2.2798	LR: 0.003814
Training Epoch: 149 [32/50000]	Loss: 1.6427	LR: 0.003814
Training Epoch: 149 [32/50000]	Loss: 1.3590	LR: 0.003814
Training Epoch: 149 [32/50000]	Loss: 1.8333	LR: 0.003814
Training Epoch: 149 [32/50000]	Loss: 1.8902	LR: 0.003814
Training Epoch: 149 [32/50000]	Loss: 2.1848	LR: 0.003814
Training Epoch: 149 [32/50000]	Loss: 2.3537	LR: 0.003814
Training Epoch: 149 [32/50000]	Loss: 1.1399	LR: 0.003814
Training Epoch: 149 [32/50000]	Loss: 1.9752	LR: 0.003814
Training Epoch: 149 [32/50000]	Loss: 1.7527	LR: 0.003814
Evaluating Network.....
Test set: Epoch: 149, Average loss: 0.0539, Top1Accuracy: 0.5174, Top3Accuracy: 0.7399, Top5Accuracy: 0.8214, Time consumed:2.70s

Training Epoch: 150 [32/50000]	Loss: 1.4689	LR: 0.003713
Training Epoch: 150 [32/50000]	Loss: 1.8449	LR: 0.003713
Training Epoch: 150 [32/50000]	Loss: 2.0408	LR: 0.003713
Training Epoch: 150 [32/50000]	Loss: 1.9531	LR: 0.003713
Training Epoch: 150 [32/50000]	Loss: 1.9099	LR: 0.003713
Training Epoch: 150 [32/50000]	Loss: 1.8719	LR: 0.003713
Training Epoch: 150 [32/50000]	Loss: 1.3393	LR: 0.003713
Training Epoch: 150 [32/50000]	Loss: 1.9218	LR: 0.003713
Training Epoch: 150 [32/50000]	Loss: 1.4607	LR: 0.003713
Training Epoch: 150 [32/50000]	Loss: 1.6104	LR: 0.003713
Evaluating Network.....
Test set: Epoch: 150, Average loss: 0.0540, Top1Accuracy: 0.5186, Top3Accuracy: 0.7374, Top5Accuracy: 0.8214, Time consumed:2.64s

Training Epoch: 151 [32/50000]	Loss: 2.4252	LR: 0.003615
Training Epoch: 151 [32/50000]	Loss: 1.8755	LR: 0.003615
Training Epoch: 151 [32/50000]	Loss: 1.5201	LR: 0.003615
Training Epoch: 151 [32/50000]	Loss: 1.5887	LR: 0.003615
Training Epoch: 151 [32/50000]	Loss: 2.0426	LR: 0.003615
Training Epoch: 151 [32/50000]	Loss: 1.9681	LR: 0.003615
Training Epoch: 151 [32/50000]	Loss: 1.2249	LR: 0.003615
Training Epoch: 151 [32/50000]	Loss: 1.7419	LR: 0.003615
Training Epoch: 151 [32/50000]	Loss: 1.7991	LR: 0.003615
Training Epoch: 151 [32/50000]	Loss: 1.7599	LR: 0.003615
Evaluating Network.....
Test set: Epoch: 151, Average loss: 0.0538, Top1Accuracy: 0.5195, Top3Accuracy: 0.7397, Top5Accuracy: 0.8217, Time consumed:2.63s

Training Epoch: 152 [32/50000]	Loss: 2.4171	LR: 0.003520
Training Epoch: 152 [32/50000]	Loss: 1.7714	LR: 0.003520
Training Epoch: 152 [32/50000]	Loss: 1.8420	LR: 0.003520
Training Epoch: 152 [32/50000]	Loss: 2.1421	LR: 0.003520
Training Epoch: 152 [32/50000]	Loss: 2.1381	LR: 0.003520
Training Epoch: 152 [32/50000]	Loss: 1.5892	LR: 0.003520
Training Epoch: 152 [32/50000]	Loss: 1.4416	LR: 0.003520
Training Epoch: 152 [32/50000]	Loss: 1.9376	LR: 0.003520
Training Epoch: 152 [32/50000]	Loss: 2.0583	LR: 0.003520
Training Epoch: 152 [32/50000]	Loss: 1.7370	LR: 0.003520
Evaluating Network.....
Test set: Epoch: 152, Average loss: 0.0536, Top1Accuracy: 0.5209, Top3Accuracy: 0.7420, Top5Accuracy: 0.8237, Time consumed:2.65s

Training Epoch: 153 [32/50000]	Loss: 1.5348	LR: 0.003427
Training Epoch: 153 [32/50000]	Loss: 1.8860	LR: 0.003427
Training Epoch: 153 [32/50000]	Loss: 1.5659	LR: 0.003427
Training Epoch: 153 [32/50000]	Loss: 1.7337	LR: 0.003427
Training Epoch: 153 [32/50000]	Loss: 1.5539	LR: 0.003427
Training Epoch: 153 [32/50000]	Loss: 1.6730	LR: 0.003427
Training Epoch: 153 [32/50000]	Loss: 2.0366	LR: 0.003427
Training Epoch: 153 [32/50000]	Loss: 1.7908	LR: 0.003427
Training Epoch: 153 [32/50000]	Loss: 2.2207	LR: 0.003427
Training Epoch: 153 [32/50000]	Loss: 1.9817	LR: 0.003427
Evaluating Network.....
Test set: Epoch: 153, Average loss: 0.0533, Top1Accuracy: 0.5228, Top3Accuracy: 0.7442, Top5Accuracy: 0.8240, Time consumed:2.73s

Training Epoch: 154 [32/50000]	Loss: 1.3790	LR: 0.003336
Training Epoch: 154 [32/50000]	Loss: 1.7437	LR: 0.003336
Training Epoch: 154 [32/50000]	Loss: 1.9732	LR: 0.003336
Training Epoch: 154 [32/50000]	Loss: 1.7599	LR: 0.003336
Training Epoch: 154 [32/50000]	Loss: 1.6199	LR: 0.003336
Training Epoch: 154 [32/50000]	Loss: 1.9673	LR: 0.003336
Training Epoch: 154 [32/50000]	Loss: 1.7015	LR: 0.003336
Training Epoch: 154 [32/50000]	Loss: 1.7276	LR: 0.003336
Training Epoch: 154 [32/50000]	Loss: 2.0304	LR: 0.003336
Training Epoch: 154 [32/50000]	Loss: 2.0643	LR: 0.003336
Evaluating Network.....
Test set: Epoch: 154, Average loss: 0.0534, Top1Accuracy: 0.5225, Top3Accuracy: 0.7410, Top5Accuracy: 0.8239, Time consumed:2.65s

Training Epoch: 155 [32/50000]	Loss: 2.0101	LR: 0.003248
Training Epoch: 155 [32/50000]	Loss: 1.5867	LR: 0.003248
Training Epoch: 155 [32/50000]	Loss: 1.7334	LR: 0.003248
Training Epoch: 155 [32/50000]	Loss: 2.1819	LR: 0.003248
Training Epoch: 155 [32/50000]	Loss: 1.7277	LR: 0.003248
Training Epoch: 155 [32/50000]	Loss: 1.7458	LR: 0.003248
Training Epoch: 155 [32/50000]	Loss: 1.2701	LR: 0.003248
Training Epoch: 155 [32/50000]	Loss: 1.7300	LR: 0.003248
Training Epoch: 155 [32/50000]	Loss: 2.2442	LR: 0.003248
Training Epoch: 155 [32/50000]	Loss: 1.8547	LR: 0.003248
Evaluating Network.....
Test set: Epoch: 155, Average loss: 0.0530, Top1Accuracy: 0.5267, Top3Accuracy: 0.7440, Top5Accuracy: 0.8247, Time consumed:2.65s

Training Epoch: 156 [32/50000]	Loss: 1.9535	LR: 0.003162
Training Epoch: 156 [32/50000]	Loss: 1.2817	LR: 0.003162
Training Epoch: 156 [32/50000]	Loss: 1.5828	LR: 0.003162
Training Epoch: 156 [32/50000]	Loss: 2.1110	LR: 0.003162
Training Epoch: 156 [32/50000]	Loss: 1.8534	LR: 0.003162
Training Epoch: 156 [32/50000]	Loss: 2.3460	LR: 0.003162
Training Epoch: 156 [32/50000]	Loss: 1.9885	LR: 0.003162
Training Epoch: 156 [32/50000]	Loss: 1.9035	LR: 0.003162
Training Epoch: 156 [32/50000]	Loss: 1.5852	LR: 0.003162
Training Epoch: 156 [32/50000]	Loss: 1.7731	LR: 0.003162
Evaluating Network.....
Test set: Epoch: 156, Average loss: 0.0531, Top1Accuracy: 0.5260, Top3Accuracy: 0.7428, Top5Accuracy: 0.8253, Time consumed:2.70s

Training Epoch: 157 [32/50000]	Loss: 1.6196	LR: 0.003079
Training Epoch: 157 [32/50000]	Loss: 1.4156	LR: 0.003079
Training Epoch: 157 [32/50000]	Loss: 2.2924	LR: 0.003079
Training Epoch: 157 [32/50000]	Loss: 1.7206	LR: 0.003079
Training Epoch: 157 [32/50000]	Loss: 1.2501	LR: 0.003079
Training Epoch: 157 [32/50000]	Loss: 1.5574	LR: 0.003079
Training Epoch: 157 [32/50000]	Loss: 1.7736	LR: 0.003079
Training Epoch: 157 [32/50000]	Loss: 1.8873	LR: 0.003079
Training Epoch: 157 [32/50000]	Loss: 1.9336	LR: 0.003079
Training Epoch: 157 [32/50000]	Loss: 1.6760	LR: 0.003079
Evaluating Network.....
Test set: Epoch: 157, Average loss: 0.0528, Top1Accuracy: 0.5311, Top3Accuracy: 0.7459, Top5Accuracy: 0.8265, Time consumed:2.90s

Training Epoch: 158 [32/50000]	Loss: 1.8544	LR: 0.002998
Training Epoch: 158 [32/50000]	Loss: 1.7472	LR: 0.002998
Training Epoch: 158 [32/50000]	Loss: 1.7156	LR: 0.002998
Training Epoch: 158 [32/50000]	Loss: 1.6714	LR: 0.002998
Training Epoch: 158 [32/50000]	Loss: 1.6959	LR: 0.002998
Training Epoch: 158 [32/50000]	Loss: 1.6854	LR: 0.002998
Training Epoch: 158 [32/50000]	Loss: 1.4396	LR: 0.002998
Training Epoch: 158 [32/50000]	Loss: 1.9890	LR: 0.002998
Training Epoch: 158 [32/50000]	Loss: 1.8880	LR: 0.002998
Training Epoch: 158 [32/50000]	Loss: 1.7137	LR: 0.002998
Evaluating Network.....
Test set: Epoch: 158, Average loss: 0.0523, Top1Accuracy: 0.5329, Top3Accuracy: 0.7496, Top5Accuracy: 0.8271, Time consumed:2.62s

Training Epoch: 159 [32/50000]	Loss: 1.9634	LR: 0.002918
Training Epoch: 159 [32/50000]	Loss: 2.1336	LR: 0.002918
Training Epoch: 159 [32/50000]	Loss: 1.9858	LR: 0.002918
Training Epoch: 159 [32/50000]	Loss: 1.7930	LR: 0.002918
Training Epoch: 159 [32/50000]	Loss: 1.3230	LR: 0.002918
Training Epoch: 159 [32/50000]	Loss: 1.5992	LR: 0.002918
Training Epoch: 159 [32/50000]	Loss: 2.4315	LR: 0.002918
Training Epoch: 159 [32/50000]	Loss: 1.3089	LR: 0.002918
Training Epoch: 159 [32/50000]	Loss: 1.3951	LR: 0.002918
Training Epoch: 159 [32/50000]	Loss: 2.0154	LR: 0.002918
Evaluating Network.....
Test set: Epoch: 159, Average loss: 0.0527, Top1Accuracy: 0.5299, Top3Accuracy: 0.7476, Top5Accuracy: 0.8258, Time consumed:3.20s

Training Epoch: 160 [32/50000]	Loss: 2.0982	LR: 0.002841
Training Epoch: 160 [32/50000]	Loss: 1.9956	LR: 0.002841
Training Epoch: 160 [32/50000]	Loss: 1.5888	LR: 0.002841
Training Epoch: 160 [32/50000]	Loss: 1.9139	LR: 0.002841
Training Epoch: 160 [32/50000]	Loss: 1.4465	LR: 0.002841
Training Epoch: 160 [32/50000]	Loss: 1.7257	LR: 0.002841
Training Epoch: 160 [32/50000]	Loss: 1.8716	LR: 0.002841
Training Epoch: 160 [32/50000]	Loss: 1.4194	LR: 0.002841
Training Epoch: 160 [32/50000]	Loss: 1.9785	LR: 0.002841
Training Epoch: 160 [32/50000]	Loss: 2.1317	LR: 0.002841
Evaluating Network.....
Test set: Epoch: 160, Average loss: 0.0523, Top1Accuracy: 0.5347, Top3Accuracy: 0.7502, Top5Accuracy: 0.8297, Time consumed:2.64s

Training Epoch: 161 [32/50000]	Loss: 2.1135	LR: 0.002766
Training Epoch: 161 [32/50000]	Loss: 1.2726	LR: 0.002766
Training Epoch: 161 [32/50000]	Loss: 1.8403	LR: 0.002766
Training Epoch: 161 [32/50000]	Loss: 2.1747	LR: 0.002766
Training Epoch: 161 [32/50000]	Loss: 1.1742	LR: 0.002766
Training Epoch: 161 [32/50000]	Loss: 1.9925	LR: 0.002766
Training Epoch: 161 [32/50000]	Loss: 1.9046	LR: 0.002766
Training Epoch: 161 [32/50000]	Loss: 1.8423	LR: 0.002766
Training Epoch: 161 [32/50000]	Loss: 1.2420	LR: 0.002766
Training Epoch: 161 [32/50000]	Loss: 1.5727	LR: 0.002766
Evaluating Network.....
Test set: Epoch: 161, Average loss: 0.0521, Top1Accuracy: 0.5365, Top3Accuracy: 0.7514, Top5Accuracy: 0.8294, Time consumed:2.62s

Training Epoch: 162 [32/50000]	Loss: 0.9917	LR: 0.002693
Training Epoch: 162 [32/50000]	Loss: 1.6388	LR: 0.002693
Training Epoch: 162 [32/50000]	Loss: 1.5412	LR: 0.002693
Training Epoch: 162 [32/50000]	Loss: 1.5071	LR: 0.002693
Training Epoch: 162 [32/50000]	Loss: 1.5124	LR: 0.002693
Training Epoch: 162 [32/50000]	Loss: 1.2904	LR: 0.002693
Training Epoch: 162 [32/50000]	Loss: 1.7734	LR: 0.002693
Training Epoch: 162 [32/50000]	Loss: 1.6559	LR: 0.002693
Training Epoch: 162 [32/50000]	Loss: 1.5644	LR: 0.002693
Training Epoch: 162 [32/50000]	Loss: 1.5813	LR: 0.002693
Evaluating Network.....
Test set: Epoch: 162, Average loss: 0.0522, Top1Accuracy: 0.5346, Top3Accuracy: 0.7516, Top5Accuracy: 0.8284, Time consumed:2.96s

Training Epoch: 163 [32/50000]	Loss: 1.8883	LR: 0.002622
Training Epoch: 163 [32/50000]	Loss: 2.0496	LR: 0.002622
Training Epoch: 163 [32/50000]	Loss: 1.5667	LR: 0.002622
Training Epoch: 163 [32/50000]	Loss: 1.4033	LR: 0.002622
Training Epoch: 163 [32/50000]	Loss: 1.8268	LR: 0.002622
Training Epoch: 163 [32/50000]	Loss: 1.4710	LR: 0.002622
Training Epoch: 163 [32/50000]	Loss: 2.1458	LR: 0.002622
Training Epoch: 163 [32/50000]	Loss: 1.5238	LR: 0.002622
Training Epoch: 163 [32/50000]	Loss: 1.2752	LR: 0.002622
Training Epoch: 163 [32/50000]	Loss: 1.6240	LR: 0.002622
Evaluating Network.....
Test set: Epoch: 163, Average loss: 0.0521, Top1Accuracy: 0.5371, Top3Accuracy: 0.7531, Top5Accuracy: 0.8311, Time consumed:2.58s

Training Epoch: 164 [32/50000]	Loss: 1.5662	LR: 0.002553
Training Epoch: 164 [32/50000]	Loss: 1.7241	LR: 0.002553
Training Epoch: 164 [32/50000]	Loss: 1.3803	LR: 0.002553
Training Epoch: 164 [32/50000]	Loss: 1.6642	LR: 0.002553
Training Epoch: 164 [32/50000]	Loss: 1.9309	LR: 0.002553
Training Epoch: 164 [32/50000]	Loss: 1.3636	LR: 0.002553
Training Epoch: 164 [32/50000]	Loss: 1.7490	LR: 0.002553
Training Epoch: 164 [32/50000]	Loss: 1.4158	LR: 0.002553
Training Epoch: 164 [32/50000]	Loss: 1.6180	LR: 0.002553
Training Epoch: 164 [32/50000]	Loss: 1.4260	LR: 0.002553
Evaluating Network.....
Test set: Epoch: 164, Average loss: 0.0521, Top1Accuracy: 0.5364, Top3Accuracy: 0.7525, Top5Accuracy: 0.8309, Time consumed:2.91s

Training Epoch: 165 [32/50000]	Loss: 1.6315	LR: 0.002486
Training Epoch: 165 [32/50000]	Loss: 1.7384	LR: 0.002486
Training Epoch: 165 [32/50000]	Loss: 1.8309	LR: 0.002486
Training Epoch: 165 [32/50000]	Loss: 1.6657	LR: 0.002486
Training Epoch: 165 [32/50000]	Loss: 1.9572	LR: 0.002486
Training Epoch: 165 [32/50000]	Loss: 1.5335	LR: 0.002486
Training Epoch: 165 [32/50000]	Loss: 1.7748	LR: 0.002486
Training Epoch: 165 [32/50000]	Loss: 1.7179	LR: 0.002486
Training Epoch: 165 [32/50000]	Loss: 2.0033	LR: 0.002486
Training Epoch: 165 [32/50000]	Loss: 1.6796	LR: 0.002486
Evaluating Network.....
Test set: Epoch: 165, Average loss: 0.0517, Top1Accuracy: 0.5371, Top3Accuracy: 0.7527, Top5Accuracy: 0.8316, Time consumed:2.79s

Training Epoch: 166 [32/50000]	Loss: 1.8154	LR: 0.002420
Training Epoch: 166 [32/50000]	Loss: 1.8474	LR: 0.002420
Training Epoch: 166 [32/50000]	Loss: 1.4479	LR: 0.002420
Training Epoch: 166 [32/50000]	Loss: 1.5616	LR: 0.002420
Training Epoch: 166 [32/50000]	Loss: 1.3749	LR: 0.002420
Training Epoch: 166 [32/50000]	Loss: 1.2043	LR: 0.002420
Training Epoch: 166 [32/50000]	Loss: 1.6061	LR: 0.002420
Training Epoch: 166 [32/50000]	Loss: 1.6908	LR: 0.002420
Training Epoch: 166 [32/50000]	Loss: 1.4046	LR: 0.002420
Training Epoch: 166 [32/50000]	Loss: 1.6289	LR: 0.002420
Evaluating Network.....
Test set: Epoch: 166, Average loss: 0.0515, Top1Accuracy: 0.5377, Top3Accuracy: 0.7534, Top5Accuracy: 0.8326, Time consumed:2.64s

Training Epoch: 167 [32/50000]	Loss: 1.9191	LR: 0.002356
Training Epoch: 167 [32/50000]	Loss: 1.6965	LR: 0.002356
Training Epoch: 167 [32/50000]	Loss: 1.7871	LR: 0.002356
Training Epoch: 167 [32/50000]	Loss: 1.7169	LR: 0.002356
Training Epoch: 167 [32/50000]	Loss: 1.5287	LR: 0.002356
Training Epoch: 167 [32/50000]	Loss: 1.7073	LR: 0.002356
Training Epoch: 167 [32/50000]	Loss: 2.2190	LR: 0.002356
Training Epoch: 167 [32/50000]	Loss: 1.7127	LR: 0.002356
Training Epoch: 167 [32/50000]	Loss: 1.8067	LR: 0.002356
Training Epoch: 167 [32/50000]	Loss: 1.4851	LR: 0.002356
Evaluating Network.....
Test set: Epoch: 167, Average loss: 0.0516, Top1Accuracy: 0.5395, Top3Accuracy: 0.7547, Top5Accuracy: 0.8347, Time consumed:2.72s

Training Epoch: 168 [32/50000]	Loss: 1.5128	LR: 0.002294
Training Epoch: 168 [32/50000]	Loss: 1.9636	LR: 0.002294
Training Epoch: 168 [32/50000]	Loss: 1.8433	LR: 0.002294
Training Epoch: 168 [32/50000]	Loss: 1.2859	LR: 0.002294
Training Epoch: 168 [32/50000]	Loss: 1.8708	LR: 0.002294
Training Epoch: 168 [32/50000]	Loss: 1.7787	LR: 0.002294
Training Epoch: 168 [32/50000]	Loss: 1.5575	LR: 0.002294
Training Epoch: 168 [32/50000]	Loss: 1.6293	LR: 0.002294
Training Epoch: 168 [32/50000]	Loss: 2.0438	LR: 0.002294
Training Epoch: 168 [32/50000]	Loss: 1.7720	LR: 0.002294
Evaluating Network.....
Test set: Epoch: 168, Average loss: 0.0514, Top1Accuracy: 0.5377, Top3Accuracy: 0.7557, Top5Accuracy: 0.8365, Time consumed:2.85s

Training Epoch: 169 [32/50000]	Loss: 1.7378	LR: 0.002233
Training Epoch: 169 [32/50000]	Loss: 1.3898	LR: 0.002233
Training Epoch: 169 [32/50000]	Loss: 1.2704	LR: 0.002233
Training Epoch: 169 [32/50000]	Loss: 1.2241	LR: 0.002233
Training Epoch: 169 [32/50000]	Loss: 2.2363	LR: 0.002233
Training Epoch: 169 [32/50000]	Loss: 1.3126	LR: 0.002233
Training Epoch: 169 [32/50000]	Loss: 1.6735	LR: 0.002233
Training Epoch: 169 [32/50000]	Loss: 1.5694	LR: 0.002233
Training Epoch: 169 [32/50000]	Loss: 1.9680	LR: 0.002233
Training Epoch: 169 [32/50000]	Loss: 1.5632	LR: 0.002233
Evaluating Network.....
Test set: Epoch: 169, Average loss: 0.0511, Top1Accuracy: 0.5412, Top3Accuracy: 0.7591, Top5Accuracy: 0.8349, Time consumed:2.70s

Training Epoch: 170 [32/50000]	Loss: 1.3339	LR: 0.002174
Training Epoch: 170 [32/50000]	Loss: 2.0030	LR: 0.002174
Training Epoch: 170 [32/50000]	Loss: 1.2236	LR: 0.002174
Training Epoch: 170 [32/50000]	Loss: 2.3007	LR: 0.002174
Training Epoch: 170 [32/50000]	Loss: 1.7523	LR: 0.002174
Training Epoch: 170 [32/50000]	Loss: 1.6769	LR: 0.002174
Training Epoch: 170 [32/50000]	Loss: 1.4548	LR: 0.002174
Training Epoch: 170 [32/50000]	Loss: 1.4907	LR: 0.002174
Training Epoch: 170 [32/50000]	Loss: 1.9856	LR: 0.002174
Training Epoch: 170 [32/50000]	Loss: 1.3494	LR: 0.002174
Evaluating Network.....
Test set: Epoch: 170, Average loss: 0.0511, Top1Accuracy: 0.5441, Top3Accuracy: 0.7568, Top5Accuracy: 0.8350, Time consumed:2.64s

Training Epoch: 171 [32/50000]	Loss: 1.6378	LR: 0.002117
Training Epoch: 171 [32/50000]	Loss: 1.9157	LR: 0.002117
Training Epoch: 171 [32/50000]	Loss: 1.8209	LR: 0.002117
Training Epoch: 171 [32/50000]	Loss: 1.9589	LR: 0.002117
Training Epoch: 171 [32/50000]	Loss: 1.7555	LR: 0.002117
Training Epoch: 171 [32/50000]	Loss: 1.3445	LR: 0.002117
Training Epoch: 171 [32/50000]	Loss: 1.4434	LR: 0.002117
Training Epoch: 171 [32/50000]	Loss: 1.6030	LR: 0.002117
Training Epoch: 171 [32/50000]	Loss: 1.9322	LR: 0.002117
Training Epoch: 171 [32/50000]	Loss: 1.6431	LR: 0.002117
Evaluating Network.....
Test set: Epoch: 171, Average loss: 0.0510, Top1Accuracy: 0.5460, Top3Accuracy: 0.7594, Top5Accuracy: 0.8367, Time consumed:3.22s

Training Epoch: 172 [32/50000]	Loss: 1.4664	LR: 0.002061
Training Epoch: 172 [32/50000]	Loss: 1.8676	LR: 0.002061
Training Epoch: 172 [32/50000]	Loss: 1.4720	LR: 0.002061
Training Epoch: 172 [32/50000]	Loss: 2.0919	LR: 0.002061
Training Epoch: 172 [32/50000]	Loss: 1.1350	LR: 0.002061
Training Epoch: 172 [32/50000]	Loss: 1.1176	LR: 0.002061
Training Epoch: 172 [32/50000]	Loss: 1.8365	LR: 0.002061
Training Epoch: 172 [32/50000]	Loss: 1.4423	LR: 0.002061
Training Epoch: 172 [32/50000]	Loss: 1.5828	LR: 0.002061
Training Epoch: 172 [32/50000]	Loss: 1.3263	LR: 0.002061
Evaluating Network.....
Test set: Epoch: 172, Average loss: 0.0507, Top1Accuracy: 0.5462, Top3Accuracy: 0.7605, Top5Accuracy: 0.8377, Time consumed:2.71s

Training Epoch: 173 [32/50000]	Loss: 1.5347	LR: 0.002007
Training Epoch: 173 [32/50000]	Loss: 1.3830	LR: 0.002007
Training Epoch: 173 [32/50000]	Loss: 1.6508	LR: 0.002007
Training Epoch: 173 [32/50000]	Loss: 1.7933	LR: 0.002007
Training Epoch: 173 [32/50000]	Loss: 1.3795	LR: 0.002007
Training Epoch: 173 [32/50000]	Loss: 2.0874	LR: 0.002007
Training Epoch: 173 [32/50000]	Loss: 1.7772	LR: 0.002007
Training Epoch: 173 [32/50000]	Loss: 1.8069	LR: 0.002007
Training Epoch: 173 [32/50000]	Loss: 1.8750	LR: 0.002007
Training Epoch: 173 [32/50000]	Loss: 1.5669	LR: 0.002007
Evaluating Network.....
Test set: Epoch: 173, Average loss: 0.0508, Top1Accuracy: 0.5420, Top3Accuracy: 0.7614, Top5Accuracy: 0.8389, Time consumed:2.67s

Training Epoch: 174 [32/50000]	Loss: 1.4377	LR: 0.001954
Training Epoch: 174 [32/50000]	Loss: 1.7207	LR: 0.001954
Training Epoch: 174 [32/50000]	Loss: 2.0934	LR: 0.001954
Training Epoch: 174 [32/50000]	Loss: 1.2492	LR: 0.001954
Training Epoch: 174 [32/50000]	Loss: 1.5669	LR: 0.001954
Training Epoch: 174 [32/50000]	Loss: 1.8249	LR: 0.001954
Training Epoch: 174 [32/50000]	Loss: 1.7097	LR: 0.001954
Training Epoch: 174 [32/50000]	Loss: 1.4649	LR: 0.001954
Training Epoch: 174 [32/50000]	Loss: 1.2111	LR: 0.001954
Training Epoch: 174 [32/50000]	Loss: 1.8837	LR: 0.001954
Evaluating Network.....
Test set: Epoch: 174, Average loss: 0.0505, Top1Accuracy: 0.5483, Top3Accuracy: 0.7615, Top5Accuracy: 0.8374, Time consumed:2.66s

Training Epoch: 175 [32/50000]	Loss: 1.6177	LR: 0.001902
Training Epoch: 175 [32/50000]	Loss: 1.3922	LR: 0.001902
Training Epoch: 175 [32/50000]	Loss: 1.7747	LR: 0.001902
Training Epoch: 175 [32/50000]	Loss: 2.0308	LR: 0.001902
Training Epoch: 175 [32/50000]	Loss: 1.6096	LR: 0.001902
Training Epoch: 175 [32/50000]	Loss: 1.6107	LR: 0.001902
Training Epoch: 175 [32/50000]	Loss: 1.5693	LR: 0.001902
Training Epoch: 175 [32/50000]	Loss: 1.2370	LR: 0.001902
Training Epoch: 175 [32/50000]	Loss: 1.6518	LR: 0.001902
Training Epoch: 175 [32/50000]	Loss: 1.5473	LR: 0.001902
Evaluating Network.....
Test set: Epoch: 175, Average loss: 0.0506, Top1Accuracy: 0.5467, Top3Accuracy: 0.7607, Top5Accuracy: 0.8392, Time consumed:2.67s

Training Epoch: 176 [32/50000]	Loss: 1.7731	LR: 0.001852
Training Epoch: 176 [32/50000]	Loss: 1.4500	LR: 0.001852
Training Epoch: 176 [32/50000]	Loss: 1.1940	LR: 0.001852
Training Epoch: 176 [32/50000]	Loss: 1.3274	LR: 0.001852
Training Epoch: 176 [32/50000]	Loss: 1.6285	LR: 0.001852
Training Epoch: 176 [32/50000]	Loss: 1.7951	LR: 0.001852
Training Epoch: 176 [32/50000]	Loss: 2.3586	LR: 0.001852
Training Epoch: 176 [32/50000]	Loss: 1.6169	LR: 0.001852
Training Epoch: 176 [32/50000]	Loss: 2.1136	LR: 0.001852
Training Epoch: 176 [32/50000]	Loss: 1.2147	LR: 0.001852
Evaluating Network.....
Test set: Epoch: 176, Average loss: 0.0504, Top1Accuracy: 0.5485, Top3Accuracy: 0.7626, Top5Accuracy: 0.8389, Time consumed:2.61s

Training Epoch: 177 [32/50000]	Loss: 1.3405	LR: 0.001803
Training Epoch: 177 [32/50000]	Loss: 1.9140	LR: 0.001803
Training Epoch: 177 [32/50000]	Loss: 2.0123	LR: 0.001803
Training Epoch: 177 [32/50000]	Loss: 1.3942	LR: 0.001803
Training Epoch: 177 [32/50000]	Loss: 2.0142	LR: 0.001803
Training Epoch: 177 [32/50000]	Loss: 2.0269	LR: 0.001803
Training Epoch: 177 [32/50000]	Loss: 1.3896	LR: 0.001803
Training Epoch: 177 [32/50000]	Loss: 1.4311	LR: 0.001803
Training Epoch: 177 [32/50000]	Loss: 1.5240	LR: 0.001803
Training Epoch: 177 [32/50000]	Loss: 1.6500	LR: 0.001803
Evaluating Network.....
Test set: Epoch: 177, Average loss: 0.0502, Top1Accuracy: 0.5510, Top3Accuracy: 0.7636, Top5Accuracy: 0.8401, Time consumed:2.61s

Training Epoch: 178 [32/50000]	Loss: 1.5788	LR: 0.001755
Training Epoch: 178 [32/50000]	Loss: 1.7470	LR: 0.001755
Training Epoch: 178 [32/50000]	Loss: 1.9161	LR: 0.001755
Training Epoch: 178 [32/50000]	Loss: 1.7019	LR: 0.001755
Training Epoch: 178 [32/50000]	Loss: 1.5070	LR: 0.001755
Training Epoch: 178 [32/50000]	Loss: 1.8669	LR: 0.001755
Training Epoch: 178 [32/50000]	Loss: 1.4755	LR: 0.001755
Training Epoch: 178 [32/50000]	Loss: 1.4469	LR: 0.001755
Training Epoch: 178 [32/50000]	Loss: 1.7579	LR: 0.001755
Training Epoch: 178 [32/50000]	Loss: 1.9060	LR: 0.001755
Evaluating Network.....
Test set: Epoch: 178, Average loss: 0.0500, Top1Accuracy: 0.5539, Top3Accuracy: 0.7654, Top5Accuracy: 0.8423, Time consumed:2.73s

Training Epoch: 179 [32/50000]	Loss: 1.8395	LR: 0.001709
Training Epoch: 179 [32/50000]	Loss: 2.0388	LR: 0.001709
Training Epoch: 179 [32/50000]	Loss: 1.4533	LR: 0.001709
Training Epoch: 179 [32/50000]	Loss: 1.8358	LR: 0.001709
Training Epoch: 179 [32/50000]	Loss: 2.2944	LR: 0.001709
Training Epoch: 179 [32/50000]	Loss: 1.1065	LR: 0.001709
Training Epoch: 179 [32/50000]	Loss: 1.8111	LR: 0.001709
Training Epoch: 179 [32/50000]	Loss: 1.6498	LR: 0.001709
Training Epoch: 179 [32/50000]	Loss: 1.5444	LR: 0.001709
Training Epoch: 179 [32/50000]	Loss: 1.7419	LR: 0.001709
Evaluating Network.....
Test set: Epoch: 179, Average loss: 0.0502, Top1Accuracy: 0.5499, Top3Accuracy: 0.7636, Top5Accuracy: 0.8411, Time consumed:2.70s

Training Epoch: 180 [32/50000]	Loss: 1.4559	LR: 0.001664
Training Epoch: 180 [32/50000]	Loss: 1.6541	LR: 0.001664
Training Epoch: 180 [32/50000]	Loss: 1.5338	LR: 0.001664
Training Epoch: 180 [32/50000]	Loss: 1.3692	LR: 0.001664
Training Epoch: 180 [32/50000]	Loss: 1.1772	LR: 0.001664
Training Epoch: 180 [32/50000]	Loss: 1.2127	LR: 0.001664
Training Epoch: 180 [32/50000]	Loss: 1.6493	LR: 0.001664
Training Epoch: 180 [32/50000]	Loss: 1.9595	LR: 0.001664
Training Epoch: 180 [32/50000]	Loss: 1.2362	LR: 0.001664
Training Epoch: 180 [32/50000]	Loss: 1.8602	LR: 0.001664
Evaluating Network.....
Test set: Epoch: 180, Average loss: 0.0501, Top1Accuracy: 0.5495, Top3Accuracy: 0.7647, Top5Accuracy: 0.8405, Time consumed:2.73s

Training Epoch: 181 [32/50000]	Loss: 2.0301	LR: 0.001620
Training Epoch: 181 [32/50000]	Loss: 1.5053	LR: 0.001620
Training Epoch: 181 [32/50000]	Loss: 1.4050	LR: 0.001620
Training Epoch: 181 [32/50000]	Loss: 1.6280	LR: 0.001620
Training Epoch: 181 [32/50000]	Loss: 1.5355	LR: 0.001620
Training Epoch: 181 [32/50000]	Loss: 1.9126	LR: 0.001620
Training Epoch: 181 [32/50000]	Loss: 1.8540	LR: 0.001620
Training Epoch: 181 [32/50000]	Loss: 1.3096	LR: 0.001620
Training Epoch: 181 [32/50000]	Loss: 1.4309	LR: 0.001620
Training Epoch: 181 [32/50000]	Loss: 1.2258	LR: 0.001620
Evaluating Network.....
Test set: Epoch: 181, Average loss: 0.0500, Top1Accuracy: 0.5576, Top3Accuracy: 0.7653, Top5Accuracy: 0.8424, Time consumed:2.62s

Training Epoch: 182 [32/50000]	Loss: 1.6923	LR: 0.001577
Training Epoch: 182 [32/50000]	Loss: 1.6562	LR: 0.001577
Training Epoch: 182 [32/50000]	Loss: 1.7489	LR: 0.001577
Training Epoch: 182 [32/50000]	Loss: 1.1236	LR: 0.001577
Training Epoch: 182 [32/50000]	Loss: 1.4314	LR: 0.001577
Training Epoch: 182 [32/50000]	Loss: 1.6304	LR: 0.001577
Training Epoch: 182 [32/50000]	Loss: 1.5744	LR: 0.001577
Training Epoch: 182 [32/50000]	Loss: 1.5286	LR: 0.001577
Training Epoch: 182 [32/50000]	Loss: 1.7506	LR: 0.001577
Training Epoch: 182 [32/50000]	Loss: 1.6927	LR: 0.001577
Evaluating Network.....
Test set: Epoch: 182, Average loss: 0.0498, Top1Accuracy: 0.5545, Top3Accuracy: 0.7689, Top5Accuracy: 0.8417, Time consumed:2.95s

Training Epoch: 183 [32/50000]	Loss: 1.2667	LR: 0.001536
Training Epoch: 183 [32/50000]	Loss: 1.8446	LR: 0.001536
Training Epoch: 183 [32/50000]	Loss: 1.5999	LR: 0.001536
Training Epoch: 183 [32/50000]	Loss: 1.4559	LR: 0.001536
Training Epoch: 183 [32/50000]	Loss: 1.6655	LR: 0.001536
Training Epoch: 183 [32/50000]	Loss: 1.5432	LR: 0.001536
Training Epoch: 183 [32/50000]	Loss: 1.3276	LR: 0.001536
Training Epoch: 183 [32/50000]	Loss: 1.2455	LR: 0.001536
Training Epoch: 183 [32/50000]	Loss: 1.0039	LR: 0.001536
Training Epoch: 183 [32/50000]	Loss: 2.2199	LR: 0.001536
Evaluating Network.....
Test set: Epoch: 183, Average loss: 0.0495, Top1Accuracy: 0.5562, Top3Accuracy: 0.7678, Top5Accuracy: 0.8435, Time consumed:2.62s

Training Epoch: 184 [32/50000]	Loss: 1.8193	LR: 0.001495
Training Epoch: 184 [32/50000]	Loss: 1.5915	LR: 0.001495
Training Epoch: 184 [32/50000]	Loss: 1.9023	LR: 0.001495
Training Epoch: 184 [32/50000]	Loss: 1.7882	LR: 0.001495
Training Epoch: 184 [32/50000]	Loss: 1.7329	LR: 0.001495
Training Epoch: 184 [32/50000]	Loss: 0.9031	LR: 0.001495
Training Epoch: 184 [32/50000]	Loss: 1.5724	LR: 0.001495
Training Epoch: 184 [32/50000]	Loss: 1.3267	LR: 0.001495
Training Epoch: 184 [32/50000]	Loss: 2.3342	LR: 0.001495
Training Epoch: 184 [32/50000]	Loss: 1.7068	LR: 0.001495
Evaluating Network.....
Test set: Epoch: 184, Average loss: 0.0497, Top1Accuracy: 0.5553, Top3Accuracy: 0.7684, Top5Accuracy: 0.8419, Time consumed:2.74s

Training Epoch: 185 [32/50000]	Loss: 2.0987	LR: 0.001456
Training Epoch: 185 [32/50000]	Loss: 1.6844	LR: 0.001456
Training Epoch: 185 [32/50000]	Loss: 1.5123	LR: 0.001456
Training Epoch: 185 [32/50000]	Loss: 1.5993	LR: 0.001456
Training Epoch: 185 [32/50000]	Loss: 1.3476	LR: 0.001456
Training Epoch: 185 [32/50000]	Loss: 1.5632	LR: 0.001456
Training Epoch: 185 [32/50000]	Loss: 1.5432	LR: 0.001456
Training Epoch: 185 [32/50000]	Loss: 1.5924	LR: 0.001456
Training Epoch: 185 [32/50000]	Loss: 1.7568	LR: 0.001456
Training Epoch: 185 [32/50000]	Loss: 1.4573	LR: 0.001456
Evaluating Network.....
Test set: Epoch: 185, Average loss: 0.0496, Top1Accuracy: 0.5563, Top3Accuracy: 0.7686, Top5Accuracy: 0.8444, Time consumed:2.66s

Training Epoch: 186 [32/50000]	Loss: 1.7201	LR: 0.001417
Training Epoch: 186 [32/50000]	Loss: 1.8541	LR: 0.001417
Training Epoch: 186 [32/50000]	Loss: 1.5151	LR: 0.001417
Training Epoch: 186 [32/50000]	Loss: 1.9275	LR: 0.001417
Training Epoch: 186 [32/50000]	Loss: 1.5747	LR: 0.001417
Training Epoch: 186 [32/50000]	Loss: 1.6336	LR: 0.001417
Training Epoch: 186 [32/50000]	Loss: 1.9127	LR: 0.001417
Training Epoch: 186 [32/50000]	Loss: 1.7708	LR: 0.001417
Training Epoch: 186 [32/50000]	Loss: 1.1859	LR: 0.001417
Training Epoch: 186 [32/50000]	Loss: 1.7608	LR: 0.001417
Evaluating Network.....
Test set: Epoch: 186, Average loss: 0.0492, Top1Accuracy: 0.5591, Top3Accuracy: 0.7704, Top5Accuracy: 0.8455, Time consumed:2.66s

Training Epoch: 187 [32/50000]	Loss: 1.4729	LR: 0.001380
Training Epoch: 187 [32/50000]	Loss: 1.7620	LR: 0.001380
Training Epoch: 187 [32/50000]	Loss: 1.6529	LR: 0.001380
Training Epoch: 187 [32/50000]	Loss: 1.1420	LR: 0.001380
Training Epoch: 187 [32/50000]	Loss: 1.3549	LR: 0.001380
Training Epoch: 187 [32/50000]	Loss: 2.0097	LR: 0.001380
Training Epoch: 187 [32/50000]	Loss: 1.7052	LR: 0.001380
Training Epoch: 187 [32/50000]	Loss: 1.4254	LR: 0.001380
Training Epoch: 187 [32/50000]	Loss: 1.5795	LR: 0.001380
Training Epoch: 187 [32/50000]	Loss: 1.5127	LR: 0.001380
Evaluating Network.....
Test set: Epoch: 187, Average loss: 0.0493, Top1Accuracy: 0.5577, Top3Accuracy: 0.7703, Top5Accuracy: 0.8470, Time consumed:2.66s

Training Epoch: 188 [32/50000]	Loss: 1.1921	LR: 0.001343
Training Epoch: 188 [32/50000]	Loss: 1.3717	LR: 0.001343
Training Epoch: 188 [32/50000]	Loss: 1.7596	LR: 0.001343
Training Epoch: 188 [32/50000]	Loss: 1.7488	LR: 0.001343
Training Epoch: 188 [32/50000]	Loss: 1.2366	LR: 0.001343
Training Epoch: 188 [32/50000]	Loss: 1.5370	LR: 0.001343
Training Epoch: 188 [32/50000]	Loss: 1.6192	LR: 0.001343
Training Epoch: 188 [32/50000]	Loss: 1.6006	LR: 0.001343
Training Epoch: 188 [32/50000]	Loss: 1.6109	LR: 0.001343
Training Epoch: 188 [32/50000]	Loss: 1.2987	LR: 0.001343
Evaluating Network.....
Test set: Epoch: 188, Average loss: 0.0492, Top1Accuracy: 0.5620, Top3Accuracy: 0.7687, Top5Accuracy: 0.8464, Time consumed:2.62s

Training Epoch: 189 [32/50000]	Loss: 1.6146	LR: 0.001308
Training Epoch: 189 [32/50000]	Loss: 1.1306	LR: 0.001308
Training Epoch: 189 [32/50000]	Loss: 1.7319	LR: 0.001308
Training Epoch: 189 [32/50000]	Loss: 1.4790	LR: 0.001308
Training Epoch: 189 [32/50000]	Loss: 1.2171	LR: 0.001308
Training Epoch: 189 [32/50000]	Loss: 0.8904	LR: 0.001308
Training Epoch: 189 [32/50000]	Loss: 1.5421	LR: 0.001308
Training Epoch: 189 [32/50000]	Loss: 1.6594	LR: 0.001308
Training Epoch: 189 [32/50000]	Loss: 1.7727	LR: 0.001308
Training Epoch: 189 [32/50000]	Loss: 1.7273	LR: 0.001308
Evaluating Network.....
Test set: Epoch: 189, Average loss: 0.0492, Top1Accuracy: 0.5575, Top3Accuracy: 0.7703, Top5Accuracy: 0.8468, Time consumed:2.60s

Training Epoch: 190 [32/50000]	Loss: 1.6891	LR: 0.001273
Training Epoch: 190 [32/50000]	Loss: 2.1014	LR: 0.001273
Training Epoch: 190 [32/50000]	Loss: 0.7961	LR: 0.001273
Training Epoch: 190 [32/50000]	Loss: 1.5060	LR: 0.001273
Training Epoch: 190 [32/50000]	Loss: 1.1834	LR: 0.001273
Training Epoch: 190 [32/50000]	Loss: 1.7487	LR: 0.001273
Training Epoch: 190 [32/50000]	Loss: 2.1304	LR: 0.001273
Training Epoch: 190 [32/50000]	Loss: 1.2482	LR: 0.001273
Training Epoch: 190 [32/50000]	Loss: 1.4732	LR: 0.001273
Training Epoch: 190 [32/50000]	Loss: 1.4971	LR: 0.001273
Evaluating Network.....
Test set: Epoch: 190, Average loss: 0.0492, Top1Accuracy: 0.5605, Top3Accuracy: 0.7697, Top5Accuracy: 0.8452, Time consumed:2.62s

Training Epoch: 191 [32/50000]	Loss: 1.5482	LR: 0.001240
Training Epoch: 191 [32/50000]	Loss: 1.7100	LR: 0.001240
Training Epoch: 191 [32/50000]	Loss: 1.5770	LR: 0.001240
Training Epoch: 191 [32/50000]	Loss: 1.7950	LR: 0.001240
Training Epoch: 191 [32/50000]	Loss: 2.0652	LR: 0.001240
Training Epoch: 191 [32/50000]	Loss: 1.8319	LR: 0.001240
Training Epoch: 191 [32/50000]	Loss: 1.2971	LR: 0.001240
Training Epoch: 191 [32/50000]	Loss: 1.3294	LR: 0.001240
Training Epoch: 191 [32/50000]	Loss: 1.6660	LR: 0.001240
Training Epoch: 191 [32/50000]	Loss: 1.9804	LR: 0.001240
Evaluating Network.....
Test set: Epoch: 191, Average loss: 0.0492, Top1Accuracy: 0.5601, Top3Accuracy: 0.7705, Top5Accuracy: 0.8460, Time consumed:2.58s

Training Epoch: 192 [32/50000]	Loss: 1.6147	LR: 0.001207
Training Epoch: 192 [32/50000]	Loss: 1.9782	LR: 0.001207
Training Epoch: 192 [32/50000]	Loss: 1.6613	LR: 0.001207
Training Epoch: 192 [32/50000]	Loss: 1.4469	LR: 0.001207
Training Epoch: 192 [32/50000]	Loss: 1.5523	LR: 0.001207
Training Epoch: 192 [32/50000]	Loss: 1.6191	LR: 0.001207
Training Epoch: 192 [32/50000]	Loss: 1.4126	LR: 0.001207
Training Epoch: 192 [32/50000]	Loss: 2.1477	LR: 0.001207
Training Epoch: 192 [32/50000]	Loss: 1.4658	LR: 0.001207
Training Epoch: 192 [32/50000]	Loss: 1.4614	LR: 0.001207
Evaluating Network.....
Test set: Epoch: 192, Average loss: 0.0490, Top1Accuracy: 0.5622, Top3Accuracy: 0.7718, Top5Accuracy: 0.8465, Time consumed:2.96s

Training Epoch: 193 [32/50000]	Loss: 1.2127	LR: 0.001175
Training Epoch: 193 [32/50000]	Loss: 1.6531	LR: 0.001175
Training Epoch: 193 [32/50000]	Loss: 1.5689	LR: 0.001175
Training Epoch: 193 [32/50000]	Loss: 1.6500	LR: 0.001175
Training Epoch: 193 [32/50000]	Loss: 1.5774	LR: 0.001175
Training Epoch: 193 [32/50000]	Loss: 1.5218	LR: 0.001175
Training Epoch: 193 [32/50000]	Loss: 1.6908	LR: 0.001175
Training Epoch: 193 [32/50000]	Loss: 1.4320	LR: 0.001175
Training Epoch: 193 [32/50000]	Loss: 1.5493	LR: 0.001175
Training Epoch: 193 [32/50000]	Loss: 1.6737	LR: 0.001175
Evaluating Network.....
Test set: Epoch: 193, Average loss: 0.0487, Top1Accuracy: 0.5652, Top3Accuracy: 0.7751, Top5Accuracy: 0.8465, Time consumed:2.81s

Training Epoch: 194 [32/50000]	Loss: 1.9960	LR: 0.001144
Training Epoch: 194 [32/50000]	Loss: 1.3502	LR: 0.001144
Training Epoch: 194 [32/50000]	Loss: 1.7630	LR: 0.001144
Training Epoch: 194 [32/50000]	Loss: 1.7888	LR: 0.001144
Training Epoch: 194 [32/50000]	Loss: 1.6067	LR: 0.001144
Training Epoch: 194 [32/50000]	Loss: 1.2989	LR: 0.001144
Training Epoch: 194 [32/50000]	Loss: 1.2372	LR: 0.001144
Training Epoch: 194 [32/50000]	Loss: 2.1639	LR: 0.001144
Training Epoch: 194 [32/50000]	Loss: 1.4645	LR: 0.001144
Training Epoch: 194 [32/50000]	Loss: 1.3694	LR: 0.001144
Evaluating Network.....
Test set: Epoch: 194, Average loss: 0.0487, Top1Accuracy: 0.5640, Top3Accuracy: 0.7735, Top5Accuracy: 0.8472, Time consumed:2.66s

Training Epoch: 195 [32/50000]	Loss: 1.5186	LR: 0.001114
Training Epoch: 195 [32/50000]	Loss: 1.8119	LR: 0.001114
Training Epoch: 195 [32/50000]	Loss: 1.2559	LR: 0.001114
Training Epoch: 195 [32/50000]	Loss: 1.5202	LR: 0.001114
Training Epoch: 195 [32/50000]	Loss: 1.8431	LR: 0.001114
Training Epoch: 195 [32/50000]	Loss: 1.3321	LR: 0.001114
Training Epoch: 195 [32/50000]	Loss: 1.3688	LR: 0.001114
Training Epoch: 195 [32/50000]	Loss: 1.5913	LR: 0.001114
Training Epoch: 195 [32/50000]	Loss: 1.7118	LR: 0.001114
Training Epoch: 195 [32/50000]	Loss: 1.7770	LR: 0.001114
Evaluating Network.....
Test set: Epoch: 195, Average loss: 0.0487, Top1Accuracy: 0.5648, Top3Accuracy: 0.7741, Top5Accuracy: 0.8479, Time consumed:2.61s

Training Epoch: 196 [32/50000]	Loss: 1.7601	LR: 0.001085
Training Epoch: 196 [32/50000]	Loss: 1.5948	LR: 0.001085
Training Epoch: 196 [32/50000]	Loss: 1.5244	LR: 0.001085
Training Epoch: 196 [32/50000]	Loss: 1.3806	LR: 0.001085
Training Epoch: 196 [32/50000]	Loss: 1.7795	LR: 0.001085
Training Epoch: 196 [32/50000]	Loss: 1.3281	LR: 0.001085
Training Epoch: 196 [32/50000]	Loss: 1.3683	LR: 0.001085
Training Epoch: 196 [32/50000]	Loss: 1.2273	LR: 0.001085
Training Epoch: 196 [32/50000]	Loss: 1.5107	LR: 0.001085
Training Epoch: 196 [32/50000]	Loss: 1.3915	LR: 0.001085
Evaluating Network.....
Test set: Epoch: 196, Average loss: 0.0486, Top1Accuracy: 0.5660, Top3Accuracy: 0.7747, Top5Accuracy: 0.8511, Time consumed:2.68s

Training Epoch: 197 [32/50000]	Loss: 1.9611	LR: 0.001056
Training Epoch: 197 [32/50000]	Loss: 1.7047	LR: 0.001056
Training Epoch: 197 [32/50000]	Loss: 1.5413	LR: 0.001056
Training Epoch: 197 [32/50000]	Loss: 1.7980	LR: 0.001056
Training Epoch: 197 [32/50000]	Loss: 1.7720	LR: 0.001056
Training Epoch: 197 [32/50000]	Loss: 1.4884	LR: 0.001056
Training Epoch: 197 [32/50000]	Loss: 1.3978	LR: 0.001056
Training Epoch: 197 [32/50000]	Loss: 1.7700	LR: 0.001056
Training Epoch: 197 [32/50000]	Loss: 1.4320	LR: 0.001056
Training Epoch: 197 [32/50000]	Loss: 1.8466	LR: 0.001056
Evaluating Network.....
Test set: Epoch: 197, Average loss: 0.0485, Top1Accuracy: 0.5679, Top3Accuracy: 0.7734, Top5Accuracy: 0.8469, Time consumed:2.57s

Training Epoch: 198 [32/50000]	Loss: 1.4505	LR: 0.001028
Training Epoch: 198 [32/50000]	Loss: 1.4596	LR: 0.001028
Training Epoch: 198 [32/50000]	Loss: 1.4001	LR: 0.001028
Training Epoch: 198 [32/50000]	Loss: 1.5049	LR: 0.001028
Training Epoch: 198 [32/50000]	Loss: 1.5536	LR: 0.001028
Training Epoch: 198 [32/50000]	Loss: 1.5635	LR: 0.001028
Training Epoch: 198 [32/50000]	Loss: 1.7711	LR: 0.001028
Training Epoch: 198 [32/50000]	Loss: 1.2843	LR: 0.001028
Training Epoch: 198 [32/50000]	Loss: 2.1240	LR: 0.001028
Training Epoch: 198 [32/50000]	Loss: 1.5869	LR: 0.001028
Evaluating Network.....
Test set: Epoch: 198, Average loss: 0.0485, Top1Accuracy: 0.5643, Top3Accuracy: 0.7737, Top5Accuracy: 0.8492, Time consumed:2.66s

Training Epoch: 199 [32/50000]	Loss: 1.7870	LR: 0.001001
Training Epoch: 199 [32/50000]	Loss: 1.1502	LR: 0.001001
Training Epoch: 199 [32/50000]	Loss: 1.2080	LR: 0.001001
Training Epoch: 199 [32/50000]	Loss: 1.8251	LR: 0.001001
Training Epoch: 199 [32/50000]	Loss: 1.1915	LR: 0.001001
Training Epoch: 199 [32/50000]	Loss: 1.5785	LR: 0.001001
Training Epoch: 199 [32/50000]	Loss: 1.8289	LR: 0.001001
Training Epoch: 199 [32/50000]	Loss: 1.1606	LR: 0.001001
Training Epoch: 199 [32/50000]	Loss: 1.8021	LR: 0.001001
Training Epoch: 199 [32/50000]	Loss: 1.5231	LR: 0.001001
Evaluating Network.....
Test set: Epoch: 199, Average loss: 0.0485, Top1Accuracy: 0.5672, Top3Accuracy: 0.7732, Top5Accuracy: 0.8488, Time consumed:2.60s

Training Epoch: 200 [32/50000]	Loss: 1.4490	LR: 0.000974
Training Epoch: 200 [32/50000]	Loss: 1.5233	LR: 0.000974
Training Epoch: 200 [32/50000]	Loss: 1.7084	LR: 0.000974
Training Epoch: 200 [32/50000]	Loss: 1.5106	LR: 0.000974
Training Epoch: 200 [32/50000]	Loss: 2.0117	LR: 0.000974
Training Epoch: 200 [32/50000]	Loss: 1.6531	LR: 0.000974
Training Epoch: 200 [32/50000]	Loss: 1.4203	LR: 0.000974
Training Epoch: 200 [32/50000]	Loss: 1.6817	LR: 0.000974
Training Epoch: 200 [32/50000]	Loss: 1.3921	LR: 0.000974
Training Epoch: 200 [32/50000]	Loss: 1.8642	LR: 0.000974
Evaluating Network.....
Test set: Epoch: 200, Average loss: 0.0485, Top1Accuracy: 0.5652, Top3Accuracy: 0.7746, Top5Accuracy: 0.8470, Time consumed:2.70s

Training Epoch: 201 [32/50000]	Loss: 1.7946	LR: 0.000949
Training Epoch: 201 [32/50000]	Loss: 1.4010	LR: 0.000949
Training Epoch: 201 [32/50000]	Loss: 1.7375	LR: 0.000949
Training Epoch: 201 [32/50000]	Loss: 1.1995	LR: 0.000949
Training Epoch: 201 [32/50000]	Loss: 1.5151	LR: 0.000949
Training Epoch: 201 [32/50000]	Loss: 1.5535	LR: 0.000949
Training Epoch: 201 [32/50000]	Loss: 1.5196	LR: 0.000949
Training Epoch: 201 [32/50000]	Loss: 1.5490	LR: 0.000949
Training Epoch: 201 [32/50000]	Loss: 1.7115	LR: 0.000949
Training Epoch: 201 [32/50000]	Loss: 1.2315	LR: 0.000949
Evaluating Network.....
Test set: Epoch: 201, Average loss: 0.0484, Top1Accuracy: 0.5670, Top3Accuracy: 0.7740, Top5Accuracy: 0.8466, Time consumed:2.60s

Training Epoch: 202 [32/50000]	Loss: 1.6213	LR: 0.000924
Training Epoch: 202 [32/50000]	Loss: 1.5988	LR: 0.000924
Training Epoch: 202 [32/50000]	Loss: 1.2246	LR: 0.000924
Training Epoch: 202 [32/50000]	Loss: 2.2899	LR: 0.000924
Training Epoch: 202 [32/50000]	Loss: 1.6666	LR: 0.000924
Training Epoch: 202 [32/50000]	Loss: 1.8991	LR: 0.000924
Training Epoch: 202 [32/50000]	Loss: 1.5824	LR: 0.000924
Training Epoch: 202 [32/50000]	Loss: 1.4933	LR: 0.000924
Training Epoch: 202 [32/50000]	Loss: 1.9108	LR: 0.000924
Training Epoch: 202 [32/50000]	Loss: 1.3031	LR: 0.000924
Evaluating Network.....
Test set: Epoch: 202, Average loss: 0.0482, Top1Accuracy: 0.5662, Top3Accuracy: 0.7774, Top5Accuracy: 0.8492, Time consumed:2.87s

Training Epoch: 203 [32/50000]	Loss: 1.9063	LR: 0.000899
Training Epoch: 203 [32/50000]	Loss: 1.3007	LR: 0.000899
Training Epoch: 203 [32/50000]	Loss: 1.5084	LR: 0.000899
Training Epoch: 203 [32/50000]	Loss: 1.4232	LR: 0.000899
Training Epoch: 203 [32/50000]	Loss: 1.4467	LR: 0.000899
Training Epoch: 203 [32/50000]	Loss: 1.3883	LR: 0.000899
Training Epoch: 203 [32/50000]	Loss: 2.0182	LR: 0.000899
Training Epoch: 203 [32/50000]	Loss: 1.2398	LR: 0.000899
Training Epoch: 203 [32/50000]	Loss: 1.9760	LR: 0.000899
Training Epoch: 203 [32/50000]	Loss: 1.5858	LR: 0.000899
Evaluating Network.....
Test set: Epoch: 203, Average loss: 0.0483, Top1Accuracy: 0.5678, Top3Accuracy: 0.7751, Top5Accuracy: 0.8482, Time consumed:2.78s

Training Epoch: 204 [32/50000]	Loss: 1.5448	LR: 0.000876
Training Epoch: 204 [32/50000]	Loss: 1.8500	LR: 0.000876
Training Epoch: 204 [32/50000]	Loss: 0.8677	LR: 0.000876
Training Epoch: 204 [32/50000]	Loss: 1.3815	LR: 0.000876
Training Epoch: 204 [32/50000]	Loss: 1.4322	LR: 0.000876
Training Epoch: 204 [32/50000]	Loss: 1.0487	LR: 0.000876
Training Epoch: 204 [32/50000]	Loss: 1.6106	LR: 0.000876
Training Epoch: 204 [32/50000]	Loss: 1.8371	LR: 0.000876
Training Epoch: 204 [32/50000]	Loss: 1.4071	LR: 0.000876
Training Epoch: 204 [32/50000]	Loss: 1.2642	LR: 0.000876
Evaluating Network.....
Test set: Epoch: 204, Average loss: 0.0482, Top1Accuracy: 0.5652, Top3Accuracy: 0.7752, Top5Accuracy: 0.8496, Time consumed:2.58s

Training Epoch: 205 [32/50000]	Loss: 1.1315	LR: 0.000852
Training Epoch: 205 [32/50000]	Loss: 1.8851	LR: 0.000852
Training Epoch: 205 [32/50000]	Loss: 1.6382	LR: 0.000852
Training Epoch: 205 [32/50000]	Loss: 1.9324	LR: 0.000852
Training Epoch: 205 [32/50000]	Loss: 1.2917	LR: 0.000852
Training Epoch: 205 [32/50000]	Loss: 1.7924	LR: 0.000852
Training Epoch: 205 [32/50000]	Loss: 1.7643	LR: 0.000852
Training Epoch: 205 [32/50000]	Loss: 1.7841	LR: 0.000852
Training Epoch: 205 [32/50000]	Loss: 1.6243	LR: 0.000852
Training Epoch: 205 [32/50000]	Loss: 1.9093	LR: 0.000852
Evaluating Network.....
Test set: Epoch: 205, Average loss: 0.0482, Top1Accuracy: 0.5682, Top3Accuracy: 0.7755, Top5Accuracy: 0.8490, Time consumed:2.62s

Training Epoch: 206 [32/50000]	Loss: 1.6401	LR: 0.000830
Training Epoch: 206 [32/50000]	Loss: 1.2479	LR: 0.000830
Training Epoch: 206 [32/50000]	Loss: 1.4950	LR: 0.000830
Training Epoch: 206 [32/50000]	Loss: 1.4591	LR: 0.000830
Training Epoch: 206 [32/50000]	Loss: 1.7442	LR: 0.000830
Training Epoch: 206 [32/50000]	Loss: 1.5140	LR: 0.000830
Training Epoch: 206 [32/50000]	Loss: 1.6536	LR: 0.000830
Training Epoch: 206 [32/50000]	Loss: 1.8622	LR: 0.000830
Training Epoch: 206 [32/50000]	Loss: 1.6099	LR: 0.000830
Training Epoch: 206 [32/50000]	Loss: 1.4631	LR: 0.000830
Evaluating Network.....
Test set: Epoch: 206, Average loss: 0.0480, Top1Accuracy: 0.5687, Top3Accuracy: 0.7742, Top5Accuracy: 0.8509, Time consumed:2.59s

Training Epoch: 207 [32/50000]	Loss: 1.6956	LR: 0.000808
Training Epoch: 207 [32/50000]	Loss: 1.8931	LR: 0.000808
Training Epoch: 207 [32/50000]	Loss: 1.8731	LR: 0.000808
Training Epoch: 207 [32/50000]	Loss: 1.8953	LR: 0.000808
Training Epoch: 207 [32/50000]	Loss: 1.2237	LR: 0.000808
Training Epoch: 207 [32/50000]	Loss: 1.6831	LR: 0.000808
Training Epoch: 207 [32/50000]	Loss: 1.3599	LR: 0.000808
Training Epoch: 207 [32/50000]	Loss: 1.3711	LR: 0.000808
Training Epoch: 207 [32/50000]	Loss: 1.6824	LR: 0.000808
Training Epoch: 207 [32/50000]	Loss: 1.4865	LR: 0.000808
Evaluating Network.....
Test set: Epoch: 207, Average loss: 0.0480, Top1Accuracy: 0.5691, Top3Accuracy: 0.7776, Top5Accuracy: 0.8481, Time consumed:2.78s

Training Epoch: 208 [32/50000]	Loss: 1.6328	LR: 0.000787
Training Epoch: 208 [32/50000]	Loss: 1.3149	LR: 0.000787
Training Epoch: 208 [32/50000]	Loss: 1.8093	LR: 0.000787
Training Epoch: 208 [32/50000]	Loss: 1.5402	LR: 0.000787
Training Epoch: 208 [32/50000]	Loss: 1.4137	LR: 0.000787
Training Epoch: 208 [32/50000]	Loss: 1.8685	LR: 0.000787
Training Epoch: 208 [32/50000]	Loss: 1.5249	LR: 0.000787
Training Epoch: 208 [32/50000]	Loss: 1.5904	LR: 0.000787
Training Epoch: 208 [32/50000]	Loss: 1.3702	LR: 0.000787
Training Epoch: 208 [32/50000]	Loss: 1.5590	LR: 0.000787
Evaluating Network.....
Test set: Epoch: 208, Average loss: 0.0479, Top1Accuracy: 0.5686, Top3Accuracy: 0.7763, Top5Accuracy: 0.8508, Time consumed:2.65s

Training Epoch: 209 [32/50000]	Loss: 1.3967	LR: 0.000766
Training Epoch: 209 [32/50000]	Loss: 1.6901	LR: 0.000766
Training Epoch: 209 [32/50000]	Loss: 1.4898	LR: 0.000766
Training Epoch: 209 [32/50000]	Loss: 1.8705	LR: 0.000766
Training Epoch: 209 [32/50000]	Loss: 1.5728	LR: 0.000766
Training Epoch: 209 [32/50000]	Loss: 1.4337	LR: 0.000766
Training Epoch: 209 [32/50000]	Loss: 1.8276	LR: 0.000766
Training Epoch: 209 [32/50000]	Loss: 1.3382	LR: 0.000766
Training Epoch: 209 [32/50000]	Loss: 1.8707	LR: 0.000766
Training Epoch: 209 [32/50000]	Loss: 1.4554	LR: 0.000766
Evaluating Network.....
Test set: Epoch: 209, Average loss: 0.0480, Top1Accuracy: 0.5688, Top3Accuracy: 0.7775, Top5Accuracy: 0.8507, Time consumed:2.67s

Training Epoch: 210 [32/50000]	Loss: 1.5584	LR: 0.000746
Training Epoch: 210 [32/50000]	Loss: 1.1430	LR: 0.000746
Training Epoch: 210 [32/50000]	Loss: 1.1414	LR: 0.000746
Training Epoch: 210 [32/50000]	Loss: 1.7435	LR: 0.000746
Training Epoch: 210 [32/50000]	Loss: 1.4704	LR: 0.000746
Training Epoch: 210 [32/50000]	Loss: 1.5271	LR: 0.000746
Training Epoch: 210 [32/50000]	Loss: 2.1952	LR: 0.000746
Training Epoch: 210 [32/50000]	Loss: 1.6938	LR: 0.000746
Training Epoch: 210 [32/50000]	Loss: 1.5438	LR: 0.000746
Training Epoch: 210 [32/50000]	Loss: 1.4418	LR: 0.000746
Evaluating Network.....
Test set: Epoch: 210, Average loss: 0.0479, Top1Accuracy: 0.5714, Top3Accuracy: 0.7774, Top5Accuracy: 0.8507, Time consumed:2.63s

Training Epoch: 211 [32/50000]	Loss: 1.5208	LR: 0.000726
Training Epoch: 211 [32/50000]	Loss: 1.2119	LR: 0.000726
Training Epoch: 211 [32/50000]	Loss: 1.1461	LR: 0.000726
Training Epoch: 211 [32/50000]	Loss: 1.6647	LR: 0.000726
Training Epoch: 211 [32/50000]	Loss: 1.7043	LR: 0.000726
Training Epoch: 211 [32/50000]	Loss: 1.4725	LR: 0.000726
Training Epoch: 211 [32/50000]	Loss: 1.8748	LR: 0.000726
Training Epoch: 211 [32/50000]	Loss: 1.1674	LR: 0.000726
Training Epoch: 211 [32/50000]	Loss: 1.9954	LR: 0.000726
Training Epoch: 211 [32/50000]	Loss: 1.3726	LR: 0.000726
Evaluating Network.....
Test set: Epoch: 211, Average loss: 0.0479, Top1Accuracy: 0.5720, Top3Accuracy: 0.7772, Top5Accuracy: 0.8521, Time consumed:2.65s

Training Epoch: 212 [32/50000]	Loss: 2.2026	LR: 0.000707
Training Epoch: 212 [32/50000]	Loss: 1.4201	LR: 0.000707
Training Epoch: 212 [32/50000]	Loss: 1.0660	LR: 0.000707
Training Epoch: 212 [32/50000]	Loss: 1.6361	LR: 0.000707
Training Epoch: 212 [32/50000]	Loss: 1.2153	LR: 0.000707
Training Epoch: 212 [32/50000]	Loss: 2.0138	LR: 0.000707
Training Epoch: 212 [32/50000]	Loss: 1.2944	LR: 0.000707
Training Epoch: 212 [32/50000]	Loss: 1.5270	LR: 0.000707
Training Epoch: 212 [32/50000]	Loss: 1.6175	LR: 0.000707
Training Epoch: 212 [32/50000]	Loss: 1.4660	LR: 0.000707
Evaluating Network.....
Test set: Epoch: 212, Average loss: 0.0477, Top1Accuracy: 0.5694, Top3Accuracy: 0.7792, Top5Accuracy: 0.8527, Time consumed:2.62s

Training Epoch: 213 [32/50000]	Loss: 1.2952	LR: 0.000688
Training Epoch: 213 [32/50000]	Loss: 1.4113	LR: 0.000688
Training Epoch: 213 [32/50000]	Loss: 1.6856	LR: 0.000688
Training Epoch: 213 [32/50000]	Loss: 1.3452	LR: 0.000688
Training Epoch: 213 [32/50000]	Loss: 1.7728	LR: 0.000688
Training Epoch: 213 [32/50000]	Loss: 1.5706	LR: 0.000688
Training Epoch: 213 [32/50000]	Loss: 1.2363	LR: 0.000688
Training Epoch: 213 [32/50000]	Loss: 1.9794	LR: 0.000688
Training Epoch: 213 [32/50000]	Loss: 1.6728	LR: 0.000688
Training Epoch: 213 [32/50000]	Loss: 1.7912	LR: 0.000688
Evaluating Network.....
Test set: Epoch: 213, Average loss: 0.0476, Top1Accuracy: 0.5726, Top3Accuracy: 0.7782, Top5Accuracy: 0.8514, Time consumed:2.64s

Training Epoch: 214 [32/50000]	Loss: 1.5924	LR: 0.000670
Training Epoch: 214 [32/50000]	Loss: 1.6703	LR: 0.000670
Training Epoch: 214 [32/50000]	Loss: 1.4867	LR: 0.000670
Training Epoch: 214 [32/50000]	Loss: 1.3864	LR: 0.000670
Training Epoch: 214 [32/50000]	Loss: 1.3270	LR: 0.000670
Training Epoch: 214 [32/50000]	Loss: 1.6722	LR: 0.000670
Training Epoch: 214 [32/50000]	Loss: 1.7127	LR: 0.000670
Training Epoch: 214 [32/50000]	Loss: 1.2599	LR: 0.000670
Training Epoch: 214 [32/50000]	Loss: 1.4254	LR: 0.000670
Training Epoch: 214 [32/50000]	Loss: 1.4732	LR: 0.000670
Evaluating Network.....
Test set: Epoch: 214, Average loss: 0.0477, Top1Accuracy: 0.5715, Top3Accuracy: 0.7791, Top5Accuracy: 0.8534, Time consumed:2.73s

Training Epoch: 215 [32/50000]	Loss: 1.2989	LR: 0.000652
Training Epoch: 215 [32/50000]	Loss: 1.4221	LR: 0.000652
Training Epoch: 215 [32/50000]	Loss: 1.5455	LR: 0.000652
Training Epoch: 215 [32/50000]	Loss: 1.2854	LR: 0.000652
Training Epoch: 215 [32/50000]	Loss: 1.3620	LR: 0.000652
Training Epoch: 215 [32/50000]	Loss: 1.3651	LR: 0.000652
Training Epoch: 215 [32/50000]	Loss: 1.3385	LR: 0.000652
Training Epoch: 215 [32/50000]	Loss: 1.3385	LR: 0.000652
Training Epoch: 215 [32/50000]	Loss: 1.3338	LR: 0.000652
Training Epoch: 215 [32/50000]	Loss: 1.4287	LR: 0.000652
Evaluating Network.....
Test set: Epoch: 215, Average loss: 0.0476, Top1Accuracy: 0.5721, Top3Accuracy: 0.7821, Top5Accuracy: 0.8527, Time consumed:2.64s

Training Epoch: 216 [32/50000]	Loss: 1.5171	LR: 0.000635
Training Epoch: 216 [32/50000]	Loss: 1.2877	LR: 0.000635
Training Epoch: 216 [32/50000]	Loss: 1.7501	LR: 0.000635
Training Epoch: 216 [32/50000]	Loss: 1.5746	LR: 0.000635
Training Epoch: 216 [32/50000]	Loss: 1.6396	LR: 0.000635
Training Epoch: 216 [32/50000]	Loss: 1.5762	LR: 0.000635
Training Epoch: 216 [32/50000]	Loss: 1.4278	LR: 0.000635
Training Epoch: 216 [32/50000]	Loss: 1.4051	LR: 0.000635
Training Epoch: 216 [32/50000]	Loss: 1.5711	LR: 0.000635
Training Epoch: 216 [32/50000]	Loss: 2.0662	LR: 0.000635
Evaluating Network.....
Test set: Epoch: 216, Average loss: 0.0476, Top1Accuracy: 0.5711, Top3Accuracy: 0.7806, Top5Accuracy: 0.8527, Time consumed:2.60s

Training Epoch: 217 [32/50000]	Loss: 1.6423	LR: 0.000618
Training Epoch: 217 [32/50000]	Loss: 1.3709	LR: 0.000618
Training Epoch: 217 [32/50000]	Loss: 1.5581	LR: 0.000618
Training Epoch: 217 [32/50000]	Loss: 1.2805	LR: 0.000618
Training Epoch: 217 [32/50000]	Loss: 1.8134	LR: 0.000618
Training Epoch: 217 [32/50000]	Loss: 1.2754	LR: 0.000618
Training Epoch: 217 [32/50000]	Loss: 1.3644	LR: 0.000618
Training Epoch: 217 [32/50000]	Loss: 1.8952	LR: 0.000618
Training Epoch: 217 [32/50000]	Loss: 1.3699	LR: 0.000618
Training Epoch: 217 [32/50000]	Loss: 1.6159	LR: 0.000618
Evaluating Network.....
Test set: Epoch: 217, Average loss: 0.0477, Top1Accuracy: 0.5709, Top3Accuracy: 0.7771, Top5Accuracy: 0.8526, Time consumed:2.61s

Training Epoch: 218 [32/50000]	Loss: 2.1658	LR: 0.000602
Training Epoch: 218 [32/50000]	Loss: 1.0900	LR: 0.000602
Training Epoch: 218 [32/50000]	Loss: 1.7706	LR: 0.000602
Training Epoch: 218 [32/50000]	Loss: 1.3340	LR: 0.000602
Training Epoch: 218 [32/50000]	Loss: 1.6749	LR: 0.000602
Training Epoch: 218 [32/50000]	Loss: 1.7105	LR: 0.000602
Training Epoch: 218 [32/50000]	Loss: 1.0576	LR: 0.000602
Training Epoch: 218 [32/50000]	Loss: 1.6074	LR: 0.000602
Training Epoch: 218 [32/50000]	Loss: 1.7116	LR: 0.000602
Training Epoch: 218 [32/50000]	Loss: 1.5203	LR: 0.000602
Evaluating Network.....
Test set: Epoch: 218, Average loss: 0.0476, Top1Accuracy: 0.5741, Top3Accuracy: 0.7797, Top5Accuracy: 0.8519, Time consumed:2.67s

Training Epoch: 219 [32/50000]	Loss: 1.4802	LR: 0.000586
Training Epoch: 219 [32/50000]	Loss: 1.8168	LR: 0.000586
Training Epoch: 219 [32/50000]	Loss: 1.1749	LR: 0.000586
Training Epoch: 219 [32/50000]	Loss: 1.3628	LR: 0.000586
Training Epoch: 219 [32/50000]	Loss: 1.3511	LR: 0.000586
Training Epoch: 219 [32/50000]	Loss: 1.0036	LR: 0.000586
Training Epoch: 219 [32/50000]	Loss: 1.2367	LR: 0.000586
Training Epoch: 219 [32/50000]	Loss: 1.7762	LR: 0.000586
Training Epoch: 219 [32/50000]	Loss: 1.2802	LR: 0.000586
Training Epoch: 219 [32/50000]	Loss: 2.1136	LR: 0.000586
Evaluating Network.....
Test set: Epoch: 219, Average loss: 0.0474, Top1Accuracy: 0.5722, Top3Accuracy: 0.7815, Top5Accuracy: 0.8538, Time consumed:2.58s

Training Epoch: 220 [32/50000]	Loss: 1.4334	LR: 0.000571
Training Epoch: 220 [32/50000]	Loss: 1.1142	LR: 0.000571
Training Epoch: 220 [32/50000]	Loss: 1.7892	LR: 0.000571
Training Epoch: 220 [32/50000]	Loss: 1.2864	LR: 0.000571
Training Epoch: 220 [32/50000]	Loss: 2.2817	LR: 0.000571
Training Epoch: 220 [32/50000]	Loss: 1.2866	LR: 0.000571
Training Epoch: 220 [32/50000]	Loss: 1.4078	LR: 0.000571
Training Epoch: 220 [32/50000]	Loss: 1.6754	LR: 0.000571
Training Epoch: 220 [32/50000]	Loss: 1.3037	LR: 0.000571
Training Epoch: 220 [32/50000]	Loss: 1.3652	LR: 0.000571
Evaluating Network.....
Test set: Epoch: 220, Average loss: 0.0473, Top1Accuracy: 0.5722, Top3Accuracy: 0.7813, Top5Accuracy: 0.8530, Time consumed:2.58s

Training Epoch: 221 [32/50000]	Loss: 1.3728	LR: 0.000556
Training Epoch: 221 [32/50000]	Loss: 1.7198	LR: 0.000556
Training Epoch: 221 [32/50000]	Loss: 1.2174	LR: 0.000556
Training Epoch: 221 [32/50000]	Loss: 1.1514	LR: 0.000556
Training Epoch: 221 [32/50000]	Loss: 1.5968	LR: 0.000556
Training Epoch: 221 [32/50000]	Loss: 1.6390	LR: 0.000556
Training Epoch: 221 [32/50000]	Loss: 1.3097	LR: 0.000556
Training Epoch: 221 [32/50000]	Loss: 1.7289	LR: 0.000556
Training Epoch: 221 [32/50000]	Loss: 1.3254	LR: 0.000556
Training Epoch: 221 [32/50000]	Loss: 1.4796	LR: 0.000556
Evaluating Network.....
Test set: Epoch: 221, Average loss: 0.0473, Top1Accuracy: 0.5712, Top3Accuracy: 0.7819, Top5Accuracy: 0.8537, Time consumed:2.58s

Training Epoch: 222 [32/50000]	Loss: 1.3699	LR: 0.000541
Training Epoch: 222 [32/50000]	Loss: 1.7394	LR: 0.000541
Training Epoch: 222 [32/50000]	Loss: 1.3315	LR: 0.000541
Training Epoch: 222 [32/50000]	Loss: 1.5993	LR: 0.000541
Training Epoch: 222 [32/50000]	Loss: 1.4517	LR: 0.000541
Training Epoch: 222 [32/50000]	Loss: 1.7824	LR: 0.000541
Training Epoch: 222 [32/50000]	Loss: 1.6481	LR: 0.000541
Training Epoch: 222 [32/50000]	Loss: 1.7163	LR: 0.000541
Training Epoch: 222 [32/50000]	Loss: 1.2705	LR: 0.000541
Training Epoch: 222 [32/50000]	Loss: 1.5912	LR: 0.000541
Evaluating Network.....
Test set: Epoch: 222, Average loss: 0.0474, Top1Accuracy: 0.5732, Top3Accuracy: 0.7823, Top5Accuracy: 0.8527, Time consumed:2.55s

Training Epoch: 223 [32/50000]	Loss: 1.3239	LR: 0.000527
Training Epoch: 223 [32/50000]	Loss: 1.4210	LR: 0.000527
Training Epoch: 223 [32/50000]	Loss: 1.4250	LR: 0.000527
Training Epoch: 223 [32/50000]	Loss: 1.4457	LR: 0.000527
Training Epoch: 223 [32/50000]	Loss: 1.8492	LR: 0.000527
Training Epoch: 223 [32/50000]	Loss: 1.5034	LR: 0.000527
Training Epoch: 223 [32/50000]	Loss: 1.1306	LR: 0.000527
Training Epoch: 223 [32/50000]	Loss: 1.5866	LR: 0.000527
Training Epoch: 223 [32/50000]	Loss: 1.1994	LR: 0.000527
Training Epoch: 223 [32/50000]	Loss: 1.4653	LR: 0.000527
Evaluating Network.....
Test set: Epoch: 223, Average loss: 0.0474, Top1Accuracy: 0.5714, Top3Accuracy: 0.7819, Top5Accuracy: 0.8546, Time consumed:2.65s

Training Epoch: 224 [32/50000]	Loss: 1.1308	LR: 0.000513
Training Epoch: 224 [32/50000]	Loss: 1.4190	LR: 0.000513
Training Epoch: 224 [32/50000]	Loss: 1.4890	LR: 0.000513
Training Epoch: 224 [32/50000]	Loss: 1.2922	LR: 0.000513
Training Epoch: 224 [32/50000]	Loss: 1.6726	LR: 0.000513
Training Epoch: 224 [32/50000]	Loss: 1.1144	LR: 0.000513
Training Epoch: 224 [32/50000]	Loss: 1.2593	LR: 0.000513
Training Epoch: 224 [32/50000]	Loss: 1.4601	LR: 0.000513
Training Epoch: 224 [32/50000]	Loss: 1.4440	LR: 0.000513
Training Epoch: 224 [32/50000]	Loss: 1.3548	LR: 0.000513
Evaluating Network.....
Test set: Epoch: 224, Average loss: 0.0473, Top1Accuracy: 0.5742, Top3Accuracy: 0.7801, Top5Accuracy: 0.8536, Time consumed:2.63s

Training Epoch: 225 [32/50000]	Loss: 1.1975	LR: 0.000499
Training Epoch: 225 [32/50000]	Loss: 1.7286	LR: 0.000499
Training Epoch: 225 [32/50000]	Loss: 1.5897	LR: 0.000499
Training Epoch: 225 [32/50000]	Loss: 1.3964	LR: 0.000499
Training Epoch: 225 [32/50000]	Loss: 0.9401	LR: 0.000499
Training Epoch: 225 [32/50000]	Loss: 1.8267	LR: 0.000499
Training Epoch: 225 [32/50000]	Loss: 1.4281	LR: 0.000499
Training Epoch: 225 [32/50000]	Loss: 1.5719	LR: 0.000499
Training Epoch: 225 [32/50000]	Loss: 1.5910	LR: 0.000499
Training Epoch: 225 [32/50000]	Loss: 1.2412	LR: 0.000499
Evaluating Network.....
Test set: Epoch: 225, Average loss: 0.0474, Top1Accuracy: 0.5757, Top3Accuracy: 0.7816, Top5Accuracy: 0.8549, Time consumed:2.97s

Training Epoch: 226 [32/50000]	Loss: 1.6219	LR: 0.000486
Training Epoch: 226 [32/50000]	Loss: 1.3719	LR: 0.000486
Training Epoch: 226 [32/50000]	Loss: 1.1433	LR: 0.000486
Training Epoch: 226 [32/50000]	Loss: 1.3755	LR: 0.000486
Training Epoch: 226 [32/50000]	Loss: 1.2818	LR: 0.000486
Training Epoch: 226 [32/50000]	Loss: 1.6903	LR: 0.000486
Training Epoch: 226 [32/50000]	Loss: 1.7229	LR: 0.000486
Training Epoch: 226 [32/50000]	Loss: 1.3805	LR: 0.000486
Training Epoch: 226 [32/50000]	Loss: 1.4074	LR: 0.000486
Training Epoch: 226 [32/50000]	Loss: 1.6331	LR: 0.000486
Evaluating Network.....
Test set: Epoch: 226, Average loss: 0.0473, Top1Accuracy: 0.5750, Top3Accuracy: 0.7803, Top5Accuracy: 0.8538, Time consumed:2.63s

Training Epoch: 227 [32/50000]	Loss: 1.3109	LR: 0.000473
Training Epoch: 227 [32/50000]	Loss: 1.3266	LR: 0.000473
Training Epoch: 227 [32/50000]	Loss: 1.4934	LR: 0.000473
Training Epoch: 227 [32/50000]	Loss: 1.3179	LR: 0.000473
Training Epoch: 227 [32/50000]	Loss: 1.5583	LR: 0.000473
Training Epoch: 227 [32/50000]	Loss: 1.6223	LR: 0.000473
Training Epoch: 227 [32/50000]	Loss: 1.1143	LR: 0.000473
Training Epoch: 227 [32/50000]	Loss: 1.2060	LR: 0.000473
Training Epoch: 227 [32/50000]	Loss: 1.9951	LR: 0.000473
Training Epoch: 227 [32/50000]	Loss: 1.7672	LR: 0.000473
Evaluating Network.....
Test set: Epoch: 227, Average loss: 0.0473, Top1Accuracy: 0.5732, Top3Accuracy: 0.7831, Top5Accuracy: 0.8538, Time consumed:2.67s

Training Epoch: 228 [32/50000]	Loss: 1.4073	LR: 0.000461
Training Epoch: 228 [32/50000]	Loss: 2.0214	LR: 0.000461
Training Epoch: 228 [32/50000]	Loss: 1.4501	LR: 0.000461
Training Epoch: 228 [32/50000]	Loss: 1.8002	LR: 0.000461
Training Epoch: 228 [32/50000]	Loss: 1.4927	LR: 0.000461
Training Epoch: 228 [32/50000]	Loss: 1.7972	LR: 0.000461
Training Epoch: 228 [32/50000]	Loss: 1.4224	LR: 0.000461
Training Epoch: 228 [32/50000]	Loss: 1.4162	LR: 0.000461
Training Epoch: 228 [32/50000]	Loss: 1.4007	LR: 0.000461
Training Epoch: 228 [32/50000]	Loss: 1.6085	LR: 0.000461
Evaluating Network.....
Test set: Epoch: 228, Average loss: 0.0472, Top1Accuracy: 0.5755, Top3Accuracy: 0.7825, Top5Accuracy: 0.8562, Time consumed:2.66s

Training Epoch: 229 [32/50000]	Loss: 1.4964	LR: 0.000449
Training Epoch: 229 [32/50000]	Loss: 1.5126	LR: 0.000449
Training Epoch: 229 [32/50000]	Loss: 1.2613	LR: 0.000449
Training Epoch: 229 [32/50000]	Loss: 1.9326	LR: 0.000449
Training Epoch: 229 [32/50000]	Loss: 1.4893	LR: 0.000449
Training Epoch: 229 [32/50000]	Loss: 1.1642	LR: 0.000449
Training Epoch: 229 [32/50000]	Loss: 1.5427	LR: 0.000449
Training Epoch: 229 [32/50000]	Loss: 1.4432	LR: 0.000449
Training Epoch: 229 [32/50000]	Loss: 1.8330	LR: 0.000449
Training Epoch: 229 [32/50000]	Loss: 1.2524	LR: 0.000449
Evaluating Network.....
Test set: Epoch: 229, Average loss: 0.0473, Top1Accuracy: 0.5725, Top3Accuracy: 0.7835, Top5Accuracy: 0.8551, Time consumed:2.78s

Training Epoch: 230 [32/50000]	Loss: 1.2782	LR: 0.000437
Training Epoch: 230 [32/50000]	Loss: 1.8551	LR: 0.000437
Training Epoch: 230 [32/50000]	Loss: 1.3414	LR: 0.000437
Training Epoch: 230 [32/50000]	Loss: 1.1546	LR: 0.000437
Training Epoch: 230 [32/50000]	Loss: 1.6446	LR: 0.000437
Training Epoch: 230 [32/50000]	Loss: 1.6968	LR: 0.000437
Training Epoch: 230 [32/50000]	Loss: 1.4920	LR: 0.000437
Training Epoch: 230 [32/50000]	Loss: 1.5142	LR: 0.000437
Training Epoch: 230 [32/50000]	Loss: 1.4735	LR: 0.000437
Training Epoch: 230 [32/50000]	Loss: 1.7449	LR: 0.000437
Evaluating Network.....
Test set: Epoch: 230, Average loss: 0.0472, Top1Accuracy: 0.5751, Top3Accuracy: 0.7845, Top5Accuracy: 0.8557, Time consumed:2.67s

Training Epoch: 231 [32/50000]	Loss: 1.2729	LR: 0.000425
Training Epoch: 231 [32/50000]	Loss: 1.5088	LR: 0.000425
Training Epoch: 231 [32/50000]	Loss: 1.4631	LR: 0.000425
Training Epoch: 231 [32/50000]	Loss: 1.3797	LR: 0.000425
Training Epoch: 231 [32/50000]	Loss: 1.5570	LR: 0.000425
Training Epoch: 231 [32/50000]	Loss: 1.4468	LR: 0.000425
Training Epoch: 231 [32/50000]	Loss: 1.4183	LR: 0.000425
Training Epoch: 231 [32/50000]	Loss: 1.3507	LR: 0.000425
Training Epoch: 231 [32/50000]	Loss: 1.3379	LR: 0.000425
Training Epoch: 231 [32/50000]	Loss: 1.2946	LR: 0.000425
Evaluating Network.....
Test set: Epoch: 231, Average loss: 0.0472, Top1Accuracy: 0.5754, Top3Accuracy: 0.7826, Top5Accuracy: 0.8562, Time consumed:2.61s

Training Epoch: 232 [32/50000]	Loss: 1.3996	LR: 0.000414
Training Epoch: 232 [32/50000]	Loss: 1.0921	LR: 0.000414
Training Epoch: 232 [32/50000]	Loss: 1.5095	LR: 0.000414
Training Epoch: 232 [32/50000]	Loss: 1.9386	LR: 0.000414
Training Epoch: 232 [32/50000]	Loss: 1.0651	LR: 0.000414
Training Epoch: 232 [32/50000]	Loss: 1.6271	LR: 0.000414
Training Epoch: 232 [32/50000]	Loss: 1.4914	LR: 0.000414
Training Epoch: 232 [32/50000]	Loss: 1.3722	LR: 0.000414
Training Epoch: 232 [32/50000]	Loss: 1.7400	LR: 0.000414
Training Epoch: 232 [32/50000]	Loss: 1.5101	LR: 0.000414
Evaluating Network.....
Test set: Epoch: 232, Average loss: 0.0472, Top1Accuracy: 0.5751, Top3Accuracy: 0.7840, Top5Accuracy: 0.8555, Time consumed:2.62s

Training Epoch: 233 [32/50000]	Loss: 1.1214	LR: 0.000403
Training Epoch: 233 [32/50000]	Loss: 1.3815	LR: 0.000403
Training Epoch: 233 [32/50000]	Loss: 0.8260	LR: 0.000403
Training Epoch: 233 [32/50000]	Loss: 1.6207	LR: 0.000403
Training Epoch: 233 [32/50000]	Loss: 1.6300	LR: 0.000403
Training Epoch: 233 [32/50000]	Loss: 1.1303	LR: 0.000403
Training Epoch: 233 [32/50000]	Loss: 1.3942	LR: 0.000403
Training Epoch: 233 [32/50000]	Loss: 1.3536	LR: 0.000403
Training Epoch: 233 [32/50000]	Loss: 1.3355	LR: 0.000403
Training Epoch: 233 [32/50000]	Loss: 1.6814	LR: 0.000403
Evaluating Network.....
Test set: Epoch: 233, Average loss: 0.0471, Top1Accuracy: 0.5739, Top3Accuracy: 0.7849, Top5Accuracy: 0.8550, Time consumed:2.75s

Training Epoch: 234 [32/50000]	Loss: 1.7564	LR: 0.000392
Training Epoch: 234 [32/50000]	Loss: 1.6938	LR: 0.000392
Training Epoch: 234 [32/50000]	Loss: 1.4361	LR: 0.000392
Training Epoch: 234 [32/50000]	Loss: 1.9152	LR: 0.000392
Training Epoch: 234 [32/50000]	Loss: 1.5341	LR: 0.000392
Training Epoch: 234 [32/50000]	Loss: 1.4703	LR: 0.000392
Training Epoch: 234 [32/50000]	Loss: 1.0270	LR: 0.000392
Training Epoch: 234 [32/50000]	Loss: 1.5481	LR: 0.000392
Training Epoch: 234 [32/50000]	Loss: 1.5670	LR: 0.000392
Training Epoch: 234 [32/50000]	Loss: 1.4540	LR: 0.000392
Evaluating Network.....
Test set: Epoch: 234, Average loss: 0.0472, Top1Accuracy: 0.5768, Top3Accuracy: 0.7829, Top5Accuracy: 0.8559, Time consumed:2.63s

Training Epoch: 235 [32/50000]	Loss: 1.0830	LR: 0.000382
Training Epoch: 235 [32/50000]	Loss: 1.6611	LR: 0.000382
Training Epoch: 235 [32/50000]	Loss: 1.5275	LR: 0.000382
Training Epoch: 235 [32/50000]	Loss: 1.1592	LR: 0.000382
Training Epoch: 235 [32/50000]	Loss: 1.6540	LR: 0.000382
Training Epoch: 235 [32/50000]	Loss: 1.7760	LR: 0.000382
Training Epoch: 235 [32/50000]	Loss: 1.5924	LR: 0.000382
Training Epoch: 235 [32/50000]	Loss: 1.4801	LR: 0.000382
Training Epoch: 235 [32/50000]	Loss: 1.5915	LR: 0.000382
Training Epoch: 235 [32/50000]	Loss: 1.8074	LR: 0.000382
Evaluating Network.....
Test set: Epoch: 235, Average loss: 0.0471, Top1Accuracy: 0.5778, Top3Accuracy: 0.7834, Top5Accuracy: 0.8556, Time consumed:2.65s

Training Epoch: 236 [32/50000]	Loss: 1.1889	LR: 0.000372
Training Epoch: 236 [32/50000]	Loss: 1.6606	LR: 0.000372
Training Epoch: 236 [32/50000]	Loss: 1.3250	LR: 0.000372
Training Epoch: 236 [32/50000]	Loss: 1.6633	LR: 0.000372
Training Epoch: 236 [32/50000]	Loss: 1.1826	LR: 0.000372
Training Epoch: 236 [32/50000]	Loss: 1.8214	LR: 0.000372
Training Epoch: 236 [32/50000]	Loss: 1.4771	LR: 0.000372
Training Epoch: 236 [32/50000]	Loss: 1.5328	LR: 0.000372
Training Epoch: 236 [32/50000]	Loss: 1.6946	LR: 0.000372
Training Epoch: 236 [32/50000]	Loss: 1.5776	LR: 0.000372
Evaluating Network.....
Test set: Epoch: 236, Average loss: 0.0471, Top1Accuracy: 0.5750, Top3Accuracy: 0.7841, Top5Accuracy: 0.8552, Time consumed:2.64s

Training Epoch: 237 [32/50000]	Loss: 1.4709	LR: 0.000362
Training Epoch: 237 [32/50000]	Loss: 1.7201	LR: 0.000362
Training Epoch: 237 [32/50000]	Loss: 1.6178	LR: 0.000362
Training Epoch: 237 [32/50000]	Loss: 1.7758	LR: 0.000362
Training Epoch: 237 [32/50000]	Loss: 1.5414	LR: 0.000362
Training Epoch: 237 [32/50000]	Loss: 1.8520	LR: 0.000362
Training Epoch: 237 [32/50000]	Loss: 1.6281	LR: 0.000362
Training Epoch: 237 [32/50000]	Loss: 1.7371	LR: 0.000362
Training Epoch: 237 [32/50000]	Loss: 1.5122	LR: 0.000362
Training Epoch: 237 [32/50000]	Loss: 1.3121	LR: 0.000362
Evaluating Network.....
Test set: Epoch: 237, Average loss: 0.0471, Top1Accuracy: 0.5772, Top3Accuracy: 0.7832, Top5Accuracy: 0.8567, Time consumed:2.66s

Training Epoch: 238 [32/50000]	Loss: 1.5516	LR: 0.000353
Training Epoch: 238 [32/50000]	Loss: 1.6082	LR: 0.000353
Training Epoch: 238 [32/50000]	Loss: 1.9796	LR: 0.000353
Training Epoch: 238 [32/50000]	Loss: 1.0633	LR: 0.000353
Training Epoch: 238 [32/50000]	Loss: 1.3839	LR: 0.000353
Training Epoch: 238 [32/50000]	Loss: 1.2305	LR: 0.000353
Training Epoch: 238 [32/50000]	Loss: 2.0065	LR: 0.000353
Training Epoch: 238 [32/50000]	Loss: 1.7966	LR: 0.000353
Training Epoch: 238 [32/50000]	Loss: 1.7502	LR: 0.000353
Training Epoch: 238 [32/50000]	Loss: 1.5439	LR: 0.000353
Evaluating Network.....
Test set: Epoch: 238, Average loss: 0.0471, Top1Accuracy: 0.5757, Top3Accuracy: 0.7831, Top5Accuracy: 0.8556, Time consumed:2.61s

Training Epoch: 239 [32/50000]	Loss: 1.5372	LR: 0.000343
Training Epoch: 239 [32/50000]	Loss: 1.3099	LR: 0.000343
Training Epoch: 239 [32/50000]	Loss: 1.4653	LR: 0.000343
Training Epoch: 239 [32/50000]	Loss: 1.0457	LR: 0.000343
Training Epoch: 239 [32/50000]	Loss: 1.8351	LR: 0.000343
Training Epoch: 239 [32/50000]	Loss: 1.6023	LR: 0.000343
Training Epoch: 239 [32/50000]	Loss: 0.9787	LR: 0.000343
Training Epoch: 239 [32/50000]	Loss: 1.6187	LR: 0.000343
Training Epoch: 239 [32/50000]	Loss: 1.9455	LR: 0.000343
Training Epoch: 239 [32/50000]	Loss: 1.3739	LR: 0.000343
Evaluating Network.....
Test set: Epoch: 239, Average loss: 0.0470, Top1Accuracy: 0.5762, Top3Accuracy: 0.7853, Top5Accuracy: 0.8575, Time consumed:2.63s

Training Epoch: 240 [32/50000]	Loss: 1.2481	LR: 0.000334
Training Epoch: 240 [32/50000]	Loss: 1.4780	LR: 0.000334
Training Epoch: 240 [32/50000]	Loss: 1.9824	LR: 0.000334
Training Epoch: 240 [32/50000]	Loss: 1.5037	LR: 0.000334
Training Epoch: 240 [32/50000]	Loss: 1.0105	LR: 0.000334
Training Epoch: 240 [32/50000]	Loss: 1.4130	LR: 0.000334
Training Epoch: 240 [32/50000]	Loss: 1.1632	LR: 0.000334
Training Epoch: 240 [32/50000]	Loss: 1.5511	LR: 0.000334
Training Epoch: 240 [32/50000]	Loss: 1.1468	LR: 0.000334
Training Epoch: 240 [32/50000]	Loss: 1.4638	LR: 0.000334
Evaluating Network.....
Test set: Epoch: 240, Average loss: 0.0470, Top1Accuracy: 0.5792, Top3Accuracy: 0.7849, Top5Accuracy: 0.8573, Time consumed:2.69s

Training Epoch: 241 [32/50000]	Loss: 1.2672	LR: 0.000325
Training Epoch: 241 [32/50000]	Loss: 1.4079	LR: 0.000325
Training Epoch: 241 [32/50000]	Loss: 1.6072	LR: 0.000325
Training Epoch: 241 [32/50000]	Loss: 1.7392	LR: 0.000325
Training Epoch: 241 [32/50000]	Loss: 1.4112	LR: 0.000325
Training Epoch: 241 [32/50000]	Loss: 1.6355	LR: 0.000325
Training Epoch: 241 [32/50000]	Loss: 1.3845	LR: 0.000325
Training Epoch: 241 [32/50000]	Loss: 1.4272	LR: 0.000325
Training Epoch: 241 [32/50000]	Loss: 1.3540	LR: 0.000325
Training Epoch: 241 [32/50000]	Loss: 1.3776	LR: 0.000325
Evaluating Network.....
Test set: Epoch: 241, Average loss: 0.0470, Top1Accuracy: 0.5782, Top3Accuracy: 0.7838, Top5Accuracy: 0.8572, Time consumed:2.63s

Training Epoch: 242 [32/50000]	Loss: 1.7283	LR: 0.000317
Training Epoch: 242 [32/50000]	Loss: 1.3101	LR: 0.000317
Training Epoch: 242 [32/50000]	Loss: 1.0665	LR: 0.000317
Training Epoch: 242 [32/50000]	Loss: 1.9755	LR: 0.000317
Training Epoch: 242 [32/50000]	Loss: 1.8560	LR: 0.000317
Training Epoch: 242 [32/50000]	Loss: 0.8938	LR: 0.000317
Training Epoch: 242 [32/50000]	Loss: 2.0199	LR: 0.000317
Training Epoch: 242 [32/50000]	Loss: 1.2938	LR: 0.000317
Training Epoch: 242 [32/50000]	Loss: 1.7904	LR: 0.000317
Training Epoch: 242 [32/50000]	Loss: 1.2195	LR: 0.000317
Evaluating Network.....
Test set: Epoch: 242, Average loss: 0.0470, Top1Accuracy: 0.5774, Top3Accuracy: 0.7850, Top5Accuracy: 0.8579, Time consumed:2.62s

Training Epoch: 243 [32/50000]	Loss: 1.6396	LR: 0.000308
Training Epoch: 243 [32/50000]	Loss: 1.5646	LR: 0.000308
Training Epoch: 243 [32/50000]	Loss: 1.7877	LR: 0.000308
Training Epoch: 243 [32/50000]	Loss: 1.3960	LR: 0.000308
Training Epoch: 243 [32/50000]	Loss: 1.2562	LR: 0.000308
Training Epoch: 243 [32/50000]	Loss: 1.3981	LR: 0.000308
Training Epoch: 243 [32/50000]	Loss: 1.6634	LR: 0.000308
Training Epoch: 243 [32/50000]	Loss: 1.4049	LR: 0.000308
Training Epoch: 243 [32/50000]	Loss: 2.2653	LR: 0.000308
Training Epoch: 243 [32/50000]	Loss: 1.9662	LR: 0.000308
Evaluating Network.....
Test set: Epoch: 243, Average loss: 0.0470, Top1Accuracy: 0.5762, Top3Accuracy: 0.7841, Top5Accuracy: 0.8575, Time consumed:2.60s

Training Epoch: 244 [32/50000]	Loss: 1.4991	LR: 0.000300
Training Epoch: 244 [32/50000]	Loss: 1.3879	LR: 0.000300
Training Epoch: 244 [32/50000]	Loss: 1.6445	LR: 0.000300
Training Epoch: 244 [32/50000]	Loss: 1.4806	LR: 0.000300
Training Epoch: 244 [32/50000]	Loss: 0.9167	LR: 0.000300
Training Epoch: 244 [32/50000]	Loss: 1.9017	LR: 0.000300
Training Epoch: 244 [32/50000]	Loss: 1.2763	LR: 0.000300
Training Epoch: 244 [32/50000]	Loss: 1.5669	LR: 0.000300
Training Epoch: 244 [32/50000]	Loss: 1.0852	LR: 0.000300
Training Epoch: 244 [32/50000]	Loss: 1.4097	LR: 0.000300
Evaluating Network.....
Test set: Epoch: 244, Average loss: 0.0470, Top1Accuracy: 0.5784, Top3Accuracy: 0.7833, Top5Accuracy: 0.8573, Time consumed:2.65s

Training Epoch: 245 [32/50000]	Loss: 1.4264	LR: 0.000292
Training Epoch: 245 [32/50000]	Loss: 1.1933	LR: 0.000292
Training Epoch: 245 [32/50000]	Loss: 1.4198	LR: 0.000292
Training Epoch: 245 [32/50000]	Loss: 1.8172	LR: 0.000292
Training Epoch: 245 [32/50000]	Loss: 1.2922	LR: 0.000292
Training Epoch: 245 [32/50000]	Loss: 1.2784	LR: 0.000292
Training Epoch: 245 [32/50000]	Loss: 0.8714	LR: 0.000292
Training Epoch: 245 [32/50000]	Loss: 1.8419	LR: 0.000292
Training Epoch: 245 [32/50000]	Loss: 1.6140	LR: 0.000292
Training Epoch: 245 [32/50000]	Loss: 1.5012	LR: 0.000292
Evaluating Network.....
Test set: Epoch: 245, Average loss: 0.0469, Top1Accuracy: 0.5788, Top3Accuracy: 0.7831, Top5Accuracy: 0.8573, Time consumed:2.80s

Training Epoch: 246 [32/50000]	Loss: 1.5434	LR: 0.000285
Training Epoch: 246 [32/50000]	Loss: 1.4291	LR: 0.000285
Training Epoch: 246 [32/50000]	Loss: 1.4612	LR: 0.000285
Training Epoch: 246 [32/50000]	Loss: 1.1110	LR: 0.000285
Training Epoch: 246 [32/50000]	Loss: 1.5538	LR: 0.000285
Training Epoch: 246 [32/50000]	Loss: 1.5340	LR: 0.000285
Training Epoch: 246 [32/50000]	Loss: 1.3519	LR: 0.000285
Training Epoch: 246 [32/50000]	Loss: 1.5178	LR: 0.000285
Training Epoch: 246 [32/50000]	Loss: 1.8429	LR: 0.000285
Training Epoch: 246 [32/50000]	Loss: 1.2406	LR: 0.000285
Evaluating Network.....
Test set: Epoch: 246, Average loss: 0.0470, Top1Accuracy: 0.5777, Top3Accuracy: 0.7844, Top5Accuracy: 0.8562, Time consumed:2.65s

Training Epoch: 247 [32/50000]	Loss: 1.4545	LR: 0.000277
Training Epoch: 247 [32/50000]	Loss: 1.3325	LR: 0.000277
Training Epoch: 247 [32/50000]	Loss: 1.6341	LR: 0.000277
Training Epoch: 247 [32/50000]	Loss: 1.2212	LR: 0.000277
Training Epoch: 247 [32/50000]	Loss: 0.9513	LR: 0.000277
Training Epoch: 247 [32/50000]	Loss: 1.0683	LR: 0.000277
Training Epoch: 247 [32/50000]	Loss: 1.3983	LR: 0.000277
Training Epoch: 247 [32/50000]	Loss: 1.7112	LR: 0.000277
Training Epoch: 247 [32/50000]	Loss: 2.1528	LR: 0.000277
Training Epoch: 247 [32/50000]	Loss: 1.4063	LR: 0.000277
Evaluating Network.....
Test set: Epoch: 247, Average loss: 0.0469, Top1Accuracy: 0.5761, Top3Accuracy: 0.7851, Top5Accuracy: 0.8569, Time consumed:2.65s

Training Epoch: 248 [32/50000]	Loss: 1.3184	LR: 0.000270
Training Epoch: 248 [32/50000]	Loss: 1.4181	LR: 0.000270
Training Epoch: 248 [32/50000]	Loss: 1.7763	LR: 0.000270
Training Epoch: 248 [32/50000]	Loss: 1.3873	LR: 0.000270
Training Epoch: 248 [32/50000]	Loss: 1.0051	LR: 0.000270
Training Epoch: 248 [32/50000]	Loss: 1.6306	LR: 0.000270
Training Epoch: 248 [32/50000]	Loss: 1.4579	LR: 0.000270
Training Epoch: 248 [32/50000]	Loss: 1.2385	LR: 0.000270
Training Epoch: 248 [32/50000]	Loss: 1.3586	LR: 0.000270
Training Epoch: 248 [32/50000]	Loss: 1.5260	LR: 0.000270
Evaluating Network.....
Test set: Epoch: 248, Average loss: 0.0469, Top1Accuracy: 0.5774, Top3Accuracy: 0.7844, Top5Accuracy: 0.8564, Time consumed:2.62s

Training Epoch: 249 [32/50000]	Loss: 1.3442	LR: 0.000263
Training Epoch: 249 [32/50000]	Loss: 1.3124	LR: 0.000263
Training Epoch: 249 [32/50000]	Loss: 1.2873	LR: 0.000263
Training Epoch: 249 [32/50000]	Loss: 1.7217	LR: 0.000263
Training Epoch: 249 [32/50000]	Loss: 1.0530	LR: 0.000263
Training Epoch: 249 [32/50000]	Loss: 1.2797	LR: 0.000263
Training Epoch: 249 [32/50000]	Loss: 1.5129	LR: 0.000263
Training Epoch: 249 [32/50000]	Loss: 1.3842	LR: 0.000263
Training Epoch: 249 [32/50000]	Loss: 1.4382	LR: 0.000263
Training Epoch: 249 [32/50000]	Loss: 1.3819	LR: 0.000263
Evaluating Network.....
Test set: Epoch: 249, Average loss: 0.0468, Top1Accuracy: 0.5774, Top3Accuracy: 0.7840, Top5Accuracy: 0.8560, Time consumed:2.69s

Training Epoch: 250 [32/50000]	Loss: 1.8913	LR: 0.000256
Training Epoch: 250 [32/50000]	Loss: 1.4198	LR: 0.000256
Training Epoch: 250 [32/50000]	Loss: 1.6664	LR: 0.000256
Training Epoch: 250 [32/50000]	Loss: 1.5457	LR: 0.000256
Training Epoch: 250 [32/50000]	Loss: 1.1781	LR: 0.000256
Training Epoch: 250 [32/50000]	Loss: 1.6523	LR: 0.000256
Training Epoch: 250 [32/50000]	Loss: 1.4436	LR: 0.000256
Training Epoch: 250 [32/50000]	Loss: 1.7667	LR: 0.000256
Training Epoch: 250 [32/50000]	Loss: 1.4685	LR: 0.000256
Training Epoch: 250 [32/50000]	Loss: 2.3758	LR: 0.000256
Evaluating Network.....
Test set: Epoch: 250, Average loss: 0.0468, Top1Accuracy: 0.5773, Top3Accuracy: 0.7869, Top5Accuracy: 0.8577, Time consumed:2.68s

Training Epoch: 251 [32/50000]	Loss: 1.4371	LR: 0.000249
Training Epoch: 251 [32/50000]	Loss: 1.6026	LR: 0.000249
Training Epoch: 251 [32/50000]	Loss: 1.9092	LR: 0.000249
Training Epoch: 251 [32/50000]	Loss: 1.3928	LR: 0.000249
Training Epoch: 251 [32/50000]	Loss: 1.8438	LR: 0.000249
Training Epoch: 251 [32/50000]	Loss: 1.4184	LR: 0.000249
Training Epoch: 251 [32/50000]	Loss: 1.6148	LR: 0.000249
Training Epoch: 251 [32/50000]	Loss: 0.9561	LR: 0.000249
Training Epoch: 251 [32/50000]	Loss: 1.2302	LR: 0.000249
Training Epoch: 251 [32/50000]	Loss: 1.5365	LR: 0.000249
Evaluating Network.....
Test set: Epoch: 251, Average loss: 0.0468, Top1Accuracy: 0.5794, Top3Accuracy: 0.7844, Top5Accuracy: 0.8575, Time consumed:2.65s

Training Epoch: 252 [32/50000]	Loss: 1.3495	LR: 0.000242
Training Epoch: 252 [32/50000]	Loss: 1.3286	LR: 0.000242
Training Epoch: 252 [32/50000]	Loss: 1.5361	LR: 0.000242
Training Epoch: 252 [32/50000]	Loss: 1.6669	LR: 0.000242
Training Epoch: 252 [32/50000]	Loss: 1.7073	LR: 0.000242
Training Epoch: 252 [32/50000]	Loss: 1.5857	LR: 0.000242
Training Epoch: 252 [32/50000]	Loss: 1.3704	LR: 0.000242
Training Epoch: 252 [32/50000]	Loss: 2.0486	LR: 0.000242
Training Epoch: 252 [32/50000]	Loss: 1.6676	LR: 0.000242
Training Epoch: 252 [32/50000]	Loss: 1.5924	LR: 0.000242
Evaluating Network.....
Test set: Epoch: 252, Average loss: 0.0469, Top1Accuracy: 0.5805, Top3Accuracy: 0.7843, Top5Accuracy: 0.8575, Time consumed:2.66s

Training Epoch: 253 [32/50000]	Loss: 1.5849	LR: 0.000236
Training Epoch: 253 [32/50000]	Loss: 1.2432	LR: 0.000236
Training Epoch: 253 [32/50000]	Loss: 1.7750	LR: 0.000236
Training Epoch: 253 [32/50000]	Loss: 1.8236	LR: 0.000236
Training Epoch: 253 [32/50000]	Loss: 1.3638	LR: 0.000236
Training Epoch: 253 [32/50000]	Loss: 1.5206	LR: 0.000236
Training Epoch: 253 [32/50000]	Loss: 1.2095	LR: 0.000236
Training Epoch: 253 [32/50000]	Loss: 1.2642	LR: 0.000236
Training Epoch: 253 [32/50000]	Loss: 1.6520	LR: 0.000236
Training Epoch: 253 [32/50000]	Loss: 1.4577	LR: 0.000236
Evaluating Network.....
Test set: Epoch: 253, Average loss: 0.0468, Top1Accuracy: 0.5788, Top3Accuracy: 0.7852, Top5Accuracy: 0.8578, Time consumed:2.61s

Training Epoch: 254 [32/50000]	Loss: 1.4733	LR: 0.000230
Training Epoch: 254 [32/50000]	Loss: 1.4654	LR: 0.000230
Training Epoch: 254 [32/50000]	Loss: 1.7728	LR: 0.000230
Training Epoch: 254 [32/50000]	Loss: 1.4603	LR: 0.000230
Training Epoch: 254 [32/50000]	Loss: 1.6036	LR: 0.000230
Training Epoch: 254 [32/50000]	Loss: 1.6992	LR: 0.000230
Training Epoch: 254 [32/50000]	Loss: 1.5734	LR: 0.000230
Training Epoch: 254 [32/50000]	Loss: 1.7048	LR: 0.000230
Training Epoch: 254 [32/50000]	Loss: 1.6274	LR: 0.000230
Training Epoch: 254 [32/50000]	Loss: 1.1320	LR: 0.000230
Evaluating Network.....
Test set: Epoch: 254, Average loss: 0.0468, Top1Accuracy: 0.5794, Top3Accuracy: 0.7857, Top5Accuracy: 0.8585, Time consumed:2.62s

Training Epoch: 255 [32/50000]	Loss: 1.9245	LR: 0.000224
Training Epoch: 255 [32/50000]	Loss: 1.7017	LR: 0.000224
Training Epoch: 255 [32/50000]	Loss: 1.2461	LR: 0.000224
Training Epoch: 255 [32/50000]	Loss: 1.5559	LR: 0.000224
Training Epoch: 255 [32/50000]	Loss: 1.4297	LR: 0.000224
Training Epoch: 255 [32/50000]	Loss: 1.2934	LR: 0.000224
Training Epoch: 255 [32/50000]	Loss: 1.0414	LR: 0.000224
Training Epoch: 255 [32/50000]	Loss: 1.0052	LR: 0.000224
Training Epoch: 255 [32/50000]	Loss: 1.4950	LR: 0.000224
Training Epoch: 255 [32/50000]	Loss: 1.6727	LR: 0.000224
Evaluating Network.....
Test set: Epoch: 255, Average loss: 0.0468, Top1Accuracy: 0.5777, Top3Accuracy: 0.7860, Top5Accuracy: 0.8570, Time consumed:2.96s

Training Epoch: 256 [32/50000]	Loss: 1.1117	LR: 0.000218
Training Epoch: 256 [32/50000]	Loss: 1.5703	LR: 0.000218
Training Epoch: 256 [32/50000]	Loss: 1.4510	LR: 0.000218
Training Epoch: 256 [32/50000]	Loss: 1.2474	LR: 0.000218
Training Epoch: 256 [32/50000]	Loss: 1.2344	LR: 0.000218
Training Epoch: 256 [32/50000]	Loss: 0.8466	LR: 0.000218
Training Epoch: 256 [32/50000]	Loss: 1.4634	LR: 0.000218
Training Epoch: 256 [32/50000]	Loss: 1.5728	LR: 0.000218
Training Epoch: 256 [32/50000]	Loss: 1.4356	LR: 0.000218
Training Epoch: 256 [32/50000]	Loss: 1.2068	LR: 0.000218
Evaluating Network.....
Test set: Epoch: 256, Average loss: 0.0469, Top1Accuracy: 0.5798, Top3Accuracy: 0.7835, Top5Accuracy: 0.8580, Time consumed:2.66s

Training Epoch: 257 [32/50000]	Loss: 1.3622	LR: 0.000212
Training Epoch: 257 [32/50000]	Loss: 1.4426	LR: 0.000212
Training Epoch: 257 [32/50000]	Loss: 1.4489	LR: 0.000212
Training Epoch: 257 [32/50000]	Loss: 1.2669	LR: 0.000212
Training Epoch: 257 [32/50000]	Loss: 1.2650	LR: 0.000212
Training Epoch: 257 [32/50000]	Loss: 1.3633	LR: 0.000212
Training Epoch: 257 [32/50000]	Loss: 1.3009	LR: 0.000212
Training Epoch: 257 [32/50000]	Loss: 1.6961	LR: 0.000212
Training Epoch: 257 [32/50000]	Loss: 1.7467	LR: 0.000212
Training Epoch: 257 [32/50000]	Loss: 1.6693	LR: 0.000212
Evaluating Network.....
Test set: Epoch: 257, Average loss: 0.0467, Top1Accuracy: 0.5799, Top3Accuracy: 0.7864, Top5Accuracy: 0.8583, Time consumed:2.66s

Training Epoch: 258 [32/50000]	Loss: 1.0524	LR: 0.000206
Training Epoch: 258 [32/50000]	Loss: 1.4323	LR: 0.000206
Training Epoch: 258 [32/50000]	Loss: 1.8863	LR: 0.000206
Training Epoch: 258 [32/50000]	Loss: 1.2976	LR: 0.000206
Training Epoch: 258 [32/50000]	Loss: 1.3434	LR: 0.000206
Training Epoch: 258 [32/50000]	Loss: 1.3310	LR: 0.000206
Training Epoch: 258 [32/50000]	Loss: 1.5883	LR: 0.000206
Training Epoch: 258 [32/50000]	Loss: 1.4784	LR: 0.000206
Training Epoch: 258 [32/50000]	Loss: 1.5766	LR: 0.000206
Training Epoch: 258 [32/50000]	Loss: 1.3746	LR: 0.000206
Evaluating Network.....
Test set: Epoch: 258, Average loss: 0.0468, Top1Accuracy: 0.5776, Top3Accuracy: 0.7849, Top5Accuracy: 0.8580, Time consumed:2.66s

Training Epoch: 259 [32/50000]	Loss: 1.5141	LR: 0.000201
Training Epoch: 259 [32/50000]	Loss: 1.1604	LR: 0.000201
Training Epoch: 259 [32/50000]	Loss: 0.9958	LR: 0.000201
Training Epoch: 259 [32/50000]	Loss: 1.3700	LR: 0.000201
Training Epoch: 259 [32/50000]	Loss: 1.1425	LR: 0.000201
Training Epoch: 259 [32/50000]	Loss: 1.5777	LR: 0.000201
Training Epoch: 259 [32/50000]	Loss: 1.2976	LR: 0.000201
Training Epoch: 259 [32/50000]	Loss: 1.6617	LR: 0.000201
Training Epoch: 259 [32/50000]	Loss: 1.5834	LR: 0.000201
Training Epoch: 259 [32/50000]	Loss: 1.1065	LR: 0.000201
Evaluating Network.....
Test set: Epoch: 259, Average loss: 0.0467, Top1Accuracy: 0.5799, Top3Accuracy: 0.7862, Top5Accuracy: 0.8575, Time consumed:2.61s

Training Epoch: 260 [32/50000]	Loss: 1.1055	LR: 0.000196
Training Epoch: 260 [32/50000]	Loss: 1.6375	LR: 0.000196
Training Epoch: 260 [32/50000]	Loss: 1.4212	LR: 0.000196
Training Epoch: 260 [32/50000]	Loss: 1.3885	LR: 0.000196
Training Epoch: 260 [32/50000]	Loss: 1.9197	LR: 0.000196
Training Epoch: 260 [32/50000]	Loss: 1.6754	LR: 0.000196
Training Epoch: 260 [32/50000]	Loss: 1.9105	LR: 0.000196
Training Epoch: 260 [32/50000]	Loss: 1.3334	LR: 0.000196
Training Epoch: 260 [32/50000]	Loss: 1.4501	LR: 0.000196
Training Epoch: 260 [32/50000]	Loss: 1.5964	LR: 0.000196
Evaluating Network.....
Test set: Epoch: 260, Average loss: 0.0467, Top1Accuracy: 0.5783, Top3Accuracy: 0.7863, Top5Accuracy: 0.8578, Time consumed:2.63s

Training Epoch: 261 [32/50000]	Loss: 1.4992	LR: 0.000191
Training Epoch: 261 [32/50000]	Loss: 1.3168	LR: 0.000191
Training Epoch: 261 [32/50000]	Loss: 1.0793	LR: 0.000191
Training Epoch: 261 [32/50000]	Loss: 1.6060	LR: 0.000191
Training Epoch: 261 [32/50000]	Loss: 1.1126	LR: 0.000191
Training Epoch: 261 [32/50000]	Loss: 1.1968	LR: 0.000191
Training Epoch: 261 [32/50000]	Loss: 1.2917	LR: 0.000191
Training Epoch: 261 [32/50000]	Loss: 1.6318	LR: 0.000191
Training Epoch: 261 [32/50000]	Loss: 1.5144	LR: 0.000191
Training Epoch: 261 [32/50000]	Loss: 1.4193	LR: 0.000191
Evaluating Network.....
Test set: Epoch: 261, Average loss: 0.0466, Top1Accuracy: 0.5788, Top3Accuracy: 0.7857, Top5Accuracy: 0.8584, Time consumed:2.63s

Training Epoch: 262 [32/50000]	Loss: 1.6002	LR: 0.000186
Training Epoch: 262 [32/50000]	Loss: 1.5557	LR: 0.000186
Training Epoch: 262 [32/50000]	Loss: 1.2088	LR: 0.000186
Training Epoch: 262 [32/50000]	Loss: 1.5355	LR: 0.000186
Training Epoch: 262 [32/50000]	Loss: 1.6329	LR: 0.000186
Training Epoch: 262 [32/50000]	Loss: 1.7434	LR: 0.000186
Training Epoch: 262 [32/50000]	Loss: 1.7618	LR: 0.000186
Training Epoch: 262 [32/50000]	Loss: 1.7641	LR: 0.000186
Training Epoch: 262 [32/50000]	Loss: 1.6610	LR: 0.000186
Training Epoch: 262 [32/50000]	Loss: 1.6248	LR: 0.000186
Evaluating Network.....
Test set: Epoch: 262, Average loss: 0.0467, Top1Accuracy: 0.5805, Top3Accuracy: 0.7862, Top5Accuracy: 0.8578, Time consumed:2.61s

Training Epoch: 263 [32/50000]	Loss: 0.9049	LR: 0.000181
Training Epoch: 263 [32/50000]	Loss: 1.1921	LR: 0.000181
Training Epoch: 263 [32/50000]	Loss: 1.7193	LR: 0.000181
Training Epoch: 263 [32/50000]	Loss: 1.2184	LR: 0.000181
Training Epoch: 263 [32/50000]	Loss: 1.4353	LR: 0.000181
Training Epoch: 263 [32/50000]	Loss: 1.4892	LR: 0.000181
Training Epoch: 263 [32/50000]	Loss: 1.6161	LR: 0.000181
Training Epoch: 263 [32/50000]	Loss: 1.3644	LR: 0.000181
Training Epoch: 263 [32/50000]	Loss: 0.9142	LR: 0.000181
Training Epoch: 263 [32/50000]	Loss: 1.2442	LR: 0.000181
Evaluating Network.....
Test set: Epoch: 263, Average loss: 0.0467, Top1Accuracy: 0.5774, Top3Accuracy: 0.7856, Top5Accuracy: 0.8579, Time consumed:2.63s

Training Epoch: 264 [32/50000]	Loss: 1.3944	LR: 0.000176
Training Epoch: 264 [32/50000]	Loss: 1.5358	LR: 0.000176
Training Epoch: 264 [32/50000]	Loss: 2.1370	LR: 0.000176
Training Epoch: 264 [32/50000]	Loss: 1.6787	LR: 0.000176
Training Epoch: 264 [32/50000]	Loss: 1.5480	LR: 0.000176
Training Epoch: 264 [32/50000]	Loss: 1.1016	LR: 0.000176
Training Epoch: 264 [32/50000]	Loss: 1.0625	LR: 0.000176
Training Epoch: 264 [32/50000]	Loss: 1.1419	LR: 0.000176
Training Epoch: 264 [32/50000]	Loss: 1.2428	LR: 0.000176
Training Epoch: 264 [32/50000]	Loss: 1.9231	LR: 0.000176
Evaluating Network.....
Test set: Epoch: 264, Average loss: 0.0467, Top1Accuracy: 0.5776, Top3Accuracy: 0.7863, Top5Accuracy: 0.8588, Time consumed:2.67s

Training Epoch: 265 [32/50000]	Loss: 1.4296	LR: 0.000171
Training Epoch: 265 [32/50000]	Loss: 1.3887	LR: 0.000171
Training Epoch: 265 [32/50000]	Loss: 1.2272	LR: 0.000171
Training Epoch: 265 [32/50000]	Loss: 1.0539	LR: 0.000171
Training Epoch: 265 [32/50000]	Loss: 1.4457	LR: 0.000171
Training Epoch: 265 [32/50000]	Loss: 1.4922	LR: 0.000171
Training Epoch: 265 [32/50000]	Loss: 1.2470	LR: 0.000171
Training Epoch: 265 [32/50000]	Loss: 1.1566	LR: 0.000171
Training Epoch: 265 [32/50000]	Loss: 1.6342	LR: 0.000171
Training Epoch: 265 [32/50000]	Loss: 1.1356	LR: 0.000171
Evaluating Network.....
Test set: Epoch: 265, Average loss: 0.0467, Top1Accuracy: 0.5815, Top3Accuracy: 0.7845, Top5Accuracy: 0.8584, Time consumed:2.61s

Training Epoch: 266 [32/50000]	Loss: 1.7067	LR: 0.000167
Training Epoch: 266 [32/50000]	Loss: 1.4485	LR: 0.000167
Training Epoch: 266 [32/50000]	Loss: 1.5259	LR: 0.000167
Training Epoch: 266 [32/50000]	Loss: 1.6999	LR: 0.000167
Training Epoch: 266 [32/50000]	Loss: 1.9064	LR: 0.000167
Training Epoch: 266 [32/50000]	Loss: 1.4511	LR: 0.000167
Training Epoch: 266 [32/50000]	Loss: 1.1875	LR: 0.000167
Training Epoch: 266 [32/50000]	Loss: 1.3350	LR: 0.000167
Training Epoch: 266 [32/50000]	Loss: 1.6021	LR: 0.000167
Training Epoch: 266 [32/50000]	Loss: 1.7824	LR: 0.000167
Evaluating Network.....
Test set: Epoch: 266, Average loss: 0.0467, Top1Accuracy: 0.5789, Top3Accuracy: 0.7866, Top5Accuracy: 0.8574, Time consumed:2.61s

Training Epoch: 267 [32/50000]	Loss: 1.4602	LR: 0.000162
Training Epoch: 267 [32/50000]	Loss: 1.3008	LR: 0.000162
Training Epoch: 267 [32/50000]	Loss: 1.9565	LR: 0.000162
Training Epoch: 267 [32/50000]	Loss: 1.3314	LR: 0.000162
Training Epoch: 267 [32/50000]	Loss: 1.3289	LR: 0.000162
Training Epoch: 267 [32/50000]	Loss: 1.8568	LR: 0.000162
Training Epoch: 267 [32/50000]	Loss: 1.2748	LR: 0.000162
Training Epoch: 267 [32/50000]	Loss: 1.2620	LR: 0.000162
Training Epoch: 267 [32/50000]	Loss: 2.0932	LR: 0.000162
Training Epoch: 267 [32/50000]	Loss: 1.7647	LR: 0.000162
Evaluating Network.....
Test set: Epoch: 267, Average loss: 0.0466, Top1Accuracy: 0.5800, Top3Accuracy: 0.7884, Top5Accuracy: 0.8588, Time consumed:2.62s

Training Epoch: 268 [32/50000]	Loss: 1.1870	LR: 0.000158
Training Epoch: 268 [32/50000]	Loss: 1.0529	LR: 0.000158
Training Epoch: 268 [32/50000]	Loss: 1.4015	LR: 0.000158
Training Epoch: 268 [32/50000]	Loss: 2.0247	LR: 0.000158
Training Epoch: 268 [32/50000]	Loss: 1.6742	LR: 0.000158
Training Epoch: 268 [32/50000]	Loss: 1.7172	LR: 0.000158
Training Epoch: 268 [32/50000]	Loss: 1.6571	LR: 0.000158
Training Epoch: 268 [32/50000]	Loss: 1.2063	LR: 0.000158
Training Epoch: 268 [32/50000]	Loss: 1.2559	LR: 0.000158
Training Epoch: 268 [32/50000]	Loss: 1.2870	LR: 0.000158
Evaluating Network.....
Test set: Epoch: 268, Average loss: 0.0467, Top1Accuracy: 0.5811, Top3Accuracy: 0.7862, Top5Accuracy: 0.8582, Time consumed:2.64s

Training Epoch: 269 [32/50000]	Loss: 1.5639	LR: 0.000154
Training Epoch: 269 [32/50000]	Loss: 1.3376	LR: 0.000154
Training Epoch: 269 [32/50000]	Loss: 1.4326	LR: 0.000154
Training Epoch: 269 [32/50000]	Loss: 2.0330	LR: 0.000154
Training Epoch: 269 [32/50000]	Loss: 1.6054	LR: 0.000154
Training Epoch: 269 [32/50000]	Loss: 1.6061	LR: 0.000154
Training Epoch: 269 [32/50000]	Loss: 1.5241	LR: 0.000154
Training Epoch: 269 [32/50000]	Loss: 1.4572	LR: 0.000154
Training Epoch: 269 [32/50000]	Loss: 1.3272	LR: 0.000154
Training Epoch: 269 [32/50000]	Loss: 1.4023	LR: 0.000154
Evaluating Network.....
Test set: Epoch: 269, Average loss: 0.0467, Top1Accuracy: 0.5821, Top3Accuracy: 0.7861, Top5Accuracy: 0.8572, Time consumed:2.60s

Training Epoch: 270 [32/50000]	Loss: 1.5390	LR: 0.000150
Training Epoch: 270 [32/50000]	Loss: 1.5869	LR: 0.000150
Training Epoch: 270 [32/50000]	Loss: 1.2713	LR: 0.000150
Training Epoch: 270 [32/50000]	Loss: 1.2463	LR: 0.000150
Training Epoch: 270 [32/50000]	Loss: 0.9144	LR: 0.000150
Training Epoch: 270 [32/50000]	Loss: 1.3570	LR: 0.000150
Training Epoch: 270 [32/50000]	Loss: 1.2953	LR: 0.000150
Training Epoch: 270 [32/50000]	Loss: 1.5312	LR: 0.000150
Training Epoch: 270 [32/50000]	Loss: 1.1124	LR: 0.000150
Training Epoch: 270 [32/50000]	Loss: 1.7794	LR: 0.000150
Evaluating Network.....
Test set: Epoch: 270, Average loss: 0.0466, Top1Accuracy: 0.5809, Top3Accuracy: 0.7861, Top5Accuracy: 0.8580, Time consumed:2.65s

Training Epoch: 271 [32/50000]	Loss: 1.6375	LR: 0.000146
Training Epoch: 271 [32/50000]	Loss: 1.3284	LR: 0.000146
Training Epoch: 271 [32/50000]	Loss: 1.4035	LR: 0.000146
Training Epoch: 271 [32/50000]	Loss: 1.5691	LR: 0.000146
Training Epoch: 271 [32/50000]	Loss: 1.4215	LR: 0.000146
Training Epoch: 271 [32/50000]	Loss: 1.2760	LR: 0.000146
Training Epoch: 271 [32/50000]	Loss: 1.2759	LR: 0.000146
Training Epoch: 271 [32/50000]	Loss: 1.1854	LR: 0.000146
Training Epoch: 271 [32/50000]	Loss: 1.2792	LR: 0.000146
Training Epoch: 271 [32/50000]	Loss: 1.3134	LR: 0.000146
Evaluating Network.....
Test set: Epoch: 271, Average loss: 0.0466, Top1Accuracy: 0.5805, Top3Accuracy: 0.7865, Top5Accuracy: 0.8588, Time consumed:2.65s

Training Epoch: 272 [32/50000]	Loss: 1.2835	LR: 0.000142
Training Epoch: 272 [32/50000]	Loss: 1.5656	LR: 0.000142
Training Epoch: 272 [32/50000]	Loss: 1.2471	LR: 0.000142
Training Epoch: 272 [32/50000]	Loss: 1.4184	LR: 0.000142
Training Epoch: 272 [32/50000]	Loss: 1.4011	LR: 0.000142
Training Epoch: 272 [32/50000]	Loss: 2.0432	LR: 0.000142
Training Epoch: 272 [32/50000]	Loss: 1.8089	LR: 0.000142
Training Epoch: 272 [32/50000]	Loss: 1.9131	LR: 0.000142
Training Epoch: 272 [32/50000]	Loss: 1.5084	LR: 0.000142
Training Epoch: 272 [32/50000]	Loss: 1.5508	LR: 0.000142
Evaluating Network.....
Test set: Epoch: 272, Average loss: 0.0466, Top1Accuracy: 0.5800, Top3Accuracy: 0.7877, Top5Accuracy: 0.8588, Time consumed:2.57s

Training Epoch: 273 [32/50000]	Loss: 1.5334	LR: 0.000138
Training Epoch: 273 [32/50000]	Loss: 0.8471	LR: 0.000138
Training Epoch: 273 [32/50000]	Loss: 1.4226	LR: 0.000138
Training Epoch: 273 [32/50000]	Loss: 1.4483	LR: 0.000138
Training Epoch: 273 [32/50000]	Loss: 1.7260	LR: 0.000138
Training Epoch: 273 [32/50000]	Loss: 1.0993	LR: 0.000138
Training Epoch: 273 [32/50000]	Loss: 1.5409	LR: 0.000138
Training Epoch: 273 [32/50000]	Loss: 1.2478	LR: 0.000138
Training Epoch: 273 [32/50000]	Loss: 1.1215	LR: 0.000138
Training Epoch: 273 [32/50000]	Loss: 1.3215	LR: 0.000138
Evaluating Network.....
Test set: Epoch: 273, Average loss: 0.0465, Top1Accuracy: 0.5798, Top3Accuracy: 0.7861, Top5Accuracy: 0.8586, Time consumed:2.62s

Training Epoch: 274 [32/50000]	Loss: 1.0913	LR: 0.000135
Training Epoch: 274 [32/50000]	Loss: 1.4827	LR: 0.000135
Training Epoch: 274 [32/50000]	Loss: 1.5590	LR: 0.000135
Training Epoch: 274 [32/50000]	Loss: 1.4911	LR: 0.000135
Training Epoch: 274 [32/50000]	Loss: 1.5070	LR: 0.000135
Training Epoch: 274 [32/50000]	Loss: 1.6817	LR: 0.000135
Training Epoch: 274 [32/50000]	Loss: 1.5971	LR: 0.000135
Training Epoch: 274 [32/50000]	Loss: 1.4631	LR: 0.000135
Training Epoch: 274 [32/50000]	Loss: 1.3502	LR: 0.000135
Training Epoch: 274 [32/50000]	Loss: 0.9090	LR: 0.000135
Evaluating Network.....
Test set: Epoch: 274, Average loss: 0.0465, Top1Accuracy: 0.5796, Top3Accuracy: 0.7890, Top5Accuracy: 0.8592, Time consumed:2.65s

Training Epoch: 275 [32/50000]	Loss: 1.4513	LR: 0.000131
Training Epoch: 275 [32/50000]	Loss: 1.1560	LR: 0.000131
Training Epoch: 275 [32/50000]	Loss: 1.6166	LR: 0.000131
Training Epoch: 275 [32/50000]	Loss: 1.6572	LR: 0.000131
Training Epoch: 275 [32/50000]	Loss: 1.0800	LR: 0.000131
Training Epoch: 275 [32/50000]	Loss: 1.4425	LR: 0.000131
Training Epoch: 275 [32/50000]	Loss: 1.5341	LR: 0.000131
Training Epoch: 275 [32/50000]	Loss: 1.5417	LR: 0.000131
Training Epoch: 275 [32/50000]	Loss: 1.2591	LR: 0.000131
Training Epoch: 275 [32/50000]	Loss: 1.5184	LR: 0.000131
Evaluating Network.....
Test set: Epoch: 275, Average loss: 0.0466, Top1Accuracy: 0.5788, Top3Accuracy: 0.7878, Top5Accuracy: 0.8581, Time consumed:2.66s

Training Epoch: 276 [32/50000]	Loss: 2.0750	LR: 0.000128
Training Epoch: 276 [32/50000]	Loss: 1.3642	LR: 0.000128
Training Epoch: 276 [32/50000]	Loss: 1.5189	LR: 0.000128
Training Epoch: 276 [32/50000]	Loss: 1.4630	LR: 0.000128
Training Epoch: 276 [32/50000]	Loss: 1.4309	LR: 0.000128
Training Epoch: 276 [32/50000]	Loss: 1.3264	LR: 0.000128
Training Epoch: 276 [32/50000]	Loss: 1.1185	LR: 0.000128
Training Epoch: 276 [32/50000]	Loss: 0.9598	LR: 0.000128
Training Epoch: 276 [32/50000]	Loss: 1.2190	LR: 0.000128
Training Epoch: 276 [32/50000]	Loss: 1.7513	LR: 0.000128
Evaluating Network.....
Test set: Epoch: 276, Average loss: 0.0466, Top1Accuracy: 0.5808, Top3Accuracy: 0.7879, Top5Accuracy: 0.8589, Time consumed:2.65s

Training Epoch: 277 [32/50000]	Loss: 0.9844	LR: 0.000124
Training Epoch: 277 [32/50000]	Loss: 1.3286	LR: 0.000124
Training Epoch: 277 [32/50000]	Loss: 1.5550	LR: 0.000124
Training Epoch: 277 [32/50000]	Loss: 1.3858	LR: 0.000124
Training Epoch: 277 [32/50000]	Loss: 1.5192	LR: 0.000124
Training Epoch: 277 [32/50000]	Loss: 1.8183	LR: 0.000124
Training Epoch: 277 [32/50000]	Loss: 1.5633	LR: 0.000124
Training Epoch: 277 [32/50000]	Loss: 1.5034	LR: 0.000124
Training Epoch: 277 [32/50000]	Loss: 1.2706	LR: 0.000124
Training Epoch: 277 [32/50000]	Loss: 1.0883	LR: 0.000124
Evaluating Network.....
Test set: Epoch: 277, Average loss: 0.0465, Top1Accuracy: 0.5801, Top3Accuracy: 0.7881, Top5Accuracy: 0.8581, Time consumed:2.63s

Training Epoch: 278 [32/50000]	Loss: 1.4829	LR: 0.000121
Training Epoch: 278 [32/50000]	Loss: 1.9324	LR: 0.000121
Training Epoch: 278 [32/50000]	Loss: 1.3989	LR: 0.000121
Training Epoch: 278 [32/50000]	Loss: 1.1867	LR: 0.000121
Training Epoch: 278 [32/50000]	Loss: 1.9316	LR: 0.000121
Training Epoch: 278 [32/50000]	Loss: 1.8668	LR: 0.000121
Training Epoch: 278 [32/50000]	Loss: 1.4223	LR: 0.000121
Training Epoch: 278 [32/50000]	Loss: 1.7143	LR: 0.000121
Training Epoch: 278 [32/50000]	Loss: 1.8901	LR: 0.000121
Training Epoch: 278 [32/50000]	Loss: 1.6738	LR: 0.000121
Evaluating Network.....
Test set: Epoch: 278, Average loss: 0.0466, Top1Accuracy: 0.5807, Top3Accuracy: 0.7863, Top5Accuracy: 0.8591, Time consumed:2.63s

Training Epoch: 279 [32/50000]	Loss: 1.7692	LR: 0.000118
Training Epoch: 279 [32/50000]	Loss: 1.1014	LR: 0.000118
Training Epoch: 279 [32/50000]	Loss: 1.3497	LR: 0.000118
Training Epoch: 279 [32/50000]	Loss: 1.6050	LR: 0.000118
Training Epoch: 279 [32/50000]	Loss: 1.1124	LR: 0.000118
Training Epoch: 279 [32/50000]	Loss: 1.4206	LR: 0.000118
Training Epoch: 279 [32/50000]	Loss: 1.6366	LR: 0.000118
Training Epoch: 279 [32/50000]	Loss: 1.2434	LR: 0.000118
Training Epoch: 279 [32/50000]	Loss: 1.5126	LR: 0.000118
Training Epoch: 279 [32/50000]	Loss: 1.8164	LR: 0.000118
Evaluating Network.....
Test set: Epoch: 279, Average loss: 0.0466, Top1Accuracy: 0.5796, Top3Accuracy: 0.7871, Top5Accuracy: 0.8583, Time consumed:2.65s

Training Epoch: 280 [32/50000]	Loss: 1.0692	LR: 0.000115
Training Epoch: 280 [32/50000]	Loss: 1.7886	LR: 0.000115
Training Epoch: 280 [32/50000]	Loss: 1.8515	LR: 0.000115
Training Epoch: 280 [32/50000]	Loss: 1.3319	LR: 0.000115
Training Epoch: 280 [32/50000]	Loss: 1.2245	LR: 0.000115
Training Epoch: 280 [32/50000]	Loss: 2.0064	LR: 0.000115
Training Epoch: 280 [32/50000]	Loss: 1.4682	LR: 0.000115
Training Epoch: 280 [32/50000]	Loss: 1.1290	LR: 0.000115
Training Epoch: 280 [32/50000]	Loss: 0.8989	LR: 0.000115
Training Epoch: 280 [32/50000]	Loss: 1.2956	LR: 0.000115
Evaluating Network.....
Test set: Epoch: 280, Average loss: 0.0465, Top1Accuracy: 0.5814, Top3Accuracy: 0.7878, Top5Accuracy: 0.8593, Time consumed:2.65s

Training Epoch: 281 [32/50000]	Loss: 1.5654	LR: 0.000112
Training Epoch: 281 [32/50000]	Loss: 1.2449	LR: 0.000112
Training Epoch: 281 [32/50000]	Loss: 1.1153	LR: 0.000112
Training Epoch: 281 [32/50000]	Loss: 1.7205	LR: 0.000112
Training Epoch: 281 [32/50000]	Loss: 1.2624	LR: 0.000112
Training Epoch: 281 [32/50000]	Loss: 1.5530	LR: 0.000112
Training Epoch: 281 [32/50000]	Loss: 1.3103	LR: 0.000112
Training Epoch: 281 [32/50000]	Loss: 1.8393	LR: 0.000112
Training Epoch: 281 [32/50000]	Loss: 2.1247	LR: 0.000112
Training Epoch: 281 [32/50000]	Loss: 1.8233	LR: 0.000112
Evaluating Network.....
Test set: Epoch: 281, Average loss: 0.0466, Top1Accuracy: 0.5802, Top3Accuracy: 0.7865, Top5Accuracy: 0.8598, Time consumed:2.86s

Training Epoch: 282 [32/50000]	Loss: 1.4516	LR: 0.000109
Training Epoch: 282 [32/50000]	Loss: 1.4854	LR: 0.000109
Training Epoch: 282 [32/50000]	Loss: 1.6743	LR: 0.000109
Training Epoch: 282 [32/50000]	Loss: 1.3994	LR: 0.000109
Training Epoch: 282 [32/50000]	Loss: 1.4039	LR: 0.000109
Training Epoch: 282 [32/50000]	Loss: 1.1940	LR: 0.000109
Training Epoch: 282 [32/50000]	Loss: 1.5048	LR: 0.000109
Training Epoch: 282 [32/50000]	Loss: 1.2166	LR: 0.000109
Training Epoch: 282 [32/50000]	Loss: 1.9503	LR: 0.000109
Training Epoch: 282 [32/50000]	Loss: 1.0824	LR: 0.000109
Evaluating Network.....
Test set: Epoch: 282, Average loss: 0.0465, Top1Accuracy: 0.5820, Top3Accuracy: 0.7866, Top5Accuracy: 0.8597, Time consumed:2.66s

Training Epoch: 283 [32/50000]	Loss: 1.9907	LR: 0.000106
Training Epoch: 283 [32/50000]	Loss: 1.7574	LR: 0.000106
Training Epoch: 283 [32/50000]	Loss: 1.3174	LR: 0.000106
Training Epoch: 283 [32/50000]	Loss: 1.8534	LR: 0.000106
Training Epoch: 283 [32/50000]	Loss: 1.0473	LR: 0.000106
Training Epoch: 283 [32/50000]	Loss: 1.5544	LR: 0.000106
Training Epoch: 283 [32/50000]	Loss: 1.7253	LR: 0.000106
Training Epoch: 283 [32/50000]	Loss: 1.1289	LR: 0.000106
Training Epoch: 283 [32/50000]	Loss: 1.3049	LR: 0.000106
Training Epoch: 283 [32/50000]	Loss: 1.5507	LR: 0.000106
Evaluating Network.....
Test set: Epoch: 283, Average loss: 0.0466, Top1Accuracy: 0.5830, Top3Accuracy: 0.7869, Top5Accuracy: 0.8577, Time consumed:2.61s

Training Epoch: 284 [32/50000]	Loss: 1.1876	LR: 0.000103
Training Epoch: 284 [32/50000]	Loss: 1.6844	LR: 0.000103
Training Epoch: 284 [32/50000]	Loss: 1.8753	LR: 0.000103
Training Epoch: 284 [32/50000]	Loss: 1.4656	LR: 0.000103
Training Epoch: 284 [32/50000]	Loss: 1.3325	LR: 0.000103
Training Epoch: 284 [32/50000]	Loss: 1.7692	LR: 0.000103
Training Epoch: 284 [32/50000]	Loss: 1.5521	LR: 0.000103
Training Epoch: 284 [32/50000]	Loss: 1.4639	LR: 0.000103
Training Epoch: 284 [32/50000]	Loss: 1.4619	LR: 0.000103
Training Epoch: 284 [32/50000]	Loss: 1.3506	LR: 0.000103
Evaluating Network.....
Test set: Epoch: 284, Average loss: 0.0465, Top1Accuracy: 0.5819, Top3Accuracy: 0.7873, Top5Accuracy: 0.8592, Time consumed:2.63s

Training Epoch: 285 [32/50000]	Loss: 1.3616	LR: 0.000100
Training Epoch: 285 [32/50000]	Loss: 1.3810	LR: 0.000100
Training Epoch: 285 [32/50000]	Loss: 1.2069	LR: 0.000100
Training Epoch: 285 [32/50000]	Loss: 1.5475	LR: 0.000100
Training Epoch: 285 [32/50000]	Loss: 1.5599	LR: 0.000100
Training Epoch: 285 [32/50000]	Loss: 1.5518	LR: 0.000100
Training Epoch: 285 [32/50000]	Loss: 1.5059	LR: 0.000100
Training Epoch: 285 [32/50000]	Loss: 1.1013	LR: 0.000100
Training Epoch: 285 [32/50000]	Loss: 1.2347	LR: 0.000100
Training Epoch: 285 [32/50000]	Loss: 1.3785	LR: 0.000100
Evaluating Network.....
Test set: Epoch: 285, Average loss: 0.0465, Top1Accuracy: 0.5821, Top3Accuracy: 0.7871, Top5Accuracy: 0.8593, Time consumed:2.64s

Training Epoch: 286 [32/50000]	Loss: 1.5809	LR: 0.000098
Training Epoch: 286 [32/50000]	Loss: 1.2609	LR: 0.000098
Training Epoch: 286 [32/50000]	Loss: 1.3172	LR: 0.000098
Training Epoch: 286 [32/50000]	Loss: 1.0702	LR: 0.000098
Training Epoch: 286 [32/50000]	Loss: 1.6919	LR: 0.000098
Training Epoch: 286 [32/50000]	Loss: 1.0268	LR: 0.000098
Training Epoch: 286 [32/50000]	Loss: 1.2967	LR: 0.000098
Training Epoch: 286 [32/50000]	Loss: 1.2821	LR: 0.000098
Training Epoch: 286 [32/50000]	Loss: 1.1993	LR: 0.000098
Training Epoch: 286 [32/50000]	Loss: 1.5992	LR: 0.000098
Evaluating Network.....
Test set: Epoch: 286, Average loss: 0.0466, Top1Accuracy: 0.5814, Top3Accuracy: 0.7854, Top5Accuracy: 0.8584, Time consumed:2.69s

Training Epoch: 287 [32/50000]	Loss: 1.0579	LR: 0.000095
Training Epoch: 287 [32/50000]	Loss: 1.4961	LR: 0.000095
Training Epoch: 287 [32/50000]	Loss: 1.1872	LR: 0.000095
Training Epoch: 287 [32/50000]	Loss: 1.3993	LR: 0.000095
Training Epoch: 287 [32/50000]	Loss: 1.1174	LR: 0.000095
Training Epoch: 287 [32/50000]	Loss: 1.4477	LR: 0.000095
Training Epoch: 287 [32/50000]	Loss: 1.8411	LR: 0.000095
Training Epoch: 287 [32/50000]	Loss: 1.4647	LR: 0.000095
Training Epoch: 287 [32/50000]	Loss: 1.5634	LR: 0.000095
Training Epoch: 287 [32/50000]	Loss: 1.8693	LR: 0.000095
Evaluating Network.....
Test set: Epoch: 287, Average loss: 0.0465, Top1Accuracy: 0.5798, Top3Accuracy: 0.7863, Top5Accuracy: 0.8590, Time consumed:2.68s

Training Epoch: 288 [32/50000]	Loss: 1.9827	LR: 0.000093
Training Epoch: 288 [32/50000]	Loss: 1.2819	LR: 0.000093
Training Epoch: 288 [32/50000]	Loss: 1.3031	LR: 0.000093
Training Epoch: 288 [32/50000]	Loss: 1.5359	LR: 0.000093
Training Epoch: 288 [32/50000]	Loss: 1.4433	LR: 0.000093
Training Epoch: 288 [32/50000]	Loss: 1.1230	LR: 0.000093
Training Epoch: 288 [32/50000]	Loss: 1.6790	LR: 0.000093
Training Epoch: 288 [32/50000]	Loss: 1.1644	LR: 0.000093
Training Epoch: 288 [32/50000]	Loss: 1.4255	LR: 0.000093
Training Epoch: 288 [32/50000]	Loss: 1.5319	LR: 0.000093
Evaluating Network.....
Test set: Epoch: 288, Average loss: 0.0465, Top1Accuracy: 0.5806, Top3Accuracy: 0.7865, Top5Accuracy: 0.8592, Time consumed:2.62s

Training Epoch: 289 [32/50000]	Loss: 1.0350	LR: 0.000090
Training Epoch: 289 [32/50000]	Loss: 1.4407	LR: 0.000090
Training Epoch: 289 [32/50000]	Loss: 1.2313	LR: 0.000090
Training Epoch: 289 [32/50000]	Loss: 1.2368	LR: 0.000090
Training Epoch: 289 [32/50000]	Loss: 1.5215	LR: 0.000090
Training Epoch: 289 [32/50000]	Loss: 1.5762	LR: 0.000090
Training Epoch: 289 [32/50000]	Loss: 1.9139	LR: 0.000090
Training Epoch: 289 [32/50000]	Loss: 1.0280	LR: 0.000090
Training Epoch: 289 [32/50000]	Loss: 1.6045	LR: 0.000090
Training Epoch: 289 [32/50000]	Loss: 1.0116	LR: 0.000090
Evaluating Network.....
Test set: Epoch: 289, Average loss: 0.0465, Top1Accuracy: 0.5827, Top3Accuracy: 0.7869, Top5Accuracy: 0.8587, Time consumed:2.70s

Training Epoch: 290 [32/50000]	Loss: 1.5755	LR: 0.000088
Training Epoch: 290 [32/50000]	Loss: 1.4094	LR: 0.000088
Training Epoch: 290 [32/50000]	Loss: 1.5591	LR: 0.000088
Training Epoch: 290 [32/50000]	Loss: 1.4589	LR: 0.000088
Training Epoch: 290 [32/50000]	Loss: 1.7561	LR: 0.000088
Training Epoch: 290 [32/50000]	Loss: 1.2799	LR: 0.000088
Training Epoch: 290 [32/50000]	Loss: 1.3455	LR: 0.000088
Training Epoch: 290 [32/50000]	Loss: 1.7175	LR: 0.000088
Training Epoch: 290 [32/50000]	Loss: 1.8562	LR: 0.000088
Training Epoch: 290 [32/50000]	Loss: 1.4279	LR: 0.000088
Evaluating Network.....
Test set: Epoch: 290, Average loss: 0.0465, Top1Accuracy: 0.5811, Top3Accuracy: 0.7871, Top5Accuracy: 0.8578, Time consumed:2.77s

Training Epoch: 291 [32/50000]	Loss: 1.6137	LR: 0.000085
Training Epoch: 291 [32/50000]	Loss: 1.6036	LR: 0.000085
Training Epoch: 291 [32/50000]	Loss: 1.4348	LR: 0.000085
Training Epoch: 291 [32/50000]	Loss: 1.7326	LR: 0.000085
Training Epoch: 291 [32/50000]	Loss: 1.4155	LR: 0.000085
Training Epoch: 291 [32/50000]	Loss: 1.0164	LR: 0.000085
Training Epoch: 291 [32/50000]	Loss: 1.5484	LR: 0.000085
Training Epoch: 291 [32/50000]	Loss: 1.2820	LR: 0.000085
Training Epoch: 291 [32/50000]	Loss: 1.2905	LR: 0.000085
Training Epoch: 291 [32/50000]	Loss: 1.4806	LR: 0.000085
Evaluating Network.....
Test set: Epoch: 291, Average loss: 0.0464, Top1Accuracy: 0.5816, Top3Accuracy: 0.7871, Top5Accuracy: 0.8591, Time consumed:2.62s

Training Epoch: 292 [32/50000]	Loss: 1.4230	LR: 0.000083
Training Epoch: 292 [32/50000]	Loss: 1.5016	LR: 0.000083
Training Epoch: 292 [32/50000]	Loss: 1.0563	LR: 0.000083
Training Epoch: 292 [32/50000]	Loss: 1.6478	LR: 0.000083
Training Epoch: 292 [32/50000]	Loss: 1.3488	LR: 0.000083
Training Epoch: 292 [32/50000]	Loss: 1.3035	LR: 0.000083
Training Epoch: 292 [32/50000]	Loss: 1.4129	LR: 0.000083
Training Epoch: 292 [32/50000]	Loss: 1.3649	LR: 0.000083
Training Epoch: 292 [32/50000]	Loss: 1.5371	LR: 0.000083
Training Epoch: 292 [32/50000]	Loss: 1.1705	LR: 0.000083
Evaluating Network.....
Test set: Epoch: 292, Average loss: 0.0465, Top1Accuracy: 0.5816, Top3Accuracy: 0.7884, Top5Accuracy: 0.8590, Time consumed:2.57s

Training Epoch: 293 [32/50000]	Loss: 1.3765	LR: 0.000081
Training Epoch: 293 [32/50000]	Loss: 1.3504	LR: 0.000081
Training Epoch: 293 [32/50000]	Loss: 1.1517	LR: 0.000081
Training Epoch: 293 [32/50000]	Loss: 1.3026	LR: 0.000081
Training Epoch: 293 [32/50000]	Loss: 1.4713	LR: 0.000081
Training Epoch: 293 [32/50000]	Loss: 2.0085	LR: 0.000081
Training Epoch: 293 [32/50000]	Loss: 1.4751	LR: 0.000081
Training Epoch: 293 [32/50000]	Loss: 1.6112	LR: 0.000081
Training Epoch: 293 [32/50000]	Loss: 1.7489	LR: 0.000081
Training Epoch: 293 [32/50000]	Loss: 1.1635	LR: 0.000081
Evaluating Network.....
Test set: Epoch: 293, Average loss: 0.0466, Top1Accuracy: 0.5812, Top3Accuracy: 0.7873, Top5Accuracy: 0.8590, Time consumed:2.63s

Training Epoch: 294 [32/50000]	Loss: 1.3203	LR: 0.000079
Training Epoch: 294 [32/50000]	Loss: 1.6598	LR: 0.000079
Training Epoch: 294 [32/50000]	Loss: 1.1399	LR: 0.000079
Training Epoch: 294 [32/50000]	Loss: 1.6810	LR: 0.000079
Training Epoch: 294 [32/50000]	Loss: 1.6905	LR: 0.000079
Training Epoch: 294 [32/50000]	Loss: 1.7102	LR: 0.000079
Training Epoch: 294 [32/50000]	Loss: 1.4731	LR: 0.000079
Training Epoch: 294 [32/50000]	Loss: 1.4975	LR: 0.000079
Training Epoch: 294 [32/50000]	Loss: 1.6407	LR: 0.000079
Training Epoch: 294 [32/50000]	Loss: 1.5140	LR: 0.000079
Evaluating Network.....
Test set: Epoch: 294, Average loss: 0.0465, Top1Accuracy: 0.5820, Top3Accuracy: 0.7876, Top5Accuracy: 0.8589, Time consumed:2.68s

Training Epoch: 295 [32/50000]	Loss: 1.4947	LR: 0.000077
Training Epoch: 295 [32/50000]	Loss: 1.3422	LR: 0.000077
Training Epoch: 295 [32/50000]	Loss: 1.4224	LR: 0.000077
Training Epoch: 295 [32/50000]	Loss: 0.9149	LR: 0.000077
Training Epoch: 295 [32/50000]	Loss: 1.5136	LR: 0.000077
Training Epoch: 295 [32/50000]	Loss: 1.4333	LR: 0.000077
Training Epoch: 295 [32/50000]	Loss: 1.5374	LR: 0.000077
Training Epoch: 295 [32/50000]	Loss: 1.2879	LR: 0.000077
Training Epoch: 295 [32/50000]	Loss: 1.2486	LR: 0.000077
Training Epoch: 295 [32/50000]	Loss: 1.3082	LR: 0.000077
Evaluating Network.....
Test set: Epoch: 295, Average loss: 0.0464, Top1Accuracy: 0.5823, Top3Accuracy: 0.7878, Top5Accuracy: 0.8583, Time consumed:2.68s

Training Epoch: 296 [32/50000]	Loss: 1.3508	LR: 0.000075
Training Epoch: 296 [32/50000]	Loss: 1.4081	LR: 0.000075
Training Epoch: 296 [32/50000]	Loss: 1.6283	LR: 0.000075
Training Epoch: 296 [32/50000]	Loss: 1.8420	LR: 0.000075
Training Epoch: 296 [32/50000]	Loss: 1.3690	LR: 0.000075
Training Epoch: 296 [32/50000]	Loss: 1.2689	LR: 0.000075
Training Epoch: 296 [32/50000]	Loss: 1.2736	LR: 0.000075
Training Epoch: 296 [32/50000]	Loss: 1.9740	LR: 0.000075
Training Epoch: 296 [32/50000]	Loss: 1.3860	LR: 0.000075
Training Epoch: 296 [32/50000]	Loss: 2.1261	LR: 0.000075
Evaluating Network.....
Test set: Epoch: 296, Average loss: 0.0465, Top1Accuracy: 0.5808, Top3Accuracy: 0.7868, Top5Accuracy: 0.8581, Time consumed:2.63s

Training Epoch: 297 [32/50000]	Loss: 1.4955	LR: 0.000073
Training Epoch: 297 [32/50000]	Loss: 1.4772	LR: 0.000073
Training Epoch: 297 [32/50000]	Loss: 1.3024	LR: 0.000073
Training Epoch: 297 [32/50000]	Loss: 1.2708	LR: 0.000073
Training Epoch: 297 [32/50000]	Loss: 1.0588	LR: 0.000073
Training Epoch: 297 [32/50000]	Loss: 1.7064	LR: 0.000073
Training Epoch: 297 [32/50000]	Loss: 1.8131	LR: 0.000073
Training Epoch: 297 [32/50000]	Loss: 1.2545	LR: 0.000073
Training Epoch: 297 [32/50000]	Loss: 1.5923	LR: 0.000073
Training Epoch: 297 [32/50000]	Loss: 1.3279	LR: 0.000073
Evaluating Network.....
Test set: Epoch: 297, Average loss: 0.0465, Top1Accuracy: 0.5807, Top3Accuracy: 0.7866, Top5Accuracy: 0.8584, Time consumed:2.64s

Training Epoch: 298 [32/50000]	Loss: 1.5518	LR: 0.000071
Training Epoch: 298 [32/50000]	Loss: 1.4127	LR: 0.000071
Training Epoch: 298 [32/50000]	Loss: 1.4351	LR: 0.000071
Training Epoch: 298 [32/50000]	Loss: 1.4006	LR: 0.000071
Training Epoch: 298 [32/50000]	Loss: 1.3411	LR: 0.000071
Training Epoch: 298 [32/50000]	Loss: 1.2816	LR: 0.000071
Training Epoch: 298 [32/50000]	Loss: 1.4014	LR: 0.000071
Training Epoch: 298 [32/50000]	Loss: 1.3138	LR: 0.000071
Training Epoch: 298 [32/50000]	Loss: 1.7134	LR: 0.000071
Training Epoch: 298 [32/50000]	Loss: 1.3128	LR: 0.000071
Evaluating Network.....
Test set: Epoch: 298, Average loss: 0.0464, Top1Accuracy: 0.5821, Top3Accuracy: 0.7876, Top5Accuracy: 0.8592, Time consumed:2.63s

Training Epoch: 299 [32/50000]	Loss: 1.2502	LR: 0.000069
Training Epoch: 299 [32/50000]	Loss: 1.6772	LR: 0.000069
Training Epoch: 299 [32/50000]	Loss: 1.3239	LR: 0.000069
Training Epoch: 299 [32/50000]	Loss: 1.3779	LR: 0.000069
Training Epoch: 299 [32/50000]	Loss: 1.5262	LR: 0.000069
Training Epoch: 299 [32/50000]	Loss: 1.3061	LR: 0.000069
Training Epoch: 299 [32/50000]	Loss: 1.0469	LR: 0.000069
Training Epoch: 299 [32/50000]	Loss: 1.9272	LR: 0.000069
Training Epoch: 299 [32/50000]	Loss: 1.9369	LR: 0.000069
Training Epoch: 299 [32/50000]	Loss: 2.0112	LR: 0.000069
Evaluating Network.....
Test set: Epoch: 299, Average loss: 0.0465, Top1Accuracy: 0.5817, Top3Accuracy: 0.7872, Top5Accuracy: 0.8591, Time consumed:2.62s

Training Epoch: 300 [32/50000]	Loss: 1.2585	LR: 0.000067
Training Epoch: 300 [32/50000]	Loss: 1.0839	LR: 0.000067
Training Epoch: 300 [32/50000]	Loss: 1.6248	LR: 0.000067
Training Epoch: 300 [32/50000]	Loss: 1.6593	LR: 0.000067
Training Epoch: 300 [32/50000]	Loss: 1.2941	LR: 0.000067
Training Epoch: 300 [32/50000]	Loss: 1.7113	LR: 0.000067
Training Epoch: 300 [32/50000]	Loss: 1.3567	LR: 0.000067
Training Epoch: 300 [32/50000]	Loss: 1.3564	LR: 0.000067
Training Epoch: 300 [32/50000]	Loss: 1.4683	LR: 0.000067
Training Epoch: 300 [32/50000]	Loss: 1.5015	LR: 0.000067
Evaluating Network.....
Test set: Epoch: 300, Average loss: 0.0466, Top1Accuracy: 0.5814, Top3Accuracy: 0.7868, Top5Accuracy: 0.8588, Time consumed:2.65s

Training Epoch: 301 [32/50000]	Loss: 0.8162	LR: 0.000065
Training Epoch: 301 [32/50000]	Loss: 1.1452	LR: 0.000065
Training Epoch: 301 [32/50000]	Loss: 1.6036	LR: 0.000065
Training Epoch: 301 [32/50000]	Loss: 1.0809	LR: 0.000065
Training Epoch: 301 [32/50000]	Loss: 1.5720	LR: 0.000065
Training Epoch: 301 [32/50000]	Loss: 1.4013	LR: 0.000065
Training Epoch: 301 [32/50000]	Loss: 1.4815	LR: 0.000065
Training Epoch: 301 [32/50000]	Loss: 1.0151	LR: 0.000065
Training Epoch: 301 [32/50000]	Loss: 1.1506	LR: 0.000065
Training Epoch: 301 [32/50000]	Loss: 1.7428	LR: 0.000065
Evaluating Network.....
Test set: Epoch: 301, Average loss: 0.0464, Top1Accuracy: 0.5829, Top3Accuracy: 0.7869, Top5Accuracy: 0.8608, Time consumed:2.65s

Training Epoch: 302 [32/50000]	Loss: 1.8878	LR: 0.000064
Training Epoch: 302 [32/50000]	Loss: 1.4144	LR: 0.000064
Training Epoch: 302 [32/50000]	Loss: 1.5980	LR: 0.000064
Training Epoch: 302 [32/50000]	Loss: 1.7366	LR: 0.000064
Training Epoch: 302 [32/50000]	Loss: 1.4364	LR: 0.000064
Training Epoch: 302 [32/50000]	Loss: 1.7591	LR: 0.000064
Training Epoch: 302 [32/50000]	Loss: 1.1059	LR: 0.000064
Training Epoch: 302 [32/50000]	Loss: 1.2358	LR: 0.000064
Training Epoch: 302 [32/50000]	Loss: 1.9183	LR: 0.000064
Training Epoch: 302 [32/50000]	Loss: 1.1088	LR: 0.000064
Evaluating Network.....
Test set: Epoch: 302, Average loss: 0.0464, Top1Accuracy: 0.5820, Top3Accuracy: 0.7862, Top5Accuracy: 0.8596, Time consumed:2.66s

Training Epoch: 303 [32/50000]	Loss: 1.6486	LR: 0.000062
Training Epoch: 303 [32/50000]	Loss: 1.6969	LR: 0.000062
Training Epoch: 303 [32/50000]	Loss: 1.2035	LR: 0.000062
Training Epoch: 303 [32/50000]	Loss: 1.3211	LR: 0.000062
Training Epoch: 303 [32/50000]	Loss: 1.7309	LR: 0.000062
Training Epoch: 303 [32/50000]	Loss: 1.1963	LR: 0.000062
Training Epoch: 303 [32/50000]	Loss: 2.1108	LR: 0.000062
Training Epoch: 303 [32/50000]	Loss: 1.2989	LR: 0.000062
Training Epoch: 303 [32/50000]	Loss: 1.6076	LR: 0.000062
Training Epoch: 303 [32/50000]	Loss: 1.0980	LR: 0.000062
Evaluating Network.....
Test set: Epoch: 303, Average loss: 0.0465, Top1Accuracy: 0.5800, Top3Accuracy: 0.7863, Top5Accuracy: 0.8598, Time consumed:2.64s

Training Epoch: 304 [32/50000]	Loss: 1.5166	LR: 0.000060
Training Epoch: 304 [32/50000]	Loss: 1.0944	LR: 0.000060
Training Epoch: 304 [32/50000]	Loss: 1.1276	LR: 0.000060
Training Epoch: 304 [32/50000]	Loss: 1.0761	LR: 0.000060
Training Epoch: 304 [32/50000]	Loss: 1.4228	LR: 0.000060
Training Epoch: 304 [32/50000]	Loss: 1.3556	LR: 0.000060
Training Epoch: 304 [32/50000]	Loss: 1.1760	LR: 0.000060
Training Epoch: 304 [32/50000]	Loss: 1.4779	LR: 0.000060
Training Epoch: 304 [32/50000]	Loss: 1.1033	LR: 0.000060
Training Epoch: 304 [32/50000]	Loss: 1.4063	LR: 0.000060
Evaluating Network.....
Test set: Epoch: 304, Average loss: 0.0465, Top1Accuracy: 0.5814, Top3Accuracy: 0.7868, Top5Accuracy: 0.8595, Time consumed:2.62s

Training Epoch: 305 [32/50000]	Loss: 1.7860	LR: 0.000059
Training Epoch: 305 [32/50000]	Loss: 1.4871	LR: 0.000059
Training Epoch: 305 [32/50000]	Loss: 1.4827	LR: 0.000059
Training Epoch: 305 [32/50000]	Loss: 1.3612	LR: 0.000059
Training Epoch: 305 [32/50000]	Loss: 1.1876	LR: 0.000059
Training Epoch: 305 [32/50000]	Loss: 1.3512	LR: 0.000059
Training Epoch: 305 [32/50000]	Loss: 1.2834	LR: 0.000059
Training Epoch: 305 [32/50000]	Loss: 1.5149	LR: 0.000059
Training Epoch: 305 [32/50000]	Loss: 1.7036	LR: 0.000059
Training Epoch: 305 [32/50000]	Loss: 1.1037	LR: 0.000059
Evaluating Network.....
Test set: Epoch: 305, Average loss: 0.0464, Top1Accuracy: 0.5821, Top3Accuracy: 0.7881, Top5Accuracy: 0.8588, Time consumed:2.66s

Training Epoch: 306 [32/50000]	Loss: 1.5975	LR: 0.000057
Training Epoch: 306 [32/50000]	Loss: 1.7338	LR: 0.000057
Training Epoch: 306 [32/50000]	Loss: 1.6557	LR: 0.000057
Training Epoch: 306 [32/50000]	Loss: 1.3919	LR: 0.000057
Training Epoch: 306 [32/50000]	Loss: 1.3610	LR: 0.000057
Training Epoch: 306 [32/50000]	Loss: 1.3116	LR: 0.000057
Training Epoch: 306 [32/50000]	Loss: 1.4975	LR: 0.000057
Training Epoch: 306 [32/50000]	Loss: 1.2085	LR: 0.000057
Training Epoch: 306 [32/50000]	Loss: 1.3214	LR: 0.000057
Training Epoch: 306 [32/50000]	Loss: 1.0235	LR: 0.000057
Evaluating Network.....
Test set: Epoch: 306, Average loss: 0.0465, Top1Accuracy: 0.5812, Top3Accuracy: 0.7871, Top5Accuracy: 0.8600, Time consumed:2.65s

Training Epoch: 307 [32/50000]	Loss: 0.9802	LR: 0.000056
Training Epoch: 307 [32/50000]	Loss: 1.3851	LR: 0.000056
Training Epoch: 307 [32/50000]	Loss: 1.2288	LR: 0.000056
Training Epoch: 307 [32/50000]	Loss: 1.9353	LR: 0.000056
Training Epoch: 307 [32/50000]	Loss: 1.9387	LR: 0.000056
Training Epoch: 307 [32/50000]	Loss: 0.7701	LR: 0.000056
Training Epoch: 307 [32/50000]	Loss: 1.2651	LR: 0.000056
Training Epoch: 307 [32/50000]	Loss: 1.4761	LR: 0.000056
Training Epoch: 307 [32/50000]	Loss: 1.4911	LR: 0.000056
Training Epoch: 307 [32/50000]	Loss: 1.9902	LR: 0.000056
Evaluating Network.....
Test set: Epoch: 307, Average loss: 0.0464, Top1Accuracy: 0.5829, Top3Accuracy: 0.7869, Top5Accuracy: 0.8595, Time consumed:2.68s

Training Epoch: 308 [32/50000]	Loss: 1.9801	LR: 0.000054
Training Epoch: 308 [32/50000]	Loss: 1.1408	LR: 0.000054
Training Epoch: 308 [32/50000]	Loss: 1.4405	LR: 0.000054
Training Epoch: 308 [32/50000]	Loss: 1.0675	LR: 0.000054
Training Epoch: 308 [32/50000]	Loss: 1.3192	LR: 0.000054
Training Epoch: 308 [32/50000]	Loss: 1.2338	LR: 0.000054
Training Epoch: 308 [32/50000]	Loss: 1.1275	LR: 0.000054
Training Epoch: 308 [32/50000]	Loss: 1.1373	LR: 0.000054
Training Epoch: 308 [32/50000]	Loss: 1.2433	LR: 0.000054
Training Epoch: 308 [32/50000]	Loss: 1.1413	LR: 0.000054
Evaluating Network.....
Test set: Epoch: 308, Average loss: 0.0465, Top1Accuracy: 0.5816, Top3Accuracy: 0.7861, Top5Accuracy: 0.8603, Time consumed:2.72s

Training Epoch: 309 [32/50000]	Loss: 1.8335	LR: 0.000053
Training Epoch: 309 [32/50000]	Loss: 1.5661	LR: 0.000053
Training Epoch: 309 [32/50000]	Loss: 1.7002	LR: 0.000053
Training Epoch: 309 [32/50000]	Loss: 1.4722	LR: 0.000053
Training Epoch: 309 [32/50000]	Loss: 1.6982	LR: 0.000053
Training Epoch: 309 [32/50000]	Loss: 1.7003	LR: 0.000053
Training Epoch: 309 [32/50000]	Loss: 1.6400	LR: 0.000053
Training Epoch: 309 [32/50000]	Loss: 0.8786	LR: 0.000053
Training Epoch: 309 [32/50000]	Loss: 1.8228	LR: 0.000053
Training Epoch: 309 [32/50000]	Loss: 1.4343	LR: 0.000053
Evaluating Network.....
Test set: Epoch: 309, Average loss: 0.0466, Top1Accuracy: 0.5801, Top3Accuracy: 0.7863, Top5Accuracy: 0.8588, Time consumed:2.61s

Training Epoch: 310 [32/50000]	Loss: 1.7814	LR: 0.000051
Training Epoch: 310 [32/50000]	Loss: 1.3056	LR: 0.000051
Training Epoch: 310 [32/50000]	Loss: 1.4902	LR: 0.000051
Training Epoch: 310 [32/50000]	Loss: 1.3198	LR: 0.000051
Training Epoch: 310 [32/50000]	Loss: 1.0197	LR: 0.000051
Training Epoch: 310 [32/50000]	Loss: 1.1792	LR: 0.000051
Training Epoch: 310 [32/50000]	Loss: 1.5729	LR: 0.000051
Training Epoch: 310 [32/50000]	Loss: 1.6670	LR: 0.000051
Training Epoch: 310 [32/50000]	Loss: 1.7223	LR: 0.000051
Training Epoch: 310 [32/50000]	Loss: 1.6032	LR: 0.000051
Evaluating Network.....
Test set: Epoch: 310, Average loss: 0.0464, Top1Accuracy: 0.5827, Top3Accuracy: 0.7862, Top5Accuracy: 0.8590, Time consumed:2.63s

Training Epoch: 311 [32/50000]	Loss: 1.1986	LR: 0.000050
Training Epoch: 311 [32/50000]	Loss: 0.9304	LR: 0.000050
Training Epoch: 311 [32/50000]	Loss: 1.2391	LR: 0.000050
Training Epoch: 311 [32/50000]	Loss: 1.3519	LR: 0.000050
Training Epoch: 311 [32/50000]	Loss: 1.5935	LR: 0.000050
Training Epoch: 311 [32/50000]	Loss: 1.7545	LR: 0.000050
Training Epoch: 311 [32/50000]	Loss: 1.2513	LR: 0.000050
Training Epoch: 311 [32/50000]	Loss: 1.3884	LR: 0.000050
Training Epoch: 311 [32/50000]	Loss: 1.3438	LR: 0.000050
Training Epoch: 311 [32/50000]	Loss: 1.4622	LR: 0.000050
Evaluating Network.....
Test set: Epoch: 311, Average loss: 0.0464, Top1Accuracy: 0.5823, Top3Accuracy: 0.7867, Top5Accuracy: 0.8598, Time consumed:2.59s

Training Epoch: 312 [32/50000]	Loss: 1.4825	LR: 0.000049
Training Epoch: 312 [32/50000]	Loss: 1.2682	LR: 0.000049
Training Epoch: 312 [32/50000]	Loss: 1.4059	LR: 0.000049
Training Epoch: 312 [32/50000]	Loss: 1.0701	LR: 0.000049
Training Epoch: 312 [32/50000]	Loss: 1.8348	LR: 0.000049
Training Epoch: 312 [32/50000]	Loss: 1.6357	LR: 0.000049
Training Epoch: 312 [32/50000]	Loss: 1.1427	LR: 0.000049
Training Epoch: 312 [32/50000]	Loss: 1.1860	LR: 0.000049
Training Epoch: 312 [32/50000]	Loss: 1.1633	LR: 0.000049
Training Epoch: 312 [32/50000]	Loss: 1.1803	LR: 0.000049
Evaluating Network.....
Test set: Epoch: 312, Average loss: 0.0464, Top1Accuracy: 0.5820, Top3Accuracy: 0.7870, Top5Accuracy: 0.8612, Time consumed:2.60s

Training Epoch: 313 [32/50000]	Loss: 1.8709	LR: 0.000047
Training Epoch: 313 [32/50000]	Loss: 1.7816	LR: 0.000047
Training Epoch: 313 [32/50000]	Loss: 1.5746	LR: 0.000047
Training Epoch: 313 [32/50000]	Loss: 1.4584	LR: 0.000047
Training Epoch: 313 [32/50000]	Loss: 1.3829	LR: 0.000047
Training Epoch: 313 [32/50000]	Loss: 1.6157	LR: 0.000047
Training Epoch: 313 [32/50000]	Loss: 1.0860	LR: 0.000047
Training Epoch: 313 [32/50000]	Loss: 1.1829	LR: 0.000047
Training Epoch: 313 [32/50000]	Loss: 0.9695	LR: 0.000047
Training Epoch: 313 [32/50000]	Loss: 1.6929	LR: 0.000047
Evaluating Network.....
Test set: Epoch: 313, Average loss: 0.0464, Top1Accuracy: 0.5813, Top3Accuracy: 0.7885, Top5Accuracy: 0.8602, Time consumed:2.66s

Training Epoch: 314 [32/50000]	Loss: 1.5262	LR: 0.000046
Training Epoch: 314 [32/50000]	Loss: 1.6152	LR: 0.000046
Training Epoch: 314 [32/50000]	Loss: 1.6876	LR: 0.000046
Training Epoch: 314 [32/50000]	Loss: 1.1943	LR: 0.000046
Training Epoch: 314 [32/50000]	Loss: 1.1503	LR: 0.000046
Training Epoch: 314 [32/50000]	Loss: 1.0940	LR: 0.000046
Training Epoch: 314 [32/50000]	Loss: 1.4549	LR: 0.000046
Training Epoch: 314 [32/50000]	Loss: 1.3523	LR: 0.000046
Training Epoch: 314 [32/50000]	Loss: 1.2425	LR: 0.000046
Training Epoch: 314 [32/50000]	Loss: 1.2436	LR: 0.000046
Evaluating Network.....
Test set: Epoch: 314, Average loss: 0.0464, Top1Accuracy: 0.5826, Top3Accuracy: 0.7876, Top5Accuracy: 0.8597, Time consumed:2.70s

Training Epoch: 315 [32/50000]	Loss: 1.6906	LR: 0.000045
Training Epoch: 315 [32/50000]	Loss: 1.5110	LR: 0.000045
Training Epoch: 315 [32/50000]	Loss: 1.5486	LR: 0.000045
Training Epoch: 315 [32/50000]	Loss: 1.1080	LR: 0.000045
Training Epoch: 315 [32/50000]	Loss: 1.5958	LR: 0.000045
Training Epoch: 315 [32/50000]	Loss: 1.2869	LR: 0.000045
Training Epoch: 315 [32/50000]	Loss: 1.5561	LR: 0.000045
Training Epoch: 315 [32/50000]	Loss: 1.2324	LR: 0.000045
Training Epoch: 315 [32/50000]	Loss: 1.8054	LR: 0.000045
Training Epoch: 315 [32/50000]	Loss: 1.8188	LR: 0.000045
Evaluating Network.....
Test set: Epoch: 315, Average loss: 0.0465, Top1Accuracy: 0.5800, Top3Accuracy: 0.7869, Top5Accuracy: 0.8594, Time consumed:2.63s

Training Epoch: 316 [32/50000]	Loss: 1.1655	LR: 0.000044
Training Epoch: 316 [32/50000]	Loss: 1.3205	LR: 0.000044
Training Epoch: 316 [32/50000]	Loss: 1.4201	LR: 0.000044
Training Epoch: 316 [32/50000]	Loss: 1.4006	LR: 0.000044
Training Epoch: 316 [32/50000]	Loss: 1.0592	LR: 0.000044
Training Epoch: 316 [32/50000]	Loss: 1.6450	LR: 0.000044
Training Epoch: 316 [32/50000]	Loss: 1.4902	LR: 0.000044
Training Epoch: 316 [32/50000]	Loss: 1.3977	LR: 0.000044
Training Epoch: 316 [32/50000]	Loss: 1.2260	LR: 0.000044
Training Epoch: 316 [32/50000]	Loss: 1.1664	LR: 0.000044
Evaluating Network.....
Test set: Epoch: 316, Average loss: 0.0464, Top1Accuracy: 0.5828, Top3Accuracy: 0.7858, Top5Accuracy: 0.8601, Time consumed:2.65s

Training Epoch: 317 [32/50000]	Loss: 1.2718	LR: 0.000043
Training Epoch: 317 [32/50000]	Loss: 1.7042	LR: 0.000043
Training Epoch: 317 [32/50000]	Loss: 1.1603	LR: 0.000043
Training Epoch: 317 [32/50000]	Loss: 1.3141	LR: 0.000043
Training Epoch: 317 [32/50000]	Loss: 1.7603	LR: 0.000043
Training Epoch: 317 [32/50000]	Loss: 1.3748	LR: 0.000043
Training Epoch: 317 [32/50000]	Loss: 1.6704	LR: 0.000043
Training Epoch: 317 [32/50000]	Loss: 1.6376	LR: 0.000043
Training Epoch: 317 [32/50000]	Loss: 1.4226	LR: 0.000043
Training Epoch: 317 [32/50000]	Loss: 1.4945	LR: 0.000043
Evaluating Network.....
Test set: Epoch: 317, Average loss: 0.0464, Top1Accuracy: 0.5826, Top3Accuracy: 0.7880, Top5Accuracy: 0.8603, Time consumed:2.62s

Training Epoch: 318 [32/50000]	Loss: 1.4394	LR: 0.000041
Training Epoch: 318 [32/50000]	Loss: 1.2511	LR: 0.000041
Training Epoch: 318 [32/50000]	Loss: 1.0377	LR: 0.000041
Training Epoch: 318 [32/50000]	Loss: 1.3235	LR: 0.000041
Training Epoch: 318 [32/50000]	Loss: 1.9648	LR: 0.000041
Training Epoch: 318 [32/50000]	Loss: 1.4253	LR: 0.000041
Training Epoch: 318 [32/50000]	Loss: 2.0925	LR: 0.000041
Training Epoch: 318 [32/50000]	Loss: 2.0330	LR: 0.000041
Training Epoch: 318 [32/50000]	Loss: 0.9873	LR: 0.000041
Training Epoch: 318 [32/50000]	Loss: 1.6203	LR: 0.000041
Evaluating Network.....
Test set: Epoch: 318, Average loss: 0.0464, Top1Accuracy: 0.5811, Top3Accuracy: 0.7878, Top5Accuracy: 0.8584, Time consumed:2.61s

Training Epoch: 319 [32/50000]	Loss: 1.1939	LR: 0.000040
Training Epoch: 319 [32/50000]	Loss: 1.5841	LR: 0.000040
Training Epoch: 319 [32/50000]	Loss: 1.2411	LR: 0.000040
Training Epoch: 319 [32/50000]	Loss: 1.2764	LR: 0.000040
Training Epoch: 319 [32/50000]	Loss: 1.8186	LR: 0.000040
Training Epoch: 319 [32/50000]	Loss: 1.2565	LR: 0.000040
Training Epoch: 319 [32/50000]	Loss: 1.1938	LR: 0.000040
Training Epoch: 319 [32/50000]	Loss: 1.2568	LR: 0.000040
Training Epoch: 319 [32/50000]	Loss: 1.3288	LR: 0.000040
Training Epoch: 319 [32/50000]	Loss: 1.1758	LR: 0.000040
Evaluating Network.....
Test set: Epoch: 319, Average loss: 0.0464, Top1Accuracy: 0.5822, Top3Accuracy: 0.7878, Top5Accuracy: 0.8598, Time consumed:2.65s

Training Epoch: 320 [32/50000]	Loss: 1.7066	LR: 0.000039
Training Epoch: 320 [32/50000]	Loss: 1.4709	LR: 0.000039
Training Epoch: 320 [32/50000]	Loss: 1.2132	LR: 0.000039
Training Epoch: 320 [32/50000]	Loss: 1.3273	LR: 0.000039
Training Epoch: 320 [32/50000]	Loss: 1.3007	LR: 0.000039
Training Epoch: 320 [32/50000]	Loss: 1.2292	LR: 0.000039
Training Epoch: 320 [32/50000]	Loss: 1.0858	LR: 0.000039
Training Epoch: 320 [32/50000]	Loss: 1.4196	LR: 0.000039
Training Epoch: 320 [32/50000]	Loss: 1.4538	LR: 0.000039
Training Epoch: 320 [32/50000]	Loss: 1.2631	LR: 0.000039
Evaluating Network.....
Test set: Epoch: 320, Average loss: 0.0464, Top1Accuracy: 0.5836, Top3Accuracy: 0.7872, Top5Accuracy: 0.8595, Time consumed:2.66s

Training Epoch: 321 [32/50000]	Loss: 1.7290	LR: 0.000038
Training Epoch: 321 [32/50000]	Loss: 1.7639	LR: 0.000038
Training Epoch: 321 [32/50000]	Loss: 1.6016	LR: 0.000038
Training Epoch: 321 [32/50000]	Loss: 1.6570	LR: 0.000038
Training Epoch: 321 [32/50000]	Loss: 0.9589	LR: 0.000038
Training Epoch: 321 [32/50000]	Loss: 1.0235	LR: 0.000038
Training Epoch: 321 [32/50000]	Loss: 1.2920	LR: 0.000038
Training Epoch: 321 [32/50000]	Loss: 2.0170	LR: 0.000038
Training Epoch: 321 [32/50000]	Loss: 0.7393	LR: 0.000038
Training Epoch: 321 [32/50000]	Loss: 1.0184	LR: 0.000038
Evaluating Network.....
Test set: Epoch: 321, Average loss: 0.0463, Top1Accuracy: 0.5828, Top3Accuracy: 0.7879, Top5Accuracy: 0.8595, Time consumed:2.69s

Training Epoch: 322 [32/50000]	Loss: 1.3939	LR: 0.000037
Training Epoch: 322 [32/50000]	Loss: 1.3557	LR: 0.000037
Training Epoch: 322 [32/50000]	Loss: 1.1806	LR: 0.000037
Training Epoch: 322 [32/50000]	Loss: 1.4800	LR: 0.000037
Training Epoch: 322 [32/50000]	Loss: 1.3638	LR: 0.000037
Training Epoch: 322 [32/50000]	Loss: 1.5237	LR: 0.000037
Training Epoch: 322 [32/50000]	Loss: 1.5926	LR: 0.000037
Training Epoch: 322 [32/50000]	Loss: 1.3733	LR: 0.000037
Training Epoch: 322 [32/50000]	Loss: 1.4662	LR: 0.000037
Training Epoch: 322 [32/50000]	Loss: 1.2582	LR: 0.000037
Evaluating Network.....
Test set: Epoch: 322, Average loss: 0.0464, Top1Accuracy: 0.5825, Top3Accuracy: 0.7860, Top5Accuracy: 0.8600, Time consumed:2.60s

Training Epoch: 323 [32/50000]	Loss: 0.9222	LR: 0.000036
Training Epoch: 323 [32/50000]	Loss: 1.5829	LR: 0.000036
Training Epoch: 323 [32/50000]	Loss: 1.4255	LR: 0.000036
Training Epoch: 323 [32/50000]	Loss: 1.2438	LR: 0.000036
Training Epoch: 323 [32/50000]	Loss: 1.2869	LR: 0.000036
Training Epoch: 323 [32/50000]	Loss: 1.7941	LR: 0.000036
Training Epoch: 323 [32/50000]	Loss: 1.6165	LR: 0.000036
Training Epoch: 323 [32/50000]	Loss: 1.2213	LR: 0.000036
Training Epoch: 323 [32/50000]	Loss: 1.6444	LR: 0.000036
Training Epoch: 323 [32/50000]	Loss: 1.4238	LR: 0.000036
Evaluating Network.....
Test set: Epoch: 323, Average loss: 0.0464, Top1Accuracy: 0.5827, Top3Accuracy: 0.7884, Top5Accuracy: 0.8601, Time consumed:2.64s

Training Epoch: 324 [32/50000]	Loss: 1.3068	LR: 0.000035
Training Epoch: 324 [32/50000]	Loss: 1.6967	LR: 0.000035
Training Epoch: 324 [32/50000]	Loss: 1.8405	LR: 0.000035
Training Epoch: 324 [32/50000]	Loss: 1.3581	LR: 0.000035
Training Epoch: 324 [32/50000]	Loss: 1.2766	LR: 0.000035
Training Epoch: 324 [32/50000]	Loss: 1.4633	LR: 0.000035
Training Epoch: 324 [32/50000]	Loss: 1.5300	LR: 0.000035
Training Epoch: 324 [32/50000]	Loss: 1.3104	LR: 0.000035
Training Epoch: 324 [32/50000]	Loss: 1.3128	LR: 0.000035
Training Epoch: 324 [32/50000]	Loss: 1.6439	LR: 0.000035
Evaluating Network.....
Test set: Epoch: 324, Average loss: 0.0464, Top1Accuracy: 0.5816, Top3Accuracy: 0.7867, Top5Accuracy: 0.8594, Time consumed:2.63s

Training Epoch: 325 [32/50000]	Loss: 1.7195	LR: 0.000034
Training Epoch: 325 [32/50000]	Loss: 1.3007	LR: 0.000034
Training Epoch: 325 [32/50000]	Loss: 1.8495	LR: 0.000034
Training Epoch: 325 [32/50000]	Loss: 1.6446	LR: 0.000034
Training Epoch: 325 [32/50000]	Loss: 1.6797	LR: 0.000034
Training Epoch: 325 [32/50000]	Loss: 1.3105	LR: 0.000034
Training Epoch: 325 [32/50000]	Loss: 1.5398	LR: 0.000034
Training Epoch: 325 [32/50000]	Loss: 1.1423	LR: 0.000034
Training Epoch: 325 [32/50000]	Loss: 1.6888	LR: 0.000034
Training Epoch: 325 [32/50000]	Loss: 1.3768	LR: 0.000034
Evaluating Network.....
Test set: Epoch: 325, Average loss: 0.0463, Top1Accuracy: 0.5831, Top3Accuracy: 0.7886, Top5Accuracy: 0.8611, Time consumed:2.64s

Training Epoch: 326 [32/50000]	Loss: 1.3115	LR: 0.000033
Training Epoch: 326 [32/50000]	Loss: 1.7196	LR: 0.000033
Training Epoch: 326 [32/50000]	Loss: 1.6086	LR: 0.000033
Training Epoch: 326 [32/50000]	Loss: 1.5110	LR: 0.000033
Training Epoch: 326 [32/50000]	Loss: 1.4660	LR: 0.000033
Training Epoch: 326 [32/50000]	Loss: 1.6112	LR: 0.000033
Training Epoch: 326 [32/50000]	Loss: 1.7321	LR: 0.000033
Training Epoch: 326 [32/50000]	Loss: 1.5933	LR: 0.000033
Training Epoch: 326 [32/50000]	Loss: 1.5091	LR: 0.000033
Training Epoch: 326 [32/50000]	Loss: 1.4873	LR: 0.000033
Evaluating Network.....
Test set: Epoch: 326, Average loss: 0.0464, Top1Accuracy: 0.5819, Top3Accuracy: 0.7861, Top5Accuracy: 0.8591, Time consumed:2.61s

Training Epoch: 327 [32/50000]	Loss: 0.9596	LR: 0.000033
Training Epoch: 327 [32/50000]	Loss: 1.3451	LR: 0.000033
Training Epoch: 327 [32/50000]	Loss: 1.3841	LR: 0.000033
Training Epoch: 327 [32/50000]	Loss: 1.6605	LR: 0.000033
Training Epoch: 327 [32/50000]	Loss: 1.4757	LR: 0.000033
Training Epoch: 327 [32/50000]	Loss: 1.0453	LR: 0.000033
Training Epoch: 327 [32/50000]	Loss: 1.2870	LR: 0.000033
Training Epoch: 327 [32/50000]	Loss: 1.7176	LR: 0.000033
Training Epoch: 327 [32/50000]	Loss: 0.9467	LR: 0.000033
Training Epoch: 327 [32/50000]	Loss: 1.1632	LR: 0.000033
Evaluating Network.....
Test set: Epoch: 327, Average loss: 0.0464, Top1Accuracy: 0.5814, Top3Accuracy: 0.7863, Top5Accuracy: 0.8600, Time consumed:2.65s

Training Epoch: 328 [32/50000]	Loss: 1.2007	LR: 0.000032
Training Epoch: 328 [32/50000]	Loss: 1.7816	LR: 0.000032
Training Epoch: 328 [32/50000]	Loss: 1.5660	LR: 0.000032
Training Epoch: 328 [32/50000]	Loss: 1.3932	LR: 0.000032
Training Epoch: 328 [32/50000]	Loss: 1.3118	LR: 0.000032
Training Epoch: 328 [32/50000]	Loss: 1.3959	LR: 0.000032
Training Epoch: 328 [32/50000]	Loss: 1.3984	LR: 0.000032
Training Epoch: 328 [32/50000]	Loss: 1.5679	LR: 0.000032
Training Epoch: 328 [32/50000]	Loss: 1.0095	LR: 0.000032
Training Epoch: 328 [32/50000]	Loss: 1.4229	LR: 0.000032
Evaluating Network.....
Test set: Epoch: 328, Average loss: 0.0464, Top1Accuracy: 0.5816, Top3Accuracy: 0.7867, Top5Accuracy: 0.8600, Time consumed:2.68s

Training Epoch: 329 [32/50000]	Loss: 1.4428	LR: 0.000031
Training Epoch: 329 [32/50000]	Loss: 1.3894	LR: 0.000031
Training Epoch: 329 [32/50000]	Loss: 1.2883	LR: 0.000031
Training Epoch: 329 [32/50000]	Loss: 0.9520	LR: 0.000031
Training Epoch: 329 [32/50000]	Loss: 1.2544	LR: 0.000031
Training Epoch: 329 [32/50000]	Loss: 1.5669	LR: 0.000031
Training Epoch: 329 [32/50000]	Loss: 1.2591	LR: 0.000031
Training Epoch: 329 [32/50000]	Loss: 1.1365	LR: 0.000031
Training Epoch: 329 [32/50000]	Loss: 1.5743	LR: 0.000031
Training Epoch: 329 [32/50000]	Loss: 1.2325	LR: 0.000031
Evaluating Network.....
Test set: Epoch: 329, Average loss: 0.0465, Top1Accuracy: 0.5807, Top3Accuracy: 0.7875, Top5Accuracy: 0.8605, Time consumed:2.63s

Training Epoch: 330 [32/50000]	Loss: 1.1403	LR: 0.000030
Training Epoch: 330 [32/50000]	Loss: 1.6694	LR: 0.000030
Training Epoch: 330 [32/50000]	Loss: 1.0904	LR: 0.000030
Training Epoch: 330 [32/50000]	Loss: 1.7424	LR: 0.000030
Training Epoch: 330 [32/50000]	Loss: 1.2064	LR: 0.000030
Training Epoch: 330 [32/50000]	Loss: 1.7241	LR: 0.000030
Training Epoch: 330 [32/50000]	Loss: 1.4190	LR: 0.000030
Training Epoch: 330 [32/50000]	Loss: 1.4753	LR: 0.000030
Training Epoch: 330 [32/50000]	Loss: 1.0933	LR: 0.000030
Training Epoch: 330 [32/50000]	Loss: 1.6139	LR: 0.000030
Evaluating Network.....
Test set: Epoch: 330, Average loss: 0.0464, Top1Accuracy: 0.5830, Top3Accuracy: 0.7853, Top5Accuracy: 0.8607, Time consumed:2.69s

Training Epoch: 331 [32/50000]	Loss: 1.5018	LR: 0.000029
Training Epoch: 331 [32/50000]	Loss: 1.4771	LR: 0.000029
Training Epoch: 331 [32/50000]	Loss: 1.1612	LR: 0.000029
Training Epoch: 331 [32/50000]	Loss: 1.5716	LR: 0.000029
Training Epoch: 331 [32/50000]	Loss: 1.7037	LR: 0.000029
Training Epoch: 331 [32/50000]	Loss: 1.0081	LR: 0.000029
Training Epoch: 331 [32/50000]	Loss: 0.9799	LR: 0.000029
Training Epoch: 331 [32/50000]	Loss: 1.6232	LR: 0.000029
Training Epoch: 331 [32/50000]	Loss: 1.5635	LR: 0.000029
Training Epoch: 331 [32/50000]	Loss: 1.3989	LR: 0.000029
Evaluating Network.....
Test set: Epoch: 331, Average loss: 0.0463, Top1Accuracy: 0.5838, Top3Accuracy: 0.7863, Top5Accuracy: 0.8605, Time consumed:2.64s

Training Epoch: 332 [32/50000]	Loss: 1.5718	LR: 0.000029
Training Epoch: 332 [32/50000]	Loss: 1.2556	LR: 0.000029
Training Epoch: 332 [32/50000]	Loss: 1.6611	LR: 0.000029
Training Epoch: 332 [32/50000]	Loss: 1.9041	LR: 0.000029
Training Epoch: 332 [32/50000]	Loss: 1.1852	LR: 0.000029
Training Epoch: 332 [32/50000]	Loss: 1.0566	LR: 0.000029
Training Epoch: 332 [32/50000]	Loss: 1.3543	LR: 0.000029
Training Epoch: 332 [32/50000]	Loss: 1.2816	LR: 0.000029
Training Epoch: 332 [32/50000]	Loss: 1.0904	LR: 0.000029
Training Epoch: 332 [32/50000]	Loss: 1.0099	LR: 0.000029
Evaluating Network.....
Test set: Epoch: 332, Average loss: 0.0463, Top1Accuracy: 0.5829, Top3Accuracy: 0.7872, Top5Accuracy: 0.8598, Time consumed:2.68s

Training Epoch: 333 [32/50000]	Loss: 1.2136	LR: 0.000028
Training Epoch: 333 [32/50000]	Loss: 1.3662	LR: 0.000028
Training Epoch: 333 [32/50000]	Loss: 1.4451	LR: 0.000028
Training Epoch: 333 [32/50000]	Loss: 1.1508	LR: 0.000028
Training Epoch: 333 [32/50000]	Loss: 1.8514	LR: 0.000028
Training Epoch: 333 [32/50000]	Loss: 1.2958	LR: 0.000028
Training Epoch: 333 [32/50000]	Loss: 0.9437	LR: 0.000028
Training Epoch: 333 [32/50000]	Loss: 1.6569	LR: 0.000028
Training Epoch: 333 [32/50000]	Loss: 1.5916	LR: 0.000028
Training Epoch: 333 [32/50000]	Loss: 1.2899	LR: 0.000028
Evaluating Network.....
Test set: Epoch: 333, Average loss: 0.0463, Top1Accuracy: 0.5830, Top3Accuracy: 0.7870, Top5Accuracy: 0.8586, Time consumed:2.66s

Training Epoch: 334 [32/50000]	Loss: 1.2772	LR: 0.000027
Training Epoch: 334 [32/50000]	Loss: 1.4939	LR: 0.000027
Training Epoch: 334 [32/50000]	Loss: 1.1946	LR: 0.000027
Training Epoch: 334 [32/50000]	Loss: 1.4632	LR: 0.000027
Training Epoch: 334 [32/50000]	Loss: 1.1916	LR: 0.000027
Training Epoch: 334 [32/50000]	Loss: 1.5115	LR: 0.000027
Training Epoch: 334 [32/50000]	Loss: 1.3996	LR: 0.000027
Training Epoch: 334 [32/50000]	Loss: 1.3307	LR: 0.000027
Training Epoch: 334 [32/50000]	Loss: 1.4546	LR: 0.000027
Training Epoch: 334 [32/50000]	Loss: 1.5110	LR: 0.000027
Evaluating Network.....
Test set: Epoch: 334, Average loss: 0.0464, Top1Accuracy: 0.5827, Top3Accuracy: 0.7880, Top5Accuracy: 0.8597, Time consumed:2.64s

Training Epoch: 335 [32/50000]	Loss: 1.2181	LR: 0.000026
Training Epoch: 335 [32/50000]	Loss: 1.1230	LR: 0.000026
Training Epoch: 335 [32/50000]	Loss: 1.7922	LR: 0.000026
Training Epoch: 335 [32/50000]	Loss: 0.8376	LR: 0.000026
Training Epoch: 335 [32/50000]	Loss: 1.8506	LR: 0.000026
Training Epoch: 335 [32/50000]	Loss: 1.5973	LR: 0.000026
Training Epoch: 335 [32/50000]	Loss: 0.9538	LR: 0.000026
Training Epoch: 335 [32/50000]	Loss: 1.3850	LR: 0.000026
Training Epoch: 335 [32/50000]	Loss: 1.4538	LR: 0.000026
Training Epoch: 335 [32/50000]	Loss: 1.7627	LR: 0.000026
Evaluating Network.....
Test set: Epoch: 335, Average loss: 0.0463, Top1Accuracy: 0.5828, Top3Accuracy: 0.7875, Top5Accuracy: 0.8605, Time consumed:2.65s

Training Epoch: 336 [32/50000]	Loss: 1.0416	LR: 0.000026
Training Epoch: 336 [32/50000]	Loss: 1.3098	LR: 0.000026
Training Epoch: 336 [32/50000]	Loss: 1.8490	LR: 0.000026
Training Epoch: 336 [32/50000]	Loss: 1.3624	LR: 0.000026
Training Epoch: 336 [32/50000]	Loss: 1.5022	LR: 0.000026
Training Epoch: 336 [32/50000]	Loss: 1.5431	LR: 0.000026
Training Epoch: 336 [32/50000]	Loss: 1.3308	LR: 0.000026
Training Epoch: 336 [32/50000]	Loss: 1.4256	LR: 0.000026
Training Epoch: 336 [32/50000]	Loss: 1.3485	LR: 0.000026
Training Epoch: 336 [32/50000]	Loss: 1.3179	LR: 0.000026
Evaluating Network.....
Test set: Epoch: 336, Average loss: 0.0463, Top1Accuracy: 0.5835, Top3Accuracy: 0.7870, Top5Accuracy: 0.8595, Time consumed:2.61s

Training Epoch: 337 [32/50000]	Loss: 1.6165	LR: 0.000025
Training Epoch: 337 [32/50000]	Loss: 1.7491	LR: 0.000025
Training Epoch: 337 [32/50000]	Loss: 1.3194	LR: 0.000025
Training Epoch: 337 [32/50000]	Loss: 1.1040	LR: 0.000025
Training Epoch: 337 [32/50000]	Loss: 1.9727	LR: 0.000025
Training Epoch: 337 [32/50000]	Loss: 1.1509	LR: 0.000025
Training Epoch: 337 [32/50000]	Loss: 1.3133	LR: 0.000025
Training Epoch: 337 [32/50000]	Loss: 1.0850	LR: 0.000025
Training Epoch: 337 [32/50000]	Loss: 1.4208	LR: 0.000025
Training Epoch: 337 [32/50000]	Loss: 1.7274	LR: 0.000025
Evaluating Network.....
Test set: Epoch: 337, Average loss: 0.0463, Top1Accuracy: 0.5818, Top3Accuracy: 0.7875, Top5Accuracy: 0.8599, Time consumed:2.60s

Training Epoch: 338 [32/50000]	Loss: 1.5515	LR: 0.000024
Training Epoch: 338 [32/50000]	Loss: 1.3465	LR: 0.000024
Training Epoch: 338 [32/50000]	Loss: 1.3541	LR: 0.000024
Training Epoch: 338 [32/50000]	Loss: 1.4593	LR: 0.000024
Training Epoch: 338 [32/50000]	Loss: 1.2516	LR: 0.000024
Training Epoch: 338 [32/50000]	Loss: 1.5831	LR: 0.000024
Training Epoch: 338 [32/50000]	Loss: 1.4955	LR: 0.000024
Training Epoch: 338 [32/50000]	Loss: 1.3036	LR: 0.000024
Training Epoch: 338 [32/50000]	Loss: 1.7054	LR: 0.000024
Training Epoch: 338 [32/50000]	Loss: 1.1443	LR: 0.000024
Evaluating Network.....
Test set: Epoch: 338, Average loss: 0.0464, Top1Accuracy: 0.5822, Top3Accuracy: 0.7887, Top5Accuracy: 0.8600, Time consumed:2.63s

Training Epoch: 339 [32/50000]	Loss: 1.7525	LR: 0.000024
Training Epoch: 339 [32/50000]	Loss: 1.1882	LR: 0.000024
Training Epoch: 339 [32/50000]	Loss: 0.9881	LR: 0.000024
Training Epoch: 339 [32/50000]	Loss: 1.4377	LR: 0.000024
Training Epoch: 339 [32/50000]	Loss: 1.0892	LR: 0.000024
Training Epoch: 339 [32/50000]	Loss: 1.2836	LR: 0.000024
Training Epoch: 339 [32/50000]	Loss: 1.2998	LR: 0.000024
Training Epoch: 339 [32/50000]	Loss: 1.5954	LR: 0.000024
Training Epoch: 339 [32/50000]	Loss: 1.2563	LR: 0.000024
Training Epoch: 339 [32/50000]	Loss: 0.9237	LR: 0.000024
Evaluating Network.....
Test set: Epoch: 339, Average loss: 0.0464, Top1Accuracy: 0.5831, Top3Accuracy: 0.7877, Top5Accuracy: 0.8610, Time consumed:2.61s

Training Epoch: 340 [32/50000]	Loss: 1.6458	LR: 0.000023
Training Epoch: 340 [32/50000]	Loss: 1.4928	LR: 0.000023
Training Epoch: 340 [32/50000]	Loss: 1.4460	LR: 0.000023
Training Epoch: 340 [32/50000]	Loss: 1.3070	LR: 0.000023
Training Epoch: 340 [32/50000]	Loss: 1.5261	LR: 0.000023
Training Epoch: 340 [32/50000]	Loss: 1.3201	LR: 0.000023
Training Epoch: 340 [32/50000]	Loss: 1.3059	LR: 0.000023
Training Epoch: 340 [32/50000]	Loss: 1.3316	LR: 0.000023
Training Epoch: 340 [32/50000]	Loss: 1.1893	LR: 0.000023
Training Epoch: 340 [32/50000]	Loss: 1.4251	LR: 0.000023
Evaluating Network.....
Test set: Epoch: 340, Average loss: 0.0463, Top1Accuracy: 0.5835, Top3Accuracy: 0.7872, Top5Accuracy: 0.8602, Time consumed:2.73s

Training Epoch: 341 [32/50000]	Loss: 1.5941	LR: 0.000022
Training Epoch: 341 [32/50000]	Loss: 1.7058	LR: 0.000022
Training Epoch: 341 [32/50000]	Loss: 1.2208	LR: 0.000022
Training Epoch: 341 [32/50000]	Loss: 1.0386	LR: 0.000022
Training Epoch: 341 [32/50000]	Loss: 1.3867	LR: 0.000022
Training Epoch: 341 [32/50000]	Loss: 1.3429	LR: 0.000022
Training Epoch: 341 [32/50000]	Loss: 1.1045	LR: 0.000022
Training Epoch: 341 [32/50000]	Loss: 1.1347	LR: 0.000022
Training Epoch: 341 [32/50000]	Loss: 1.6099	LR: 0.000022
Training Epoch: 341 [32/50000]	Loss: 1.1894	LR: 0.000022
Evaluating Network.....
Test set: Epoch: 341, Average loss: 0.0464, Top1Accuracy: 0.5831, Top3Accuracy: 0.7873, Top5Accuracy: 0.8594, Time consumed:2.60s

Training Epoch: 342 [32/50000]	Loss: 0.9289	LR: 0.000022
Training Epoch: 342 [32/50000]	Loss: 1.2131	LR: 0.000022
Training Epoch: 342 [32/50000]	Loss: 1.9154	LR: 0.000022
Training Epoch: 342 [32/50000]	Loss: 1.8599	LR: 0.000022
Training Epoch: 342 [32/50000]	Loss: 1.1057	LR: 0.000022
Training Epoch: 342 [32/50000]	Loss: 1.6756	LR: 0.000022
Training Epoch: 342 [32/50000]	Loss: 1.5241	LR: 0.000022
Training Epoch: 342 [32/50000]	Loss: 1.2101	LR: 0.000022
Training Epoch: 342 [32/50000]	Loss: 0.9107	LR: 0.000022
Training Epoch: 342 [32/50000]	Loss: 1.8326	LR: 0.000022
Evaluating Network.....
Test set: Epoch: 342, Average loss: 0.0463, Top1Accuracy: 0.5824, Top3Accuracy: 0.7869, Top5Accuracy: 0.8604, Time consumed:2.66s

Training Epoch: 343 [32/50000]	Loss: 1.5155	LR: 0.000021
Training Epoch: 343 [32/50000]	Loss: 1.6588	LR: 0.000021
Training Epoch: 343 [32/50000]	Loss: 1.4495	LR: 0.000021
Training Epoch: 343 [32/50000]	Loss: 1.5516	LR: 0.000021
Training Epoch: 343 [32/50000]	Loss: 1.1291	LR: 0.000021
Training Epoch: 343 [32/50000]	Loss: 1.5691	LR: 0.000021
Training Epoch: 343 [32/50000]	Loss: 1.6300	LR: 0.000021
Training Epoch: 343 [32/50000]	Loss: 1.0591	LR: 0.000021
Training Epoch: 343 [32/50000]	Loss: 1.2613	LR: 0.000021
Training Epoch: 343 [32/50000]	Loss: 1.6166	LR: 0.000021
Evaluating Network.....
Test set: Epoch: 343, Average loss: 0.0463, Top1Accuracy: 0.5828, Top3Accuracy: 0.7873, Top5Accuracy: 0.8597, Time consumed:2.97s

Training Epoch: 344 [32/50000]	Loss: 1.1789	LR: 0.000021
Training Epoch: 344 [32/50000]	Loss: 1.2535	LR: 0.000021
Training Epoch: 344 [32/50000]	Loss: 1.1524	LR: 0.000021
Training Epoch: 344 [32/50000]	Loss: 1.9525	LR: 0.000021
Training Epoch: 344 [32/50000]	Loss: 1.1861	LR: 0.000021
Training Epoch: 344 [32/50000]	Loss: 0.9675	LR: 0.000021
Training Epoch: 344 [32/50000]	Loss: 1.4006	LR: 0.000021
Training Epoch: 344 [32/50000]	Loss: 1.8988	LR: 0.000021
Training Epoch: 344 [32/50000]	Loss: 1.0231	LR: 0.000021
Training Epoch: 344 [32/50000]	Loss: 1.3519	LR: 0.000021
Evaluating Network.....
Test set: Epoch: 344, Average loss: 0.0464, Top1Accuracy: 0.5829, Top3Accuracy: 0.7882, Top5Accuracy: 0.8596, Time consumed:2.62s

Training Epoch: 345 [32/50000]	Loss: 1.4810	LR: 0.000020
Training Epoch: 345 [32/50000]	Loss: 1.4424	LR: 0.000020
Training Epoch: 345 [32/50000]	Loss: 2.0426	LR: 0.000020
Training Epoch: 345 [32/50000]	Loss: 1.1205	LR: 0.000020
Training Epoch: 345 [32/50000]	Loss: 1.4368	LR: 0.000020
Training Epoch: 345 [32/50000]	Loss: 1.5939	LR: 0.000020
Training Epoch: 345 [32/50000]	Loss: 1.3639	LR: 0.000020
Training Epoch: 345 [32/50000]	Loss: 1.2261	LR: 0.000020
Training Epoch: 345 [32/50000]	Loss: 1.2753	LR: 0.000020
Training Epoch: 345 [32/50000]	Loss: 1.8260	LR: 0.000020
Evaluating Network.....
Test set: Epoch: 345, Average loss: 0.0464, Top1Accuracy: 0.5810, Top3Accuracy: 0.7861, Top5Accuracy: 0.8591, Time consumed:2.63s

Training Epoch: 346 [32/50000]	Loss: 1.2597	LR: 0.000020
Training Epoch: 346 [32/50000]	Loss: 1.5494	LR: 0.000020
Training Epoch: 346 [32/50000]	Loss: 1.2672	LR: 0.000020
Training Epoch: 346 [32/50000]	Loss: 1.4336	LR: 0.000020
Training Epoch: 346 [32/50000]	Loss: 1.2410	LR: 0.000020
Training Epoch: 346 [32/50000]	Loss: 1.4072	LR: 0.000020
Training Epoch: 346 [32/50000]	Loss: 1.4829	LR: 0.000020
Training Epoch: 346 [32/50000]	Loss: 1.2011	LR: 0.000020
Training Epoch: 346 [32/50000]	Loss: 1.7411	LR: 0.000020
Training Epoch: 346 [32/50000]	Loss: 1.5991	LR: 0.000020
Evaluating Network.....
Test set: Epoch: 346, Average loss: 0.0463, Top1Accuracy: 0.5819, Top3Accuracy: 0.7882, Top5Accuracy: 0.8594, Time consumed:2.61s

Training Epoch: 347 [32/50000]	Loss: 1.3091	LR: 0.000019
Training Epoch: 347 [32/50000]	Loss: 1.2075	LR: 0.000019
Training Epoch: 347 [32/50000]	Loss: 1.2383	LR: 0.000019
Training Epoch: 347 [32/50000]	Loss: 1.8011	LR: 0.000019
Training Epoch: 347 [32/50000]	Loss: 1.3070	LR: 0.000019
Training Epoch: 347 [32/50000]	Loss: 1.3150	LR: 0.000019
Training Epoch: 347 [32/50000]	Loss: 0.8512	LR: 0.000019
Training Epoch: 347 [32/50000]	Loss: 1.8562	LR: 0.000019
Training Epoch: 347 [32/50000]	Loss: 1.0906	LR: 0.000019
Training Epoch: 347 [32/50000]	Loss: 1.3038	LR: 0.000019
Evaluating Network.....
Test set: Epoch: 347, Average loss: 0.0464, Top1Accuracy: 0.5814, Top3Accuracy: 0.7852, Top5Accuracy: 0.8598, Time consumed:2.61s

Training Epoch: 348 [32/50000]	Loss: 1.1849	LR: 0.000019
Training Epoch: 348 [32/50000]	Loss: 1.3077	LR: 0.000019
Training Epoch: 348 [32/50000]	Loss: 1.1967	LR: 0.000019
Training Epoch: 348 [32/50000]	Loss: 1.5502	LR: 0.000019
Training Epoch: 348 [32/50000]	Loss: 1.0225	LR: 0.000019
Training Epoch: 348 [32/50000]	Loss: 1.7570	LR: 0.000019
Training Epoch: 348 [32/50000]	Loss: 1.2169	LR: 0.000019
Training Epoch: 348 [32/50000]	Loss: 1.6425	LR: 0.000019
Training Epoch: 348 [32/50000]	Loss: 1.5214	LR: 0.000019
Training Epoch: 348 [32/50000]	Loss: 1.4435	LR: 0.000019
Evaluating Network.....
Test set: Epoch: 348, Average loss: 0.0463, Top1Accuracy: 0.5821, Top3Accuracy: 0.7867, Top5Accuracy: 0.8600, Time consumed:2.59s

Training Epoch: 349 [32/50000]	Loss: 1.2724	LR: 0.000018
Training Epoch: 349 [32/50000]	Loss: 1.7554	LR: 0.000018
Training Epoch: 349 [32/50000]	Loss: 1.3272	LR: 0.000018
Training Epoch: 349 [32/50000]	Loss: 1.1586	LR: 0.000018
Training Epoch: 349 [32/50000]	Loss: 1.9713	LR: 0.000018
Training Epoch: 349 [32/50000]	Loss: 1.4571	LR: 0.000018
Training Epoch: 349 [32/50000]	Loss: 1.2013	LR: 0.000018
Training Epoch: 349 [32/50000]	Loss: 1.1112	LR: 0.000018
Training Epoch: 349 [32/50000]	Loss: 1.8238	LR: 0.000018
Training Epoch: 349 [32/50000]	Loss: 1.6962	LR: 0.000018
Evaluating Network.....
Test set: Epoch: 349, Average loss: 0.0464, Top1Accuracy: 0.5837, Top3Accuracy: 0.7886, Top5Accuracy: 0.8596, Time consumed:2.90s

Training Epoch: 350 [32/50000]	Loss: 1.0837	LR: 0.000018
Training Epoch: 350 [32/50000]	Loss: 1.3574	LR: 0.000018
Training Epoch: 350 [32/50000]	Loss: 1.9202	LR: 0.000018
Training Epoch: 350 [32/50000]	Loss: 1.1200	LR: 0.000018
Training Epoch: 350 [32/50000]	Loss: 1.8340	LR: 0.000018
Training Epoch: 350 [32/50000]	Loss: 1.3904	LR: 0.000018
Training Epoch: 350 [32/50000]	Loss: 1.5886	LR: 0.000018
Training Epoch: 350 [32/50000]	Loss: 1.5383	LR: 0.000018
Training Epoch: 350 [32/50000]	Loss: 1.5108	LR: 0.000018
Training Epoch: 350 [32/50000]	Loss: 1.0706	LR: 0.000018
Evaluating Network.....
Test set: Epoch: 350, Average loss: 0.0464, Top1Accuracy: 0.5838, Top3Accuracy: 0.7877, Top5Accuracy: 0.8598, Time consumed:2.61s

Training Epoch: 351 [32/50000]	Loss: 0.9499	LR: 0.000017
Training Epoch: 351 [32/50000]	Loss: 1.8559	LR: 0.000017
Training Epoch: 351 [32/50000]	Loss: 1.0195	LR: 0.000017
Training Epoch: 351 [32/50000]	Loss: 1.5348	LR: 0.000017
Training Epoch: 351 [32/50000]	Loss: 1.1742	LR: 0.000017
Training Epoch: 351 [32/50000]	Loss: 1.3915	LR: 0.000017
Training Epoch: 351 [32/50000]	Loss: 1.1538	LR: 0.000017
Training Epoch: 351 [32/50000]	Loss: 1.4327	LR: 0.000017
Training Epoch: 351 [32/50000]	Loss: 1.2081	LR: 0.000017
Training Epoch: 351 [32/50000]	Loss: 1.8364	LR: 0.000017
Evaluating Network.....
Test set: Epoch: 351, Average loss: 0.0463, Top1Accuracy: 0.5824, Top3Accuracy: 0.7872, Top5Accuracy: 0.8597, Time consumed:2.89s

Training Epoch: 352 [32/50000]	Loss: 1.3353	LR: 0.000017
Training Epoch: 352 [32/50000]	Loss: 1.8194	LR: 0.000017
Training Epoch: 352 [32/50000]	Loss: 1.2680	LR: 0.000017
Training Epoch: 352 [32/50000]	Loss: 1.4758	LR: 0.000017
Training Epoch: 352 [32/50000]	Loss: 1.3835	LR: 0.000017
Training Epoch: 352 [32/50000]	Loss: 1.5651	LR: 0.000017
Training Epoch: 352 [32/50000]	Loss: 1.1351	LR: 0.000017
Training Epoch: 352 [32/50000]	Loss: 0.9145	LR: 0.000017
Training Epoch: 352 [32/50000]	Loss: 1.2009	LR: 0.000017
Training Epoch: 352 [32/50000]	Loss: 1.2259	LR: 0.000017
Evaluating Network.....
Test set: Epoch: 352, Average loss: 0.0464, Top1Accuracy: 0.5807, Top3Accuracy: 0.7871, Top5Accuracy: 0.8602, Time consumed:2.66s

Training Epoch: 353 [32/50000]	Loss: 1.2592	LR: 0.000016
Training Epoch: 353 [32/50000]	Loss: 1.4417	LR: 0.000016
Training Epoch: 353 [32/50000]	Loss: 1.2088	LR: 0.000016
Training Epoch: 353 [32/50000]	Loss: 1.4342	LR: 0.000016
Training Epoch: 353 [32/50000]	Loss: 1.1607	LR: 0.000016
Training Epoch: 353 [32/50000]	Loss: 1.3141	LR: 0.000016
Training Epoch: 353 [32/50000]	Loss: 0.9985	LR: 0.000016
Training Epoch: 353 [32/50000]	Loss: 1.6882	LR: 0.000016
Training Epoch: 353 [32/50000]	Loss: 1.1033	LR: 0.000016
Training Epoch: 353 [32/50000]	Loss: 1.0252	LR: 0.000016
Evaluating Network.....
Test set: Epoch: 353, Average loss: 0.0463, Top1Accuracy: 0.5827, Top3Accuracy: 0.7867, Top5Accuracy: 0.8597, Time consumed:2.60s

Training Epoch: 354 [32/50000]	Loss: 1.6215	LR: 0.000016
Training Epoch: 354 [32/50000]	Loss: 1.4064	LR: 0.000016
Training Epoch: 354 [32/50000]	Loss: 1.4420	LR: 0.000016
Training Epoch: 354 [32/50000]	Loss: 1.4842	LR: 0.000016
Training Epoch: 354 [32/50000]	Loss: 1.0167	LR: 0.000016
Training Epoch: 354 [32/50000]	Loss: 0.8007	LR: 0.000016
Training Epoch: 354 [32/50000]	Loss: 1.2024	LR: 0.000016
Training Epoch: 354 [32/50000]	Loss: 1.4803	LR: 0.000016
Training Epoch: 354 [32/50000]	Loss: 1.2686	LR: 0.000016
Training Epoch: 354 [32/50000]	Loss: 1.5995	LR: 0.000016
Evaluating Network.....
Test set: Epoch: 354, Average loss: 0.0464, Top1Accuracy: 0.5819, Top3Accuracy: 0.7869, Top5Accuracy: 0.8596, Time consumed:2.64s

Training Epoch: 355 [32/50000]	Loss: 1.0057	LR: 0.000015
Training Epoch: 355 [32/50000]	Loss: 1.8072	LR: 0.000015
Training Epoch: 355 [32/50000]	Loss: 1.0298	LR: 0.000015
Training Epoch: 355 [32/50000]	Loss: 1.6828	LR: 0.000015
Training Epoch: 355 [32/50000]	Loss: 1.5041	LR: 0.000015
Training Epoch: 355 [32/50000]	Loss: 1.4456	LR: 0.000015
Training Epoch: 355 [32/50000]	Loss: 1.1666	LR: 0.000015
Training Epoch: 355 [32/50000]	Loss: 1.0538	LR: 0.000015
Training Epoch: 355 [32/50000]	Loss: 1.3271	LR: 0.000015
Training Epoch: 355 [32/50000]	Loss: 1.5053	LR: 0.000015
Evaluating Network.....
Test set: Epoch: 355, Average loss: 0.0464, Top1Accuracy: 0.5836, Top3Accuracy: 0.7870, Top5Accuracy: 0.8596, Time consumed:2.65s

Training Epoch: 356 [32/50000]	Loss: 1.5754	LR: 0.000015
Training Epoch: 356 [32/50000]	Loss: 1.1420	LR: 0.000015
Training Epoch: 356 [32/50000]	Loss: 1.3889	LR: 0.000015
Training Epoch: 356 [32/50000]	Loss: 1.0559	LR: 0.000015
Training Epoch: 356 [32/50000]	Loss: 1.4220	LR: 0.000015
Training Epoch: 356 [32/50000]	Loss: 1.7046	LR: 0.000015
Training Epoch: 356 [32/50000]	Loss: 1.4841	LR: 0.000015
Training Epoch: 356 [32/50000]	Loss: 1.0932	LR: 0.000015
Training Epoch: 356 [32/50000]	Loss: 1.5428	LR: 0.000015
Training Epoch: 356 [32/50000]	Loss: 1.7146	LR: 0.000015
Evaluating Network.....
Test set: Epoch: 356, Average loss: 0.0463, Top1Accuracy: 0.5829, Top3Accuracy: 0.7877, Top5Accuracy: 0.8603, Time consumed:2.61s

Training Epoch: 357 [32/50000]	Loss: 1.4392	LR: 0.000015
Training Epoch: 357 [32/50000]	Loss: 1.3639	LR: 0.000015
Training Epoch: 357 [32/50000]	Loss: 1.6279	LR: 0.000015
Training Epoch: 357 [32/50000]	Loss: 2.0526	LR: 0.000015
Training Epoch: 357 [32/50000]	Loss: 1.3784	LR: 0.000015
Training Epoch: 357 [32/50000]	Loss: 1.0446	LR: 0.000015
Training Epoch: 357 [32/50000]	Loss: 1.3192	LR: 0.000015
Training Epoch: 357 [32/50000]	Loss: 1.2192	LR: 0.000015
Training Epoch: 357 [32/50000]	Loss: 1.3426	LR: 0.000015
Training Epoch: 357 [32/50000]	Loss: 1.7598	LR: 0.000015
Evaluating Network.....
Test set: Epoch: 357, Average loss: 0.0464, Top1Accuracy: 0.5831, Top3Accuracy: 0.7866, Top5Accuracy: 0.8596, Time consumed:2.62s

Training Epoch: 358 [32/50000]	Loss: 1.3446	LR: 0.000014
Training Epoch: 358 [32/50000]	Loss: 1.4921	LR: 0.000014
Training Epoch: 358 [32/50000]	Loss: 1.8750	LR: 0.000014
Training Epoch: 358 [32/50000]	Loss: 1.0776	LR: 0.000014
Training Epoch: 358 [32/50000]	Loss: 0.9400	LR: 0.000014
Training Epoch: 358 [32/50000]	Loss: 1.4833	LR: 0.000014
Training Epoch: 358 [32/50000]	Loss: 1.7245	LR: 0.000014
Training Epoch: 358 [32/50000]	Loss: 1.4606	LR: 0.000014
Training Epoch: 358 [32/50000]	Loss: 1.5461	LR: 0.000014
Training Epoch: 358 [32/50000]	Loss: 1.7395	LR: 0.000014
Evaluating Network.....
Test set: Epoch: 358, Average loss: 0.0463, Top1Accuracy: 0.5819, Top3Accuracy: 0.7882, Top5Accuracy: 0.8601, Time consumed:2.60s

Training Epoch: 359 [32/50000]	Loss: 0.9233	LR: 0.000014
Training Epoch: 359 [32/50000]	Loss: 1.2150	LR: 0.000014
Training Epoch: 359 [32/50000]	Loss: 1.3428	LR: 0.000014
Training Epoch: 359 [32/50000]	Loss: 1.5715	LR: 0.000014
Training Epoch: 359 [32/50000]	Loss: 1.1448	LR: 0.000014
Training Epoch: 359 [32/50000]	Loss: 1.1324	LR: 0.000014
Training Epoch: 359 [32/50000]	Loss: 1.2132	LR: 0.000014
Training Epoch: 359 [32/50000]	Loss: 1.6377	LR: 0.000014
Training Epoch: 359 [32/50000]	Loss: 1.4393	LR: 0.000014
Training Epoch: 359 [32/50000]	Loss: 1.4337	LR: 0.000014
Evaluating Network.....
Test set: Epoch: 359, Average loss: 0.0463, Top1Accuracy: 0.5842, Top3Accuracy: 0.7862, Top5Accuracy: 0.8605, Time consumed:2.66s

Training Epoch: 360 [32/50000]	Loss: 1.4132	LR: 0.000013
Training Epoch: 360 [32/50000]	Loss: 1.8247	LR: 0.000013
Training Epoch: 360 [32/50000]	Loss: 1.3277	LR: 0.000013
Training Epoch: 360 [32/50000]	Loss: 1.5655	LR: 0.000013
Training Epoch: 360 [32/50000]	Loss: 1.4867	LR: 0.000013
Training Epoch: 360 [32/50000]	Loss: 1.2916	LR: 0.000013
Training Epoch: 360 [32/50000]	Loss: 1.3096	LR: 0.000013
Training Epoch: 360 [32/50000]	Loss: 1.2218	LR: 0.000013
Training Epoch: 360 [32/50000]	Loss: 1.3398	LR: 0.000013
Training Epoch: 360 [32/50000]	Loss: 1.2994	LR: 0.000013
Evaluating Network.....
Test set: Epoch: 360, Average loss: 0.0463, Top1Accuracy: 0.5823, Top3Accuracy: 0.7871, Top5Accuracy: 0.8592, Time consumed:2.60s

Training Epoch: 361 [32/50000]	Loss: 1.2360	LR: 0.000013
Training Epoch: 361 [32/50000]	Loss: 0.9970	LR: 0.000013
Training Epoch: 361 [32/50000]	Loss: 1.4941	LR: 0.000013
Training Epoch: 361 [32/50000]	Loss: 1.2331	LR: 0.000013
Training Epoch: 361 [32/50000]	Loss: 1.1962	LR: 0.000013
Training Epoch: 361 [32/50000]	Loss: 1.5519	LR: 0.000013
Training Epoch: 361 [32/50000]	Loss: 1.2836	LR: 0.000013
Training Epoch: 361 [32/50000]	Loss: 1.2907	LR: 0.000013
Training Epoch: 361 [32/50000]	Loss: 0.8980	LR: 0.000013
Training Epoch: 361 [32/50000]	Loss: 1.1205	LR: 0.000013
Evaluating Network.....
Test set: Epoch: 361, Average loss: 0.0464, Top1Accuracy: 0.5828, Top3Accuracy: 0.7873, Top5Accuracy: 0.8607, Time consumed:2.64s

Training Epoch: 362 [32/50000]	Loss: 1.4866	LR: 0.000013
Training Epoch: 362 [32/50000]	Loss: 1.3786	LR: 0.000013
Training Epoch: 362 [32/50000]	Loss: 1.0002	LR: 0.000013
Training Epoch: 362 [32/50000]	Loss: 1.7761	LR: 0.000013
Training Epoch: 362 [32/50000]	Loss: 1.9038	LR: 0.000013
Training Epoch: 362 [32/50000]	Loss: 1.2396	LR: 0.000013
Training Epoch: 362 [32/50000]	Loss: 1.5491	LR: 0.000013
Training Epoch: 362 [32/50000]	Loss: 1.4225	LR: 0.000013
Training Epoch: 362 [32/50000]	Loss: 1.2560	LR: 0.000013
Training Epoch: 362 [32/50000]	Loss: 1.3622	LR: 0.000013
Evaluating Network.....
Test set: Epoch: 362, Average loss: 0.0463, Top1Accuracy: 0.5813, Top3Accuracy: 0.7883, Top5Accuracy: 0.8600, Time consumed:2.67s

Training Epoch: 363 [32/50000]	Loss: 1.4649	LR: 0.000012
Training Epoch: 363 [32/50000]	Loss: 1.1103	LR: 0.000012
Training Epoch: 363 [32/50000]	Loss: 1.3003	LR: 0.000012
Training Epoch: 363 [32/50000]	Loss: 1.0931	LR: 0.000012
Training Epoch: 363 [32/50000]	Loss: 1.3780	LR: 0.000012
Training Epoch: 363 [32/50000]	Loss: 1.1150	LR: 0.000012
Training Epoch: 363 [32/50000]	Loss: 2.3612	LR: 0.000012
Training Epoch: 363 [32/50000]	Loss: 1.8338	LR: 0.000012
Training Epoch: 363 [32/50000]	Loss: 1.6170	LR: 0.000012
Training Epoch: 363 [32/50000]	Loss: 1.0584	LR: 0.000012
Evaluating Network.....
Test set: Epoch: 363, Average loss: 0.0464, Top1Accuracy: 0.5834, Top3Accuracy: 0.7880, Top5Accuracy: 0.8598, Time consumed:2.59s

Training Epoch: 364 [32/50000]	Loss: 1.0980	LR: 0.000012
Training Epoch: 364 [32/50000]	Loss: 1.7926	LR: 0.000012
Training Epoch: 364 [32/50000]	Loss: 1.0873	LR: 0.000012
Training Epoch: 364 [32/50000]	Loss: 1.4938	LR: 0.000012
Training Epoch: 364 [32/50000]	Loss: 1.3465	LR: 0.000012
Training Epoch: 364 [32/50000]	Loss: 1.4534	LR: 0.000012
Training Epoch: 364 [32/50000]	Loss: 1.2387	LR: 0.000012
Training Epoch: 364 [32/50000]	Loss: 1.1590	LR: 0.000012
Training Epoch: 364 [32/50000]	Loss: 1.4702	LR: 0.000012
Training Epoch: 364 [32/50000]	Loss: 1.1728	LR: 0.000012
Evaluating Network.....
Test set: Epoch: 364, Average loss: 0.0463, Top1Accuracy: 0.5813, Top3Accuracy: 0.7865, Top5Accuracy: 0.8607, Time consumed:2.61s

Training Epoch: 365 [32/50000]	Loss: 1.0758	LR: 0.000012
Training Epoch: 365 [32/50000]	Loss: 1.4261	LR: 0.000012
Training Epoch: 365 [32/50000]	Loss: 1.3132	LR: 0.000012
Training Epoch: 365 [32/50000]	Loss: 1.4049	LR: 0.000012
Training Epoch: 365 [32/50000]	Loss: 1.0971	LR: 0.000012
Training Epoch: 365 [32/50000]	Loss: 1.4017	LR: 0.000012
Training Epoch: 365 [32/50000]	Loss: 1.2123	LR: 0.000012
Training Epoch: 365 [32/50000]	Loss: 1.2038	LR: 0.000012
Training Epoch: 365 [32/50000]	Loss: 1.5081	LR: 0.000012
Training Epoch: 365 [32/50000]	Loss: 1.2422	LR: 0.000012
Evaluating Network.....
Test set: Epoch: 365, Average loss: 0.0463, Top1Accuracy: 0.5834, Top3Accuracy: 0.7865, Top5Accuracy: 0.8612, Time consumed:2.79s

Training Epoch: 366 [32/50000]	Loss: 1.1058	LR: 0.000011
Training Epoch: 366 [32/50000]	Loss: 1.1454	LR: 0.000011
Training Epoch: 366 [32/50000]	Loss: 1.3740	LR: 0.000011
Training Epoch: 366 [32/50000]	Loss: 1.2115	LR: 0.000011
Training Epoch: 366 [32/50000]	Loss: 1.0210	LR: 0.000011
Training Epoch: 366 [32/50000]	Loss: 1.6751	LR: 0.000011
Training Epoch: 366 [32/50000]	Loss: 1.5875	LR: 0.000011
Training Epoch: 366 [32/50000]	Loss: 1.1547	LR: 0.000011
Training Epoch: 366 [32/50000]	Loss: 1.5884	LR: 0.000011
Training Epoch: 366 [32/50000]	Loss: 1.4204	LR: 0.000011
Evaluating Network.....
Test set: Epoch: 366, Average loss: 0.0463, Top1Accuracy: 0.5828, Top3Accuracy: 0.7873, Top5Accuracy: 0.8601, Time consumed:2.61s

Training Epoch: 367 [32/50000]	Loss: 1.5797	LR: 0.000011
Training Epoch: 367 [32/50000]	Loss: 1.3471	LR: 0.000011
Training Epoch: 367 [32/50000]	Loss: 1.2536	LR: 0.000011
Training Epoch: 367 [32/50000]	Loss: 1.4908	LR: 0.000011
Training Epoch: 367 [32/50000]	Loss: 1.5180	LR: 0.000011
Training Epoch: 367 [32/50000]	Loss: 1.3186	LR: 0.000011
Training Epoch: 367 [32/50000]	Loss: 1.4491	LR: 0.000011
Training Epoch: 367 [32/50000]	Loss: 1.4062	LR: 0.000011
Training Epoch: 367 [32/50000]	Loss: 0.9881	LR: 0.000011
Training Epoch: 367 [32/50000]	Loss: 1.4778	LR: 0.000011
Evaluating Network.....
Test set: Epoch: 367, Average loss: 0.0463, Top1Accuracy: 0.5833, Top3Accuracy: 0.7875, Top5Accuracy: 0.8617, Time consumed:2.62s

Training Epoch: 368 [32/50000]	Loss: 1.2324	LR: 0.000011
Training Epoch: 368 [32/50000]	Loss: 1.2230	LR: 0.000011
Training Epoch: 368 [32/50000]	Loss: 1.1045	LR: 0.000011
Training Epoch: 368 [32/50000]	Loss: 1.4297	LR: 0.000011
Training Epoch: 368 [32/50000]	Loss: 1.7151	LR: 0.000011
Training Epoch: 368 [32/50000]	Loss: 1.0677	LR: 0.000011
Training Epoch: 368 [32/50000]	Loss: 1.5980	LR: 0.000011
Training Epoch: 368 [32/50000]	Loss: 1.4386	LR: 0.000011
Training Epoch: 368 [32/50000]	Loss: 1.4884	LR: 0.000011
Training Epoch: 368 [32/50000]	Loss: 2.0752	LR: 0.000011
Evaluating Network.....
Test set: Epoch: 368, Average loss: 0.0464, Top1Accuracy: 0.5837, Top3Accuracy: 0.7877, Top5Accuracy: 0.8600, Time consumed:2.63s

Training Epoch: 369 [32/50000]	Loss: 1.1420	LR: 0.000011
Training Epoch: 369 [32/50000]	Loss: 1.3937	LR: 0.000011
Training Epoch: 369 [32/50000]	Loss: 1.7138	LR: 0.000011
Training Epoch: 369 [32/50000]	Loss: 1.1420	LR: 0.000011
Training Epoch: 369 [32/50000]	Loss: 1.3627	LR: 0.000011
Training Epoch: 369 [32/50000]	Loss: 1.5689	LR: 0.000011
Training Epoch: 369 [32/50000]	Loss: 1.5723	LR: 0.000011
Training Epoch: 369 [32/50000]	Loss: 1.1968	LR: 0.000011
Training Epoch: 369 [32/50000]	Loss: 1.3973	LR: 0.000011
Training Epoch: 369 [32/50000]	Loss: 1.0568	LR: 0.000011
Evaluating Network.....
Test set: Epoch: 369, Average loss: 0.0463, Top1Accuracy: 0.5833, Top3Accuracy: 0.7871, Top5Accuracy: 0.8601, Time consumed:2.69s

Training Epoch: 370 [32/50000]	Loss: 1.8952	LR: 0.000010
Training Epoch: 370 [32/50000]	Loss: 1.6983	LR: 0.000010
Training Epoch: 370 [32/50000]	Loss: 1.6433	LR: 0.000010
Training Epoch: 370 [32/50000]	Loss: 1.1251	LR: 0.000010
Training Epoch: 370 [32/50000]	Loss: 0.9542	LR: 0.000010
Training Epoch: 370 [32/50000]	Loss: 1.0535	LR: 0.000010
Training Epoch: 370 [32/50000]	Loss: 0.9286	LR: 0.000010
Training Epoch: 370 [32/50000]	Loss: 1.1332	LR: 0.000010
Training Epoch: 370 [32/50000]	Loss: 1.2380	LR: 0.000010
Training Epoch: 370 [32/50000]	Loss: 1.5836	LR: 0.000010
Evaluating Network.....
Test set: Epoch: 370, Average loss: 0.0464, Top1Accuracy: 0.5825, Top3Accuracy: 0.7868, Top5Accuracy: 0.8607, Time consumed:3.22s

Training Epoch: 371 [32/50000]	Loss: 1.6163	LR: 0.000010
Training Epoch: 371 [32/50000]	Loss: 1.3732	LR: 0.000010
Training Epoch: 371 [32/50000]	Loss: 1.1043	LR: 0.000010
Training Epoch: 371 [32/50000]	Loss: 1.5157	LR: 0.000010
Training Epoch: 371 [32/50000]	Loss: 1.1537	LR: 0.000010
Training Epoch: 371 [32/50000]	Loss: 1.1782	LR: 0.000010
Training Epoch: 371 [32/50000]	Loss: 1.2064	LR: 0.000010
Training Epoch: 371 [32/50000]	Loss: 1.8520	LR: 0.000010
Training Epoch: 371 [32/50000]	Loss: 1.1264	LR: 0.000010
Training Epoch: 371 [32/50000]	Loss: 1.5611	LR: 0.000010
Evaluating Network.....
Test set: Epoch: 371, Average loss: 0.0463, Top1Accuracy: 0.5831, Top3Accuracy: 0.7876, Top5Accuracy: 0.8595, Time consumed:2.63s

Training Epoch: 372 [32/50000]	Loss: 1.2790	LR: 0.000010
Training Epoch: 372 [32/50000]	Loss: 1.3151	LR: 0.000010
Training Epoch: 372 [32/50000]	Loss: 1.7196	LR: 0.000010
Training Epoch: 372 [32/50000]	Loss: 1.4373	LR: 0.000010
Training Epoch: 372 [32/50000]	Loss: 1.2508	LR: 0.000010
Training Epoch: 372 [32/50000]	Loss: 1.1481	LR: 0.000010
Training Epoch: 372 [32/50000]	Loss: 1.3133	LR: 0.000010
Training Epoch: 372 [32/50000]	Loss: 1.3271	LR: 0.000010
Training Epoch: 372 [32/50000]	Loss: 1.2295	LR: 0.000010
Training Epoch: 372 [32/50000]	Loss: 1.2996	LR: 0.000010
Evaluating Network.....
Test set: Epoch: 372, Average loss: 0.0464, Top1Accuracy: 0.5825, Top3Accuracy: 0.7873, Top5Accuracy: 0.8591, Time consumed:2.65s

Training Epoch: 373 [32/50000]	Loss: 1.6722	LR: 0.000010
Training Epoch: 373 [32/50000]	Loss: 1.1955	LR: 0.000010
Training Epoch: 373 [32/50000]	Loss: 1.3726	LR: 0.000010
Training Epoch: 373 [32/50000]	Loss: 1.4541	LR: 0.000010
Training Epoch: 373 [32/50000]	Loss: 1.4663	LR: 0.000010
Training Epoch: 373 [32/50000]	Loss: 1.0727	LR: 0.000010
Training Epoch: 373 [32/50000]	Loss: 1.4771	LR: 0.000010
Training Epoch: 373 [32/50000]	Loss: 1.3308	LR: 0.000010
Training Epoch: 373 [32/50000]	Loss: 1.8294	LR: 0.000010
Training Epoch: 373 [32/50000]	Loss: 1.5240	LR: 0.000010
Evaluating Network.....
Test set: Epoch: 373, Average loss: 0.0463, Top1Accuracy: 0.5834, Top3Accuracy: 0.7866, Top5Accuracy: 0.8603, Time consumed:3.22s

Training Epoch: 374 [32/50000]	Loss: 0.8629	LR: 0.000009
Training Epoch: 374 [32/50000]	Loss: 1.4375	LR: 0.000009
Training Epoch: 374 [32/50000]	Loss: 1.3542	LR: 0.000009
Training Epoch: 374 [32/50000]	Loss: 1.3281	LR: 0.000009
Training Epoch: 374 [32/50000]	Loss: 1.2820	LR: 0.000009
Training Epoch: 374 [32/50000]	Loss: 1.3191	LR: 0.000009
Training Epoch: 374 [32/50000]	Loss: 1.0930	LR: 0.000009
Training Epoch: 374 [32/50000]	Loss: 1.4054	LR: 0.000009
Training Epoch: 374 [32/50000]	Loss: 0.9807	LR: 0.000009
Training Epoch: 374 [32/50000]	Loss: 1.8825	LR: 0.000009
Evaluating Network.....
Test set: Epoch: 374, Average loss: 0.0463, Top1Accuracy: 0.5835, Top3Accuracy: 0.7885, Top5Accuracy: 0.8609, Time consumed:2.62s

Training Epoch: 375 [32/50000]	Loss: 1.5047	LR: 0.000009
Training Epoch: 375 [32/50000]	Loss: 1.4395	LR: 0.000009
Training Epoch: 375 [32/50000]	Loss: 1.3010	LR: 0.000009
Training Epoch: 375 [32/50000]	Loss: 1.8567	LR: 0.000009
Training Epoch: 375 [32/50000]	Loss: 0.9943	LR: 0.000009
Training Epoch: 375 [32/50000]	Loss: 1.4460	LR: 0.000009
Training Epoch: 375 [32/50000]	Loss: 1.4494	LR: 0.000009
Training Epoch: 375 [32/50000]	Loss: 1.3047	LR: 0.000009
Training Epoch: 375 [32/50000]	Loss: 1.5156	LR: 0.000009
Training Epoch: 375 [32/50000]	Loss: 1.2131	LR: 0.000009
Evaluating Network.....
Test set: Epoch: 375, Average loss: 0.0463, Top1Accuracy: 0.5831, Top3Accuracy: 0.7877, Top5Accuracy: 0.8593, Time consumed:2.66s

Training Epoch: 376 [32/50000]	Loss: 1.4592	LR: 0.000009
Training Epoch: 376 [32/50000]	Loss: 2.0302	LR: 0.000009
Training Epoch: 376 [32/50000]	Loss: 1.6894	LR: 0.000009
Training Epoch: 376 [32/50000]	Loss: 1.4053	LR: 0.000009
Training Epoch: 376 [32/50000]	Loss: 1.5804	LR: 0.000009
Training Epoch: 376 [32/50000]	Loss: 1.7776	LR: 0.000009
Training Epoch: 376 [32/50000]	Loss: 1.5600	LR: 0.000009
Training Epoch: 376 [32/50000]	Loss: 1.5169	LR: 0.000009
Training Epoch: 376 [32/50000]	Loss: 1.3285	LR: 0.000009
Training Epoch: 376 [32/50000]	Loss: 1.7445	LR: 0.000009
Evaluating Network.....
Test set: Epoch: 376, Average loss: 0.0464, Top1Accuracy: 0.5823, Top3Accuracy: 0.7865, Top5Accuracy: 0.8603, Time consumed:2.68s

Training Epoch: 377 [32/50000]	Loss: 1.3554	LR: 0.000009
Training Epoch: 377 [32/50000]	Loss: 0.8412	LR: 0.000009
Training Epoch: 377 [32/50000]	Loss: 1.8368	LR: 0.000009
Training Epoch: 377 [32/50000]	Loss: 1.8607	LR: 0.000009
Training Epoch: 377 [32/50000]	Loss: 1.5662	LR: 0.000009
Training Epoch: 377 [32/50000]	Loss: 1.3561	LR: 0.000009
Training Epoch: 377 [32/50000]	Loss: 1.3279	LR: 0.000009
Training Epoch: 377 [32/50000]	Loss: 1.8165	LR: 0.000009
Training Epoch: 377 [32/50000]	Loss: 1.8760	LR: 0.000009
Training Epoch: 377 [32/50000]	Loss: 1.4898	LR: 0.000009
Evaluating Network.....
Test set: Epoch: 377, Average loss: 0.0463, Top1Accuracy: 0.5831, Top3Accuracy: 0.7869, Top5Accuracy: 0.8608, Time consumed:2.69s

Training Epoch: 378 [32/50000]	Loss: 1.6212	LR: 0.000008
Training Epoch: 378 [32/50000]	Loss: 1.3238	LR: 0.000008
Training Epoch: 378 [32/50000]	Loss: 1.2241	LR: 0.000008
Training Epoch: 378 [32/50000]	Loss: 1.5073	LR: 0.000008
Training Epoch: 378 [32/50000]	Loss: 1.3866	LR: 0.000008
Training Epoch: 378 [32/50000]	Loss: 1.3246	LR: 0.000008
Training Epoch: 378 [32/50000]	Loss: 1.2301	LR: 0.000008
Training Epoch: 378 [32/50000]	Loss: 1.7479	LR: 0.000008
Training Epoch: 378 [32/50000]	Loss: 1.6127	LR: 0.000008
Training Epoch: 378 [32/50000]	Loss: 1.3628	LR: 0.000008
Evaluating Network.....
Test set: Epoch: 378, Average loss: 0.0462, Top1Accuracy: 0.5838, Top3Accuracy: 0.7885, Top5Accuracy: 0.8597, Time consumed:2.69s

Training Epoch: 379 [32/50000]	Loss: 1.3033	LR: 0.000008
Training Epoch: 379 [32/50000]	Loss: 1.3060	LR: 0.000008
Training Epoch: 379 [32/50000]	Loss: 1.3552	LR: 0.000008
Training Epoch: 379 [32/50000]	Loss: 1.5326	LR: 0.000008
Training Epoch: 379 [32/50000]	Loss: 1.4975	LR: 0.000008
Training Epoch: 379 [32/50000]	Loss: 0.9868	LR: 0.000008
Training Epoch: 379 [32/50000]	Loss: 1.2543	LR: 0.000008
Training Epoch: 379 [32/50000]	Loss: 1.2156	LR: 0.000008
Training Epoch: 379 [32/50000]	Loss: 1.4035	LR: 0.000008
Training Epoch: 379 [32/50000]	Loss: 1.2947	LR: 0.000008
Evaluating Network.....
Test set: Epoch: 379, Average loss: 0.0463, Top1Accuracy: 0.5829, Top3Accuracy: 0.7883, Top5Accuracy: 0.8600, Time consumed:2.70s

Training Epoch: 380 [32/50000]	Loss: 1.4585	LR: 0.000008
Training Epoch: 380 [32/50000]	Loss: 1.2630	LR: 0.000008
Training Epoch: 380 [32/50000]	Loss: 1.3107	LR: 0.000008
Training Epoch: 380 [32/50000]	Loss: 1.1966	LR: 0.000008
Training Epoch: 380 [32/50000]	Loss: 1.2097	LR: 0.000008
Training Epoch: 380 [32/50000]	Loss: 1.4231	LR: 0.000008
Training Epoch: 380 [32/50000]	Loss: 1.4035	LR: 0.000008
Training Epoch: 380 [32/50000]	Loss: 0.9857	LR: 0.000008
Training Epoch: 380 [32/50000]	Loss: 1.2349	LR: 0.000008
Training Epoch: 380 [32/50000]	Loss: 1.2776	LR: 0.000008
Evaluating Network.....
Test set: Epoch: 380, Average loss: 0.0464, Top1Accuracy: 0.5830, Top3Accuracy: 0.7869, Top5Accuracy: 0.8606, Time consumed:2.61s

Training Epoch: 381 [32/50000]	Loss: 1.3510	LR: 0.000008
Training Epoch: 381 [32/50000]	Loss: 1.9397	LR: 0.000008
Training Epoch: 381 [32/50000]	Loss: 1.4263	LR: 0.000008
Training Epoch: 381 [32/50000]	Loss: 1.4655	LR: 0.000008
Training Epoch: 381 [32/50000]	Loss: 1.6634	LR: 0.000008
Training Epoch: 381 [32/50000]	Loss: 2.0536	LR: 0.000008
Training Epoch: 381 [32/50000]	Loss: 1.3460	LR: 0.000008
Training Epoch: 381 [32/50000]	Loss: 1.5342	LR: 0.000008
Training Epoch: 381 [32/50000]	Loss: 1.3276	LR: 0.000008
Training Epoch: 381 [32/50000]	Loss: 1.4108	LR: 0.000008
Evaluating Network.....
Test set: Epoch: 381, Average loss: 0.0463, Top1Accuracy: 0.5821, Top3Accuracy: 0.7866, Top5Accuracy: 0.8597, Time consumed:2.60s

Training Epoch: 382 [32/50000]	Loss: 1.1975	LR: 0.000007
Training Epoch: 382 [32/50000]	Loss: 1.0163	LR: 0.000007
Training Epoch: 382 [32/50000]	Loss: 1.2127	LR: 0.000007
Training Epoch: 382 [32/50000]	Loss: 1.3434	LR: 0.000007
Training Epoch: 382 [32/50000]	Loss: 0.9736	LR: 0.000007
Training Epoch: 382 [32/50000]	Loss: 1.0939	LR: 0.000007
Training Epoch: 382 [32/50000]	Loss: 1.4684	LR: 0.000007
Training Epoch: 382 [32/50000]	Loss: 1.5420	LR: 0.000007
Training Epoch: 382 [32/50000]	Loss: 1.9063	LR: 0.000007
Training Epoch: 382 [32/50000]	Loss: 1.3456	LR: 0.000007
Evaluating Network.....
Test set: Epoch: 382, Average loss: 0.0463, Top1Accuracy: 0.5843, Top3Accuracy: 0.7876, Top5Accuracy: 0.8606, Time consumed:2.64s

Training Epoch: 383 [32/50000]	Loss: 1.2866	LR: 0.000007
Training Epoch: 383 [32/50000]	Loss: 0.8895	LR: 0.000007
Training Epoch: 383 [32/50000]	Loss: 1.4509	LR: 0.000007
Training Epoch: 383 [32/50000]	Loss: 1.4065	LR: 0.000007
Training Epoch: 383 [32/50000]	Loss: 1.1587	LR: 0.000007
Training Epoch: 383 [32/50000]	Loss: 1.1335	LR: 0.000007
Training Epoch: 383 [32/50000]	Loss: 1.1932	LR: 0.000007
Training Epoch: 383 [32/50000]	Loss: 1.0870	LR: 0.000007
Training Epoch: 383 [32/50000]	Loss: 1.7738	LR: 0.000007
Training Epoch: 383 [32/50000]	Loss: 1.5615	LR: 0.000007
Evaluating Network.....
Test set: Epoch: 383, Average loss: 0.0463, Top1Accuracy: 0.5830, Top3Accuracy: 0.7859, Top5Accuracy: 0.8604, Time consumed:2.66s

Training Epoch: 384 [32/50000]	Loss: 1.3957	LR: 0.000007
Training Epoch: 384 [32/50000]	Loss: 0.9714	LR: 0.000007
Training Epoch: 384 [32/50000]	Loss: 1.4795	LR: 0.000007
Training Epoch: 384 [32/50000]	Loss: 2.0162	LR: 0.000007
Training Epoch: 384 [32/50000]	Loss: 1.2945	LR: 0.000007
Training Epoch: 384 [32/50000]	Loss: 1.4305	LR: 0.000007
Training Epoch: 384 [32/50000]	Loss: 1.3885	LR: 0.000007
Training Epoch: 384 [32/50000]	Loss: 1.1583	LR: 0.000007
Training Epoch: 384 [32/50000]	Loss: 1.2849	LR: 0.000007
Training Epoch: 384 [32/50000]	Loss: 1.5958	LR: 0.000007
Evaluating Network.....
Test set: Epoch: 384, Average loss: 0.0465, Top1Accuracy: 0.5822, Top3Accuracy: 0.7871, Top5Accuracy: 0.8598, Time consumed:2.59s

Training Epoch: 385 [32/50000]	Loss: 1.2021	LR: 0.000007
Training Epoch: 385 [32/50000]	Loss: 1.7938	LR: 0.000007
Training Epoch: 385 [32/50000]	Loss: 1.3826	LR: 0.000007
Training Epoch: 385 [32/50000]	Loss: 1.2483	LR: 0.000007
Training Epoch: 385 [32/50000]	Loss: 1.4737	LR: 0.000007
Training Epoch: 385 [32/50000]	Loss: 1.1915	LR: 0.000007
Training Epoch: 385 [32/50000]	Loss: 1.3224	LR: 0.000007
Training Epoch: 385 [32/50000]	Loss: 0.8591	LR: 0.000007
Training Epoch: 385 [32/50000]	Loss: 1.3327	LR: 0.000007
Training Epoch: 385 [32/50000]	Loss: 1.4313	LR: 0.000007
Evaluating Network.....
Test set: Epoch: 385, Average loss: 0.0464, Top1Accuracy: 0.5833, Top3Accuracy: 0.7873, Top5Accuracy: 0.8596, Time consumed:2.61s

Training Epoch: 386 [32/50000]	Loss: 1.3843	LR: 0.000007
Training Epoch: 386 [32/50000]	Loss: 1.7927	LR: 0.000007
Training Epoch: 386 [32/50000]	Loss: 1.7568	LR: 0.000007
Training Epoch: 386 [32/50000]	Loss: 1.9487	LR: 0.000007
Training Epoch: 386 [32/50000]	Loss: 1.2629	LR: 0.000007
Training Epoch: 386 [32/50000]	Loss: 1.3357	LR: 0.000007
Training Epoch: 386 [32/50000]	Loss: 1.5684	LR: 0.000007
Training Epoch: 386 [32/50000]	Loss: 1.2895	LR: 0.000007
Training Epoch: 386 [32/50000]	Loss: 1.4301	LR: 0.000007
Training Epoch: 386 [32/50000]	Loss: 1.7538	LR: 0.000007
Evaluating Network.....
Test set: Epoch: 386, Average loss: 0.0463, Top1Accuracy: 0.5831, Top3Accuracy: 0.7883, Top5Accuracy: 0.8598, Time consumed:2.67s

Training Epoch: 387 [32/50000]	Loss: 1.3475	LR: 0.000007
Training Epoch: 387 [32/50000]	Loss: 1.3063	LR: 0.000007
Training Epoch: 387 [32/50000]	Loss: 1.1747	LR: 0.000007
Training Epoch: 387 [32/50000]	Loss: 1.2516	LR: 0.000007
Training Epoch: 387 [32/50000]	Loss: 1.2790	LR: 0.000007
Training Epoch: 387 [32/50000]	Loss: 1.2485	LR: 0.000007
Training Epoch: 387 [32/50000]	Loss: 1.6160	LR: 0.000007
Training Epoch: 387 [32/50000]	Loss: 1.4804	LR: 0.000007
Training Epoch: 387 [32/50000]	Loss: 2.0639	LR: 0.000007
Training Epoch: 387 [32/50000]	Loss: 1.5375	LR: 0.000007
Evaluating Network.....
Test set: Epoch: 387, Average loss: 0.0463, Top1Accuracy: 0.5827, Top3Accuracy: 0.7872, Top5Accuracy: 0.8597, Time consumed:2.64s

Training Epoch: 388 [32/50000]	Loss: 1.4035	LR: 0.000006
Training Epoch: 388 [32/50000]	Loss: 1.8373	LR: 0.000006
Training Epoch: 388 [32/50000]	Loss: 1.3063	LR: 0.000006
Training Epoch: 388 [32/50000]	Loss: 1.2511	LR: 0.000006
Training Epoch: 388 [32/50000]	Loss: 1.4662	LR: 0.000006
Training Epoch: 388 [32/50000]	Loss: 1.2661	LR: 0.000006
Training Epoch: 388 [32/50000]	Loss: 1.1274	LR: 0.000006
Training Epoch: 388 [32/50000]	Loss: 1.2724	LR: 0.000006
Training Epoch: 388 [32/50000]	Loss: 1.4167	LR: 0.000006
Training Epoch: 388 [32/50000]	Loss: 1.8926	LR: 0.000006
Evaluating Network.....
Test set: Epoch: 388, Average loss: 0.0463, Top1Accuracy: 0.5838, Top3Accuracy: 0.7867, Top5Accuracy: 0.8605, Time consumed:2.62s

Training Epoch: 389 [32/50000]	Loss: 1.6341	LR: 0.000006
Training Epoch: 389 [32/50000]	Loss: 1.9030	LR: 0.000006
Training Epoch: 389 [32/50000]	Loss: 1.2985	LR: 0.000006
Training Epoch: 389 [32/50000]	Loss: 1.4837	LR: 0.000006
Training Epoch: 389 [32/50000]	Loss: 1.2657	LR: 0.000006
Training Epoch: 389 [32/50000]	Loss: 1.6434	LR: 0.000006
Training Epoch: 389 [32/50000]	Loss: 1.0224	LR: 0.000006
Training Epoch: 389 [32/50000]	Loss: 1.7383	LR: 0.000006
Training Epoch: 389 [32/50000]	Loss: 1.2281	LR: 0.000006
Training Epoch: 389 [32/50000]	Loss: 1.5050	LR: 0.000006
Evaluating Network.....
Test set: Epoch: 389, Average loss: 0.0463, Top1Accuracy: 0.5839, Top3Accuracy: 0.7868, Top5Accuracy: 0.8609, Time consumed:2.71s

Training Epoch: 390 [32/50000]	Loss: 1.2762	LR: 0.000006
Training Epoch: 390 [32/50000]	Loss: 1.3168	LR: 0.000006
Training Epoch: 390 [32/50000]	Loss: 1.6164	LR: 0.000006
Training Epoch: 390 [32/50000]	Loss: 1.4502	LR: 0.000006
Training Epoch: 390 [32/50000]	Loss: 1.3509	LR: 0.000006
Training Epoch: 390 [32/50000]	Loss: 0.9897	LR: 0.000006
Training Epoch: 390 [32/50000]	Loss: 1.1894	LR: 0.000006
Training Epoch: 390 [32/50000]	Loss: 1.1325	LR: 0.000006
Training Epoch: 390 [32/50000]	Loss: 1.5744	LR: 0.000006
Training Epoch: 390 [32/50000]	Loss: 1.3575	LR: 0.000006
Evaluating Network.....
Test set: Epoch: 390, Average loss: 0.0463, Top1Accuracy: 0.5841, Top3Accuracy: 0.7865, Top5Accuracy: 0.8603, Time consumed:2.63s

Training Epoch: 391 [32/50000]	Loss: 1.0975	LR: 0.000006
Training Epoch: 391 [32/50000]	Loss: 1.6690	LR: 0.000006
Training Epoch: 391 [32/50000]	Loss: 1.0857	LR: 0.000006
Training Epoch: 391 [32/50000]	Loss: 1.3826	LR: 0.000006
Training Epoch: 391 [32/50000]	Loss: 0.9288	LR: 0.000006
Training Epoch: 391 [32/50000]	Loss: 1.2917	LR: 0.000006
Training Epoch: 391 [32/50000]	Loss: 1.2950	LR: 0.000006
Training Epoch: 391 [32/50000]	Loss: 1.1113	LR: 0.000006
Training Epoch: 391 [32/50000]	Loss: 1.8726	LR: 0.000006
Training Epoch: 391 [32/50000]	Loss: 1.2910	LR: 0.000006
Evaluating Network.....
Test set: Epoch: 391, Average loss: 0.0463, Top1Accuracy: 0.5845, Top3Accuracy: 0.7873, Top5Accuracy: 0.8607, Time consumed:2.66s

Training Epoch: 392 [32/50000]	Loss: 1.3322	LR: 0.000006
Training Epoch: 392 [32/50000]	Loss: 1.2503	LR: 0.000006
Training Epoch: 392 [32/50000]	Loss: 1.4898	LR: 0.000006
Training Epoch: 392 [32/50000]	Loss: 1.3948	LR: 0.000006
Training Epoch: 392 [32/50000]	Loss: 1.1663	LR: 0.000006
Training Epoch: 392 [32/50000]	Loss: 1.3987	LR: 0.000006
Training Epoch: 392 [32/50000]	Loss: 1.3754	LR: 0.000006
Training Epoch: 392 [32/50000]	Loss: 1.7590	LR: 0.000006
Training Epoch: 392 [32/50000]	Loss: 1.2045	LR: 0.000006
Training Epoch: 392 [32/50000]	Loss: 0.9656	LR: 0.000006
Evaluating Network.....
Test set: Epoch: 392, Average loss: 0.0464, Top1Accuracy: 0.5836, Top3Accuracy: 0.7853, Top5Accuracy: 0.8598, Time consumed:2.64s

Training Epoch: 393 [32/50000]	Loss: 1.4158	LR: 0.000006
Training Epoch: 393 [32/50000]	Loss: 1.2333	LR: 0.000006
Training Epoch: 393 [32/50000]	Loss: 1.2987	LR: 0.000006
Training Epoch: 393 [32/50000]	Loss: 0.9006	LR: 0.000006
Training Epoch: 393 [32/50000]	Loss: 1.7188	LR: 0.000006
Training Epoch: 393 [32/50000]	Loss: 1.3445	LR: 0.000006
Training Epoch: 393 [32/50000]	Loss: 1.2417	LR: 0.000006
Training Epoch: 393 [32/50000]	Loss: 1.5530	LR: 0.000006
Training Epoch: 393 [32/50000]	Loss: 1.2549	LR: 0.000006
Training Epoch: 393 [32/50000]	Loss: 1.2265	LR: 0.000006
Evaluating Network.....
Test set: Epoch: 393, Average loss: 0.0464, Top1Accuracy: 0.5831, Top3Accuracy: 0.7858, Top5Accuracy: 0.8597, Time consumed:2.67s

Training Epoch: 394 [32/50000]	Loss: 1.0459	LR: 0.000005
Training Epoch: 394 [32/50000]	Loss: 1.1363	LR: 0.000005
Training Epoch: 394 [32/50000]	Loss: 1.4951	LR: 0.000005
Training Epoch: 394 [32/50000]	Loss: 1.4017	LR: 0.000005
Training Epoch: 394 [32/50000]	Loss: 1.4063	LR: 0.000005
Training Epoch: 394 [32/50000]	Loss: 1.5586	LR: 0.000005
Training Epoch: 394 [32/50000]	Loss: 1.2531	LR: 0.000005
Training Epoch: 394 [32/50000]	Loss: 1.3585	LR: 0.000005
Training Epoch: 394 [32/50000]	Loss: 1.7235	LR: 0.000005
Training Epoch: 394 [32/50000]	Loss: 1.1304	LR: 0.000005
Evaluating Network.....
Test set: Epoch: 394, Average loss: 0.0463, Top1Accuracy: 0.5834, Top3Accuracy: 0.7877, Top5Accuracy: 0.8596, Time consumed:2.72s

Training Epoch: 395 [32/50000]	Loss: 1.7187	LR: 0.000005
Training Epoch: 395 [32/50000]	Loss: 1.3568	LR: 0.000005
Training Epoch: 395 [32/50000]	Loss: 1.9383	LR: 0.000005
Training Epoch: 395 [32/50000]	Loss: 1.3302	LR: 0.000005
Training Epoch: 395 [32/50000]	Loss: 1.5736	LR: 0.000005
Training Epoch: 395 [32/50000]	Loss: 1.1844	LR: 0.000005
Training Epoch: 395 [32/50000]	Loss: 1.6552	LR: 0.000005
Training Epoch: 395 [32/50000]	Loss: 1.5096	LR: 0.000005
Training Epoch: 395 [32/50000]	Loss: 1.3014	LR: 0.000005
Training Epoch: 395 [32/50000]	Loss: 1.0567	LR: 0.000005
Evaluating Network.....
Test set: Epoch: 395, Average loss: 0.0464, Top1Accuracy: 0.5817, Top3Accuracy: 0.7873, Top5Accuracy: 0.8609, Time consumed:2.62s

Training Epoch: 396 [32/50000]	Loss: 1.6496	LR: 0.000005
Training Epoch: 396 [32/50000]	Loss: 1.2873	LR: 0.000005
Training Epoch: 396 [32/50000]	Loss: 1.3967	LR: 0.000005
Training Epoch: 396 [32/50000]	Loss: 1.3270	LR: 0.000005
Training Epoch: 396 [32/50000]	Loss: 1.3119	LR: 0.000005
Training Epoch: 396 [32/50000]	Loss: 1.6666	LR: 0.000005
Training Epoch: 396 [32/50000]	Loss: 1.2020	LR: 0.000005
Training Epoch: 396 [32/50000]	Loss: 1.4359	LR: 0.000005
Training Epoch: 396 [32/50000]	Loss: 1.9412	LR: 0.000005
Training Epoch: 396 [32/50000]	Loss: 1.0422	LR: 0.000005
Evaluating Network.....
Test set: Epoch: 396, Average loss: 0.0464, Top1Accuracy: 0.5815, Top3Accuracy: 0.7863, Top5Accuracy: 0.8597, Time consumed:2.63s

Training Epoch: 397 [32/50000]	Loss: 1.4057	LR: 0.000005
Training Epoch: 397 [32/50000]	Loss: 1.6318	LR: 0.000005
Training Epoch: 397 [32/50000]	Loss: 1.5252	LR: 0.000005
Training Epoch: 397 [32/50000]	Loss: 1.6080	LR: 0.000005
Training Epoch: 397 [32/50000]	Loss: 0.9858	LR: 0.000005
Training Epoch: 397 [32/50000]	Loss: 1.0937	LR: 0.000005
Training Epoch: 397 [32/50000]	Loss: 1.7250	LR: 0.000005
Training Epoch: 397 [32/50000]	Loss: 1.3051	LR: 0.000005
Training Epoch: 397 [32/50000]	Loss: 1.3779	LR: 0.000005
Training Epoch: 397 [32/50000]	Loss: 1.1448	LR: 0.000005
Evaluating Network.....
Test set: Epoch: 397, Average loss: 0.0463, Top1Accuracy: 0.5823, Top3Accuracy: 0.7866, Top5Accuracy: 0.8597, Time consumed:2.62s

Training Epoch: 398 [32/50000]	Loss: 1.6084	LR: 0.000005
Training Epoch: 398 [32/50000]	Loss: 1.7738	LR: 0.000005
Training Epoch: 398 [32/50000]	Loss: 1.0479	LR: 0.000005
Training Epoch: 398 [32/50000]	Loss: 1.1966	LR: 0.000005
Training Epoch: 398 [32/50000]	Loss: 1.0791	LR: 0.000005
Training Epoch: 398 [32/50000]	Loss: 1.3027	LR: 0.000005
Training Epoch: 398 [32/50000]	Loss: 1.4595	LR: 0.000005
Training Epoch: 398 [32/50000]	Loss: 1.1436	LR: 0.000005
Training Epoch: 398 [32/50000]	Loss: 1.7853	LR: 0.000005
Training Epoch: 398 [32/50000]	Loss: 1.3809	LR: 0.000005
Evaluating Network.....
Test set: Epoch: 398, Average loss: 0.0463, Top1Accuracy: 0.5834, Top3Accuracy: 0.7875, Top5Accuracy: 0.8605, Time consumed:2.77s

Training Epoch: 399 [32/50000]	Loss: 1.0676	LR: 0.000005
Training Epoch: 399 [32/50000]	Loss: 1.0168	LR: 0.000005
Training Epoch: 399 [32/50000]	Loss: 2.4916	LR: 0.000005
Training Epoch: 399 [32/50000]	Loss: 1.6757	LR: 0.000005
Training Epoch: 399 [32/50000]	Loss: 2.0259	LR: 0.000005
Training Epoch: 399 [32/50000]	Loss: 1.3922	LR: 0.000005
Training Epoch: 399 [32/50000]	Loss: 1.6514	LR: 0.000005
Training Epoch: 399 [32/50000]	Loss: 1.2149	LR: 0.000005
Training Epoch: 399 [32/50000]	Loss: 1.2506	LR: 0.000005
Training Epoch: 399 [32/50000]	Loss: 1.5760	LR: 0.000005
Evaluating Network.....
Test set: Epoch: 399, Average loss: 0.0463, Top1Accuracy: 0.5833, Top3Accuracy: 0.7874, Top5Accuracy: 0.8594, Time consumed:2.62s

Training Epoch: 400 [32/50000]	Loss: 1.6403	LR: 0.000005
Training Epoch: 400 [32/50000]	Loss: 0.9479	LR: 0.000005
Training Epoch: 400 [32/50000]	Loss: 1.6114	LR: 0.000005
Training Epoch: 400 [32/50000]	Loss: 1.1881	LR: 0.000005
Training Epoch: 400 [32/50000]	Loss: 1.3739	LR: 0.000005
Training Epoch: 400 [32/50000]	Loss: 1.5195	LR: 0.000005
Training Epoch: 400 [32/50000]	Loss: 1.2652	LR: 0.000005
Training Epoch: 400 [32/50000]	Loss: 1.2224	LR: 0.000005
Training Epoch: 400 [32/50000]	Loss: 2.2243	LR: 0.000005
Training Epoch: 400 [32/50000]	Loss: 1.0525	LR: 0.000005
Evaluating Network.....
Test set: Epoch: 400, Average loss: 0.0464, Top1Accuracy: 0.5825, Top3Accuracy: 0.7878, Top5Accuracy: 0.8609, Time consumed:2.62s

