Files already downloaded and verified
Files already downloaded and verified
Training Epoch: 1 [128/50000]	Loss: 4.6195	LR: 0.300000
Training Epoch: 1 [128/50000]	Loss: 4.6186	LR: 0.300000
Training Epoch: 1 [128/50000]	Loss: 4.6043	LR: 0.300000
Training Epoch: 1 [128/50000]	Loss: 4.6057	LR: 0.300000
Training Epoch: 1 [128/50000]	Loss: 4.6391	LR: 0.300000
Training Epoch: 1 [128/50000]	Loss: 4.5982	LR: 0.300000
Training Epoch: 1 [128/50000]	Loss: 4.6343	LR: 0.300000
Training Epoch: 1 [128/50000]	Loss: 4.5903	LR: 0.300000
Training Epoch: 1 [128/50000]	Loss: 4.6438	LR: 0.300000
Training Epoch: 1 [128/50000]	Loss: 4.6494	LR: 0.300000
Evaluating Network.....
Test set: Epoch: 1, Average loss: 0.0364, Top1Accuracy: 0.0100, Top3Accuracy: 0.0300, Top5Accuracy: 0.0500, Time consumed:1.10s

Training Epoch: 2 [128/50000]	Loss: 4.6437	LR: 0.292080
Training Epoch: 2 [128/50000]	Loss: 4.6050	LR: 0.292080
Training Epoch: 2 [128/50000]	Loss: 4.6483	LR: 0.292080
Training Epoch: 2 [128/50000]	Loss: 4.6555	LR: 0.292080
Training Epoch: 2 [128/50000]	Loss: 4.6333	LR: 0.292080
Training Epoch: 2 [128/50000]	Loss: 4.6833	LR: 0.292080
Training Epoch: 2 [128/50000]	Loss: 4.6676	LR: 0.292080
Training Epoch: 2 [128/50000]	Loss: 4.6153	LR: 0.292080
Training Epoch: 2 [128/50000]	Loss: 4.6919	LR: 0.292080
Training Epoch: 2 [128/50000]	Loss: 4.6246	LR: 0.292080
Evaluating Network.....
Test set: Epoch: 2, Average loss: 0.0351, Top1Accuracy: 0.0274, Top3Accuracy: 0.0738, Top5Accuracy: 0.1183, Time consumed:1.10s

Training Epoch: 3 [128/50000]	Loss: 4.0981	LR: 0.284369
Training Epoch: 3 [128/50000]	Loss: 4.0728	LR: 0.284369
Training Epoch: 3 [128/50000]	Loss: 4.1210	LR: 0.284369
Training Epoch: 3 [128/50000]	Loss: 4.1082	LR: 0.284369
Training Epoch: 3 [128/50000]	Loss: 3.9627	LR: 0.284369
Training Epoch: 3 [128/50000]	Loss: 3.9826	LR: 0.284369
Training Epoch: 3 [128/50000]	Loss: 4.0632	LR: 0.284369
Training Epoch: 3 [128/50000]	Loss: 4.1034	LR: 0.284369
Training Epoch: 3 [128/50000]	Loss: 4.0841	LR: 0.284369
Training Epoch: 3 [128/50000]	Loss: 4.1280	LR: 0.284369
Evaluating Network.....
Test set: Epoch: 3, Average loss: 0.0326, Top1Accuracy: 0.0613, Top3Accuracy: 0.1612, Top5Accuracy: 0.2301, Time consumed:1.11s

Training Epoch: 4 [128/50000]	Loss: 4.0449	LR: 0.276862
Training Epoch: 4 [128/50000]	Loss: 4.0077	LR: 0.276862
Training Epoch: 4 [128/50000]	Loss: 3.9667	LR: 0.276862
Training Epoch: 4 [128/50000]	Loss: 3.8871	LR: 0.276862
Training Epoch: 4 [128/50000]	Loss: 3.8596	LR: 0.276862
Training Epoch: 4 [128/50000]	Loss: 3.9247	LR: 0.276862
Training Epoch: 4 [128/50000]	Loss: 3.8869	LR: 0.276862
Training Epoch: 4 [128/50000]	Loss: 3.9185	LR: 0.276862
Training Epoch: 4 [128/50000]	Loss: 3.8436	LR: 0.276862
Training Epoch: 4 [128/50000]	Loss: 3.8913	LR: 0.276862
Evaluating Network.....
Test set: Epoch: 4, Average loss: 0.0322, Top1Accuracy: 0.0617, Top3Accuracy: 0.1624, Top5Accuracy: 0.2369, Time consumed:1.10s

Training Epoch: 5 [128/50000]	Loss: 3.7821	LR: 0.269553
Training Epoch: 5 [128/50000]	Loss: 3.9407	LR: 0.269553
Training Epoch: 5 [128/50000]	Loss: 3.8443	LR: 0.269553
Training Epoch: 5 [128/50000]	Loss: 3.6616	LR: 0.269553
Training Epoch: 5 [128/50000]	Loss: 3.8371	LR: 0.269553
Training Epoch: 5 [128/50000]	Loss: 3.7857	LR: 0.269553
Training Epoch: 5 [128/50000]	Loss: 3.9283	LR: 0.269553
Training Epoch: 5 [128/50000]	Loss: 3.8969	LR: 0.269553
Training Epoch: 5 [128/50000]	Loss: 3.7543	LR: 0.269553
Training Epoch: 5 [128/50000]	Loss: 3.7761	LR: 0.269553
Evaluating Network.....
Test set: Epoch: 5, Average loss: 0.0306, Top1Accuracy: 0.0925, Top3Accuracy: 0.2154, Top5Accuracy: 0.3065, Time consumed:1.11s

Training Epoch: 6 [128/50000]	Loss: 3.7561	LR: 0.262436
Training Epoch: 6 [128/50000]	Loss: 3.7296	LR: 0.262436
Training Epoch: 6 [128/50000]	Loss: 3.7447	LR: 0.262436
Training Epoch: 6 [128/50000]	Loss: 3.5986	LR: 0.262436
Training Epoch: 6 [128/50000]	Loss: 3.6378	LR: 0.262436
Training Epoch: 6 [128/50000]	Loss: 3.7525	LR: 0.262436
Training Epoch: 6 [128/50000]	Loss: 3.7783	LR: 0.262436
Training Epoch: 6 [128/50000]	Loss: 3.6035	LR: 0.262436
Training Epoch: 6 [128/50000]	Loss: 3.5823	LR: 0.262436
Training Epoch: 6 [128/50000]	Loss: 3.9130	LR: 0.262436
Evaluating Network.....
Test set: Epoch: 6, Average loss: 0.0307, Top1Accuracy: 0.0983, Top3Accuracy: 0.2209, Top5Accuracy: 0.3048, Time consumed:1.10s

Training Epoch: 7 [128/50000]	Loss: 3.8377	LR: 0.255508
Training Epoch: 7 [128/50000]	Loss: 3.7362	LR: 0.255508
Training Epoch: 7 [128/50000]	Loss: 3.5031	LR: 0.255508
Training Epoch: 7 [128/50000]	Loss: 3.5982	LR: 0.255508
Training Epoch: 7 [128/50000]	Loss: 3.7691	LR: 0.255508
Training Epoch: 7 [128/50000]	Loss: 3.7461	LR: 0.255508
Training Epoch: 7 [128/50000]	Loss: 3.6911	LR: 0.255508
Training Epoch: 7 [128/50000]	Loss: 3.6440	LR: 0.255508
Training Epoch: 7 [128/50000]	Loss: 3.6383	LR: 0.255508
Training Epoch: 7 [128/50000]	Loss: 3.6841	LR: 0.255508
Evaluating Network.....
Test set: Epoch: 7, Average loss: 0.0295, Top1Accuracy: 0.1222, Top3Accuracy: 0.2583, Top5Accuracy: 0.3484, Time consumed:1.12s

Training Epoch: 8 [128/50000]	Loss: 3.6441	LR: 0.248763
Training Epoch: 8 [128/50000]	Loss: 3.5333	LR: 0.248763
Training Epoch: 8 [128/50000]	Loss: 3.6891	LR: 0.248763
Training Epoch: 8 [128/50000]	Loss: 3.4992	LR: 0.248763
Training Epoch: 8 [128/50000]	Loss: 3.6184	LR: 0.248763
Training Epoch: 8 [128/50000]	Loss: 3.5243	LR: 0.248763
Training Epoch: 8 [128/50000]	Loss: 3.6220	LR: 0.248763
Training Epoch: 8 [128/50000]	Loss: 3.5722	LR: 0.248763
Training Epoch: 8 [128/50000]	Loss: 3.7036	LR: 0.248763
Training Epoch: 8 [128/50000]	Loss: 3.6013	LR: 0.248763
Evaluating Network.....
Test set: Epoch: 8, Average loss: 0.0288, Top1Accuracy: 0.1270, Top3Accuracy: 0.2718, Top5Accuracy: 0.3726, Time consumed:1.10s

Training Epoch: 9 [128/50000]	Loss: 3.3494	LR: 0.242195
Training Epoch: 9 [128/50000]	Loss: 3.5902	LR: 0.242195
Training Epoch: 9 [128/50000]	Loss: 3.3705	LR: 0.242195
Training Epoch: 9 [128/50000]	Loss: 3.7005	LR: 0.242195
Training Epoch: 9 [128/50000]	Loss: 3.5089	LR: 0.242195
Training Epoch: 9 [128/50000]	Loss: 3.4132	LR: 0.242195
Training Epoch: 9 [128/50000]	Loss: 3.5928	LR: 0.242195
Training Epoch: 9 [128/50000]	Loss: 3.5045	LR: 0.242195
Training Epoch: 9 [128/50000]	Loss: 3.5886	LR: 0.242195
Training Epoch: 9 [128/50000]	Loss: 3.6991	LR: 0.242195
Evaluating Network.....
Test set: Epoch: 9, Average loss: 0.0290, Top1Accuracy: 0.1310, Top3Accuracy: 0.2757, Top5Accuracy: 0.3676, Time consumed:1.09s

Training Epoch: 10 [128/50000]	Loss: 3.4749	LR: 0.235801
Training Epoch: 10 [128/50000]	Loss: 3.6138	LR: 0.235801
Training Epoch: 10 [128/50000]	Loss: 3.4880	LR: 0.235801
Training Epoch: 10 [128/50000]	Loss: 3.4994	LR: 0.235801
Training Epoch: 10 [128/50000]	Loss: 3.2961	LR: 0.235801
Training Epoch: 10 [128/50000]	Loss: 3.5727	LR: 0.235801
Training Epoch: 10 [128/50000]	Loss: 3.5048	LR: 0.235801
Training Epoch: 10 [128/50000]	Loss: 3.4849	LR: 0.235801
Training Epoch: 10 [128/50000]	Loss: 3.4879	LR: 0.235801
Training Epoch: 10 [128/50000]	Loss: 3.4899	LR: 0.235801
Evaluating Network.....
Test set: Epoch: 10, Average loss: 0.0274, Top1Accuracy: 0.1639, Top3Accuracy: 0.3302, Top5Accuracy: 0.4296, Time consumed:1.11s

Training Epoch: 11 [128/50000]	Loss: 3.4166	LR: 0.229576
Training Epoch: 11 [128/50000]	Loss: 3.3018	LR: 0.229576
Training Epoch: 11 [128/50000]	Loss: 3.1963	LR: 0.229576
Training Epoch: 11 [128/50000]	Loss: 3.3339	LR: 0.229576
Training Epoch: 11 [128/50000]	Loss: 3.5531	LR: 0.229576
Training Epoch: 11 [128/50000]	Loss: 3.4815	LR: 0.229576
Training Epoch: 11 [128/50000]	Loss: 3.4103	LR: 0.229576
Training Epoch: 11 [128/50000]	Loss: 3.1599	LR: 0.229576
Training Epoch: 11 [128/50000]	Loss: 3.4223	LR: 0.229576
Training Epoch: 11 [128/50000]	Loss: 3.2789	LR: 0.229576
Evaluating Network.....
Test set: Epoch: 11, Average loss: 0.0268, Top1Accuracy: 0.1751, Top3Accuracy: 0.3428, Top5Accuracy: 0.4431, Time consumed:1.11s

Training Epoch: 12 [128/50000]	Loss: 3.2412	LR: 0.223515
Training Epoch: 12 [128/50000]	Loss: 3.4532	LR: 0.223515
Training Epoch: 12 [128/50000]	Loss: 3.4886	LR: 0.223515
Training Epoch: 12 [128/50000]	Loss: 3.2329	LR: 0.223515
Training Epoch: 12 [128/50000]	Loss: 3.4740	LR: 0.223515
Training Epoch: 12 [128/50000]	Loss: 3.2913	LR: 0.223515
Training Epoch: 12 [128/50000]	Loss: 3.1927	LR: 0.223515
Training Epoch: 12 [128/50000]	Loss: 3.3931	LR: 0.223515
Training Epoch: 12 [128/50000]	Loss: 3.1452	LR: 0.223515
Training Epoch: 12 [128/50000]	Loss: 3.4121	LR: 0.223515
Evaluating Network.....
Test set: Epoch: 12, Average loss: 0.0271, Top1Accuracy: 0.1717, Top3Accuracy: 0.3438, Top5Accuracy: 0.4474, Time consumed:1.10s

Training Epoch: 13 [128/50000]	Loss: 3.4313	LR: 0.217615
Training Epoch: 13 [128/50000]	Loss: 3.2661	LR: 0.217615
Training Epoch: 13 [128/50000]	Loss: 3.1810	LR: 0.217615
Training Epoch: 13 [128/50000]	Loss: 3.2151	LR: 0.217615
Training Epoch: 13 [128/50000]	Loss: 3.2717	LR: 0.217615
Training Epoch: 13 [128/50000]	Loss: 3.0929	LR: 0.217615
Training Epoch: 13 [128/50000]	Loss: 3.3111	LR: 0.217615
Training Epoch: 13 [128/50000]	Loss: 3.1914	LR: 0.217615
Training Epoch: 13 [128/50000]	Loss: 3.2446	LR: 0.217615
Training Epoch: 13 [128/50000]	Loss: 3.2554	LR: 0.217615
Evaluating Network.....
Test set: Epoch: 13, Average loss: 0.0264, Top1Accuracy: 0.1869, Top3Accuracy: 0.3614, Top5Accuracy: 0.4651, Time consumed:1.09s

Training Epoch: 14 [128/50000]	Loss: 3.0924	LR: 0.211870
Training Epoch: 14 [128/50000]	Loss: 3.0332	LR: 0.211870
Training Epoch: 14 [128/50000]	Loss: 3.0521	LR: 0.211870
Training Epoch: 14 [128/50000]	Loss: 3.0597	LR: 0.211870
Training Epoch: 14 [128/50000]	Loss: 3.2235	LR: 0.211870
Training Epoch: 14 [128/50000]	Loss: 3.1285	LR: 0.211870
Training Epoch: 14 [128/50000]	Loss: 3.2592	LR: 0.211870
Training Epoch: 14 [128/50000]	Loss: 3.2564	LR: 0.211870
Training Epoch: 14 [128/50000]	Loss: 3.3782	LR: 0.211870
Training Epoch: 14 [128/50000]	Loss: 3.2396	LR: 0.211870
Evaluating Network.....
Test set: Epoch: 14, Average loss: 0.0257, Top1Accuracy: 0.2068, Top3Accuracy: 0.3836, Top5Accuracy: 0.4879, Time consumed:1.10s

Training Epoch: 15 [128/50000]	Loss: 3.3806	LR: 0.206276
Training Epoch: 15 [128/50000]	Loss: 3.0266	LR: 0.206276
Training Epoch: 15 [128/50000]	Loss: 3.1220	LR: 0.206276
Training Epoch: 15 [128/50000]	Loss: 3.1830	LR: 0.206276
Training Epoch: 15 [128/50000]	Loss: 3.2389	LR: 0.206276
Training Epoch: 15 [128/50000]	Loss: 3.0786	LR: 0.206276
Training Epoch: 15 [128/50000]	Loss: 2.9786	LR: 0.206276
Training Epoch: 15 [128/50000]	Loss: 3.1041	LR: 0.206276
Training Epoch: 15 [128/50000]	Loss: 3.1864	LR: 0.206276
Training Epoch: 15 [128/50000]	Loss: 3.2796	LR: 0.206276
Evaluating Network.....
Test set: Epoch: 15, Average loss: 0.0252, Top1Accuracy: 0.2066, Top3Accuracy: 0.3974, Top5Accuracy: 0.5082, Time consumed:1.11s

Training Epoch: 16 [128/50000]	Loss: 3.2881	LR: 0.200831
Training Epoch: 16 [128/50000]	Loss: 3.1690	LR: 0.200831
Training Epoch: 16 [128/50000]	Loss: 3.1219	LR: 0.200831
Training Epoch: 16 [128/50000]	Loss: 3.3189	LR: 0.200831
Training Epoch: 16 [128/50000]	Loss: 3.1742	LR: 0.200831
Training Epoch: 16 [128/50000]	Loss: 2.9824	LR: 0.200831
Training Epoch: 16 [128/50000]	Loss: 3.1415	LR: 0.200831
Training Epoch: 16 [128/50000]	Loss: 3.0615	LR: 0.200831
Training Epoch: 16 [128/50000]	Loss: 3.1722	LR: 0.200831
Training Epoch: 16 [128/50000]	Loss: 2.9114	LR: 0.200831
Evaluating Network.....
Test set: Epoch: 16, Average loss: 0.0246, Top1Accuracy: 0.2285, Top3Accuracy: 0.4195, Top5Accuracy: 0.5240, Time consumed:1.09s

Training Epoch: 17 [128/50000]	Loss: 3.0068	LR: 0.195529
Training Epoch: 17 [128/50000]	Loss: 3.0343	LR: 0.195529
Training Epoch: 17 [128/50000]	Loss: 3.0643	LR: 0.195529
Training Epoch: 17 [128/50000]	Loss: 2.6921	LR: 0.195529
Training Epoch: 17 [128/50000]	Loss: 2.9959	LR: 0.195529
Training Epoch: 17 [128/50000]	Loss: 3.1513	LR: 0.195529
Training Epoch: 17 [128/50000]	Loss: 3.0549	LR: 0.195529
Training Epoch: 17 [128/50000]	Loss: 3.0929	LR: 0.195529
Training Epoch: 17 [128/50000]	Loss: 2.9846	LR: 0.195529
Training Epoch: 17 [128/50000]	Loss: 3.2271	LR: 0.195529
Evaluating Network.....
Test set: Epoch: 17, Average loss: 0.0243, Top1Accuracy: 0.2386, Top3Accuracy: 0.4332, Top5Accuracy: 0.5393, Time consumed:1.10s

Training Epoch: 18 [128/50000]	Loss: 3.2691	LR: 0.190367
Training Epoch: 18 [128/50000]	Loss: 3.0780	LR: 0.190367
Training Epoch: 18 [128/50000]	Loss: 2.8599	LR: 0.190367
Training Epoch: 18 [128/50000]	Loss: 2.9535	LR: 0.190367
Training Epoch: 18 [128/50000]	Loss: 2.9998	LR: 0.190367
Training Epoch: 18 [128/50000]	Loss: 2.9544	LR: 0.190367
Training Epoch: 18 [128/50000]	Loss: 2.7832	LR: 0.190367
Training Epoch: 18 [128/50000]	Loss: 3.0529	LR: 0.190367
Training Epoch: 18 [128/50000]	Loss: 2.9457	LR: 0.190367
Training Epoch: 18 [128/50000]	Loss: 3.1513	LR: 0.190367
Evaluating Network.....
Test set: Epoch: 18, Average loss: 0.0239, Top1Accuracy: 0.2507, Top3Accuracy: 0.4395, Top5Accuracy: 0.5428, Time consumed:1.09s

Training Epoch: 19 [128/50000]	Loss: 2.9226	LR: 0.185341
Training Epoch: 19 [128/50000]	Loss: 2.7352	LR: 0.185341
Training Epoch: 19 [128/50000]	Loss: 2.8520	LR: 0.185341
Training Epoch: 19 [128/50000]	Loss: 2.9224	LR: 0.185341
Training Epoch: 19 [128/50000]	Loss: 2.7471	LR: 0.185341
Training Epoch: 19 [128/50000]	Loss: 2.8095	LR: 0.185341
Training Epoch: 19 [128/50000]	Loss: 2.9365	LR: 0.185341
Training Epoch: 19 [128/50000]	Loss: 3.0335	LR: 0.185341
Training Epoch: 19 [128/50000]	Loss: 3.0319	LR: 0.185341
Training Epoch: 19 [128/50000]	Loss: 2.9204	LR: 0.185341
Evaluating Network.....
Test set: Epoch: 19, Average loss: 0.0238, Top1Accuracy: 0.2503, Top3Accuracy: 0.4469, Top5Accuracy: 0.5555, Time consumed:1.11s

Training Epoch: 20 [128/50000]	Loss: 2.9751	LR: 0.180448
Training Epoch: 20 [128/50000]	Loss: 3.0031	LR: 0.180448
Training Epoch: 20 [128/50000]	Loss: 2.7478	LR: 0.180448
Training Epoch: 20 [128/50000]	Loss: 2.8229	LR: 0.180448
Training Epoch: 20 [128/50000]	Loss: 3.0194	LR: 0.180448
Training Epoch: 20 [128/50000]	Loss: 3.0785	LR: 0.180448
Training Epoch: 20 [128/50000]	Loss: 3.0910	LR: 0.180448
Training Epoch: 20 [128/50000]	Loss: 2.7270	LR: 0.180448
Training Epoch: 20 [128/50000]	Loss: 2.6987	LR: 0.180448
Training Epoch: 20 [128/50000]	Loss: 2.8931	LR: 0.180448
Evaluating Network.....
Test set: Epoch: 20, Average loss: 0.0228, Top1Accuracy: 0.2704, Top3Accuracy: 0.4820, Top5Accuracy: 0.5875, Time consumed:1.12s

Training Epoch: 21 [128/50000]	Loss: 2.8972	LR: 0.175684
Training Epoch: 21 [128/50000]	Loss: 3.0564	LR: 0.175684
Training Epoch: 21 [128/50000]	Loss: 2.8156	LR: 0.175684
Training Epoch: 21 [128/50000]	Loss: 2.7502	LR: 0.175684
Training Epoch: 21 [128/50000]	Loss: 2.9632	LR: 0.175684
Training Epoch: 21 [128/50000]	Loss: 2.8018	LR: 0.175684
Training Epoch: 21 [128/50000]	Loss: 3.0252	LR: 0.175684
Training Epoch: 21 [128/50000]	Loss: 2.8483	LR: 0.175684
Training Epoch: 21 [128/50000]	Loss: 2.7526	LR: 0.175684
Training Epoch: 21 [128/50000]	Loss: 3.1763	LR: 0.175684
Evaluating Network.....
Test set: Epoch: 21, Average loss: 0.0227, Top1Accuracy: 0.2724, Top3Accuracy: 0.4780, Top5Accuracy: 0.5847, Time consumed:1.10s

Training Epoch: 22 [128/50000]	Loss: 2.9180	LR: 0.171046
Training Epoch: 22 [128/50000]	Loss: 2.8238	LR: 0.171046
Training Epoch: 22 [128/50000]	Loss: 2.7970	LR: 0.171046
Training Epoch: 22 [128/50000]	Loss: 2.8694	LR: 0.171046
Training Epoch: 22 [128/50000]	Loss: 3.0601	LR: 0.171046
Training Epoch: 22 [128/50000]	Loss: 2.6022	LR: 0.171046
Training Epoch: 22 [128/50000]	Loss: 2.8143	LR: 0.171046
Training Epoch: 22 [128/50000]	Loss: 2.8820	LR: 0.171046
Training Epoch: 22 [128/50000]	Loss: 2.8428	LR: 0.171046
Training Epoch: 22 [128/50000]	Loss: 2.5235	LR: 0.171046
Evaluating Network.....
Test set: Epoch: 22, Average loss: 0.0225, Top1Accuracy: 0.2763, Top3Accuracy: 0.4878, Top5Accuracy: 0.5975, Time consumed:1.11s

Training Epoch: 23 [128/50000]	Loss: 2.6418	LR: 0.166530
Training Epoch: 23 [128/50000]	Loss: 2.9291	LR: 0.166530
Training Epoch: 23 [128/50000]	Loss: 2.8838	LR: 0.166530
Training Epoch: 23 [128/50000]	Loss: 2.8992	LR: 0.166530
Training Epoch: 23 [128/50000]	Loss: 2.7196	LR: 0.166530
Training Epoch: 23 [128/50000]	Loss: 2.7995	LR: 0.166530
Training Epoch: 23 [128/50000]	Loss: 2.7516	LR: 0.166530
Training Epoch: 23 [128/50000]	Loss: 2.6659	LR: 0.166530
Training Epoch: 23 [128/50000]	Loss: 2.5463	LR: 0.166530
Training Epoch: 23 [128/50000]	Loss: 2.7269	LR: 0.166530
Evaluating Network.....
Test set: Epoch: 23, Average loss: 0.0221, Top1Accuracy: 0.2888, Top3Accuracy: 0.5046, Top5Accuracy: 0.6088, Time consumed:1.11s

Training Epoch: 24 [128/50000]	Loss: 2.8094	LR: 0.162134
Training Epoch: 24 [128/50000]	Loss: 2.5590	LR: 0.162134
Training Epoch: 24 [128/50000]	Loss: 2.5129	LR: 0.162134
Training Epoch: 24 [128/50000]	Loss: 2.9742	LR: 0.162134
Training Epoch: 24 [128/50000]	Loss: 2.7121	LR: 0.162134
Training Epoch: 24 [128/50000]	Loss: 2.9313	LR: 0.162134
Training Epoch: 24 [128/50000]	Loss: 2.7545	LR: 0.162134
Training Epoch: 24 [128/50000]	Loss: 2.6481	LR: 0.162134
Training Epoch: 24 [128/50000]	Loss: 2.7406	LR: 0.162134
Training Epoch: 24 [128/50000]	Loss: 2.6725	LR: 0.162134
Evaluating Network.....
Test set: Epoch: 24, Average loss: 0.0220, Top1Accuracy: 0.2983, Top3Accuracy: 0.5005, Top5Accuracy: 0.6094, Time consumed:1.11s

Training Epoch: 25 [128/50000]	Loss: 2.3852	LR: 0.157854
Training Epoch: 25 [128/50000]	Loss: 2.6301	LR: 0.157854
Training Epoch: 25 [128/50000]	Loss: 2.7596	LR: 0.157854
Training Epoch: 25 [128/50000]	Loss: 2.7846	LR: 0.157854
Training Epoch: 25 [128/50000]	Loss: 2.5079	LR: 0.157854
Training Epoch: 25 [128/50000]	Loss: 2.5388	LR: 0.157854
Training Epoch: 25 [128/50000]	Loss: 2.6454	LR: 0.157854
Training Epoch: 25 [128/50000]	Loss: 2.5540	LR: 0.157854
Training Epoch: 25 [128/50000]	Loss: 2.8686	LR: 0.157854
Training Epoch: 25 [128/50000]	Loss: 2.7926	LR: 0.157854
Evaluating Network.....
Test set: Epoch: 25, Average loss: 0.0219, Top1Accuracy: 0.2976, Top3Accuracy: 0.5101, Top5Accuracy: 0.6145, Time consumed:1.11s

Training Epoch: 26 [128/50000]	Loss: 2.7555	LR: 0.153686
Training Epoch: 26 [128/50000]	Loss: 2.6400	LR: 0.153686
Training Epoch: 26 [128/50000]	Loss: 2.5093	LR: 0.153686
Training Epoch: 26 [128/50000]	Loss: 2.2915	LR: 0.153686
Training Epoch: 26 [128/50000]	Loss: 2.7645	LR: 0.153686
Training Epoch: 26 [128/50000]	Loss: 2.4383	LR: 0.153686
Training Epoch: 26 [128/50000]	Loss: 2.5133	LR: 0.153686
Training Epoch: 26 [128/50000]	Loss: 2.6030	LR: 0.153686
Training Epoch: 26 [128/50000]	Loss: 2.6868	LR: 0.153686
Training Epoch: 26 [128/50000]	Loss: 2.6444	LR: 0.153686
Evaluating Network.....
Test set: Epoch: 26, Average loss: 0.0208, Top1Accuracy: 0.3165, Top3Accuracy: 0.5346, Top5Accuracy: 0.6417, Time consumed:1.11s

Training Epoch: 27 [128/50000]	Loss: 2.6792	LR: 0.149629
Training Epoch: 27 [128/50000]	Loss: 2.6264	LR: 0.149629
Training Epoch: 27 [128/50000]	Loss: 2.6912	LR: 0.149629
Training Epoch: 27 [128/50000]	Loss: 2.4449	LR: 0.149629
Training Epoch: 27 [128/50000]	Loss: 2.5563	LR: 0.149629
Training Epoch: 27 [128/50000]	Loss: 2.6083	LR: 0.149629
Training Epoch: 27 [128/50000]	Loss: 2.5755	LR: 0.149629
Training Epoch: 27 [128/50000]	Loss: 2.6667	LR: 0.149629
Training Epoch: 27 [128/50000]	Loss: 2.6645	LR: 0.149629
Training Epoch: 27 [128/50000]	Loss: 2.7035	LR: 0.149629
Evaluating Network.....
Test set: Epoch: 27, Average loss: 0.0202, Top1Accuracy: 0.3311, Top3Accuracy: 0.5570, Top5Accuracy: 0.6577, Time consumed:1.11s

Training Epoch: 28 [128/50000]	Loss: 2.5296	LR: 0.145679
Training Epoch: 28 [128/50000]	Loss: 2.7374	LR: 0.145679
Training Epoch: 28 [128/50000]	Loss: 2.5320	LR: 0.145679
Training Epoch: 28 [128/50000]	Loss: 2.4362	LR: 0.145679
Training Epoch: 28 [128/50000]	Loss: 2.4975	LR: 0.145679
Training Epoch: 28 [128/50000]	Loss: 2.6495	LR: 0.145679
Training Epoch: 28 [128/50000]	Loss: 2.7498	LR: 0.145679
Training Epoch: 28 [128/50000]	Loss: 2.4535	LR: 0.145679
Training Epoch: 28 [128/50000]	Loss: 2.6158	LR: 0.145679
Training Epoch: 28 [128/50000]	Loss: 2.4870	LR: 0.145679
Evaluating Network.....
Test set: Epoch: 28, Average loss: 0.0203, Top1Accuracy: 0.3342, Top3Accuracy: 0.5548, Top5Accuracy: 0.6592, Time consumed:1.10s

Training Epoch: 29 [128/50000]	Loss: 2.2486	LR: 0.141833
Training Epoch: 29 [128/50000]	Loss: 2.3673	LR: 0.141833
Training Epoch: 29 [128/50000]	Loss: 2.6936	LR: 0.141833
Training Epoch: 29 [128/50000]	Loss: 2.4218	LR: 0.141833
Training Epoch: 29 [128/50000]	Loss: 2.5181	LR: 0.141833
Training Epoch: 29 [128/50000]	Loss: 2.6936	LR: 0.141833
Training Epoch: 29 [128/50000]	Loss: 2.5141	LR: 0.141833
Training Epoch: 29 [128/50000]	Loss: 2.5026	LR: 0.141833
Training Epoch: 29 [128/50000]	Loss: 2.4902	LR: 0.141833
Training Epoch: 29 [128/50000]	Loss: 2.6150	LR: 0.141833
Evaluating Network.....
Test set: Epoch: 29, Average loss: 0.0197, Top1Accuracy: 0.3516, Top3Accuracy: 0.5719, Top5Accuracy: 0.6716, Time consumed:1.11s

Training Epoch: 30 [128/50000]	Loss: 2.4929	LR: 0.138089
Training Epoch: 30 [128/50000]	Loss: 2.4474	LR: 0.138089
Training Epoch: 30 [128/50000]	Loss: 2.2439	LR: 0.138089
Training Epoch: 30 [128/50000]	Loss: 2.4498	LR: 0.138089
Training Epoch: 30 [128/50000]	Loss: 2.5569	LR: 0.138089
Training Epoch: 30 [128/50000]	Loss: 2.5517	LR: 0.138089
Training Epoch: 30 [128/50000]	Loss: 2.3931	LR: 0.138089
Training Epoch: 30 [128/50000]	Loss: 2.1740	LR: 0.138089
Training Epoch: 30 [128/50000]	Loss: 2.4611	LR: 0.138089
Training Epoch: 30 [128/50000]	Loss: 2.6933	LR: 0.138089
Evaluating Network.....
Test set: Epoch: 30, Average loss: 0.0204, Top1Accuracy: 0.3310, Top3Accuracy: 0.5509, Top5Accuracy: 0.6545, Time consumed:1.10s

Training Epoch: 31 [128/50000]	Loss: 2.4211	LR: 0.134443
Training Epoch: 31 [128/50000]	Loss: 2.3983	LR: 0.134443
Training Epoch: 31 [128/50000]	Loss: 2.2609	LR: 0.134443
Training Epoch: 31 [128/50000]	Loss: 2.3647	LR: 0.134443
Training Epoch: 31 [128/50000]	Loss: 2.1557	LR: 0.134443
Training Epoch: 31 [128/50000]	Loss: 2.4109	LR: 0.134443
Training Epoch: 31 [128/50000]	Loss: 2.4548	LR: 0.134443
Training Epoch: 31 [128/50000]	Loss: 2.4523	LR: 0.134443
Training Epoch: 31 [128/50000]	Loss: 2.3611	LR: 0.134443
Training Epoch: 31 [128/50000]	Loss: 2.2710	LR: 0.134443
Evaluating Network.....
Test set: Epoch: 31, Average loss: 0.0200, Top1Accuracy: 0.3445, Top3Accuracy: 0.5671, Top5Accuracy: 0.6685, Time consumed:1.11s

Training Epoch: 32 [128/50000]	Loss: 2.3110	LR: 0.130894
Training Epoch: 32 [128/50000]	Loss: 2.4493	LR: 0.130894
Training Epoch: 32 [128/50000]	Loss: 2.4104	LR: 0.130894
Training Epoch: 32 [128/50000]	Loss: 2.3802	LR: 0.130894
Training Epoch: 32 [128/50000]	Loss: 2.7203	LR: 0.130894
Training Epoch: 32 [128/50000]	Loss: 2.5044	LR: 0.130894
Training Epoch: 32 [128/50000]	Loss: 2.3296	LR: 0.130894
Training Epoch: 32 [128/50000]	Loss: 2.3428	LR: 0.130894
Training Epoch: 32 [128/50000]	Loss: 2.5236	LR: 0.130894
Training Epoch: 32 [128/50000]	Loss: 2.3942	LR: 0.130894
Evaluating Network.....
Test set: Epoch: 32, Average loss: 0.0191, Top1Accuracy: 0.3677, Top3Accuracy: 0.5894, Top5Accuracy: 0.6922, Time consumed:1.11s

Training Epoch: 33 [128/50000]	Loss: 2.4407	LR: 0.127438
Training Epoch: 33 [128/50000]	Loss: 2.2537	LR: 0.127438
Training Epoch: 33 [128/50000]	Loss: 2.2291	LR: 0.127438
Training Epoch: 33 [128/50000]	Loss: 2.6394	LR: 0.127438
Training Epoch: 33 [128/50000]	Loss: 2.3473	LR: 0.127438
Training Epoch: 33 [128/50000]	Loss: 2.2727	LR: 0.127438
Training Epoch: 33 [128/50000]	Loss: 2.3451	LR: 0.127438
Training Epoch: 33 [128/50000]	Loss: 2.4770	LR: 0.127438
Training Epoch: 33 [128/50000]	Loss: 2.3111	LR: 0.127438
Training Epoch: 33 [128/50000]	Loss: 2.2371	LR: 0.127438
Evaluating Network.....
Test set: Epoch: 33, Average loss: 0.0195, Top1Accuracy: 0.3637, Top3Accuracy: 0.5843, Top5Accuracy: 0.6808, Time consumed:1.11s

Training Epoch: 34 [128/50000]	Loss: 2.3242	LR: 0.124074
Training Epoch: 34 [128/50000]	Loss: 2.2115	LR: 0.124074
Training Epoch: 34 [128/50000]	Loss: 2.2499	LR: 0.124074
Training Epoch: 34 [128/50000]	Loss: 2.2633	LR: 0.124074
Training Epoch: 34 [128/50000]	Loss: 2.2453	LR: 0.124074
Training Epoch: 34 [128/50000]	Loss: 2.5575	LR: 0.124074
Training Epoch: 34 [128/50000]	Loss: 2.1456	LR: 0.124074
Training Epoch: 34 [128/50000]	Loss: 2.3069	LR: 0.124074
Training Epoch: 34 [128/50000]	Loss: 2.3685	LR: 0.124074
Training Epoch: 34 [128/50000]	Loss: 2.2388	LR: 0.124074
Evaluating Network.....
Test set: Epoch: 34, Average loss: 0.0197, Top1Accuracy: 0.3535, Top3Accuracy: 0.5805, Top5Accuracy: 0.6818, Time consumed:1.10s

Training Epoch: 35 [128/50000]	Loss: 2.3042	LR: 0.120798
Training Epoch: 35 [128/50000]	Loss: 2.4658	LR: 0.120798
Training Epoch: 35 [128/50000]	Loss: 2.3161	LR: 0.120798
Training Epoch: 35 [128/50000]	Loss: 2.2629	LR: 0.120798
Training Epoch: 35 [128/50000]	Loss: 2.3608	LR: 0.120798
Training Epoch: 35 [128/50000]	Loss: 2.3105	LR: 0.120798
Training Epoch: 35 [128/50000]	Loss: 2.3738	LR: 0.120798
Training Epoch: 35 [128/50000]	Loss: 2.2175	LR: 0.120798
Training Epoch: 35 [128/50000]	Loss: 2.4595	LR: 0.120798
Training Epoch: 35 [128/50000]	Loss: 2.4148	LR: 0.120798
Evaluating Network.....
Test set: Epoch: 35, Average loss: 0.0183, Top1Accuracy: 0.3915, Top3Accuracy: 0.6123, Top5Accuracy: 0.7079, Time consumed:1.10s

Training Epoch: 36 [128/50000]	Loss: 2.3405	LR: 0.117609
Training Epoch: 36 [128/50000]	Loss: 2.3731	LR: 0.117609
Training Epoch: 36 [128/50000]	Loss: 2.4160	LR: 0.117609
Training Epoch: 36 [128/50000]	Loss: 2.2325	LR: 0.117609
Training Epoch: 36 [128/50000]	Loss: 2.1324	LR: 0.117609
Training Epoch: 36 [128/50000]	Loss: 1.9466	LR: 0.117609
Training Epoch: 36 [128/50000]	Loss: 1.9183	LR: 0.117609
Training Epoch: 36 [128/50000]	Loss: 1.9198	LR: 0.117609
Training Epoch: 36 [128/50000]	Loss: 2.1113	LR: 0.117609
Training Epoch: 36 [128/50000]	Loss: 2.3273	LR: 0.117609
Evaluating Network.....
Test set: Epoch: 36, Average loss: 0.0185, Top1Accuracy: 0.3822, Top3Accuracy: 0.6079, Top5Accuracy: 0.7113, Time consumed:1.12s

Training Epoch: 37 [128/50000]	Loss: 2.1014	LR: 0.114504
Training Epoch: 37 [128/50000]	Loss: 2.4065	LR: 0.114504
Training Epoch: 37 [128/50000]	Loss: 2.3245	LR: 0.114504
Training Epoch: 37 [128/50000]	Loss: 2.1879	LR: 0.114504
Training Epoch: 37 [128/50000]	Loss: 1.9783	LR: 0.114504
Training Epoch: 37 [128/50000]	Loss: 2.1733	LR: 0.114504
Training Epoch: 37 [128/50000]	Loss: 2.3054	LR: 0.114504
Training Epoch: 37 [128/50000]	Loss: 2.0991	LR: 0.114504
Training Epoch: 37 [128/50000]	Loss: 2.0872	LR: 0.114504
Training Epoch: 37 [128/50000]	Loss: 2.2042	LR: 0.114504
Evaluating Network.....
Test set: Epoch: 37, Average loss: 0.0189, Top1Accuracy: 0.3788, Top3Accuracy: 0.6016, Top5Accuracy: 0.6988, Time consumed:1.10s

Training Epoch: 38 [128/50000]	Loss: 2.2242	LR: 0.111481
Training Epoch: 38 [128/50000]	Loss: 2.1362	LR: 0.111481
Training Epoch: 38 [128/50000]	Loss: 2.3028	LR: 0.111481
Training Epoch: 38 [128/50000]	Loss: 2.1699	LR: 0.111481
Training Epoch: 38 [128/50000]	Loss: 1.9506	LR: 0.111481
Training Epoch: 38 [128/50000]	Loss: 2.1483	LR: 0.111481
Training Epoch: 38 [128/50000]	Loss: 2.1978	LR: 0.111481
Training Epoch: 38 [128/50000]	Loss: 2.2837	LR: 0.111481
Training Epoch: 38 [128/50000]	Loss: 2.1511	LR: 0.111481
Training Epoch: 38 [128/50000]	Loss: 2.0145	LR: 0.111481
Evaluating Network.....
Test set: Epoch: 38, Average loss: 0.0179, Top1Accuracy: 0.4051, Top3Accuracy: 0.6260, Top5Accuracy: 0.7222, Time consumed:1.12s

Training Epoch: 39 [128/50000]	Loss: 2.2855	LR: 0.108538
Training Epoch: 39 [128/50000]	Loss: 2.0253	LR: 0.108538
Training Epoch: 39 [128/50000]	Loss: 2.0288	LR: 0.108538
Training Epoch: 39 [128/50000]	Loss: 2.2153	LR: 0.108538
Training Epoch: 39 [128/50000]	Loss: 2.0892	LR: 0.108538
Training Epoch: 39 [128/50000]	Loss: 2.2021	LR: 0.108538
Training Epoch: 39 [128/50000]	Loss: 2.1645	LR: 0.108538
Training Epoch: 39 [128/50000]	Loss: 2.1677	LR: 0.108538
Training Epoch: 39 [128/50000]	Loss: 2.1345	LR: 0.108538
Training Epoch: 39 [128/50000]	Loss: 2.2264	LR: 0.108538
Evaluating Network.....
Test set: Epoch: 39, Average loss: 0.0177, Top1Accuracy: 0.4029, Top3Accuracy: 0.6293, Top5Accuracy: 0.7286, Time consumed:1.11s

Training Epoch: 40 [128/50000]	Loss: 2.1172	LR: 0.105673
Training Epoch: 40 [128/50000]	Loss: 2.1416	LR: 0.105673
Training Epoch: 40 [128/50000]	Loss: 2.2677	LR: 0.105673
Training Epoch: 40 [128/50000]	Loss: 1.9742	LR: 0.105673
Training Epoch: 40 [128/50000]	Loss: 2.1652	LR: 0.105673
Training Epoch: 40 [128/50000]	Loss: 2.0636	LR: 0.105673
Training Epoch: 40 [128/50000]	Loss: 1.9127	LR: 0.105673
Training Epoch: 40 [128/50000]	Loss: 2.1188	LR: 0.105673
Training Epoch: 40 [128/50000]	Loss: 1.9783	LR: 0.105673
Training Epoch: 40 [128/50000]	Loss: 2.2344	LR: 0.105673
Evaluating Network.....
Test set: Epoch: 40, Average loss: 0.0178, Top1Accuracy: 0.4037, Top3Accuracy: 0.6343, Top5Accuracy: 0.7324, Time consumed:1.11s

Training Epoch: 41 [128/50000]	Loss: 2.0930	LR: 0.102883
Training Epoch: 41 [128/50000]	Loss: 2.1558	LR: 0.102883
Training Epoch: 41 [128/50000]	Loss: 2.1717	LR: 0.102883
Training Epoch: 41 [128/50000]	Loss: 2.0612	LR: 0.102883
Training Epoch: 41 [128/50000]	Loss: 2.2789	LR: 0.102883
Training Epoch: 41 [128/50000]	Loss: 1.9728	LR: 0.102883
Training Epoch: 41 [128/50000]	Loss: 2.0428	LR: 0.102883
Training Epoch: 41 [128/50000]	Loss: 2.1323	LR: 0.102883
Training Epoch: 41 [128/50000]	Loss: 2.3474	LR: 0.102883
Training Epoch: 41 [128/50000]	Loss: 1.9734	LR: 0.102883
Evaluating Network.....
Test set: Epoch: 41, Average loss: 0.0170, Top1Accuracy: 0.4283, Top3Accuracy: 0.6534, Top5Accuracy: 0.7471, Time consumed:1.11s

Training Epoch: 42 [128/50000]	Loss: 2.2413	LR: 0.100167
Training Epoch: 42 [128/50000]	Loss: 2.1603	LR: 0.100167
Training Epoch: 42 [128/50000]	Loss: 2.1853	LR: 0.100167
Training Epoch: 42 [128/50000]	Loss: 2.2636	LR: 0.100167
Training Epoch: 42 [128/50000]	Loss: 2.0219	LR: 0.100167
Training Epoch: 42 [128/50000]	Loss: 1.8968	LR: 0.100167
Training Epoch: 42 [128/50000]	Loss: 2.0749	LR: 0.100167
Training Epoch: 42 [128/50000]	Loss: 2.1096	LR: 0.100167
Training Epoch: 42 [128/50000]	Loss: 2.1502	LR: 0.100167
Training Epoch: 42 [128/50000]	Loss: 2.1095	LR: 0.100167
Evaluating Network.....
Test set: Epoch: 42, Average loss: 0.0168, Top1Accuracy: 0.4258, Top3Accuracy: 0.6542, Top5Accuracy: 0.7470, Time consumed:1.11s

Training Epoch: 43 [128/50000]	Loss: 1.9250	LR: 0.097523
Training Epoch: 43 [128/50000]	Loss: 1.9314	LR: 0.097523
Training Epoch: 43 [128/50000]	Loss: 2.0345	LR: 0.097523
Training Epoch: 43 [128/50000]	Loss: 1.9868	LR: 0.097523
Training Epoch: 43 [128/50000]	Loss: 2.1303	LR: 0.097523
Training Epoch: 43 [128/50000]	Loss: 2.0295	LR: 0.097523
Training Epoch: 43 [128/50000]	Loss: 2.1419	LR: 0.097523
Training Epoch: 43 [128/50000]	Loss: 1.8806	LR: 0.097523
Training Epoch: 43 [128/50000]	Loss: 1.7995	LR: 0.097523
Training Epoch: 43 [128/50000]	Loss: 2.3226	LR: 0.097523
Evaluating Network.....
Test set: Epoch: 43, Average loss: 0.0166, Top1Accuracy: 0.4370, Top3Accuracy: 0.6642, Top5Accuracy: 0.7564, Time consumed:1.09s

Training Epoch: 44 [128/50000]	Loss: 2.4387	LR: 0.094948
Training Epoch: 44 [128/50000]	Loss: 1.9155	LR: 0.094948
Training Epoch: 44 [128/50000]	Loss: 1.9812	LR: 0.094948
Training Epoch: 44 [128/50000]	Loss: 1.9696	LR: 0.094948
Training Epoch: 44 [128/50000]	Loss: 2.1266	LR: 0.094948
Training Epoch: 44 [128/50000]	Loss: 2.1665	LR: 0.094948
Training Epoch: 44 [128/50000]	Loss: 2.1594	LR: 0.094948
Training Epoch: 44 [128/50000]	Loss: 1.8991	LR: 0.094948
Training Epoch: 44 [128/50000]	Loss: 2.0689	LR: 0.094948
Training Epoch: 44 [128/50000]	Loss: 1.8654	LR: 0.094948
Evaluating Network.....
Test set: Epoch: 44, Average loss: 0.0167, Top1Accuracy: 0.4354, Top3Accuracy: 0.6624, Top5Accuracy: 0.7572, Time consumed:1.11s

Training Epoch: 45 [128/50000]	Loss: 2.0825	LR: 0.092441
Training Epoch: 45 [128/50000]	Loss: 1.9680	LR: 0.092441
Training Epoch: 45 [128/50000]	Loss: 1.9570	LR: 0.092441
Training Epoch: 45 [128/50000]	Loss: 2.1519	LR: 0.092441
Training Epoch: 45 [128/50000]	Loss: 1.8872	LR: 0.092441
Training Epoch: 45 [128/50000]	Loss: 2.0705	LR: 0.092441
Training Epoch: 45 [128/50000]	Loss: 1.8905	LR: 0.092441
Training Epoch: 45 [128/50000]	Loss: 2.2153	LR: 0.092441
Training Epoch: 45 [128/50000]	Loss: 1.8892	LR: 0.092441
Training Epoch: 45 [128/50000]	Loss: 2.3735	LR: 0.092441
Evaluating Network.....
Test set: Epoch: 45, Average loss: 0.0166, Top1Accuracy: 0.4395, Top3Accuracy: 0.6645, Top5Accuracy: 0.7590, Time consumed:1.11s

Training Epoch: 46 [128/50000]	Loss: 2.0884	LR: 0.090001
Training Epoch: 46 [128/50000]	Loss: 1.9985	LR: 0.090001
Training Epoch: 46 [128/50000]	Loss: 1.9409	LR: 0.090001
Training Epoch: 46 [128/50000]	Loss: 1.9493	LR: 0.090001
Training Epoch: 46 [128/50000]	Loss: 1.8389	LR: 0.090001
Training Epoch: 46 [128/50000]	Loss: 1.8958	LR: 0.090001
Training Epoch: 46 [128/50000]	Loss: 2.1502	LR: 0.090001
Training Epoch: 46 [128/50000]	Loss: 2.1692	LR: 0.090001
Training Epoch: 46 [128/50000]	Loss: 1.9847	LR: 0.090001
Training Epoch: 46 [128/50000]	Loss: 2.1062	LR: 0.090001
Evaluating Network.....
Test set: Epoch: 46, Average loss: 0.0168, Top1Accuracy: 0.4293, Top3Accuracy: 0.6560, Top5Accuracy: 0.7549, Time consumed:1.11s

Training Epoch: 47 [128/50000]	Loss: 1.8855	LR: 0.087625
Training Epoch: 47 [128/50000]	Loss: 2.1030	LR: 0.087625
Training Epoch: 47 [128/50000]	Loss: 2.2146	LR: 0.087625
Training Epoch: 47 [128/50000]	Loss: 1.9370	LR: 0.087625
Training Epoch: 47 [128/50000]	Loss: 2.0852	LR: 0.087625
Training Epoch: 47 [128/50000]	Loss: 1.8793	LR: 0.087625
Training Epoch: 47 [128/50000]	Loss: 1.9293	LR: 0.087625
Training Epoch: 47 [128/50000]	Loss: 1.6987	LR: 0.087625
Training Epoch: 47 [128/50000]	Loss: 1.8687	LR: 0.087625
Training Epoch: 47 [128/50000]	Loss: 2.0045	LR: 0.087625
Evaluating Network.....
Test set: Epoch: 47, Average loss: 0.0167, Top1Accuracy: 0.4360, Top3Accuracy: 0.6673, Top5Accuracy: 0.7577, Time consumed:1.14s

Training Epoch: 48 [128/50000]	Loss: 1.8618	LR: 0.085312
Training Epoch: 48 [128/50000]	Loss: 1.6308	LR: 0.085312
Training Epoch: 48 [128/50000]	Loss: 1.8101	LR: 0.085312
Training Epoch: 48 [128/50000]	Loss: 1.7459	LR: 0.085312
Training Epoch: 48 [128/50000]	Loss: 2.1479	LR: 0.085312
Training Epoch: 48 [128/50000]	Loss: 1.9322	LR: 0.085312
Training Epoch: 48 [128/50000]	Loss: 1.9617	LR: 0.085312
Training Epoch: 48 [128/50000]	Loss: 1.8727	LR: 0.085312
Training Epoch: 48 [128/50000]	Loss: 2.1245	LR: 0.085312
Training Epoch: 48 [128/50000]	Loss: 1.8517	LR: 0.085312
Evaluating Network.....
Test set: Epoch: 48, Average loss: 0.0170, Top1Accuracy: 0.4318, Top3Accuracy: 0.6539, Top5Accuracy: 0.7526, Time consumed:1.11s

Training Epoch: 49 [128/50000]	Loss: 1.7082	LR: 0.083059
Training Epoch: 49 [128/50000]	Loss: 1.9382	LR: 0.083059
Training Epoch: 49 [128/50000]	Loss: 1.8690	LR: 0.083059
Training Epoch: 49 [128/50000]	Loss: 1.8638	LR: 0.083059
Training Epoch: 49 [128/50000]	Loss: 1.9866	LR: 0.083059
Training Epoch: 49 [128/50000]	Loss: 2.0812	LR: 0.083059
Training Epoch: 49 [128/50000]	Loss: 2.0498	LR: 0.083059
Training Epoch: 49 [128/50000]	Loss: 1.7239	LR: 0.083059
Training Epoch: 49 [128/50000]	Loss: 2.0242	LR: 0.083059
Training Epoch: 49 [128/50000]	Loss: 1.7854	LR: 0.083059
Evaluating Network.....
Test set: Epoch: 49, Average loss: 0.0158, Top1Accuracy: 0.4541, Top3Accuracy: 0.6837, Top5Accuracy: 0.7724, Time consumed:1.11s

Training Epoch: 50 [128/50000]	Loss: 1.9362	LR: 0.080867
Training Epoch: 50 [128/50000]	Loss: 1.9748	LR: 0.080867
Training Epoch: 50 [128/50000]	Loss: 1.8705	LR: 0.080867
Training Epoch: 50 [128/50000]	Loss: 1.9000	LR: 0.080867
Training Epoch: 50 [128/50000]	Loss: 2.2712	LR: 0.080867
Training Epoch: 50 [128/50000]	Loss: 2.0584	LR: 0.080867
Training Epoch: 50 [128/50000]	Loss: 2.2095	LR: 0.080867
Training Epoch: 50 [128/50000]	Loss: 1.8845	LR: 0.080867
Training Epoch: 50 [128/50000]	Loss: 1.8641	LR: 0.080867
Training Epoch: 50 [128/50000]	Loss: 1.9209	LR: 0.080867
Evaluating Network.....
Test set: Epoch: 50, Average loss: 0.0162, Top1Accuracy: 0.4490, Top3Accuracy: 0.6718, Top5Accuracy: 0.7668, Time consumed:1.09s

Training Epoch: 51 [128/50000]	Loss: 2.0171	LR: 0.078732
Training Epoch: 51 [128/50000]	Loss: 1.9281	LR: 0.078732
Training Epoch: 51 [128/50000]	Loss: 1.6738	LR: 0.078732
Training Epoch: 51 [128/50000]	Loss: 1.9498	LR: 0.078732
Training Epoch: 51 [128/50000]	Loss: 1.5977	LR: 0.078732
Training Epoch: 51 [128/50000]	Loss: 1.8780	LR: 0.078732
Training Epoch: 51 [128/50000]	Loss: 1.5694	LR: 0.078732
Training Epoch: 51 [128/50000]	Loss: 1.7882	LR: 0.078732
Training Epoch: 51 [128/50000]	Loss: 1.8076	LR: 0.078732
Training Epoch: 51 [128/50000]	Loss: 1.7873	LR: 0.078732
Evaluating Network.....
Test set: Epoch: 51, Average loss: 0.0153, Top1Accuracy: 0.4717, Top3Accuracy: 0.6983, Top5Accuracy: 0.7873, Time consumed:1.10s

Training Epoch: 52 [128/50000]	Loss: 1.7932	LR: 0.076653
Training Epoch: 52 [128/50000]	Loss: 1.8530	LR: 0.076653
Training Epoch: 52 [128/50000]	Loss: 1.7780	LR: 0.076653
Training Epoch: 52 [128/50000]	Loss: 1.8656	LR: 0.076653
Training Epoch: 52 [128/50000]	Loss: 1.7111	LR: 0.076653
Training Epoch: 52 [128/50000]	Loss: 1.9028	LR: 0.076653
Training Epoch: 52 [128/50000]	Loss: 2.0660	LR: 0.076653
Training Epoch: 52 [128/50000]	Loss: 1.8340	LR: 0.076653
Training Epoch: 52 [128/50000]	Loss: 1.8377	LR: 0.076653
Training Epoch: 52 [128/50000]	Loss: 2.0246	LR: 0.076653
Evaluating Network.....
Test set: Epoch: 52, Average loss: 0.0153, Top1Accuracy: 0.4753, Top3Accuracy: 0.7003, Top5Accuracy: 0.7863, Time consumed:1.11s

Training Epoch: 53 [128/50000]	Loss: 1.9948	LR: 0.074630
Training Epoch: 53 [128/50000]	Loss: 1.7487	LR: 0.074630
Training Epoch: 53 [128/50000]	Loss: 1.8429	LR: 0.074630
Training Epoch: 53 [128/50000]	Loss: 1.8299	LR: 0.074630
Training Epoch: 53 [128/50000]	Loss: 1.7599	LR: 0.074630
Training Epoch: 53 [128/50000]	Loss: 1.8650	LR: 0.074630
Training Epoch: 53 [128/50000]	Loss: 2.0297	LR: 0.074630
Training Epoch: 53 [128/50000]	Loss: 1.8515	LR: 0.074630
Training Epoch: 53 [128/50000]	Loss: 1.9282	LR: 0.074630
Training Epoch: 53 [128/50000]	Loss: 1.8265	LR: 0.074630
Evaluating Network.....
Test set: Epoch: 53, Average loss: 0.0154, Top1Accuracy: 0.4697, Top3Accuracy: 0.6955, Top5Accuracy: 0.7825, Time consumed:1.10s

Training Epoch: 54 [128/50000]	Loss: 2.0508	LR: 0.072659
Training Epoch: 54 [128/50000]	Loss: 1.7648	LR: 0.072659
Training Epoch: 54 [128/50000]	Loss: 1.8821	LR: 0.072659
Training Epoch: 54 [128/50000]	Loss: 1.9650	LR: 0.072659
Training Epoch: 54 [128/50000]	Loss: 1.7632	LR: 0.072659
Training Epoch: 54 [128/50000]	Loss: 1.6603	LR: 0.072659
Training Epoch: 54 [128/50000]	Loss: 1.7140	LR: 0.072659
Training Epoch: 54 [128/50000]	Loss: 1.7393	LR: 0.072659
Training Epoch: 54 [128/50000]	Loss: 1.8761	LR: 0.072659
Training Epoch: 54 [128/50000]	Loss: 1.7482	LR: 0.072659
Evaluating Network.....
Test set: Epoch: 54, Average loss: 0.0149, Top1Accuracy: 0.4821, Top3Accuracy: 0.7097, Top5Accuracy: 0.7951, Time consumed:1.11s

Training Epoch: 55 [128/50000]	Loss: 1.9279	LR: 0.070741
Training Epoch: 55 [128/50000]	Loss: 2.0367	LR: 0.070741
Training Epoch: 55 [128/50000]	Loss: 1.8847	LR: 0.070741
Training Epoch: 55 [128/50000]	Loss: 1.9153	LR: 0.070741
Training Epoch: 55 [128/50000]	Loss: 1.7861	LR: 0.070741
Training Epoch: 55 [128/50000]	Loss: 2.0827	LR: 0.070741
Training Epoch: 55 [128/50000]	Loss: 1.7532	LR: 0.070741
Training Epoch: 55 [128/50000]	Loss: 1.8563	LR: 0.070741
Training Epoch: 55 [128/50000]	Loss: 1.6977	LR: 0.070741
Training Epoch: 55 [128/50000]	Loss: 1.7518	LR: 0.070741
Evaluating Network.....
Test set: Epoch: 55, Average loss: 0.0150, Top1Accuracy: 0.4792, Top3Accuracy: 0.7051, Top5Accuracy: 0.7929, Time consumed:1.11s

Training Epoch: 56 [128/50000]	Loss: 1.7262	LR: 0.068874
Training Epoch: 56 [128/50000]	Loss: 1.7866	LR: 0.068874
Training Epoch: 56 [128/50000]	Loss: 1.7872	LR: 0.068874
Training Epoch: 56 [128/50000]	Loss: 1.8086	LR: 0.068874
Training Epoch: 56 [128/50000]	Loss: 1.7173	LR: 0.068874
Training Epoch: 56 [128/50000]	Loss: 1.6323	LR: 0.068874
Training Epoch: 56 [128/50000]	Loss: 1.9272	LR: 0.068874
Training Epoch: 56 [128/50000]	Loss: 1.7025	LR: 0.068874
Training Epoch: 56 [128/50000]	Loss: 1.7711	LR: 0.068874
Training Epoch: 56 [128/50000]	Loss: 1.7136	LR: 0.068874
Evaluating Network.....
Test set: Epoch: 56, Average loss: 0.0144, Top1Accuracy: 0.4966, Top3Accuracy: 0.7262, Top5Accuracy: 0.8083, Time consumed:1.11s

Training Epoch: 57 [128/50000]	Loss: 1.6337	LR: 0.067055
Training Epoch: 57 [128/50000]	Loss: 1.9491	LR: 0.067055
Training Epoch: 57 [128/50000]	Loss: 1.7812	LR: 0.067055
Training Epoch: 57 [128/50000]	Loss: 1.7510	LR: 0.067055
Training Epoch: 57 [128/50000]	Loss: 1.6763	LR: 0.067055
Training Epoch: 57 [128/50000]	Loss: 1.7190	LR: 0.067055
Training Epoch: 57 [128/50000]	Loss: 1.7356	LR: 0.067055
Training Epoch: 57 [128/50000]	Loss: 1.7814	LR: 0.067055
Training Epoch: 57 [128/50000]	Loss: 1.5965	LR: 0.067055
Training Epoch: 57 [128/50000]	Loss: 1.8669	LR: 0.067055
Evaluating Network.....
Test set: Epoch: 57, Average loss: 0.0148, Top1Accuracy: 0.4895, Top3Accuracy: 0.7083, Top5Accuracy: 0.7977, Time consumed:1.10s

Training Epoch: 58 [128/50000]	Loss: 1.6413	LR: 0.065285
Training Epoch: 58 [128/50000]	Loss: 1.8764	LR: 0.065285
Training Epoch: 58 [128/50000]	Loss: 1.8628	LR: 0.065285
Training Epoch: 58 [128/50000]	Loss: 1.5891	LR: 0.065285
Training Epoch: 58 [128/50000]	Loss: 1.5652	LR: 0.065285
Training Epoch: 58 [128/50000]	Loss: 1.6679	LR: 0.065285
Training Epoch: 58 [128/50000]	Loss: 1.5949	LR: 0.065285
Training Epoch: 58 [128/50000]	Loss: 1.8354	LR: 0.065285
Training Epoch: 58 [128/50000]	Loss: 1.6177	LR: 0.065285
Training Epoch: 58 [128/50000]	Loss: 1.6823	LR: 0.065285
Evaluating Network.....
Test set: Epoch: 58, Average loss: 0.0147, Top1Accuracy: 0.4938, Top3Accuracy: 0.7125, Top5Accuracy: 0.8004, Time consumed:1.11s

Training Epoch: 59 [128/50000]	Loss: 1.5936	LR: 0.063561
Training Epoch: 59 [128/50000]	Loss: 1.8044	LR: 0.063561
Training Epoch: 59 [128/50000]	Loss: 1.5690	LR: 0.063561
Training Epoch: 59 [128/50000]	Loss: 1.6772	LR: 0.063561
Training Epoch: 59 [128/50000]	Loss: 1.8321	LR: 0.063561
Training Epoch: 59 [128/50000]	Loss: 2.1303	LR: 0.063561
Training Epoch: 59 [128/50000]	Loss: 1.9412	LR: 0.063561
Training Epoch: 59 [128/50000]	Loss: 1.6632	LR: 0.063561
Training Epoch: 59 [128/50000]	Loss: 1.7028	LR: 0.063561
Training Epoch: 59 [128/50000]	Loss: 1.7035	LR: 0.063561
Evaluating Network.....
Test set: Epoch: 59, Average loss: 0.0148, Top1Accuracy: 0.4899, Top3Accuracy: 0.7135, Top5Accuracy: 0.7973, Time consumed:1.10s

Training Epoch: 60 [128/50000]	Loss: 1.8584	LR: 0.061883
Training Epoch: 60 [128/50000]	Loss: 1.7859	LR: 0.061883
Training Epoch: 60 [128/50000]	Loss: 1.8432	LR: 0.061883
Training Epoch: 60 [128/50000]	Loss: 1.6728	LR: 0.061883
Training Epoch: 60 [128/50000]	Loss: 1.6439	LR: 0.061883
Training Epoch: 60 [128/50000]	Loss: 1.7872	LR: 0.061883
Training Epoch: 60 [128/50000]	Loss: 1.7558	LR: 0.061883
Training Epoch: 60 [128/50000]	Loss: 1.8290	LR: 0.061883
Training Epoch: 60 [128/50000]	Loss: 1.5722	LR: 0.061883
Training Epoch: 60 [128/50000]	Loss: 1.5364	LR: 0.061883
Evaluating Network.....
Test set: Epoch: 60, Average loss: 0.0147, Top1Accuracy: 0.4959, Top3Accuracy: 0.7140, Top5Accuracy: 0.8000, Time consumed:1.11s

Training Epoch: 61 [128/50000]	Loss: 1.5714	LR: 0.060250
Training Epoch: 61 [128/50000]	Loss: 1.6042	LR: 0.060250
Training Epoch: 61 [128/50000]	Loss: 1.7045	LR: 0.060250
Training Epoch: 61 [128/50000]	Loss: 1.5557	LR: 0.060250
Training Epoch: 61 [128/50000]	Loss: 1.5874	LR: 0.060250
Training Epoch: 61 [128/50000]	Loss: 1.5517	LR: 0.060250
Training Epoch: 61 [128/50000]	Loss: 1.6669	LR: 0.060250
Training Epoch: 61 [128/50000]	Loss: 1.6997	LR: 0.060250
Training Epoch: 61 [128/50000]	Loss: 1.7673	LR: 0.060250
Training Epoch: 61 [128/50000]	Loss: 1.8324	LR: 0.060250
Evaluating Network.....
Test set: Epoch: 61, Average loss: 0.0143, Top1Accuracy: 0.5020, Top3Accuracy: 0.7271, Top5Accuracy: 0.8111, Time consumed:1.10s

Training Epoch: 62 [128/50000]	Loss: 1.6698	LR: 0.058659
Training Epoch: 62 [128/50000]	Loss: 1.7477	LR: 0.058659
Training Epoch: 62 [128/50000]	Loss: 1.5361	LR: 0.058659
Training Epoch: 62 [128/50000]	Loss: 1.6100	LR: 0.058659
Training Epoch: 62 [128/50000]	Loss: 1.6322	LR: 0.058659
Training Epoch: 62 [128/50000]	Loss: 1.7251	LR: 0.058659
Training Epoch: 62 [128/50000]	Loss: 1.8188	LR: 0.058659
Training Epoch: 62 [128/50000]	Loss: 1.7815	LR: 0.058659
Training Epoch: 62 [128/50000]	Loss: 1.7520	LR: 0.058659
Training Epoch: 62 [128/50000]	Loss: 1.5491	LR: 0.058659
Evaluating Network.....
Test set: Epoch: 62, Average loss: 0.0145, Top1Accuracy: 0.4956, Top3Accuracy: 0.7211, Top5Accuracy: 0.8066, Time consumed:1.11s

Training Epoch: 63 [128/50000]	Loss: 1.9107	LR: 0.057111
Training Epoch: 63 [128/50000]	Loss: 1.6150	LR: 0.057111
Training Epoch: 63 [128/50000]	Loss: 1.5494	LR: 0.057111
Training Epoch: 63 [128/50000]	Loss: 1.5132	LR: 0.057111
Training Epoch: 63 [128/50000]	Loss: 1.9290	LR: 0.057111
Training Epoch: 63 [128/50000]	Loss: 1.5782	LR: 0.057111
Training Epoch: 63 [128/50000]	Loss: 1.6404	LR: 0.057111
Training Epoch: 63 [128/50000]	Loss: 1.6957	LR: 0.057111
Training Epoch: 63 [128/50000]	Loss: 1.6354	LR: 0.057111
Training Epoch: 63 [128/50000]	Loss: 1.7116	LR: 0.057111
Evaluating Network.....
Test set: Epoch: 63, Average loss: 0.0143, Top1Accuracy: 0.5069, Top3Accuracy: 0.7325, Top5Accuracy: 0.8143, Time consumed:1.12s

Training Epoch: 64 [128/50000]	Loss: 1.5655	LR: 0.055603
Training Epoch: 64 [128/50000]	Loss: 1.4270	LR: 0.055603
Training Epoch: 64 [128/50000]	Loss: 1.6781	LR: 0.055603
Training Epoch: 64 [128/50000]	Loss: 1.8603	LR: 0.055603
Training Epoch: 64 [128/50000]	Loss: 1.4817	LR: 0.055603
Training Epoch: 64 [128/50000]	Loss: 1.5964	LR: 0.055603
Training Epoch: 64 [128/50000]	Loss: 1.7777	LR: 0.055603
Training Epoch: 64 [128/50000]	Loss: 1.4639	LR: 0.055603
Training Epoch: 64 [128/50000]	Loss: 1.7892	LR: 0.055603
Training Epoch: 64 [128/50000]	Loss: 1.7011	LR: 0.055603
Evaluating Network.....
Test set: Epoch: 64, Average loss: 0.0145, Top1Accuracy: 0.5021, Top3Accuracy: 0.7302, Top5Accuracy: 0.8087, Time consumed:1.11s

Training Epoch: 65 [128/50000]	Loss: 1.5344	LR: 0.054135
Training Epoch: 65 [128/50000]	Loss: 1.7031	LR: 0.054135
Training Epoch: 65 [128/50000]	Loss: 1.4938	LR: 0.054135
Training Epoch: 65 [128/50000]	Loss: 1.4303	LR: 0.054135
Training Epoch: 65 [128/50000]	Loss: 1.5175	LR: 0.054135
Training Epoch: 65 [128/50000]	Loss: 1.5867	LR: 0.054135
Training Epoch: 65 [128/50000]	Loss: 1.7291	LR: 0.054135
Training Epoch: 65 [128/50000]	Loss: 1.5459	LR: 0.054135
Training Epoch: 65 [128/50000]	Loss: 1.6552	LR: 0.054135
Training Epoch: 65 [128/50000]	Loss: 1.7433	LR: 0.054135
Evaluating Network.....
Test set: Epoch: 65, Average loss: 0.0141, Top1Accuracy: 0.5115, Top3Accuracy: 0.7300, Top5Accuracy: 0.8121, Time consumed:1.12s

Training Epoch: 66 [128/50000]	Loss: 1.7191	LR: 0.052706
Training Epoch: 66 [128/50000]	Loss: 1.7344	LR: 0.052706
Training Epoch: 66 [128/50000]	Loss: 1.6848	LR: 0.052706
Training Epoch: 66 [128/50000]	Loss: 1.6790	LR: 0.052706
Training Epoch: 66 [128/50000]	Loss: 1.8077	LR: 0.052706
Training Epoch: 66 [128/50000]	Loss: 1.5906	LR: 0.052706
Training Epoch: 66 [128/50000]	Loss: 1.6720	LR: 0.052706
Training Epoch: 66 [128/50000]	Loss: 1.4906	LR: 0.052706
Training Epoch: 66 [128/50000]	Loss: 1.5561	LR: 0.052706
Training Epoch: 66 [128/50000]	Loss: 1.5500	LR: 0.052706
Evaluating Network.....
Test set: Epoch: 66, Average loss: 0.0137, Top1Accuracy: 0.5189, Top3Accuracy: 0.7397, Top5Accuracy: 0.8240, Time consumed:1.12s

Training Epoch: 67 [128/50000]	Loss: 1.6651	LR: 0.051314
Training Epoch: 67 [128/50000]	Loss: 1.7981	LR: 0.051314
Training Epoch: 67 [128/50000]	Loss: 1.5507	LR: 0.051314
Training Epoch: 67 [128/50000]	Loss: 1.4448	LR: 0.051314
Training Epoch: 67 [128/50000]	Loss: 1.7796	LR: 0.051314
Training Epoch: 67 [128/50000]	Loss: 1.6014	LR: 0.051314
Training Epoch: 67 [128/50000]	Loss: 1.4715	LR: 0.051314
Training Epoch: 67 [128/50000]	Loss: 1.4508	LR: 0.051314
Training Epoch: 67 [128/50000]	Loss: 1.7497	LR: 0.051314
Training Epoch: 67 [128/50000]	Loss: 1.5865	LR: 0.051314
Evaluating Network.....
Test set: Epoch: 67, Average loss: 0.0136, Top1Accuracy: 0.5247, Top3Accuracy: 0.7409, Top5Accuracy: 0.8197, Time consumed:1.11s

Training Epoch: 68 [128/50000]	Loss: 1.6064	LR: 0.049960
Training Epoch: 68 [128/50000]	Loss: 1.6679	LR: 0.049960
Training Epoch: 68 [128/50000]	Loss: 1.7055	LR: 0.049960
Training Epoch: 68 [128/50000]	Loss: 1.6128	LR: 0.049960
Training Epoch: 68 [128/50000]	Loss: 1.6416	LR: 0.049960
Training Epoch: 68 [128/50000]	Loss: 1.5712	LR: 0.049960
Training Epoch: 68 [128/50000]	Loss: 1.7459	LR: 0.049960
Training Epoch: 68 [128/50000]	Loss: 1.4615	LR: 0.049960
Training Epoch: 68 [128/50000]	Loss: 1.6174	LR: 0.049960
Training Epoch: 68 [128/50000]	Loss: 1.5173	LR: 0.049960
Evaluating Network.....
Test set: Epoch: 68, Average loss: 0.0134, Top1Accuracy: 0.5356, Top3Accuracy: 0.7521, Top5Accuracy: 0.8280, Time consumed:1.22s

Training Epoch: 69 [128/50000]	Loss: 1.6337	LR: 0.048641
Training Epoch: 69 [128/50000]	Loss: 1.3165	LR: 0.048641
Training Epoch: 69 [128/50000]	Loss: 1.4096	LR: 0.048641
Training Epoch: 69 [128/50000]	Loss: 1.7370	LR: 0.048641
Training Epoch: 69 [128/50000]	Loss: 1.7583	LR: 0.048641
Training Epoch: 69 [128/50000]	Loss: 1.6178	LR: 0.048641
Training Epoch: 69 [128/50000]	Loss: 1.6557	LR: 0.048641
Training Epoch: 69 [128/50000]	Loss: 1.5402	LR: 0.048641
Training Epoch: 69 [128/50000]	Loss: 1.7593	LR: 0.048641
Training Epoch: 69 [128/50000]	Loss: 1.4216	LR: 0.048641
Evaluating Network.....
Test set: Epoch: 69, Average loss: 0.0132, Top1Accuracy: 0.5372, Top3Accuracy: 0.7512, Top5Accuracy: 0.8307, Time consumed:1.10s

Training Epoch: 70 [128/50000]	Loss: 1.6568	LR: 0.047357
Training Epoch: 70 [128/50000]	Loss: 1.4803	LR: 0.047357
Training Epoch: 70 [128/50000]	Loss: 1.4250	LR: 0.047357
Training Epoch: 70 [128/50000]	Loss: 1.6026	LR: 0.047357
Training Epoch: 70 [128/50000]	Loss: 1.4302	LR: 0.047357
Training Epoch: 70 [128/50000]	Loss: 1.4611	LR: 0.047357
Training Epoch: 70 [128/50000]	Loss: 1.6070	LR: 0.047357
Training Epoch: 70 [128/50000]	Loss: 1.6841	LR: 0.047357
Training Epoch: 70 [128/50000]	Loss: 1.6263	LR: 0.047357
Training Epoch: 70 [128/50000]	Loss: 1.6921	LR: 0.047357
Evaluating Network.....
Test set: Epoch: 70, Average loss: 0.0135, Top1Accuracy: 0.5319, Top3Accuracy: 0.7514, Top5Accuracy: 0.8287, Time consumed:1.10s

Training Epoch: 71 [128/50000]	Loss: 1.5801	LR: 0.046106
Training Epoch: 71 [128/50000]	Loss: 1.5962	LR: 0.046106
Training Epoch: 71 [128/50000]	Loss: 1.5153	LR: 0.046106
Training Epoch: 71 [128/50000]	Loss: 1.5025	LR: 0.046106
Training Epoch: 71 [128/50000]	Loss: 1.5263	LR: 0.046106
Training Epoch: 71 [128/50000]	Loss: 1.7617	LR: 0.046106
Training Epoch: 71 [128/50000]	Loss: 1.7128	LR: 0.046106
Training Epoch: 71 [128/50000]	Loss: 1.4813	LR: 0.046106
Training Epoch: 71 [128/50000]	Loss: 1.5048	LR: 0.046106
Training Epoch: 71 [128/50000]	Loss: 1.7146	LR: 0.046106
Evaluating Network.....
Test set: Epoch: 71, Average loss: 0.0138, Top1Accuracy: 0.5175, Top3Accuracy: 0.7409, Top5Accuracy: 0.8230, Time consumed:1.11s

Training Epoch: 72 [128/50000]	Loss: 1.4091	LR: 0.044889
Training Epoch: 72 [128/50000]	Loss: 1.2043	LR: 0.044889
Training Epoch: 72 [128/50000]	Loss: 1.7755	LR: 0.044889
Training Epoch: 72 [128/50000]	Loss: 1.7599	LR: 0.044889
Training Epoch: 72 [128/50000]	Loss: 1.4909	LR: 0.044889
Training Epoch: 72 [128/50000]	Loss: 1.3445	LR: 0.044889
Training Epoch: 72 [128/50000]	Loss: 1.3608	LR: 0.044889
Training Epoch: 72 [128/50000]	Loss: 1.5700	LR: 0.044889
Training Epoch: 72 [128/50000]	Loss: 1.6684	LR: 0.044889
Training Epoch: 72 [128/50000]	Loss: 1.5363	LR: 0.044889
Evaluating Network.....
Test set: Epoch: 72, Average loss: 0.0135, Top1Accuracy: 0.5296, Top3Accuracy: 0.7532, Top5Accuracy: 0.8300, Time consumed:1.12s

Training Epoch: 73 [128/50000]	Loss: 1.4742	LR: 0.043704
Training Epoch: 73 [128/50000]	Loss: 1.3842	LR: 0.043704
Training Epoch: 73 [128/50000]	Loss: 1.4718	LR: 0.043704
Training Epoch: 73 [128/50000]	Loss: 1.2993	LR: 0.043704
Training Epoch: 73 [128/50000]	Loss: 1.3809	LR: 0.043704
Training Epoch: 73 [128/50000]	Loss: 1.4644	LR: 0.043704
Training Epoch: 73 [128/50000]	Loss: 1.3313	LR: 0.043704
Training Epoch: 73 [128/50000]	Loss: 1.6821	LR: 0.043704
Training Epoch: 73 [128/50000]	Loss: 1.5298	LR: 0.043704
Training Epoch: 73 [128/50000]	Loss: 1.5343	LR: 0.043704
Evaluating Network.....
Test set: Epoch: 73, Average loss: 0.0131, Top1Accuracy: 0.5448, Top3Accuracy: 0.7589, Top5Accuracy: 0.8340, Time consumed:1.11s

Training Epoch: 74 [128/50000]	Loss: 1.4540	LR: 0.042550
Training Epoch: 74 [128/50000]	Loss: 1.3163	LR: 0.042550
Training Epoch: 74 [128/50000]	Loss: 1.2641	LR: 0.042550
Training Epoch: 74 [128/50000]	Loss: 1.6352	LR: 0.042550
Training Epoch: 74 [128/50000]	Loss: 1.5011	LR: 0.042550
Training Epoch: 74 [128/50000]	Loss: 1.4120	LR: 0.042550
Training Epoch: 74 [128/50000]	Loss: 1.4100	LR: 0.042550
Training Epoch: 74 [128/50000]	Loss: 1.4756	LR: 0.042550
Training Epoch: 74 [128/50000]	Loss: 1.7923	LR: 0.042550
Training Epoch: 74 [128/50000]	Loss: 1.5468	LR: 0.042550
Evaluating Network.....
Test set: Epoch: 74, Average loss: 0.0129, Top1Accuracy: 0.5501, Top3Accuracy: 0.7655, Top5Accuracy: 0.8383, Time consumed:1.10s

Training Epoch: 75 [128/50000]	Loss: 1.5443	LR: 0.041427
Training Epoch: 75 [128/50000]	Loss: 1.2776	LR: 0.041427
Training Epoch: 75 [128/50000]	Loss: 1.5859	LR: 0.041427
Training Epoch: 75 [128/50000]	Loss: 1.2935	LR: 0.041427
Training Epoch: 75 [128/50000]	Loss: 1.5157	LR: 0.041427
Training Epoch: 75 [128/50000]	Loss: 1.8738	LR: 0.041427
Training Epoch: 75 [128/50000]	Loss: 1.4647	LR: 0.041427
Training Epoch: 75 [128/50000]	Loss: 1.7283	LR: 0.041427
Training Epoch: 75 [128/50000]	Loss: 1.5194	LR: 0.041427
Training Epoch: 75 [128/50000]	Loss: 1.4511	LR: 0.041427
Evaluating Network.....
Test set: Epoch: 75, Average loss: 0.0132, Top1Accuracy: 0.5415, Top3Accuracy: 0.7563, Top5Accuracy: 0.8364, Time consumed:1.13s

Training Epoch: 76 [128/50000]	Loss: 1.4374	LR: 0.040333
Training Epoch: 76 [128/50000]	Loss: 1.3069	LR: 0.040333
Training Epoch: 76 [128/50000]	Loss: 1.3206	LR: 0.040333
Training Epoch: 76 [128/50000]	Loss: 1.4971	LR: 0.040333
Training Epoch: 76 [128/50000]	Loss: 1.7213	LR: 0.040333
Training Epoch: 76 [128/50000]	Loss: 1.5163	LR: 0.040333
Training Epoch: 76 [128/50000]	Loss: 1.4969	LR: 0.040333
Training Epoch: 76 [128/50000]	Loss: 1.5333	LR: 0.040333
Training Epoch: 76 [128/50000]	Loss: 1.4660	LR: 0.040333
Training Epoch: 76 [128/50000]	Loss: 1.5440	LR: 0.040333
Evaluating Network.....
Test set: Epoch: 76, Average loss: 0.0126, Top1Accuracy: 0.5594, Top3Accuracy: 0.7738, Top5Accuracy: 0.8445, Time consumed:1.11s

Training Epoch: 77 [128/50000]	Loss: 1.2797	LR: 0.039268
Training Epoch: 77 [128/50000]	Loss: 1.6983	LR: 0.039268
Training Epoch: 77 [128/50000]	Loss: 1.3708	LR: 0.039268
Training Epoch: 77 [128/50000]	Loss: 1.4443	LR: 0.039268
Training Epoch: 77 [128/50000]	Loss: 1.4912	LR: 0.039268
Training Epoch: 77 [128/50000]	Loss: 1.7937	LR: 0.039268
Training Epoch: 77 [128/50000]	Loss: 1.6743	LR: 0.039268
Training Epoch: 77 [128/50000]	Loss: 1.3672	LR: 0.039268
Training Epoch: 77 [128/50000]	Loss: 1.4125	LR: 0.039268
Training Epoch: 77 [128/50000]	Loss: 1.2942	LR: 0.039268
Evaluating Network.....
Test set: Epoch: 77, Average loss: 0.0130, Top1Accuracy: 0.5516, Top3Accuracy: 0.7629, Top5Accuracy: 0.8386, Time consumed:1.10s

Training Epoch: 78 [128/50000]	Loss: 1.3321	LR: 0.038232
Training Epoch: 78 [128/50000]	Loss: 1.3032	LR: 0.038232
Training Epoch: 78 [128/50000]	Loss: 1.4739	LR: 0.038232
Training Epoch: 78 [128/50000]	Loss: 1.5409	LR: 0.038232
Training Epoch: 78 [128/50000]	Loss: 1.2218	LR: 0.038232
Training Epoch: 78 [128/50000]	Loss: 1.3736	LR: 0.038232
Training Epoch: 78 [128/50000]	Loss: 1.3870	LR: 0.038232
Training Epoch: 78 [128/50000]	Loss: 1.4630	LR: 0.038232
Training Epoch: 78 [128/50000]	Loss: 1.6526	LR: 0.038232
Training Epoch: 78 [128/50000]	Loss: 1.4743	LR: 0.038232
Evaluating Network.....
Test set: Epoch: 78, Average loss: 0.0128, Top1Accuracy: 0.5531, Top3Accuracy: 0.7699, Top5Accuracy: 0.8444, Time consumed:1.11s

Training Epoch: 79 [128/50000]	Loss: 1.6388	LR: 0.037222
Training Epoch: 79 [128/50000]	Loss: 1.4108	LR: 0.037222
Training Epoch: 79 [128/50000]	Loss: 1.3363	LR: 0.037222
Training Epoch: 79 [128/50000]	Loss: 1.5563	LR: 0.037222
Training Epoch: 79 [128/50000]	Loss: 1.2952	LR: 0.037222
Training Epoch: 79 [128/50000]	Loss: 1.5120	LR: 0.037222
Training Epoch: 79 [128/50000]	Loss: 1.5703	LR: 0.037222
Training Epoch: 79 [128/50000]	Loss: 1.4648	LR: 0.037222
Training Epoch: 79 [128/50000]	Loss: 1.6431	LR: 0.037222
Training Epoch: 79 [128/50000]	Loss: 1.7110	LR: 0.037222
Evaluating Network.....
Test set: Epoch: 79, Average loss: 0.0129, Top1Accuracy: 0.5543, Top3Accuracy: 0.7637, Top5Accuracy: 0.8346, Time consumed:1.11s

Training Epoch: 80 [128/50000]	Loss: 1.3919	LR: 0.036240
Training Epoch: 80 [128/50000]	Loss: 1.5401	LR: 0.036240
Training Epoch: 80 [128/50000]	Loss: 1.6870	LR: 0.036240
Training Epoch: 80 [128/50000]	Loss: 1.1744	LR: 0.036240
Training Epoch: 80 [128/50000]	Loss: 1.3834	LR: 0.036240
Training Epoch: 80 [128/50000]	Loss: 1.5138	LR: 0.036240
Training Epoch: 80 [128/50000]	Loss: 1.3657	LR: 0.036240
Training Epoch: 80 [128/50000]	Loss: 1.5186	LR: 0.036240
Training Epoch: 80 [128/50000]	Loss: 1.5006	LR: 0.036240
Training Epoch: 80 [128/50000]	Loss: 1.3348	LR: 0.036240
Evaluating Network.....
Test set: Epoch: 80, Average loss: 0.0126, Top1Accuracy: 0.5598, Top3Accuracy: 0.7726, Top5Accuracy: 0.8442, Time consumed:1.11s

Training Epoch: 81 [128/50000]	Loss: 1.4916	LR: 0.035283
Training Epoch: 81 [128/50000]	Loss: 1.4347	LR: 0.035283
Training Epoch: 81 [128/50000]	Loss: 1.4041	LR: 0.035283
Training Epoch: 81 [128/50000]	Loss: 1.2200	LR: 0.035283
Training Epoch: 81 [128/50000]	Loss: 1.3248	LR: 0.035283
Training Epoch: 81 [128/50000]	Loss: 1.4348	LR: 0.035283
Training Epoch: 81 [128/50000]	Loss: 1.3596	LR: 0.035283
Training Epoch: 81 [128/50000]	Loss: 1.3045	LR: 0.035283
Training Epoch: 81 [128/50000]	Loss: 1.3716	LR: 0.035283
Training Epoch: 81 [128/50000]	Loss: 1.3391	LR: 0.035283
Evaluating Network.....
Test set: Epoch: 81, Average loss: 0.0126, Top1Accuracy: 0.5591, Top3Accuracy: 0.7723, Top5Accuracy: 0.8405, Time consumed:1.11s

Training Epoch: 82 [128/50000]	Loss: 1.3812	LR: 0.034352
Training Epoch: 82 [128/50000]	Loss: 1.2669	LR: 0.034352
Training Epoch: 82 [128/50000]	Loss: 1.3459	LR: 0.034352
Training Epoch: 82 [128/50000]	Loss: 1.4727	LR: 0.034352
Training Epoch: 82 [128/50000]	Loss: 1.2774	LR: 0.034352
Training Epoch: 82 [128/50000]	Loss: 1.4931	LR: 0.034352
Training Epoch: 82 [128/50000]	Loss: 1.5753	LR: 0.034352
Training Epoch: 82 [128/50000]	Loss: 1.4293	LR: 0.034352
Training Epoch: 82 [128/50000]	Loss: 1.3672	LR: 0.034352
Training Epoch: 82 [128/50000]	Loss: 1.3906	LR: 0.034352
Evaluating Network.....
Test set: Epoch: 82, Average loss: 0.0125, Top1Accuracy: 0.5646, Top3Accuracy: 0.7738, Top5Accuracy: 0.8463, Time consumed:1.11s

Training Epoch: 83 [128/50000]	Loss: 1.3803	LR: 0.033445
Training Epoch: 83 [128/50000]	Loss: 1.4680	LR: 0.033445
Training Epoch: 83 [128/50000]	Loss: 1.4423	LR: 0.033445
Training Epoch: 83 [128/50000]	Loss: 1.4607	LR: 0.033445
Training Epoch: 83 [128/50000]	Loss: 1.5986	LR: 0.033445
Training Epoch: 83 [128/50000]	Loss: 1.4898	LR: 0.033445
Training Epoch: 83 [128/50000]	Loss: 1.2995	LR: 0.033445
Training Epoch: 83 [128/50000]	Loss: 1.5039	LR: 0.033445
Training Epoch: 83 [128/50000]	Loss: 1.3370	LR: 0.033445
Training Epoch: 83 [128/50000]	Loss: 1.5192	LR: 0.033445
Evaluating Network.....
Test set: Epoch: 83, Average loss: 0.0127, Top1Accuracy: 0.5595, Top3Accuracy: 0.7729, Top5Accuracy: 0.8456, Time consumed:1.08s

Training Epoch: 84 [128/50000]	Loss: 1.3251	LR: 0.032562
Training Epoch: 84 [128/50000]	Loss: 1.4810	LR: 0.032562
Training Epoch: 84 [128/50000]	Loss: 1.3911	LR: 0.032562
Training Epoch: 84 [128/50000]	Loss: 1.2507	LR: 0.032562
Training Epoch: 84 [128/50000]	Loss: 1.4868	LR: 0.032562
Training Epoch: 84 [128/50000]	Loss: 1.2875	LR: 0.032562
Training Epoch: 84 [128/50000]	Loss: 1.3805	LR: 0.032562
Training Epoch: 84 [128/50000]	Loss: 1.4302	LR: 0.032562
Training Epoch: 84 [128/50000]	Loss: 1.2990	LR: 0.032562
Training Epoch: 84 [128/50000]	Loss: 1.4034	LR: 0.032562
Evaluating Network.....
Test set: Epoch: 84, Average loss: 0.0124, Top1Accuracy: 0.5652, Top3Accuracy: 0.7748, Top5Accuracy: 0.8468, Time consumed:1.10s

Training Epoch: 85 [128/50000]	Loss: 1.2456	LR: 0.031702
Training Epoch: 85 [128/50000]	Loss: 1.5639	LR: 0.031702
Training Epoch: 85 [128/50000]	Loss: 1.2701	LR: 0.031702
Training Epoch: 85 [128/50000]	Loss: 1.4587	LR: 0.031702
Training Epoch: 85 [128/50000]	Loss: 1.3117	LR: 0.031702
Training Epoch: 85 [128/50000]	Loss: 1.4116	LR: 0.031702
Training Epoch: 85 [128/50000]	Loss: 1.3548	LR: 0.031702
Training Epoch: 85 [128/50000]	Loss: 1.5569	LR: 0.031702
Training Epoch: 85 [128/50000]	Loss: 1.3136	LR: 0.031702
Training Epoch: 85 [128/50000]	Loss: 1.2539	LR: 0.031702
Evaluating Network.....
Test set: Epoch: 85, Average loss: 0.0125, Top1Accuracy: 0.5636, Top3Accuracy: 0.7761, Top5Accuracy: 0.8482, Time consumed:1.10s

Training Epoch: 86 [128/50000]	Loss: 1.3047	LR: 0.030865
Training Epoch: 86 [128/50000]	Loss: 1.3054	LR: 0.030865
Training Epoch: 86 [128/50000]	Loss: 1.3031	LR: 0.030865
Training Epoch: 86 [128/50000]	Loss: 1.4019	LR: 0.030865
Training Epoch: 86 [128/50000]	Loss: 1.3950	LR: 0.030865
Training Epoch: 86 [128/50000]	Loss: 1.2579	LR: 0.030865
Training Epoch: 86 [128/50000]	Loss: 1.3694	LR: 0.030865
Training Epoch: 86 [128/50000]	Loss: 1.3220	LR: 0.030865
Training Epoch: 86 [128/50000]	Loss: 1.5010	LR: 0.030865
Training Epoch: 86 [128/50000]	Loss: 1.2668	LR: 0.030865
Evaluating Network.....
Test set: Epoch: 86, Average loss: 0.0124, Top1Accuracy: 0.5683, Top3Accuracy: 0.7816, Top5Accuracy: 0.8507, Time consumed:1.10s

Training Epoch: 87 [128/50000]	Loss: 1.1608	LR: 0.030050
Training Epoch: 87 [128/50000]	Loss: 1.1978	LR: 0.030050
Training Epoch: 87 [128/50000]	Loss: 1.4237	LR: 0.030050
Training Epoch: 87 [128/50000]	Loss: 1.2604	LR: 0.030050
Training Epoch: 87 [128/50000]	Loss: 1.2163	LR: 0.030050
Training Epoch: 87 [128/50000]	Loss: 1.2149	LR: 0.030050
Training Epoch: 87 [128/50000]	Loss: 1.3427	LR: 0.030050
Training Epoch: 87 [128/50000]	Loss: 1.3122	LR: 0.030050
Training Epoch: 87 [128/50000]	Loss: 1.2991	LR: 0.030050
Training Epoch: 87 [128/50000]	Loss: 1.4449	LR: 0.030050
Evaluating Network.....
Test set: Epoch: 87, Average loss: 0.0120, Top1Accuracy: 0.5798, Top3Accuracy: 0.7895, Top5Accuracy: 0.8567, Time consumed:1.10s

Training Epoch: 88 [128/50000]	Loss: 1.4107	LR: 0.029257
Training Epoch: 88 [128/50000]	Loss: 1.3284	LR: 0.029257
Training Epoch: 88 [128/50000]	Loss: 1.3679	LR: 0.029257
Training Epoch: 88 [128/50000]	Loss: 1.5256	LR: 0.029257
Training Epoch: 88 [128/50000]	Loss: 1.2291	LR: 0.029257
Training Epoch: 88 [128/50000]	Loss: 1.2387	LR: 0.029257
Training Epoch: 88 [128/50000]	Loss: 1.4682	LR: 0.029257
Training Epoch: 88 [128/50000]	Loss: 1.2027	LR: 0.029257
Training Epoch: 88 [128/50000]	Loss: 1.2386	LR: 0.029257
Training Epoch: 88 [128/50000]	Loss: 1.3776	LR: 0.029257
Evaluating Network.....
Test set: Epoch: 88, Average loss: 0.0122, Top1Accuracy: 0.5788, Top3Accuracy: 0.7828, Top5Accuracy: 0.8525, Time consumed:1.10s

Training Epoch: 89 [128/50000]	Loss: 1.3576	LR: 0.028485
Training Epoch: 89 [128/50000]	Loss: 1.3021	LR: 0.028485
Training Epoch: 89 [128/50000]	Loss: 1.4002	LR: 0.028485
Training Epoch: 89 [128/50000]	Loss: 1.8291	LR: 0.028485
Training Epoch: 89 [128/50000]	Loss: 1.3287	LR: 0.028485
Training Epoch: 89 [128/50000]	Loss: 1.4386	LR: 0.028485
Training Epoch: 89 [128/50000]	Loss: 1.3298	LR: 0.028485
Training Epoch: 89 [128/50000]	Loss: 1.2922	LR: 0.028485
Training Epoch: 89 [128/50000]	Loss: 1.4502	LR: 0.028485
Training Epoch: 89 [128/50000]	Loss: 1.2841	LR: 0.028485
Evaluating Network.....
Test set: Epoch: 89, Average loss: 0.0120, Top1Accuracy: 0.5797, Top3Accuracy: 0.7891, Top5Accuracy: 0.8574, Time consumed:1.10s

Training Epoch: 90 [128/50000]	Loss: 1.0975	LR: 0.027733
Training Epoch: 90 [128/50000]	Loss: 1.5849	LR: 0.027733
Training Epoch: 90 [128/50000]	Loss: 1.4873	LR: 0.027733
Training Epoch: 90 [128/50000]	Loss: 1.2689	LR: 0.027733
Training Epoch: 90 [128/50000]	Loss: 1.4250	LR: 0.027733
Training Epoch: 90 [128/50000]	Loss: 1.3772	LR: 0.027733
Training Epoch: 90 [128/50000]	Loss: 1.2960	LR: 0.027733
Training Epoch: 90 [128/50000]	Loss: 1.2071	LR: 0.027733
Training Epoch: 90 [128/50000]	Loss: 1.6049	LR: 0.027733
Training Epoch: 90 [128/50000]	Loss: 1.4037	LR: 0.027733
Evaluating Network.....
Test set: Epoch: 90, Average loss: 0.0122, Top1Accuracy: 0.5739, Top3Accuracy: 0.7841, Top5Accuracy: 0.8538, Time consumed:1.12s

Training Epoch: 91 [128/50000]	Loss: 1.3496	LR: 0.027001
Training Epoch: 91 [128/50000]	Loss: 1.3816	LR: 0.027001
Training Epoch: 91 [128/50000]	Loss: 1.3922	LR: 0.027001
Training Epoch: 91 [128/50000]	Loss: 1.6571	LR: 0.027001
Training Epoch: 91 [128/50000]	Loss: 1.4970	LR: 0.027001
Training Epoch: 91 [128/50000]	Loss: 1.5393	LR: 0.027001
Training Epoch: 91 [128/50000]	Loss: 1.3417	LR: 0.027001
Training Epoch: 91 [128/50000]	Loss: 1.3080	LR: 0.027001
Training Epoch: 91 [128/50000]	Loss: 1.3851	LR: 0.027001
Training Epoch: 91 [128/50000]	Loss: 1.5256	LR: 0.027001
Evaluating Network.....
Test set: Epoch: 91, Average loss: 0.0121, Top1Accuracy: 0.5781, Top3Accuracy: 0.7825, Top5Accuracy: 0.8530, Time consumed:1.12s

Training Epoch: 92 [128/50000]	Loss: 1.4388	LR: 0.026288
Training Epoch: 92 [128/50000]	Loss: 1.2413	LR: 0.026288
Training Epoch: 92 [128/50000]	Loss: 1.2936	LR: 0.026288
Training Epoch: 92 [128/50000]	Loss: 1.6273	LR: 0.026288
Training Epoch: 92 [128/50000]	Loss: 1.4143	LR: 0.026288
Training Epoch: 92 [128/50000]	Loss: 1.4473	LR: 0.026288
Training Epoch: 92 [128/50000]	Loss: 1.1733	LR: 0.026288
Training Epoch: 92 [128/50000]	Loss: 1.4443	LR: 0.026288
Training Epoch: 92 [128/50000]	Loss: 1.2695	LR: 0.026288
Training Epoch: 92 [128/50000]	Loss: 1.2695	LR: 0.026288
Evaluating Network.....
Test set: Epoch: 92, Average loss: 0.0119, Top1Accuracy: 0.5825, Top3Accuracy: 0.7882, Top5Accuracy: 0.8589, Time consumed:1.10s

Training Epoch: 93 [128/50000]	Loss: 1.2830	LR: 0.025594
Training Epoch: 93 [128/50000]	Loss: 1.1101	LR: 0.025594
Training Epoch: 93 [128/50000]	Loss: 1.1489	LR: 0.025594
Training Epoch: 93 [128/50000]	Loss: 1.1916	LR: 0.025594
Training Epoch: 93 [128/50000]	Loss: 1.3548	LR: 0.025594
Training Epoch: 93 [128/50000]	Loss: 1.3321	LR: 0.025594
Training Epoch: 93 [128/50000]	Loss: 1.3416	LR: 0.025594
Training Epoch: 93 [128/50000]	Loss: 1.3242	LR: 0.025594
Training Epoch: 93 [128/50000]	Loss: 1.3223	LR: 0.025594
Training Epoch: 93 [128/50000]	Loss: 1.2279	LR: 0.025594
Evaluating Network.....
Test set: Epoch: 93, Average loss: 0.0123, Top1Accuracy: 0.5723, Top3Accuracy: 0.7776, Top5Accuracy: 0.8466, Time consumed:1.10s

Training Epoch: 94 [128/50000]	Loss: 1.1161	LR: 0.024918
Training Epoch: 94 [128/50000]	Loss: 1.3200	LR: 0.024918
Training Epoch: 94 [128/50000]	Loss: 1.2668	LR: 0.024918
Training Epoch: 94 [128/50000]	Loss: 1.2935	LR: 0.024918
Training Epoch: 94 [128/50000]	Loss: 1.2068	LR: 0.024918
Training Epoch: 94 [128/50000]	Loss: 1.4159	LR: 0.024918
Training Epoch: 94 [128/50000]	Loss: 1.1694	LR: 0.024918
Training Epoch: 94 [128/50000]	Loss: 1.0871	LR: 0.024918
Training Epoch: 94 [128/50000]	Loss: 1.3933	LR: 0.024918
Training Epoch: 94 [128/50000]	Loss: 1.2490	LR: 0.024918
Evaluating Network.....
Test set: Epoch: 94, Average loss: 0.0118, Top1Accuracy: 0.5892, Top3Accuracy: 0.7894, Top5Accuracy: 0.8576, Time consumed:1.11s

Training Epoch: 95 [128/50000]	Loss: 1.4240	LR: 0.024260
Training Epoch: 95 [128/50000]	Loss: 1.2370	LR: 0.024260
Training Epoch: 95 [128/50000]	Loss: 1.4363	LR: 0.024260
Training Epoch: 95 [128/50000]	Loss: 1.3676	LR: 0.024260
Training Epoch: 95 [128/50000]	Loss: 1.3261	LR: 0.024260
Training Epoch: 95 [128/50000]	Loss: 1.3148	LR: 0.024260
Training Epoch: 95 [128/50000]	Loss: 1.3401	LR: 0.024260
Training Epoch: 95 [128/50000]	Loss: 1.2162	LR: 0.024260
Training Epoch: 95 [128/50000]	Loss: 1.2162	LR: 0.024260
Training Epoch: 95 [128/50000]	Loss: 1.2467	LR: 0.024260
Evaluating Network.....
Test set: Epoch: 95, Average loss: 0.0116, Top1Accuracy: 0.5939, Top3Accuracy: 0.7930, Top5Accuracy: 0.8624, Time consumed:1.11s

Training Epoch: 96 [128/50000]	Loss: 1.1134	LR: 0.023620
Training Epoch: 96 [128/50000]	Loss: 1.1804	LR: 0.023620
Training Epoch: 96 [128/50000]	Loss: 1.1963	LR: 0.023620
Training Epoch: 96 [128/50000]	Loss: 1.4360	LR: 0.023620
Training Epoch: 96 [128/50000]	Loss: 1.4168	LR: 0.023620
Training Epoch: 96 [128/50000]	Loss: 1.2851	LR: 0.023620
Training Epoch: 96 [128/50000]	Loss: 1.3197	LR: 0.023620
Training Epoch: 96 [128/50000]	Loss: 1.4477	LR: 0.023620
Training Epoch: 96 [128/50000]	Loss: 1.2372	LR: 0.023620
Training Epoch: 96 [128/50000]	Loss: 1.2559	LR: 0.023620
Evaluating Network.....
Test set: Epoch: 96, Average loss: 0.0118, Top1Accuracy: 0.5903, Top3Accuracy: 0.7916, Top5Accuracy: 0.8594, Time consumed:1.12s

Training Epoch: 97 [128/50000]	Loss: 1.2998	LR: 0.022996
Training Epoch: 97 [128/50000]	Loss: 1.2749	LR: 0.022996
Training Epoch: 97 [128/50000]	Loss: 1.1555	LR: 0.022996
Training Epoch: 97 [128/50000]	Loss: 1.2871	LR: 0.022996
Training Epoch: 97 [128/50000]	Loss: 1.2247	LR: 0.022996
Training Epoch: 97 [128/50000]	Loss: 1.3486	LR: 0.022996
Training Epoch: 97 [128/50000]	Loss: 1.1564	LR: 0.022996
Training Epoch: 97 [128/50000]	Loss: 1.3566	LR: 0.022996
Training Epoch: 97 [128/50000]	Loss: 1.2563	LR: 0.022996
Training Epoch: 97 [128/50000]	Loss: 1.2746	LR: 0.022996
Evaluating Network.....
Test set: Epoch: 97, Average loss: 0.0117, Top1Accuracy: 0.5900, Top3Accuracy: 0.7913, Top5Accuracy: 0.8605, Time consumed:1.12s

Training Epoch: 98 [128/50000]	Loss: 1.3031	LR: 0.022389
Training Epoch: 98 [128/50000]	Loss: 1.1668	LR: 0.022389
Training Epoch: 98 [128/50000]	Loss: 1.2814	LR: 0.022389
Training Epoch: 98 [128/50000]	Loss: 1.1331	LR: 0.022389
Training Epoch: 98 [128/50000]	Loss: 1.3366	LR: 0.022389
Training Epoch: 98 [128/50000]	Loss: 1.4736	LR: 0.022389
Training Epoch: 98 [128/50000]	Loss: 1.3126	LR: 0.022389
Training Epoch: 98 [128/50000]	Loss: 1.4062	LR: 0.022389
Training Epoch: 98 [128/50000]	Loss: 1.1916	LR: 0.022389
Training Epoch: 98 [128/50000]	Loss: 1.1228	LR: 0.022389
Evaluating Network.....
Test set: Epoch: 98, Average loss: 0.0116, Top1Accuracy: 0.5913, Top3Accuracy: 0.7931, Top5Accuracy: 0.8594, Time consumed:1.10s

Training Epoch: 99 [128/50000]	Loss: 1.3242	LR: 0.021798
Training Epoch: 99 [128/50000]	Loss: 1.3749	LR: 0.021798
Training Epoch: 99 [128/50000]	Loss: 1.2951	LR: 0.021798
Training Epoch: 99 [128/50000]	Loss: 1.4946	LR: 0.021798
Training Epoch: 99 [128/50000]	Loss: 1.1708	LR: 0.021798
Training Epoch: 99 [128/50000]	Loss: 1.0173	LR: 0.021798
Training Epoch: 99 [128/50000]	Loss: 1.0682	LR: 0.021798
Training Epoch: 99 [128/50000]	Loss: 1.1448	LR: 0.021798
Training Epoch: 99 [128/50000]	Loss: 1.3906	LR: 0.021798
Training Epoch: 99 [128/50000]	Loss: 1.1837	LR: 0.021798
Evaluating Network.....
Test set: Epoch: 99, Average loss: 0.0116, Top1Accuracy: 0.5969, Top3Accuracy: 0.7945, Top5Accuracy: 0.8647, Time consumed:1.11s

Training Epoch: 100 [128/50000]	Loss: 1.3027	LR: 0.021223
Training Epoch: 100 [128/50000]	Loss: 1.4792	LR: 0.021223
Training Epoch: 100 [128/50000]	Loss: 1.2148	LR: 0.021223
Training Epoch: 100 [128/50000]	Loss: 1.1783	LR: 0.021223
Training Epoch: 100 [128/50000]	Loss: 1.4274	LR: 0.021223
Training Epoch: 100 [128/50000]	Loss: 1.1356	LR: 0.021223
Training Epoch: 100 [128/50000]	Loss: 1.3328	LR: 0.021223
Training Epoch: 100 [128/50000]	Loss: 1.1131	LR: 0.021223
Training Epoch: 100 [128/50000]	Loss: 1.0161	LR: 0.021223
Training Epoch: 100 [128/50000]	Loss: 1.2672	LR: 0.021223
Evaluating Network.....
Test set: Epoch: 100, Average loss: 0.0117, Top1Accuracy: 0.5923, Top3Accuracy: 0.7917, Top5Accuracy: 0.8606, Time consumed:1.10s

Training Epoch: 101 [128/50000]	Loss: 1.2057	LR: 0.020662
Training Epoch: 101 [128/50000]	Loss: 1.0934	LR: 0.020662
Training Epoch: 101 [128/50000]	Loss: 1.3105	LR: 0.020662
Training Epoch: 101 [128/50000]	Loss: 1.3751	LR: 0.020662
Training Epoch: 101 [128/50000]	Loss: 1.4499	LR: 0.020662
Training Epoch: 101 [128/50000]	Loss: 1.2476	LR: 0.020662
Training Epoch: 101 [128/50000]	Loss: 1.2826	LR: 0.020662
Training Epoch: 101 [128/50000]	Loss: 1.4069	LR: 0.020662
Training Epoch: 101 [128/50000]	Loss: 1.2509	LR: 0.020662
Training Epoch: 101 [128/50000]	Loss: 1.4908	LR: 0.020662
Evaluating Network.....
Test set: Epoch: 101, Average loss: 0.0115, Top1Accuracy: 0.5985, Top3Accuracy: 0.7964, Top5Accuracy: 0.8640, Time consumed:1.09s

Training Epoch: 102 [128/50000]	Loss: 1.0769	LR: 0.020117
Training Epoch: 102 [128/50000]	Loss: 1.2756	LR: 0.020117
Training Epoch: 102 [128/50000]	Loss: 1.2777	LR: 0.020117
Training Epoch: 102 [128/50000]	Loss: 1.4530	LR: 0.020117
Training Epoch: 102 [128/50000]	Loss: 0.9528	LR: 0.020117
Training Epoch: 102 [128/50000]	Loss: 1.3723	LR: 0.020117
Training Epoch: 102 [128/50000]	Loss: 1.2810	LR: 0.020117
Training Epoch: 102 [128/50000]	Loss: 1.2425	LR: 0.020117
Training Epoch: 102 [128/50000]	Loss: 1.0869	LR: 0.020117
Training Epoch: 102 [128/50000]	Loss: 1.1750	LR: 0.020117
Evaluating Network.....
Test set: Epoch: 102, Average loss: 0.0114, Top1Accuracy: 0.5989, Top3Accuracy: 0.7991, Top5Accuracy: 0.8667, Time consumed:1.10s

Training Epoch: 103 [128/50000]	Loss: 1.2297	LR: 0.019586
Training Epoch: 103 [128/50000]	Loss: 1.2725	LR: 0.019586
Training Epoch: 103 [128/50000]	Loss: 1.2269	LR: 0.019586
Training Epoch: 103 [128/50000]	Loss: 1.0586	LR: 0.019586
Training Epoch: 103 [128/50000]	Loss: 1.1688	LR: 0.019586
Training Epoch: 103 [128/50000]	Loss: 1.1818	LR: 0.019586
Training Epoch: 103 [128/50000]	Loss: 1.0416	LR: 0.019586
Training Epoch: 103 [128/50000]	Loss: 1.3177	LR: 0.019586
Training Epoch: 103 [128/50000]	Loss: 1.1813	LR: 0.019586
Training Epoch: 103 [128/50000]	Loss: 1.2522	LR: 0.019586
Evaluating Network.....
Test set: Epoch: 103, Average loss: 0.0115, Top1Accuracy: 0.5996, Top3Accuracy: 0.7997, Top5Accuracy: 0.8664, Time consumed:1.10s

Training Epoch: 104 [128/50000]	Loss: 1.1185	LR: 0.019069
Training Epoch: 104 [128/50000]	Loss: 1.4485	LR: 0.019069
Training Epoch: 104 [128/50000]	Loss: 1.1808	LR: 0.019069
Training Epoch: 104 [128/50000]	Loss: 1.1627	LR: 0.019069
Training Epoch: 104 [128/50000]	Loss: 1.0542	LR: 0.019069
Training Epoch: 104 [128/50000]	Loss: 1.1850	LR: 0.019069
Training Epoch: 104 [128/50000]	Loss: 1.1392	LR: 0.019069
Training Epoch: 104 [128/50000]	Loss: 1.0052	LR: 0.019069
Training Epoch: 104 [128/50000]	Loss: 1.2157	LR: 0.019069
Training Epoch: 104 [128/50000]	Loss: 1.2472	LR: 0.019069
Evaluating Network.....
Test set: Epoch: 104, Average loss: 0.0114, Top1Accuracy: 0.6066, Top3Accuracy: 0.8058, Top5Accuracy: 0.8683, Time consumed:1.12s

Training Epoch: 105 [128/50000]	Loss: 1.3874	LR: 0.018565
Training Epoch: 105 [128/50000]	Loss: 1.0782	LR: 0.018565
Training Epoch: 105 [128/50000]	Loss: 1.1418	LR: 0.018565
Training Epoch: 105 [128/50000]	Loss: 1.4763	LR: 0.018565
Training Epoch: 105 [128/50000]	Loss: 1.2370	LR: 0.018565
Training Epoch: 105 [128/50000]	Loss: 1.0160	LR: 0.018565
Training Epoch: 105 [128/50000]	Loss: 1.1872	LR: 0.018565
Training Epoch: 105 [128/50000]	Loss: 1.2313	LR: 0.018565
Training Epoch: 105 [128/50000]	Loss: 1.2342	LR: 0.018565
Training Epoch: 105 [128/50000]	Loss: 1.0798	LR: 0.018565
Evaluating Network.....
Test set: Epoch: 105, Average loss: 0.0115, Top1Accuracy: 0.6009, Top3Accuracy: 0.8002, Top5Accuracy: 0.8645, Time consumed:1.09s

Training Epoch: 106 [128/50000]	Loss: 1.3066	LR: 0.018075
Training Epoch: 106 [128/50000]	Loss: 1.1928	LR: 0.018075
Training Epoch: 106 [128/50000]	Loss: 1.5504	LR: 0.018075
Training Epoch: 106 [128/50000]	Loss: 1.1881	LR: 0.018075
Training Epoch: 106 [128/50000]	Loss: 1.1183	LR: 0.018075
Training Epoch: 106 [128/50000]	Loss: 1.1355	LR: 0.018075
Training Epoch: 106 [128/50000]	Loss: 1.2809	LR: 0.018075
Training Epoch: 106 [128/50000]	Loss: 1.3207	LR: 0.018075
Training Epoch: 106 [128/50000]	Loss: 1.1399	LR: 0.018075
Training Epoch: 106 [128/50000]	Loss: 1.1368	LR: 0.018075
Evaluating Network.....
Test set: Epoch: 106, Average loss: 0.0115, Top1Accuracy: 0.5986, Top3Accuracy: 0.7949, Top5Accuracy: 0.8617, Time consumed:1.11s

Training Epoch: 107 [128/50000]	Loss: 1.2014	LR: 0.017598
Training Epoch: 107 [128/50000]	Loss: 1.1100	LR: 0.017598
Training Epoch: 107 [128/50000]	Loss: 0.9439	LR: 0.017598
Training Epoch: 107 [128/50000]	Loss: 1.0929	LR: 0.017598
Training Epoch: 107 [128/50000]	Loss: 1.2226	LR: 0.017598
Training Epoch: 107 [128/50000]	Loss: 1.2238	LR: 0.017598
Training Epoch: 107 [128/50000]	Loss: 1.0381	LR: 0.017598
Training Epoch: 107 [128/50000]	Loss: 1.1966	LR: 0.017598
Training Epoch: 107 [128/50000]	Loss: 1.1031	LR: 0.017598
Training Epoch: 107 [128/50000]	Loss: 1.3271	LR: 0.017598
Evaluating Network.....
Test set: Epoch: 107, Average loss: 0.0112, Top1Accuracy: 0.6038, Top3Accuracy: 0.8018, Top5Accuracy: 0.8656, Time consumed:1.09s

Training Epoch: 108 [128/50000]	Loss: 1.2218	LR: 0.017133
Training Epoch: 108 [128/50000]	Loss: 1.1410	LR: 0.017133
Training Epoch: 108 [128/50000]	Loss: 1.1024	LR: 0.017133
Training Epoch: 108 [128/50000]	Loss: 1.0384	LR: 0.017133
Training Epoch: 108 [128/50000]	Loss: 1.1580	LR: 0.017133
Training Epoch: 108 [128/50000]	Loss: 1.3959	LR: 0.017133
Training Epoch: 108 [128/50000]	Loss: 1.2164	LR: 0.017133
Training Epoch: 108 [128/50000]	Loss: 1.0371	LR: 0.017133
Training Epoch: 108 [128/50000]	Loss: 1.0328	LR: 0.017133
Training Epoch: 108 [128/50000]	Loss: 1.1964	LR: 0.017133
Evaluating Network.....
Test set: Epoch: 108, Average loss: 0.0112, Top1Accuracy: 0.6039, Top3Accuracy: 0.8033, Top5Accuracy: 0.8686, Time consumed:1.10s

Training Epoch: 109 [128/50000]	Loss: 1.0110	LR: 0.016681
Training Epoch: 109 [128/50000]	Loss: 0.9578	LR: 0.016681
Training Epoch: 109 [128/50000]	Loss: 1.2257	LR: 0.016681
Training Epoch: 109 [128/50000]	Loss: 1.3027	LR: 0.016681
Training Epoch: 109 [128/50000]	Loss: 1.0105	LR: 0.016681
Training Epoch: 109 [128/50000]	Loss: 1.3084	LR: 0.016681
Training Epoch: 109 [128/50000]	Loss: 1.0741	LR: 0.016681
Training Epoch: 109 [128/50000]	Loss: 1.3056	LR: 0.016681
Training Epoch: 109 [128/50000]	Loss: 1.2152	LR: 0.016681
Training Epoch: 109 [128/50000]	Loss: 1.2537	LR: 0.016681
Evaluating Network.....
Test set: Epoch: 109, Average loss: 0.0114, Top1Accuracy: 0.6007, Top3Accuracy: 0.8023, Top5Accuracy: 0.8692, Time consumed:1.11s

Training Epoch: 110 [128/50000]	Loss: 1.2215	LR: 0.016241
Training Epoch: 110 [128/50000]	Loss: 1.3742	LR: 0.016241
Training Epoch: 110 [128/50000]	Loss: 1.2570	LR: 0.016241
Training Epoch: 110 [128/50000]	Loss: 1.1148	LR: 0.016241
Training Epoch: 110 [128/50000]	Loss: 1.2253	LR: 0.016241
Training Epoch: 110 [128/50000]	Loss: 1.0925	LR: 0.016241
Training Epoch: 110 [128/50000]	Loss: 1.1441	LR: 0.016241
Training Epoch: 110 [128/50000]	Loss: 0.9508	LR: 0.016241
Training Epoch: 110 [128/50000]	Loss: 1.1088	LR: 0.016241
Training Epoch: 110 [128/50000]	Loss: 1.2190	LR: 0.016241
Evaluating Network.....
Test set: Epoch: 110, Average loss: 0.0111, Top1Accuracy: 0.6070, Top3Accuracy: 0.8039, Top5Accuracy: 0.8681, Time consumed:1.11s

Training Epoch: 111 [128/50000]	Loss: 1.3053	LR: 0.015812
Training Epoch: 111 [128/50000]	Loss: 1.2267	LR: 0.015812
Training Epoch: 111 [128/50000]	Loss: 1.0017	LR: 0.015812
Training Epoch: 111 [128/50000]	Loss: 1.2264	LR: 0.015812
Training Epoch: 111 [128/50000]	Loss: 1.2885	LR: 0.015812
Training Epoch: 111 [128/50000]	Loss: 1.1813	LR: 0.015812
Training Epoch: 111 [128/50000]	Loss: 1.1649	LR: 0.015812
Training Epoch: 111 [128/50000]	Loss: 1.1028	LR: 0.015812
Training Epoch: 111 [128/50000]	Loss: 1.1827	LR: 0.015812
Training Epoch: 111 [128/50000]	Loss: 1.0944	LR: 0.015812
Evaluating Network.....
Test set: Epoch: 111, Average loss: 0.0112, Top1Accuracy: 0.6041, Top3Accuracy: 0.8070, Top5Accuracy: 0.8723, Time consumed:1.09s

Training Epoch: 112 [128/50000]	Loss: 1.3651	LR: 0.015394
Training Epoch: 112 [128/50000]	Loss: 1.0833	LR: 0.015394
Training Epoch: 112 [128/50000]	Loss: 1.3546	LR: 0.015394
Training Epoch: 112 [128/50000]	Loss: 1.1414	LR: 0.015394
Training Epoch: 112 [128/50000]	Loss: 1.1220	LR: 0.015394
Training Epoch: 112 [128/50000]	Loss: 1.0725	LR: 0.015394
Training Epoch: 112 [128/50000]	Loss: 1.0551	LR: 0.015394
Training Epoch: 112 [128/50000]	Loss: 1.2999	LR: 0.015394
Training Epoch: 112 [128/50000]	Loss: 1.1550	LR: 0.015394
Training Epoch: 112 [128/50000]	Loss: 1.2622	LR: 0.015394
Evaluating Network.....
Test set: Epoch: 112, Average loss: 0.0112, Top1Accuracy: 0.6084, Top3Accuracy: 0.8068, Top5Accuracy: 0.8712, Time consumed:1.10s

Training Epoch: 113 [128/50000]	Loss: 1.1017	LR: 0.014988
Training Epoch: 113 [128/50000]	Loss: 1.2011	LR: 0.014988
Training Epoch: 113 [128/50000]	Loss: 1.3561	LR: 0.014988
Training Epoch: 113 [128/50000]	Loss: 0.9312	LR: 0.014988
Training Epoch: 113 [128/50000]	Loss: 1.1313	LR: 0.014988
Training Epoch: 113 [128/50000]	Loss: 1.1701	LR: 0.014988
Training Epoch: 113 [128/50000]	Loss: 1.1770	LR: 0.014988
Training Epoch: 113 [128/50000]	Loss: 0.9688	LR: 0.014988
Training Epoch: 113 [128/50000]	Loss: 1.1557	LR: 0.014988
Training Epoch: 113 [128/50000]	Loss: 1.1844	LR: 0.014988
Evaluating Network.....
Test set: Epoch: 113, Average loss: 0.0110, Top1Accuracy: 0.6098, Top3Accuracy: 0.8097, Top5Accuracy: 0.8723, Time consumed:1.11s

Training Epoch: 114 [128/50000]	Loss: 1.1512	LR: 0.014592
Training Epoch: 114 [128/50000]	Loss: 1.0673	LR: 0.014592
Training Epoch: 114 [128/50000]	Loss: 1.0720	LR: 0.014592
Training Epoch: 114 [128/50000]	Loss: 1.2772	LR: 0.014592
Training Epoch: 114 [128/50000]	Loss: 1.2245	LR: 0.014592
Training Epoch: 114 [128/50000]	Loss: 1.3407	LR: 0.014592
Training Epoch: 114 [128/50000]	Loss: 1.0658	LR: 0.014592
Training Epoch: 114 [128/50000]	Loss: 1.1787	LR: 0.014592
Training Epoch: 114 [128/50000]	Loss: 1.1535	LR: 0.014592
Training Epoch: 114 [128/50000]	Loss: 1.1624	LR: 0.014592
Evaluating Network.....
Test set: Epoch: 114, Average loss: 0.0111, Top1Accuracy: 0.6070, Top3Accuracy: 0.8079, Top5Accuracy: 0.8740, Time consumed:1.10s

Training Epoch: 115 [128/50000]	Loss: 1.1800	LR: 0.014207
Training Epoch: 115 [128/50000]	Loss: 1.1831	LR: 0.014207
Training Epoch: 115 [128/50000]	Loss: 1.1208	LR: 0.014207
Training Epoch: 115 [128/50000]	Loss: 1.1335	LR: 0.014207
Training Epoch: 115 [128/50000]	Loss: 1.0641	LR: 0.014207
Training Epoch: 115 [128/50000]	Loss: 1.2255	LR: 0.014207
Training Epoch: 115 [128/50000]	Loss: 1.3360	LR: 0.014207
Training Epoch: 115 [128/50000]	Loss: 1.1208	LR: 0.014207
Training Epoch: 115 [128/50000]	Loss: 1.0182	LR: 0.014207
Training Epoch: 115 [128/50000]	Loss: 0.9866	LR: 0.014207
Evaluating Network.....
Test set: Epoch: 115, Average loss: 0.0110, Top1Accuracy: 0.6144, Top3Accuracy: 0.8091, Top5Accuracy: 0.8725, Time consumed:1.13s

Training Epoch: 116 [128/50000]	Loss: 1.1418	LR: 0.013832
Training Epoch: 116 [128/50000]	Loss: 1.1864	LR: 0.013832
Training Epoch: 116 [128/50000]	Loss: 1.1073	LR: 0.013832
Training Epoch: 116 [128/50000]	Loss: 0.9044	LR: 0.013832
Training Epoch: 116 [128/50000]	Loss: 1.0377	LR: 0.013832
Training Epoch: 116 [128/50000]	Loss: 1.0512	LR: 0.013832
Training Epoch: 116 [128/50000]	Loss: 1.2716	LR: 0.013832
Training Epoch: 116 [128/50000]	Loss: 1.0178	LR: 0.013832
Training Epoch: 116 [128/50000]	Loss: 0.8885	LR: 0.013832
Training Epoch: 116 [128/50000]	Loss: 1.0736	LR: 0.013832
Evaluating Network.....
Test set: Epoch: 116, Average loss: 0.0112, Top1Accuracy: 0.6062, Top3Accuracy: 0.8019, Top5Accuracy: 0.8688, Time consumed:1.12s

Training Epoch: 117 [128/50000]	Loss: 0.9130	LR: 0.013467
Training Epoch: 117 [128/50000]	Loss: 1.1828	LR: 0.013467
Training Epoch: 117 [128/50000]	Loss: 1.3051	LR: 0.013467
Training Epoch: 117 [128/50000]	Loss: 1.1383	LR: 0.013467
Training Epoch: 117 [128/50000]	Loss: 1.1693	LR: 0.013467
Training Epoch: 117 [128/50000]	Loss: 1.2372	LR: 0.013467
Training Epoch: 117 [128/50000]	Loss: 1.1000	LR: 0.013467
Training Epoch: 117 [128/50000]	Loss: 0.9535	LR: 0.013467
Training Epoch: 117 [128/50000]	Loss: 1.0636	LR: 0.013467
Training Epoch: 117 [128/50000]	Loss: 1.2587	LR: 0.013467
Evaluating Network.....
Test set: Epoch: 117, Average loss: 0.0111, Top1Accuracy: 0.6104, Top3Accuracy: 0.8066, Top5Accuracy: 0.8732, Time consumed:1.11s

Training Epoch: 118 [128/50000]	Loss: 1.1643	LR: 0.013111
Training Epoch: 118 [128/50000]	Loss: 1.2676	LR: 0.013111
Training Epoch: 118 [128/50000]	Loss: 1.0916	LR: 0.013111
Training Epoch: 118 [128/50000]	Loss: 1.0653	LR: 0.013111
Training Epoch: 118 [128/50000]	Loss: 1.2144	LR: 0.013111
Training Epoch: 118 [128/50000]	Loss: 1.2642	LR: 0.013111
Training Epoch: 118 [128/50000]	Loss: 0.9087	LR: 0.013111
Training Epoch: 118 [128/50000]	Loss: 1.1898	LR: 0.013111
Training Epoch: 118 [128/50000]	Loss: 1.1148	LR: 0.013111
Training Epoch: 118 [128/50000]	Loss: 1.0120	LR: 0.013111
Evaluating Network.....
Test set: Epoch: 118, Average loss: 0.0110, Top1Accuracy: 0.6179, Top3Accuracy: 0.8122, Top5Accuracy: 0.8766, Time consumed:1.10s

Training Epoch: 119 [128/50000]	Loss: 1.0399	LR: 0.012765
Training Epoch: 119 [128/50000]	Loss: 1.1102	LR: 0.012765
Training Epoch: 119 [128/50000]	Loss: 1.0687	LR: 0.012765
Training Epoch: 119 [128/50000]	Loss: 1.0486	LR: 0.012765
Training Epoch: 119 [128/50000]	Loss: 1.0812	LR: 0.012765
Training Epoch: 119 [128/50000]	Loss: 1.1759	LR: 0.012765
Training Epoch: 119 [128/50000]	Loss: 1.1696	LR: 0.012765
Training Epoch: 119 [128/50000]	Loss: 1.1151	LR: 0.012765
Training Epoch: 119 [128/50000]	Loss: 0.9939	LR: 0.012765
Training Epoch: 119 [128/50000]	Loss: 1.3516	LR: 0.012765
Evaluating Network.....
Test set: Epoch: 119, Average loss: 0.0110, Top1Accuracy: 0.6105, Top3Accuracy: 0.8109, Top5Accuracy: 0.8727, Time consumed:1.10s

Training Epoch: 120 [128/50000]	Loss: 1.2226	LR: 0.012428
Training Epoch: 120 [128/50000]	Loss: 1.2608	LR: 0.012428
Training Epoch: 120 [128/50000]	Loss: 1.1760	LR: 0.012428
Training Epoch: 120 [128/50000]	Loss: 1.0389	LR: 0.012428
Training Epoch: 120 [128/50000]	Loss: 1.2698	LR: 0.012428
Training Epoch: 120 [128/50000]	Loss: 1.1766	LR: 0.012428
Training Epoch: 120 [128/50000]	Loss: 0.9522	LR: 0.012428
Training Epoch: 120 [128/50000]	Loss: 1.1379	LR: 0.012428
Training Epoch: 120 [128/50000]	Loss: 1.2147	LR: 0.012428
Training Epoch: 120 [128/50000]	Loss: 1.0775	LR: 0.012428
Evaluating Network.....
Test set: Epoch: 120, Average loss: 0.0109, Top1Accuracy: 0.6155, Top3Accuracy: 0.8120, Top5Accuracy: 0.8765, Time consumed:1.10s

Training Epoch: 121 [128/50000]	Loss: 0.9586	LR: 0.012100
Training Epoch: 121 [128/50000]	Loss: 1.1703	LR: 0.012100
Training Epoch: 121 [128/50000]	Loss: 1.3077	LR: 0.012100
Training Epoch: 121 [128/50000]	Loss: 1.1154	LR: 0.012100
Training Epoch: 121 [128/50000]	Loss: 1.1306	LR: 0.012100
Training Epoch: 121 [128/50000]	Loss: 1.1404	LR: 0.012100
Training Epoch: 121 [128/50000]	Loss: 1.0728	LR: 0.012100
Training Epoch: 121 [128/50000]	Loss: 1.0300	LR: 0.012100
Training Epoch: 121 [128/50000]	Loss: 1.2474	LR: 0.012100
Training Epoch: 121 [128/50000]	Loss: 1.1166	LR: 0.012100
Evaluating Network.....
Test set: Epoch: 121, Average loss: 0.0109, Top1Accuracy: 0.6169, Top3Accuracy: 0.8142, Top5Accuracy: 0.8747, Time consumed:1.10s

Training Epoch: 122 [128/50000]	Loss: 1.3260	LR: 0.011781
Training Epoch: 122 [128/50000]	Loss: 1.0938	LR: 0.011781
Training Epoch: 122 [128/50000]	Loss: 1.1647	LR: 0.011781
Training Epoch: 122 [128/50000]	Loss: 1.0502	LR: 0.011781
Training Epoch: 122 [128/50000]	Loss: 0.9735	LR: 0.011781
Training Epoch: 122 [128/50000]	Loss: 1.2659	LR: 0.011781
Training Epoch: 122 [128/50000]	Loss: 1.3756	LR: 0.011781
Training Epoch: 122 [128/50000]	Loss: 0.9768	LR: 0.011781
Training Epoch: 122 [128/50000]	Loss: 1.0328	LR: 0.011781
Training Epoch: 122 [128/50000]	Loss: 1.2968	LR: 0.011781
Evaluating Network.....
Test set: Epoch: 122, Average loss: 0.0110, Top1Accuracy: 0.6159, Top3Accuracy: 0.8086, Top5Accuracy: 0.8733, Time consumed:1.10s

Training Epoch: 123 [128/50000]	Loss: 1.1432	LR: 0.011470
Training Epoch: 123 [128/50000]	Loss: 0.9294	LR: 0.011470
Training Epoch: 123 [128/50000]	Loss: 1.0925	LR: 0.011470
Training Epoch: 123 [128/50000]	Loss: 1.0074	LR: 0.011470
Training Epoch: 123 [128/50000]	Loss: 1.0863	LR: 0.011470
Training Epoch: 123 [128/50000]	Loss: 1.0538	LR: 0.011470
Training Epoch: 123 [128/50000]	Loss: 1.1596	LR: 0.011470
Training Epoch: 123 [128/50000]	Loss: 1.0999	LR: 0.011470
Training Epoch: 123 [128/50000]	Loss: 1.2911	LR: 0.011470
Training Epoch: 123 [128/50000]	Loss: 1.1903	LR: 0.011470
Evaluating Network.....
Test set: Epoch: 123, Average loss: 0.0109, Top1Accuracy: 0.6184, Top3Accuracy: 0.8108, Top5Accuracy: 0.8757, Time consumed:1.09s

Training Epoch: 124 [128/50000]	Loss: 1.0822	LR: 0.011167
Training Epoch: 124 [128/50000]	Loss: 1.0682	LR: 0.011167
Training Epoch: 124 [128/50000]	Loss: 0.9728	LR: 0.011167
Training Epoch: 124 [128/50000]	Loss: 0.9091	LR: 0.011167
Training Epoch: 124 [128/50000]	Loss: 1.0912	LR: 0.011167
Training Epoch: 124 [128/50000]	Loss: 1.0064	LR: 0.011167
Training Epoch: 124 [128/50000]	Loss: 1.1150	LR: 0.011167
Training Epoch: 124 [128/50000]	Loss: 1.0191	LR: 0.011167
Training Epoch: 124 [128/50000]	Loss: 1.1366	LR: 0.011167
Training Epoch: 124 [128/50000]	Loss: 1.0132	LR: 0.011167
Evaluating Network.....
Test set: Epoch: 124, Average loss: 0.0110, Top1Accuracy: 0.6152, Top3Accuracy: 0.8132, Top5Accuracy: 0.8753, Time consumed:1.12s

Training Epoch: 125 [128/50000]	Loss: 0.8344	LR: 0.010872
Training Epoch: 125 [128/50000]	Loss: 1.0450	LR: 0.010872
Training Epoch: 125 [128/50000]	Loss: 0.8522	LR: 0.010872
Training Epoch: 125 [128/50000]	Loss: 0.9806	LR: 0.010872
Training Epoch: 125 [128/50000]	Loss: 1.1797	LR: 0.010872
Training Epoch: 125 [128/50000]	Loss: 0.9930	LR: 0.010872
Training Epoch: 125 [128/50000]	Loss: 0.9879	LR: 0.010872
Training Epoch: 125 [128/50000]	Loss: 0.9585	LR: 0.010872
Training Epoch: 125 [128/50000]	Loss: 1.1050	LR: 0.010872
Training Epoch: 125 [128/50000]	Loss: 1.0476	LR: 0.010872
Evaluating Network.....
Test set: Epoch: 125, Average loss: 0.0111, Top1Accuracy: 0.6138, Top3Accuracy: 0.8073, Top5Accuracy: 0.8742, Time consumed:1.11s

Training Epoch: 126 [128/50000]	Loss: 1.1569	LR: 0.010585
Training Epoch: 126 [128/50000]	Loss: 0.9576	LR: 0.010585
Training Epoch: 126 [128/50000]	Loss: 1.3186	LR: 0.010585
Training Epoch: 126 [128/50000]	Loss: 1.2108	LR: 0.010585
Training Epoch: 126 [128/50000]	Loss: 1.1540	LR: 0.010585
Training Epoch: 126 [128/50000]	Loss: 1.0540	LR: 0.010585
Training Epoch: 126 [128/50000]	Loss: 1.0305	LR: 0.010585
Training Epoch: 126 [128/50000]	Loss: 0.9457	LR: 0.010585
Training Epoch: 126 [128/50000]	Loss: 1.3303	LR: 0.010585
Training Epoch: 126 [128/50000]	Loss: 1.1571	LR: 0.010585
Evaluating Network.....
Test set: Epoch: 126, Average loss: 0.0109, Top1Accuracy: 0.6188, Top3Accuracy: 0.8136, Top5Accuracy: 0.8756, Time consumed:1.09s

Training Epoch: 127 [128/50000]	Loss: 1.0699	LR: 0.010306
Training Epoch: 127 [128/50000]	Loss: 0.9321	LR: 0.010306
Training Epoch: 127 [128/50000]	Loss: 1.0061	LR: 0.010306
Training Epoch: 127 [128/50000]	Loss: 1.0208	LR: 0.010306
Training Epoch: 127 [128/50000]	Loss: 1.0050	LR: 0.010306
Training Epoch: 127 [128/50000]	Loss: 1.0052	LR: 0.010306
Training Epoch: 127 [128/50000]	Loss: 0.9653	LR: 0.010306
Training Epoch: 127 [128/50000]	Loss: 1.1673	LR: 0.010306
Training Epoch: 127 [128/50000]	Loss: 1.0619	LR: 0.010306
Training Epoch: 127 [128/50000]	Loss: 0.8843	LR: 0.010306
Evaluating Network.....
Test set: Epoch: 127, Average loss: 0.0110, Top1Accuracy: 0.6178, Top3Accuracy: 0.8145, Top5Accuracy: 0.8756, Time consumed:1.10s

Training Epoch: 128 [128/50000]	Loss: 1.0305	LR: 0.010034
Training Epoch: 128 [128/50000]	Loss: 1.0600	LR: 0.010034
Training Epoch: 128 [128/50000]	Loss: 1.0510	LR: 0.010034
Training Epoch: 128 [128/50000]	Loss: 1.1127	LR: 0.010034
Training Epoch: 128 [128/50000]	Loss: 1.1213	LR: 0.010034
Training Epoch: 128 [128/50000]	Loss: 1.2526	LR: 0.010034
Training Epoch: 128 [128/50000]	Loss: 1.1336	LR: 0.010034
Training Epoch: 128 [128/50000]	Loss: 1.0274	LR: 0.010034
Training Epoch: 128 [128/50000]	Loss: 0.9834	LR: 0.010034
Training Epoch: 128 [128/50000]	Loss: 1.0930	LR: 0.010034
Evaluating Network.....
Test set: Epoch: 128, Average loss: 0.0109, Top1Accuracy: 0.6148, Top3Accuracy: 0.8154, Top5Accuracy: 0.8777, Time consumed:1.14s

Training Epoch: 129 [128/50000]	Loss: 0.8717	LR: 0.009769
Training Epoch: 129 [128/50000]	Loss: 1.1243	LR: 0.009769
Training Epoch: 129 [128/50000]	Loss: 1.1170	LR: 0.009769
Training Epoch: 129 [128/50000]	Loss: 0.9438	LR: 0.009769
Training Epoch: 129 [128/50000]	Loss: 0.9541	LR: 0.009769
Training Epoch: 129 [128/50000]	Loss: 1.1345	LR: 0.009769
Training Epoch: 129 [128/50000]	Loss: 1.1143	LR: 0.009769
Training Epoch: 129 [128/50000]	Loss: 0.8957	LR: 0.009769
Training Epoch: 129 [128/50000]	Loss: 1.1122	LR: 0.009769
Training Epoch: 129 [128/50000]	Loss: 1.1243	LR: 0.009769
Evaluating Network.....
Test set: Epoch: 129, Average loss: 0.0109, Top1Accuracy: 0.6206, Top3Accuracy: 0.8157, Top5Accuracy: 0.8790, Time consumed:1.11s

Training Epoch: 130 [128/50000]	Loss: 1.0478	LR: 0.009511
Training Epoch: 130 [128/50000]	Loss: 1.0978	LR: 0.009511
Training Epoch: 130 [128/50000]	Loss: 1.1016	LR: 0.009511
Training Epoch: 130 [128/50000]	Loss: 1.0176	LR: 0.009511
Training Epoch: 130 [128/50000]	Loss: 1.0039	LR: 0.009511
Training Epoch: 130 [128/50000]	Loss: 1.0266	LR: 0.009511
Training Epoch: 130 [128/50000]	Loss: 1.1380	LR: 0.009511
Training Epoch: 130 [128/50000]	Loss: 0.8107	LR: 0.009511
Training Epoch: 130 [128/50000]	Loss: 1.0765	LR: 0.009511
Training Epoch: 130 [128/50000]	Loss: 1.1033	LR: 0.009511
Evaluating Network.....
Test set: Epoch: 130, Average loss: 0.0109, Top1Accuracy: 0.6198, Top3Accuracy: 0.8179, Top5Accuracy: 0.8790, Time consumed:1.13s

Training Epoch: 131 [128/50000]	Loss: 1.2935	LR: 0.009260
Training Epoch: 131 [128/50000]	Loss: 0.9939	LR: 0.009260
Training Epoch: 131 [128/50000]	Loss: 1.0295	LR: 0.009260
Training Epoch: 131 [128/50000]	Loss: 1.0498	LR: 0.009260
Training Epoch: 131 [128/50000]	Loss: 0.9930	LR: 0.009260
Training Epoch: 131 [128/50000]	Loss: 1.0758	LR: 0.009260
Training Epoch: 131 [128/50000]	Loss: 0.9870	LR: 0.009260
Training Epoch: 131 [128/50000]	Loss: 0.8507	LR: 0.009260
Training Epoch: 131 [128/50000]	Loss: 1.0796	LR: 0.009260
Training Epoch: 131 [128/50000]	Loss: 1.1375	LR: 0.009260
Evaluating Network.....
Test set: Epoch: 131, Average loss: 0.0108, Top1Accuracy: 0.6224, Top3Accuracy: 0.8115, Top5Accuracy: 0.8786, Time consumed:1.11s

Training Epoch: 132 [128/50000]	Loss: 1.0548	LR: 0.009015
Training Epoch: 132 [128/50000]	Loss: 1.0520	LR: 0.009015
Training Epoch: 132 [128/50000]	Loss: 0.9595	LR: 0.009015
Training Epoch: 132 [128/50000]	Loss: 1.1130	LR: 0.009015
Training Epoch: 132 [128/50000]	Loss: 1.1127	LR: 0.009015
Training Epoch: 132 [128/50000]	Loss: 1.1560	LR: 0.009015
Training Epoch: 132 [128/50000]	Loss: 0.9239	LR: 0.009015
Training Epoch: 132 [128/50000]	Loss: 1.0579	LR: 0.009015
Training Epoch: 132 [128/50000]	Loss: 0.8152	LR: 0.009015
Training Epoch: 132 [128/50000]	Loss: 0.8850	LR: 0.009015
Evaluating Network.....
Test set: Epoch: 132, Average loss: 0.0108, Top1Accuracy: 0.6204, Top3Accuracy: 0.8139, Top5Accuracy: 0.8782, Time consumed:1.10s

Training Epoch: 133 [128/50000]	Loss: 0.9096	LR: 0.008777
Training Epoch: 133 [128/50000]	Loss: 1.2401	LR: 0.008777
Training Epoch: 133 [128/50000]	Loss: 0.8201	LR: 0.008777
Training Epoch: 133 [128/50000]	Loss: 1.0891	LR: 0.008777
Training Epoch: 133 [128/50000]	Loss: 1.0110	LR: 0.008777
Training Epoch: 133 [128/50000]	Loss: 0.9771	LR: 0.008777
Training Epoch: 133 [128/50000]	Loss: 1.1856	LR: 0.008777
Training Epoch: 133 [128/50000]	Loss: 0.9901	LR: 0.008777
Training Epoch: 133 [128/50000]	Loss: 1.1459	LR: 0.008777
Training Epoch: 133 [128/50000]	Loss: 1.0767	LR: 0.008777
Evaluating Network.....
Test set: Epoch: 133, Average loss: 0.0108, Top1Accuracy: 0.6171, Top3Accuracy: 0.8170, Top5Accuracy: 0.8782, Time consumed:1.11s

Training Epoch: 134 [128/50000]	Loss: 1.1595	LR: 0.008545
Training Epoch: 134 [128/50000]	Loss: 1.0751	LR: 0.008545
Training Epoch: 134 [128/50000]	Loss: 1.1293	LR: 0.008545
Training Epoch: 134 [128/50000]	Loss: 1.1884	LR: 0.008545
Training Epoch: 134 [128/50000]	Loss: 1.0045	LR: 0.008545
Training Epoch: 134 [128/50000]	Loss: 1.1320	LR: 0.008545
Training Epoch: 134 [128/50000]	Loss: 1.0817	LR: 0.008545
Training Epoch: 134 [128/50000]	Loss: 1.1999	LR: 0.008545
Training Epoch: 134 [128/50000]	Loss: 1.2688	LR: 0.008545
Training Epoch: 134 [128/50000]	Loss: 0.8147	LR: 0.008545
Evaluating Network.....
Test set: Epoch: 134, Average loss: 0.0108, Top1Accuracy: 0.6208, Top3Accuracy: 0.8139, Top5Accuracy: 0.8800, Time consumed:1.11s

Training Epoch: 135 [128/50000]	Loss: 1.0848	LR: 0.008320
Training Epoch: 135 [128/50000]	Loss: 1.0123	LR: 0.008320
Training Epoch: 135 [128/50000]	Loss: 1.1605	LR: 0.008320
Training Epoch: 135 [128/50000]	Loss: 1.1586	LR: 0.008320
Training Epoch: 135 [128/50000]	Loss: 0.9664	LR: 0.008320
Training Epoch: 135 [128/50000]	Loss: 0.9542	LR: 0.008320
Training Epoch: 135 [128/50000]	Loss: 0.9053	LR: 0.008320
Training Epoch: 135 [128/50000]	Loss: 1.1279	LR: 0.008320
Training Epoch: 135 [128/50000]	Loss: 1.0324	LR: 0.008320
Training Epoch: 135 [128/50000]	Loss: 1.3150	LR: 0.008320
Evaluating Network.....
Test set: Epoch: 135, Average loss: 0.0107, Top1Accuracy: 0.6220, Top3Accuracy: 0.8178, Top5Accuracy: 0.8792, Time consumed:1.10s

Training Epoch: 136 [128/50000]	Loss: 1.1240	LR: 0.008100
Training Epoch: 136 [128/50000]	Loss: 0.9347	LR: 0.008100
Training Epoch: 136 [128/50000]	Loss: 1.1777	LR: 0.008100
Training Epoch: 136 [128/50000]	Loss: 1.0242	LR: 0.008100
Training Epoch: 136 [128/50000]	Loss: 0.9787	LR: 0.008100
Training Epoch: 136 [128/50000]	Loss: 0.8984	LR: 0.008100
Training Epoch: 136 [128/50000]	Loss: 0.9846	LR: 0.008100
Training Epoch: 136 [128/50000]	Loss: 1.1564	LR: 0.008100
Training Epoch: 136 [128/50000]	Loss: 1.1434	LR: 0.008100
Training Epoch: 136 [128/50000]	Loss: 1.0619	LR: 0.008100
Evaluating Network.....
Test set: Epoch: 136, Average loss: 0.0106, Top1Accuracy: 0.6245, Top3Accuracy: 0.8179, Top5Accuracy: 0.8823, Time consumed:1.10s

Training Epoch: 137 [128/50000]	Loss: 0.9277	LR: 0.007886
Training Epoch: 137 [128/50000]	Loss: 1.0130	LR: 0.007886
Training Epoch: 137 [128/50000]	Loss: 1.2270	LR: 0.007886
Training Epoch: 137 [128/50000]	Loss: 0.8709	LR: 0.007886
Training Epoch: 137 [128/50000]	Loss: 1.0586	LR: 0.007886
Training Epoch: 137 [128/50000]	Loss: 1.0441	LR: 0.007886
Training Epoch: 137 [128/50000]	Loss: 1.0004	LR: 0.007886
Training Epoch: 137 [128/50000]	Loss: 1.0668	LR: 0.007886
Training Epoch: 137 [128/50000]	Loss: 1.0179	LR: 0.007886
Training Epoch: 137 [128/50000]	Loss: 0.9346	LR: 0.007886
Evaluating Network.....
Test set: Epoch: 137, Average loss: 0.0108, Top1Accuracy: 0.6225, Top3Accuracy: 0.8194, Top5Accuracy: 0.8822, Time consumed:1.10s

Training Epoch: 138 [128/50000]	Loss: 1.0855	LR: 0.007678
Training Epoch: 138 [128/50000]	Loss: 0.9355	LR: 0.007678
Training Epoch: 138 [128/50000]	Loss: 1.0622	LR: 0.007678
Training Epoch: 138 [128/50000]	Loss: 0.9724	LR: 0.007678
Training Epoch: 138 [128/50000]	Loss: 0.9380	LR: 0.007678
Training Epoch: 138 [128/50000]	Loss: 0.9833	LR: 0.007678
Training Epoch: 138 [128/50000]	Loss: 0.9517	LR: 0.007678
Training Epoch: 138 [128/50000]	Loss: 1.2566	LR: 0.007678
Training Epoch: 138 [128/50000]	Loss: 1.1865	LR: 0.007678
Training Epoch: 138 [128/50000]	Loss: 0.9800	LR: 0.007678
Evaluating Network.....
Test set: Epoch: 138, Average loss: 0.0108, Top1Accuracy: 0.6223, Top3Accuracy: 0.8169, Top5Accuracy: 0.8786, Time consumed:1.12s

Training Epoch: 139 [128/50000]	Loss: 0.8479	LR: 0.007475
Training Epoch: 139 [128/50000]	Loss: 0.8861	LR: 0.007475
Training Epoch: 139 [128/50000]	Loss: 1.1464	LR: 0.007475
Training Epoch: 139 [128/50000]	Loss: 1.0708	LR: 0.007475
Training Epoch: 139 [128/50000]	Loss: 1.0226	LR: 0.007475
Training Epoch: 139 [128/50000]	Loss: 1.0259	LR: 0.007475
Training Epoch: 139 [128/50000]	Loss: 0.9041	LR: 0.007475
Training Epoch: 139 [128/50000]	Loss: 1.1398	LR: 0.007475
Training Epoch: 139 [128/50000]	Loss: 0.9196	LR: 0.007475
Training Epoch: 139 [128/50000]	Loss: 0.9407	LR: 0.007475
Evaluating Network.....
Test set: Epoch: 139, Average loss: 0.0108, Top1Accuracy: 0.6241, Top3Accuracy: 0.8185, Top5Accuracy: 0.8813, Time consumed:1.11s

Training Epoch: 140 [128/50000]	Loss: 1.0771	LR: 0.007278
Training Epoch: 140 [128/50000]	Loss: 0.9740	LR: 0.007278
Training Epoch: 140 [128/50000]	Loss: 1.1155	LR: 0.007278
Training Epoch: 140 [128/50000]	Loss: 0.9716	LR: 0.007278
Training Epoch: 140 [128/50000]	Loss: 1.0107	LR: 0.007278
Training Epoch: 140 [128/50000]	Loss: 0.9252	LR: 0.007278
Training Epoch: 140 [128/50000]	Loss: 1.1170	LR: 0.007278
Training Epoch: 140 [128/50000]	Loss: 1.0197	LR: 0.007278
Training Epoch: 140 [128/50000]	Loss: 0.8506	LR: 0.007278
Training Epoch: 140 [128/50000]	Loss: 1.0506	LR: 0.007278
Evaluating Network.....
Test set: Epoch: 140, Average loss: 0.0107, Top1Accuracy: 0.6213, Top3Accuracy: 0.8197, Top5Accuracy: 0.8817, Time consumed:1.14s

Training Epoch: 141 [128/50000]	Loss: 1.2319	LR: 0.007086
Training Epoch: 141 [128/50000]	Loss: 1.2165	LR: 0.007086
Training Epoch: 141 [128/50000]	Loss: 0.9652	LR: 0.007086
Training Epoch: 141 [128/50000]	Loss: 1.0037	LR: 0.007086
Training Epoch: 141 [128/50000]	Loss: 0.9613	LR: 0.007086
Training Epoch: 141 [128/50000]	Loss: 0.9305	LR: 0.007086
Training Epoch: 141 [128/50000]	Loss: 1.0861	LR: 0.007086
Training Epoch: 141 [128/50000]	Loss: 0.9500	LR: 0.007086
Training Epoch: 141 [128/50000]	Loss: 0.9679	LR: 0.007086
Training Epoch: 141 [128/50000]	Loss: 0.8915	LR: 0.007086
Evaluating Network.....
Test set: Epoch: 141, Average loss: 0.0107, Top1Accuracy: 0.6242, Top3Accuracy: 0.8178, Top5Accuracy: 0.8802, Time consumed:1.11s

Training Epoch: 142 [128/50000]	Loss: 1.0226	LR: 0.006899
Training Epoch: 142 [128/50000]	Loss: 1.1917	LR: 0.006899
Training Epoch: 142 [128/50000]	Loss: 1.1422	LR: 0.006899
Training Epoch: 142 [128/50000]	Loss: 0.8017	LR: 0.006899
Training Epoch: 142 [128/50000]	Loss: 0.8654	LR: 0.006899
Training Epoch: 142 [128/50000]	Loss: 1.0035	LR: 0.006899
Training Epoch: 142 [128/50000]	Loss: 1.0930	LR: 0.006899
Training Epoch: 142 [128/50000]	Loss: 1.0482	LR: 0.006899
Training Epoch: 142 [128/50000]	Loss: 0.9289	LR: 0.006899
Training Epoch: 142 [128/50000]	Loss: 1.0451	LR: 0.006899
Evaluating Network.....
Test set: Epoch: 142, Average loss: 0.0108, Top1Accuracy: 0.6231, Top3Accuracy: 0.8185, Top5Accuracy: 0.8810, Time consumed:1.11s

Training Epoch: 143 [128/50000]	Loss: 0.9014	LR: 0.006717
Training Epoch: 143 [128/50000]	Loss: 1.1507	LR: 0.006717
Training Epoch: 143 [128/50000]	Loss: 0.7981	LR: 0.006717
Training Epoch: 143 [128/50000]	Loss: 0.8979	LR: 0.006717
Training Epoch: 143 [128/50000]	Loss: 0.8798	LR: 0.006717
Training Epoch: 143 [128/50000]	Loss: 1.0903	LR: 0.006717
Training Epoch: 143 [128/50000]	Loss: 0.9882	LR: 0.006717
Training Epoch: 143 [128/50000]	Loss: 0.9828	LR: 0.006717
Training Epoch: 143 [128/50000]	Loss: 0.9985	LR: 0.006717
Training Epoch: 143 [128/50000]	Loss: 0.9445	LR: 0.006717
Evaluating Network.....
Test set: Epoch: 143, Average loss: 0.0108, Top1Accuracy: 0.6214, Top3Accuracy: 0.8185, Top5Accuracy: 0.8813, Time consumed:1.10s

Training Epoch: 144 [128/50000]	Loss: 1.0679	LR: 0.006539
Training Epoch: 144 [128/50000]	Loss: 0.8993	LR: 0.006539
Training Epoch: 144 [128/50000]	Loss: 0.7699	LR: 0.006539
Training Epoch: 144 [128/50000]	Loss: 0.6964	LR: 0.006539
Training Epoch: 144 [128/50000]	Loss: 1.1093	LR: 0.006539
Training Epoch: 144 [128/50000]	Loss: 1.1634	LR: 0.006539
Training Epoch: 144 [128/50000]	Loss: 0.9006	LR: 0.006539
Training Epoch: 144 [128/50000]	Loss: 0.8894	LR: 0.006539
Training Epoch: 144 [128/50000]	Loss: 1.2085	LR: 0.006539
Training Epoch: 144 [128/50000]	Loss: 0.8746	LR: 0.006539
Evaluating Network.....
Test set: Epoch: 144, Average loss: 0.0107, Top1Accuracy: 0.6231, Top3Accuracy: 0.8208, Top5Accuracy: 0.8813, Time consumed:1.11s

Training Epoch: 145 [128/50000]	Loss: 1.0608	LR: 0.006367
Training Epoch: 145 [128/50000]	Loss: 0.8923	LR: 0.006367
Training Epoch: 145 [128/50000]	Loss: 1.0090	LR: 0.006367
Training Epoch: 145 [128/50000]	Loss: 0.8732	LR: 0.006367
Training Epoch: 145 [128/50000]	Loss: 1.0280	LR: 0.006367
Training Epoch: 145 [128/50000]	Loss: 0.8833	LR: 0.006367
Training Epoch: 145 [128/50000]	Loss: 1.1476	LR: 0.006367
Training Epoch: 145 [128/50000]	Loss: 1.1239	LR: 0.006367
Training Epoch: 145 [128/50000]	Loss: 0.9037	LR: 0.006367
Training Epoch: 145 [128/50000]	Loss: 0.8948	LR: 0.006367
Evaluating Network.....
Test set: Epoch: 145, Average loss: 0.0107, Top1Accuracy: 0.6237, Top3Accuracy: 0.8200, Top5Accuracy: 0.8808, Time consumed:1.11s

Training Epoch: 146 [128/50000]	Loss: 1.0097	LR: 0.006199
Training Epoch: 146 [128/50000]	Loss: 1.1436	LR: 0.006199
Training Epoch: 146 [128/50000]	Loss: 0.8953	LR: 0.006199
Training Epoch: 146 [128/50000]	Loss: 0.9760	LR: 0.006199
Training Epoch: 146 [128/50000]	Loss: 0.9925	LR: 0.006199
Training Epoch: 146 [128/50000]	Loss: 0.9739	LR: 0.006199
Training Epoch: 146 [128/50000]	Loss: 0.8482	LR: 0.006199
Training Epoch: 146 [128/50000]	Loss: 1.0570	LR: 0.006199
Training Epoch: 146 [128/50000]	Loss: 0.8775	LR: 0.006199
Training Epoch: 146 [128/50000]	Loss: 0.8756	LR: 0.006199
Evaluating Network.....
Test set: Epoch: 146, Average loss: 0.0109, Top1Accuracy: 0.6226, Top3Accuracy: 0.8163, Top5Accuracy: 0.8822, Time consumed:1.11s

Training Epoch: 147 [128/50000]	Loss: 0.9440	LR: 0.006035
Training Epoch: 147 [128/50000]	Loss: 0.9936	LR: 0.006035
Training Epoch: 147 [128/50000]	Loss: 1.1278	LR: 0.006035
Training Epoch: 147 [128/50000]	Loss: 1.0943	LR: 0.006035
Training Epoch: 147 [128/50000]	Loss: 1.0531	LR: 0.006035
Training Epoch: 147 [128/50000]	Loss: 1.1059	LR: 0.006035
Training Epoch: 147 [128/50000]	Loss: 0.8779	LR: 0.006035
Training Epoch: 147 [128/50000]	Loss: 1.0291	LR: 0.006035
Training Epoch: 147 [128/50000]	Loss: 1.1387	LR: 0.006035
Training Epoch: 147 [128/50000]	Loss: 0.9983	LR: 0.006035
Evaluating Network.....
Test set: Epoch: 147, Average loss: 0.0107, Top1Accuracy: 0.6253, Top3Accuracy: 0.8209, Top5Accuracy: 0.8807, Time consumed:1.12s

Training Epoch: 148 [128/50000]	Loss: 1.0620	LR: 0.005876
Training Epoch: 148 [128/50000]	Loss: 0.9259	LR: 0.005876
Training Epoch: 148 [128/50000]	Loss: 1.2379	LR: 0.005876
Training Epoch: 148 [128/50000]	Loss: 0.8805	LR: 0.005876
Training Epoch: 148 [128/50000]	Loss: 1.0650	LR: 0.005876
Training Epoch: 148 [128/50000]	Loss: 1.1153	LR: 0.005876
Training Epoch: 148 [128/50000]	Loss: 1.1725	LR: 0.005876
Training Epoch: 148 [128/50000]	Loss: 0.7737	LR: 0.005876
Training Epoch: 148 [128/50000]	Loss: 1.0090	LR: 0.005876
Training Epoch: 148 [128/50000]	Loss: 0.9556	LR: 0.005876
Evaluating Network.....
Test set: Epoch: 148, Average loss: 0.0106, Top1Accuracy: 0.6280, Top3Accuracy: 0.8235, Top5Accuracy: 0.8822, Time consumed:1.11s

Training Epoch: 149 [128/50000]	Loss: 1.1211	LR: 0.005721
Training Epoch: 149 [128/50000]	Loss: 1.0653	LR: 0.005721
Training Epoch: 149 [128/50000]	Loss: 1.0326	LR: 0.005721
Training Epoch: 149 [128/50000]	Loss: 0.9566	LR: 0.005721
Training Epoch: 149 [128/50000]	Loss: 0.9802	LR: 0.005721
Training Epoch: 149 [128/50000]	Loss: 0.8717	LR: 0.005721
Training Epoch: 149 [128/50000]	Loss: 1.0566	LR: 0.005721
Training Epoch: 149 [128/50000]	Loss: 0.8371	LR: 0.005721
Training Epoch: 149 [128/50000]	Loss: 0.9254	LR: 0.005721
Training Epoch: 149 [128/50000]	Loss: 1.0807	LR: 0.005721
Evaluating Network.....
Test set: Epoch: 149, Average loss: 0.0107, Top1Accuracy: 0.6250, Top3Accuracy: 0.8199, Top5Accuracy: 0.8822, Time consumed:1.09s

Training Epoch: 150 [128/50000]	Loss: 0.9078	LR: 0.005570
Training Epoch: 150 [128/50000]	Loss: 0.9280	LR: 0.005570
Training Epoch: 150 [128/50000]	Loss: 0.9246	LR: 0.005570
Training Epoch: 150 [128/50000]	Loss: 1.0443	LR: 0.005570
Training Epoch: 150 [128/50000]	Loss: 1.0037	LR: 0.005570
Training Epoch: 150 [128/50000]	Loss: 1.0167	LR: 0.005570
Training Epoch: 150 [128/50000]	Loss: 0.9675	LR: 0.005570
Training Epoch: 150 [128/50000]	Loss: 0.9270	LR: 0.005570
Training Epoch: 150 [128/50000]	Loss: 1.1949	LR: 0.005570
Training Epoch: 150 [128/50000]	Loss: 1.0235	LR: 0.005570
Evaluating Network.....
Test set: Epoch: 150, Average loss: 0.0109, Top1Accuracy: 0.6252, Top3Accuracy: 0.8191, Top5Accuracy: 0.8788, Time consumed:1.08s

Training Epoch: 151 [128/50000]	Loss: 0.9774	LR: 0.005423
Training Epoch: 151 [128/50000]	Loss: 1.0323	LR: 0.005423
Training Epoch: 151 [128/50000]	Loss: 1.0042	LR: 0.005423
Training Epoch: 151 [128/50000]	Loss: 0.8125	LR: 0.005423
Training Epoch: 151 [128/50000]	Loss: 1.1410	LR: 0.005423
Training Epoch: 151 [128/50000]	Loss: 0.8567	LR: 0.005423
Training Epoch: 151 [128/50000]	Loss: 0.9486	LR: 0.005423
Training Epoch: 151 [128/50000]	Loss: 1.0486	LR: 0.005423
Training Epoch: 151 [128/50000]	Loss: 1.0368	LR: 0.005423
Training Epoch: 151 [128/50000]	Loss: 0.9105	LR: 0.005423
Evaluating Network.....
Test set: Epoch: 151, Average loss: 0.0107, Top1Accuracy: 0.6263, Top3Accuracy: 0.8193, Top5Accuracy: 0.8814, Time consumed:1.10s

Training Epoch: 152 [128/50000]	Loss: 0.9929	LR: 0.005279
Training Epoch: 152 [128/50000]	Loss: 1.0895	LR: 0.005279
Training Epoch: 152 [128/50000]	Loss: 0.9596	LR: 0.005279
Training Epoch: 152 [128/50000]	Loss: 1.0913	LR: 0.005279
Training Epoch: 152 [128/50000]	Loss: 0.8569	LR: 0.005279
Training Epoch: 152 [128/50000]	Loss: 0.9678	LR: 0.005279
Training Epoch: 152 [128/50000]	Loss: 1.2434	LR: 0.005279
Training Epoch: 152 [128/50000]	Loss: 0.8420	LR: 0.005279
Training Epoch: 152 [128/50000]	Loss: 0.9965	LR: 0.005279
Training Epoch: 152 [128/50000]	Loss: 0.8475	LR: 0.005279
Evaluating Network.....
Test set: Epoch: 152, Average loss: 0.0106, Top1Accuracy: 0.6242, Top3Accuracy: 0.8230, Top5Accuracy: 0.8840, Time consumed:1.09s

Training Epoch: 153 [128/50000]	Loss: 0.9660	LR: 0.005140
Training Epoch: 153 [128/50000]	Loss: 1.0352	LR: 0.005140
Training Epoch: 153 [128/50000]	Loss: 1.0428	LR: 0.005140
Training Epoch: 153 [128/50000]	Loss: 0.7517	LR: 0.005140
Training Epoch: 153 [128/50000]	Loss: 0.8288	LR: 0.005140
Training Epoch: 153 [128/50000]	Loss: 0.8941	LR: 0.005140
Training Epoch: 153 [128/50000]	Loss: 0.8291	LR: 0.005140
Training Epoch: 153 [128/50000]	Loss: 1.0506	LR: 0.005140
Training Epoch: 153 [128/50000]	Loss: 0.9052	LR: 0.005140
Training Epoch: 153 [128/50000]	Loss: 0.9192	LR: 0.005140
Evaluating Network.....
Test set: Epoch: 153, Average loss: 0.0106, Top1Accuracy: 0.6262, Top3Accuracy: 0.8221, Top5Accuracy: 0.8825, Time consumed:1.11s

Training Epoch: 154 [128/50000]	Loss: 0.8566	LR: 0.005004
Training Epoch: 154 [128/50000]	Loss: 1.0341	LR: 0.005004
Training Epoch: 154 [128/50000]	Loss: 0.9077	LR: 0.005004
Training Epoch: 154 [128/50000]	Loss: 0.8021	LR: 0.005004
Training Epoch: 154 [128/50000]	Loss: 1.0370	LR: 0.005004
Training Epoch: 154 [128/50000]	Loss: 0.9932	LR: 0.005004
Training Epoch: 154 [128/50000]	Loss: 0.9605	LR: 0.005004
Training Epoch: 154 [128/50000]	Loss: 1.0770	LR: 0.005004
Training Epoch: 154 [128/50000]	Loss: 0.9088	LR: 0.005004
Training Epoch: 154 [128/50000]	Loss: 0.9632	LR: 0.005004
Evaluating Network.....
Test set: Epoch: 154, Average loss: 0.0106, Top1Accuracy: 0.6271, Top3Accuracy: 0.8233, Top5Accuracy: 0.8847, Time consumed:1.10s

Training Epoch: 155 [128/50000]	Loss: 1.0524	LR: 0.004872
Training Epoch: 155 [128/50000]	Loss: 0.9306	LR: 0.004872
Training Epoch: 155 [128/50000]	Loss: 1.0854	LR: 0.004872
Training Epoch: 155 [128/50000]	Loss: 0.7375	LR: 0.004872
Training Epoch: 155 [128/50000]	Loss: 1.1243	LR: 0.004872
Training Epoch: 155 [128/50000]	Loss: 0.8432	LR: 0.004872
Training Epoch: 155 [128/50000]	Loss: 0.9426	LR: 0.004872
Training Epoch: 155 [128/50000]	Loss: 0.8169	LR: 0.004872
Training Epoch: 155 [128/50000]	Loss: 1.0606	LR: 0.004872
Training Epoch: 155 [128/50000]	Loss: 1.0886	LR: 0.004872
Evaluating Network.....
Test set: Epoch: 155, Average loss: 0.0107, Top1Accuracy: 0.6251, Top3Accuracy: 0.8205, Top5Accuracy: 0.8838, Time consumed:1.10s

Training Epoch: 156 [128/50000]	Loss: 1.0293	LR: 0.004744
Training Epoch: 156 [128/50000]	Loss: 1.2571	LR: 0.004744
Training Epoch: 156 [128/50000]	Loss: 0.8894	LR: 0.004744
Training Epoch: 156 [128/50000]	Loss: 0.9375	LR: 0.004744
Training Epoch: 156 [128/50000]	Loss: 0.9814	LR: 0.004744
Training Epoch: 156 [128/50000]	Loss: 1.0118	LR: 0.004744
Training Epoch: 156 [128/50000]	Loss: 1.0895	LR: 0.004744
Training Epoch: 156 [128/50000]	Loss: 1.3476	LR: 0.004744
Training Epoch: 156 [128/50000]	Loss: 1.0601	LR: 0.004744
Training Epoch: 156 [128/50000]	Loss: 0.9219	LR: 0.004744
Evaluating Network.....
Test set: Epoch: 156, Average loss: 0.0106, Top1Accuracy: 0.6235, Top3Accuracy: 0.8191, Top5Accuracy: 0.8834, Time consumed:1.09s

Training Epoch: 157 [128/50000]	Loss: 0.9003	LR: 0.004618
Training Epoch: 157 [128/50000]	Loss: 0.9971	LR: 0.004618
Training Epoch: 157 [128/50000]	Loss: 1.1247	LR: 0.004618
Training Epoch: 157 [128/50000]	Loss: 1.0345	LR: 0.004618
Training Epoch: 157 [128/50000]	Loss: 0.9063	LR: 0.004618
Training Epoch: 157 [128/50000]	Loss: 1.1908	LR: 0.004618
Training Epoch: 157 [128/50000]	Loss: 0.8572	LR: 0.004618
Training Epoch: 157 [128/50000]	Loss: 1.0541	LR: 0.004618
Training Epoch: 157 [128/50000]	Loss: 1.0360	LR: 0.004618
Training Epoch: 157 [128/50000]	Loss: 1.0776	LR: 0.004618
Evaluating Network.....
Test set: Epoch: 157, Average loss: 0.0106, Top1Accuracy: 0.6286, Top3Accuracy: 0.8233, Top5Accuracy: 0.8854, Time consumed:1.11s

Training Epoch: 158 [128/50000]	Loss: 0.9152	LR: 0.004496
Training Epoch: 158 [128/50000]	Loss: 0.8091	LR: 0.004496
Training Epoch: 158 [128/50000]	Loss: 0.8749	LR: 0.004496
Training Epoch: 158 [128/50000]	Loss: 0.8523	LR: 0.004496
Training Epoch: 158 [128/50000]	Loss: 1.0570	LR: 0.004496
Training Epoch: 158 [128/50000]	Loss: 0.8844	LR: 0.004496
Training Epoch: 158 [128/50000]	Loss: 0.9072	LR: 0.004496
Training Epoch: 158 [128/50000]	Loss: 1.0565	LR: 0.004496
Training Epoch: 158 [128/50000]	Loss: 0.9247	LR: 0.004496
Training Epoch: 158 [128/50000]	Loss: 1.0330	LR: 0.004496
Evaluating Network.....
Test set: Epoch: 158, Average loss: 0.0106, Top1Accuracy: 0.6254, Top3Accuracy: 0.8212, Top5Accuracy: 0.8848, Time consumed:1.10s

Training Epoch: 159 [128/50000]	Loss: 1.0502	LR: 0.004378
Training Epoch: 159 [128/50000]	Loss: 0.9365	LR: 0.004378
Training Epoch: 159 [128/50000]	Loss: 0.9129	LR: 0.004378
Training Epoch: 159 [128/50000]	Loss: 1.0440	LR: 0.004378
Training Epoch: 159 [128/50000]	Loss: 1.0193	LR: 0.004378
Training Epoch: 159 [128/50000]	Loss: 0.9864	LR: 0.004378
Training Epoch: 159 [128/50000]	Loss: 1.1408	LR: 0.004378
Training Epoch: 159 [128/50000]	Loss: 0.8836	LR: 0.004378
Training Epoch: 159 [128/50000]	Loss: 0.9841	LR: 0.004378
Training Epoch: 159 [128/50000]	Loss: 1.0599	LR: 0.004378
Evaluating Network.....
Test set: Epoch: 159, Average loss: 0.0107, Top1Accuracy: 0.6257, Top3Accuracy: 0.8208, Top5Accuracy: 0.8818, Time consumed:1.11s

Training Epoch: 160 [128/50000]	Loss: 1.0329	LR: 0.004262
Training Epoch: 160 [128/50000]	Loss: 0.8206	LR: 0.004262
Training Epoch: 160 [128/50000]	Loss: 0.8517	LR: 0.004262
Training Epoch: 160 [128/50000]	Loss: 1.0044	LR: 0.004262
Training Epoch: 160 [128/50000]	Loss: 0.9921	LR: 0.004262
Training Epoch: 160 [128/50000]	Loss: 1.2291	LR: 0.004262
Training Epoch: 160 [128/50000]	Loss: 0.8275	LR: 0.004262
Training Epoch: 160 [128/50000]	Loss: 0.8393	LR: 0.004262
Training Epoch: 160 [128/50000]	Loss: 1.0182	LR: 0.004262
Training Epoch: 160 [128/50000]	Loss: 0.9521	LR: 0.004262
Evaluating Network.....
Test set: Epoch: 160, Average loss: 0.0107, Top1Accuracy: 0.6270, Top3Accuracy: 0.8229, Top5Accuracy: 0.8841, Time consumed:1.11s

Training Epoch: 161 [128/50000]	Loss: 0.8591	LR: 0.004150
Training Epoch: 161 [128/50000]	Loss: 1.0045	LR: 0.004150
Training Epoch: 161 [128/50000]	Loss: 0.9600	LR: 0.004150
Training Epoch: 161 [128/50000]	Loss: 0.8733	LR: 0.004150
Training Epoch: 161 [128/50000]	Loss: 0.7415	LR: 0.004150
Training Epoch: 161 [128/50000]	Loss: 0.9551	LR: 0.004150
Training Epoch: 161 [128/50000]	Loss: 0.9179	LR: 0.004150
Training Epoch: 161 [128/50000]	Loss: 0.9054	LR: 0.004150
Training Epoch: 161 [128/50000]	Loss: 0.8497	LR: 0.004150
Training Epoch: 161 [128/50000]	Loss: 0.8003	LR: 0.004150
Evaluating Network.....
Test set: Epoch: 161, Average loss: 0.0106, Top1Accuracy: 0.6262, Top3Accuracy: 0.8211, Top5Accuracy: 0.8846, Time consumed:1.09s

Training Epoch: 162 [128/50000]	Loss: 0.9254	LR: 0.004040
Training Epoch: 162 [128/50000]	Loss: 0.7816	LR: 0.004040
Training Epoch: 162 [128/50000]	Loss: 0.9121	LR: 0.004040
Training Epoch: 162 [128/50000]	Loss: 0.8933	LR: 0.004040
Training Epoch: 162 [128/50000]	Loss: 0.9825	LR: 0.004040
Training Epoch: 162 [128/50000]	Loss: 0.8349	LR: 0.004040
Training Epoch: 162 [128/50000]	Loss: 0.9108	LR: 0.004040
Training Epoch: 162 [128/50000]	Loss: 0.7745	LR: 0.004040
Training Epoch: 162 [128/50000]	Loss: 0.8365	LR: 0.004040
Training Epoch: 162 [128/50000]	Loss: 0.9848	LR: 0.004040
Evaluating Network.....
Test set: Epoch: 162, Average loss: 0.0106, Top1Accuracy: 0.6267, Top3Accuracy: 0.8218, Top5Accuracy: 0.8847, Time consumed:1.09s

Training Epoch: 163 [128/50000]	Loss: 0.9455	LR: 0.003933
Training Epoch: 163 [128/50000]	Loss: 0.9551	LR: 0.003933
Training Epoch: 163 [128/50000]	Loss: 0.8855	LR: 0.003933
Training Epoch: 163 [128/50000]	Loss: 1.0491	LR: 0.003933
Training Epoch: 163 [128/50000]	Loss: 0.9811	LR: 0.003933
Training Epoch: 163 [128/50000]	Loss: 0.7618	LR: 0.003933
Training Epoch: 163 [128/50000]	Loss: 1.0194	LR: 0.003933
Training Epoch: 163 [128/50000]	Loss: 1.0688	LR: 0.003933
Training Epoch: 163 [128/50000]	Loss: 0.8378	LR: 0.003933
Training Epoch: 163 [128/50000]	Loss: 1.0402	LR: 0.003933
Evaluating Network.....
Test set: Epoch: 163, Average loss: 0.0106, Top1Accuracy: 0.6262, Top3Accuracy: 0.8231, Top5Accuracy: 0.8860, Time consumed:1.11s

Training Epoch: 164 [128/50000]	Loss: 0.9168	LR: 0.003830
Training Epoch: 164 [128/50000]	Loss: 0.9528	LR: 0.003830
Training Epoch: 164 [128/50000]	Loss: 0.8660	LR: 0.003830
Training Epoch: 164 [128/50000]	Loss: 1.0436	LR: 0.003830
Training Epoch: 164 [128/50000]	Loss: 1.0580	LR: 0.003830
Training Epoch: 164 [128/50000]	Loss: 0.7149	LR: 0.003830
Training Epoch: 164 [128/50000]	Loss: 1.0727	LR: 0.003830
Training Epoch: 164 [128/50000]	Loss: 1.0619	LR: 0.003830
Training Epoch: 164 [128/50000]	Loss: 0.9668	LR: 0.003830
Training Epoch: 164 [128/50000]	Loss: 1.0355	LR: 0.003830
Evaluating Network.....
Test set: Epoch: 164, Average loss: 0.0106, Top1Accuracy: 0.6257, Top3Accuracy: 0.8232, Top5Accuracy: 0.8853, Time consumed:1.10s

Training Epoch: 165 [128/50000]	Loss: 0.9997	LR: 0.003728
Training Epoch: 165 [128/50000]	Loss: 0.8558	LR: 0.003728
Training Epoch: 165 [128/50000]	Loss: 0.8806	LR: 0.003728
Training Epoch: 165 [128/50000]	Loss: 0.7482	LR: 0.003728
Training Epoch: 165 [128/50000]	Loss: 0.8459	LR: 0.003728
Training Epoch: 165 [128/50000]	Loss: 0.7900	LR: 0.003728
Training Epoch: 165 [128/50000]	Loss: 0.8146	LR: 0.003728
Training Epoch: 165 [128/50000]	Loss: 1.0413	LR: 0.003728
Training Epoch: 165 [128/50000]	Loss: 0.8579	LR: 0.003728
Training Epoch: 165 [128/50000]	Loss: 0.9375	LR: 0.003728
Evaluating Network.....
Test set: Epoch: 165, Average loss: 0.0106, Top1Accuracy: 0.6282, Top3Accuracy: 0.8237, Top5Accuracy: 0.8842, Time consumed:1.08s

Training Epoch: 166 [128/50000]	Loss: 0.8727	LR: 0.003630
Training Epoch: 166 [128/50000]	Loss: 0.7951	LR: 0.003630
Training Epoch: 166 [128/50000]	Loss: 0.9531	LR: 0.003630
Training Epoch: 166 [128/50000]	Loss: 1.0002	LR: 0.003630
Training Epoch: 166 [128/50000]	Loss: 0.9668	LR: 0.003630
Training Epoch: 166 [128/50000]	Loss: 0.9173	LR: 0.003630
Training Epoch: 166 [128/50000]	Loss: 1.0158	LR: 0.003630
Training Epoch: 166 [128/50000]	Loss: 1.0319	LR: 0.003630
Training Epoch: 166 [128/50000]	Loss: 1.0083	LR: 0.003630
Training Epoch: 166 [128/50000]	Loss: 0.9928	LR: 0.003630
Evaluating Network.....
Test set: Epoch: 166, Average loss: 0.0106, Top1Accuracy: 0.6264, Top3Accuracy: 0.8231, Top5Accuracy: 0.8851, Time consumed:1.08s

Training Epoch: 167 [128/50000]	Loss: 0.9190	LR: 0.003534
Training Epoch: 167 [128/50000]	Loss: 0.8757	LR: 0.003534
Training Epoch: 167 [128/50000]	Loss: 1.0219	LR: 0.003534
Training Epoch: 167 [128/50000]	Loss: 0.9039	LR: 0.003534
Training Epoch: 167 [128/50000]	Loss: 0.7953	LR: 0.003534
Training Epoch: 167 [128/50000]	Loss: 0.9612	LR: 0.003534
Training Epoch: 167 [128/50000]	Loss: 0.8769	LR: 0.003534
Training Epoch: 167 [128/50000]	Loss: 0.8780	LR: 0.003534
Training Epoch: 167 [128/50000]	Loss: 1.0777	LR: 0.003534
Training Epoch: 167 [128/50000]	Loss: 0.7064	LR: 0.003534
Evaluating Network.....
Test set: Epoch: 167, Average loss: 0.0106, Top1Accuracy: 0.6261, Top3Accuracy: 0.8218, Top5Accuracy: 0.8834, Time consumed:1.13s

Training Epoch: 168 [128/50000]	Loss: 0.9077	LR: 0.003441
Training Epoch: 168 [128/50000]	Loss: 0.8413	LR: 0.003441
Training Epoch: 168 [128/50000]	Loss: 0.7858	LR: 0.003441
Training Epoch: 168 [128/50000]	Loss: 0.8776	LR: 0.003441
Training Epoch: 168 [128/50000]	Loss: 0.9556	LR: 0.003441
Training Epoch: 168 [128/50000]	Loss: 1.0341	LR: 0.003441
Training Epoch: 168 [128/50000]	Loss: 0.9518	LR: 0.003441
Training Epoch: 168 [128/50000]	Loss: 1.0039	LR: 0.003441
Training Epoch: 168 [128/50000]	Loss: 1.0370	LR: 0.003441
Training Epoch: 168 [128/50000]	Loss: 1.0577	LR: 0.003441
Evaluating Network.....
Test set: Epoch: 168, Average loss: 0.0106, Top1Accuracy: 0.6261, Top3Accuracy: 0.8234, Top5Accuracy: 0.8835, Time consumed:1.11s

Training Epoch: 169 [128/50000]	Loss: 0.8935	LR: 0.003350
Training Epoch: 169 [128/50000]	Loss: 0.8603	LR: 0.003350
Training Epoch: 169 [128/50000]	Loss: 0.9520	LR: 0.003350
Training Epoch: 169 [128/50000]	Loss: 0.8554	LR: 0.003350
Training Epoch: 169 [128/50000]	Loss: 0.8802	LR: 0.003350
Training Epoch: 169 [128/50000]	Loss: 0.9427	LR: 0.003350
Training Epoch: 169 [128/50000]	Loss: 0.8234	LR: 0.003350
Training Epoch: 169 [128/50000]	Loss: 0.8068	LR: 0.003350
Training Epoch: 169 [128/50000]	Loss: 0.8830	LR: 0.003350
Training Epoch: 169 [128/50000]	Loss: 1.0915	LR: 0.003350
Evaluating Network.....
Test set: Epoch: 169, Average loss: 0.0106, Top1Accuracy: 0.6300, Top3Accuracy: 0.8202, Top5Accuracy: 0.8835, Time consumed:1.10s

Training Epoch: 170 [128/50000]	Loss: 0.9479	LR: 0.003262
Training Epoch: 170 [128/50000]	Loss: 0.9573	LR: 0.003262
Training Epoch: 170 [128/50000]	Loss: 0.9425	LR: 0.003262
Training Epoch: 170 [128/50000]	Loss: 0.9878	LR: 0.003262
Training Epoch: 170 [128/50000]	Loss: 1.0666	LR: 0.003262
Training Epoch: 170 [128/50000]	Loss: 0.9072	LR: 0.003262
Training Epoch: 170 [128/50000]	Loss: 0.9174	LR: 0.003262
Training Epoch: 170 [128/50000]	Loss: 0.8214	LR: 0.003262
Training Epoch: 170 [128/50000]	Loss: 0.8447	LR: 0.003262
Training Epoch: 170 [128/50000]	Loss: 0.9219	LR: 0.003262
Evaluating Network.....
Test set: Epoch: 170, Average loss: 0.0107, Top1Accuracy: 0.6280, Top3Accuracy: 0.8233, Top5Accuracy: 0.8841, Time consumed:1.12s

Training Epoch: 171 [128/50000]	Loss: 0.9503	LR: 0.003176
Training Epoch: 171 [128/50000]	Loss: 0.9354	LR: 0.003176
Training Epoch: 171 [128/50000]	Loss: 1.0659	LR: 0.003176
Training Epoch: 171 [128/50000]	Loss: 0.7401	LR: 0.003176
Training Epoch: 171 [128/50000]	Loss: 0.8847	LR: 0.003176
Training Epoch: 171 [128/50000]	Loss: 0.7587	LR: 0.003176
Training Epoch: 171 [128/50000]	Loss: 1.0672	LR: 0.003176
Training Epoch: 171 [128/50000]	Loss: 1.0449	LR: 0.003176
Training Epoch: 171 [128/50000]	Loss: 0.9046	LR: 0.003176
Training Epoch: 171 [128/50000]	Loss: 1.0047	LR: 0.003176
Evaluating Network.....
Test set: Epoch: 171, Average loss: 0.0105, Top1Accuracy: 0.6307, Top3Accuracy: 0.8226, Top5Accuracy: 0.8841, Time consumed:1.10s

Training Epoch: 172 [128/50000]	Loss: 0.8606	LR: 0.003092
Training Epoch: 172 [128/50000]	Loss: 0.9083	LR: 0.003092
Training Epoch: 172 [128/50000]	Loss: 0.9187	LR: 0.003092
Training Epoch: 172 [128/50000]	Loss: 0.8651	LR: 0.003092
Training Epoch: 172 [128/50000]	Loss: 1.1595	LR: 0.003092
Training Epoch: 172 [128/50000]	Loss: 0.7586	LR: 0.003092
Training Epoch: 172 [128/50000]	Loss: 0.8914	LR: 0.003092
Training Epoch: 172 [128/50000]	Loss: 0.7992	LR: 0.003092
Training Epoch: 172 [128/50000]	Loss: 1.0676	LR: 0.003092
Training Epoch: 172 [128/50000]	Loss: 0.9146	LR: 0.003092
Evaluating Network.....
Test set: Epoch: 172, Average loss: 0.0106, Top1Accuracy: 0.6245, Top3Accuracy: 0.8227, Top5Accuracy: 0.8838, Time consumed:1.13s

Training Epoch: 173 [128/50000]	Loss: 0.9645	LR: 0.003010
Training Epoch: 173 [128/50000]	Loss: 0.9709	LR: 0.003010
Training Epoch: 173 [128/50000]	Loss: 1.0530	LR: 0.003010
Training Epoch: 173 [128/50000]	Loss: 0.8992	LR: 0.003010
Training Epoch: 173 [128/50000]	Loss: 0.8686	LR: 0.003010
Training Epoch: 173 [128/50000]	Loss: 0.9448	LR: 0.003010
Training Epoch: 173 [128/50000]	Loss: 0.8815	LR: 0.003010
Training Epoch: 173 [128/50000]	Loss: 1.0151	LR: 0.003010
Training Epoch: 173 [128/50000]	Loss: 0.8169	LR: 0.003010
Training Epoch: 173 [128/50000]	Loss: 1.0243	LR: 0.003010
Evaluating Network.....
Test set: Epoch: 173, Average loss: 0.0106, Top1Accuracy: 0.6279, Top3Accuracy: 0.8239, Top5Accuracy: 0.8840, Time consumed:1.11s

Training Epoch: 174 [128/50000]	Loss: 0.7572	LR: 0.002931
Training Epoch: 174 [128/50000]	Loss: 1.0715	LR: 0.002931
Training Epoch: 174 [128/50000]	Loss: 0.8041	LR: 0.002931
Training Epoch: 174 [128/50000]	Loss: 0.8117	LR: 0.002931
Training Epoch: 174 [128/50000]	Loss: 0.9275	LR: 0.002931
Training Epoch: 174 [128/50000]	Loss: 0.6987	LR: 0.002931
Training Epoch: 174 [128/50000]	Loss: 0.9739	LR: 0.002931
Training Epoch: 174 [128/50000]	Loss: 0.8649	LR: 0.002931
Training Epoch: 174 [128/50000]	Loss: 0.9223	LR: 0.002931
Training Epoch: 174 [128/50000]	Loss: 1.0663	LR: 0.002931
Evaluating Network.....
Test set: Epoch: 174, Average loss: 0.0106, Top1Accuracy: 0.6315, Top3Accuracy: 0.8223, Top5Accuracy: 0.8852, Time consumed:1.10s

Training Epoch: 175 [128/50000]	Loss: 0.9850	LR: 0.002853
Training Epoch: 175 [128/50000]	Loss: 0.9592	LR: 0.002853
Training Epoch: 175 [128/50000]	Loss: 0.7366	LR: 0.002853
Training Epoch: 175 [128/50000]	Loss: 0.9796	LR: 0.002853
Training Epoch: 175 [128/50000]	Loss: 0.9567	LR: 0.002853
Training Epoch: 175 [128/50000]	Loss: 0.9684	LR: 0.002853
Training Epoch: 175 [128/50000]	Loss: 1.0884	LR: 0.002853
Training Epoch: 175 [128/50000]	Loss: 0.8685	LR: 0.002853
Training Epoch: 175 [128/50000]	Loss: 0.9958	LR: 0.002853
Training Epoch: 175 [128/50000]	Loss: 0.9721	LR: 0.002853
Evaluating Network.....
Test set: Epoch: 175, Average loss: 0.0107, Top1Accuracy: 0.6289, Top3Accuracy: 0.8243, Top5Accuracy: 0.8826, Time consumed:1.12s

Training Epoch: 176 [128/50000]	Loss: 0.7973	LR: 0.002778
Training Epoch: 176 [128/50000]	Loss: 0.9177	LR: 0.002778
Training Epoch: 176 [128/50000]	Loss: 0.9009	LR: 0.002778
Training Epoch: 176 [128/50000]	Loss: 0.8738	LR: 0.002778
Training Epoch: 176 [128/50000]	Loss: 0.8100	LR: 0.002778
Training Epoch: 176 [128/50000]	Loss: 0.8470	LR: 0.002778
Training Epoch: 176 [128/50000]	Loss: 0.7112	LR: 0.002778
Training Epoch: 176 [128/50000]	Loss: 1.0202	LR: 0.002778
Training Epoch: 176 [128/50000]	Loss: 0.8949	LR: 0.002778
Training Epoch: 176 [128/50000]	Loss: 0.9121	LR: 0.002778
Evaluating Network.....
Test set: Epoch: 176, Average loss: 0.0106, Top1Accuracy: 0.6301, Top3Accuracy: 0.8245, Top5Accuracy: 0.8845, Time consumed:1.10s

Training Epoch: 177 [128/50000]	Loss: 1.1387	LR: 0.002705
Training Epoch: 177 [128/50000]	Loss: 0.9798	LR: 0.002705
Training Epoch: 177 [128/50000]	Loss: 1.0225	LR: 0.002705
Training Epoch: 177 [128/50000]	Loss: 0.7946	LR: 0.002705
Training Epoch: 177 [128/50000]	Loss: 1.0414	LR: 0.002705
Training Epoch: 177 [128/50000]	Loss: 1.1377	LR: 0.002705
Training Epoch: 177 [128/50000]	Loss: 0.9439	LR: 0.002705
Training Epoch: 177 [128/50000]	Loss: 1.2178	LR: 0.002705
Training Epoch: 177 [128/50000]	Loss: 0.9408	LR: 0.002705
Training Epoch: 177 [128/50000]	Loss: 0.8481	LR: 0.002705
Evaluating Network.....
Test set: Epoch: 177, Average loss: 0.0105, Top1Accuracy: 0.6272, Top3Accuracy: 0.8253, Top5Accuracy: 0.8859, Time consumed:1.10s

Training Epoch: 178 [128/50000]	Loss: 0.9174	LR: 0.002633
Training Epoch: 178 [128/50000]	Loss: 0.8727	LR: 0.002633
Training Epoch: 178 [128/50000]	Loss: 0.9251	LR: 0.002633
Training Epoch: 178 [128/50000]	Loss: 0.9324	LR: 0.002633
Training Epoch: 178 [128/50000]	Loss: 0.7678	LR: 0.002633
Training Epoch: 178 [128/50000]	Loss: 0.8957	LR: 0.002633
Training Epoch: 178 [128/50000]	Loss: 0.8794	LR: 0.002633
Training Epoch: 178 [128/50000]	Loss: 1.0837	LR: 0.002633
Training Epoch: 178 [128/50000]	Loss: 1.0633	LR: 0.002633
Training Epoch: 178 [128/50000]	Loss: 0.8923	LR: 0.002633
Evaluating Network.....
Test set: Epoch: 178, Average loss: 0.0106, Top1Accuracy: 0.6266, Top3Accuracy: 0.8248, Top5Accuracy: 0.8846, Time consumed:1.10s

Training Epoch: 179 [128/50000]	Loss: 0.7650	LR: 0.002564
Training Epoch: 179 [128/50000]	Loss: 0.7752	LR: 0.002564
Training Epoch: 179 [128/50000]	Loss: 0.7434	LR: 0.002564
Training Epoch: 179 [128/50000]	Loss: 0.8173	LR: 0.002564
Training Epoch: 179 [128/50000]	Loss: 0.8867	LR: 0.002564
Training Epoch: 179 [128/50000]	Loss: 1.0188	LR: 0.002564
Training Epoch: 179 [128/50000]	Loss: 0.9358	LR: 0.002564
Training Epoch: 179 [128/50000]	Loss: 0.7799	LR: 0.002564
Training Epoch: 179 [128/50000]	Loss: 0.8760	LR: 0.002564
Training Epoch: 179 [128/50000]	Loss: 0.8263	LR: 0.002564
Evaluating Network.....
Test set: Epoch: 179, Average loss: 0.0107, Top1Accuracy: 0.6282, Top3Accuracy: 0.8235, Top5Accuracy: 0.8841, Time consumed:1.11s

Training Epoch: 180 [128/50000]	Loss: 0.8390	LR: 0.002496
Training Epoch: 180 [128/50000]	Loss: 0.8019	LR: 0.002496
Training Epoch: 180 [128/50000]	Loss: 0.7892	LR: 0.002496
Training Epoch: 180 [128/50000]	Loss: 0.9262	LR: 0.002496
Training Epoch: 180 [128/50000]	Loss: 1.0109	LR: 0.002496
Training Epoch: 180 [128/50000]	Loss: 0.9001	LR: 0.002496
Training Epoch: 180 [128/50000]	Loss: 0.8334	LR: 0.002496
Training Epoch: 180 [128/50000]	Loss: 0.6808	LR: 0.002496
Training Epoch: 180 [128/50000]	Loss: 0.8511	LR: 0.002496
Training Epoch: 180 [128/50000]	Loss: 0.9905	LR: 0.002496
Evaluating Network.....
Test set: Epoch: 180, Average loss: 0.0106, Top1Accuracy: 0.6269, Top3Accuracy: 0.8241, Top5Accuracy: 0.8839, Time consumed:1.12s

Training Epoch: 181 [128/50000]	Loss: 1.0325	LR: 0.002430
Training Epoch: 181 [128/50000]	Loss: 0.9490	LR: 0.002430
Training Epoch: 181 [128/50000]	Loss: 0.9657	LR: 0.002430
Training Epoch: 181 [128/50000]	Loss: 0.8432	LR: 0.002430
Training Epoch: 181 [128/50000]	Loss: 1.0176	LR: 0.002430
Training Epoch: 181 [128/50000]	Loss: 0.9193	LR: 0.002430
Training Epoch: 181 [128/50000]	Loss: 0.7527	LR: 0.002430
Training Epoch: 181 [128/50000]	Loss: 1.0012	LR: 0.002430
Training Epoch: 181 [128/50000]	Loss: 0.8262	LR: 0.002430
Training Epoch: 181 [128/50000]	Loss: 0.8852	LR: 0.002430
Evaluating Network.....
Test set: Epoch: 181, Average loss: 0.0106, Top1Accuracy: 0.6285, Top3Accuracy: 0.8252, Top5Accuracy: 0.8841, Time consumed:1.10s

Training Epoch: 182 [128/50000]	Loss: 1.0181	LR: 0.002366
Training Epoch: 182 [128/50000]	Loss: 1.0345	LR: 0.002366
Training Epoch: 182 [128/50000]	Loss: 0.9808	LR: 0.002366
Training Epoch: 182 [128/50000]	Loss: 1.0578	LR: 0.002366
Training Epoch: 182 [128/50000]	Loss: 0.9567	LR: 0.002366
Training Epoch: 182 [128/50000]	Loss: 0.7755	LR: 0.002366
Training Epoch: 182 [128/50000]	Loss: 0.9441	LR: 0.002366
Training Epoch: 182 [128/50000]	Loss: 1.0504	LR: 0.002366
Training Epoch: 182 [128/50000]	Loss: 1.0757	LR: 0.002366
Training Epoch: 182 [128/50000]	Loss: 0.9574	LR: 0.002366
Evaluating Network.....
Test set: Epoch: 182, Average loss: 0.0106, Top1Accuracy: 0.6300, Top3Accuracy: 0.8240, Top5Accuracy: 0.8820, Time consumed:1.10s

Training Epoch: 183 [128/50000]	Loss: 0.9922	LR: 0.002303
Training Epoch: 183 [128/50000]	Loss: 0.8597	LR: 0.002303
Training Epoch: 183 [128/50000]	Loss: 0.8369	LR: 0.002303
Training Epoch: 183 [128/50000]	Loss: 0.6951	LR: 0.002303
Training Epoch: 183 [128/50000]	Loss: 0.9089	LR: 0.002303
Training Epoch: 183 [128/50000]	Loss: 1.0342	LR: 0.002303
Training Epoch: 183 [128/50000]	Loss: 1.1054	LR: 0.002303
Training Epoch: 183 [128/50000]	Loss: 0.5985	LR: 0.002303
Training Epoch: 183 [128/50000]	Loss: 1.0067	LR: 0.002303
Training Epoch: 183 [128/50000]	Loss: 0.7106	LR: 0.002303
Evaluating Network.....
Test set: Epoch: 183, Average loss: 0.0107, Top1Accuracy: 0.6305, Top3Accuracy: 0.8242, Top5Accuracy: 0.8837, Time consumed:1.11s

Training Epoch: 184 [128/50000]	Loss: 0.8569	LR: 0.002243
Training Epoch: 184 [128/50000]	Loss: 1.0827	LR: 0.002243
Training Epoch: 184 [128/50000]	Loss: 0.9323	LR: 0.002243
Training Epoch: 184 [128/50000]	Loss: 0.9971	LR: 0.002243
Training Epoch: 184 [128/50000]	Loss: 0.9695	LR: 0.002243
Training Epoch: 184 [128/50000]	Loss: 0.9420	LR: 0.002243
Training Epoch: 184 [128/50000]	Loss: 0.8785	LR: 0.002243
Training Epoch: 184 [128/50000]	Loss: 0.6556	LR: 0.002243
Training Epoch: 184 [128/50000]	Loss: 1.0565	LR: 0.002243
Training Epoch: 184 [128/50000]	Loss: 0.8571	LR: 0.002243
Evaluating Network.....
Test set: Epoch: 184, Average loss: 0.0106, Top1Accuracy: 0.6286, Top3Accuracy: 0.8254, Top5Accuracy: 0.8846, Time consumed:1.12s

Training Epoch: 185 [128/50000]	Loss: 0.9231	LR: 0.002183
Training Epoch: 185 [128/50000]	Loss: 0.8669	LR: 0.002183
Training Epoch: 185 [128/50000]	Loss: 0.9748	LR: 0.002183
Training Epoch: 185 [128/50000]	Loss: 0.6645	LR: 0.002183
Training Epoch: 185 [128/50000]	Loss: 0.9453	LR: 0.002183
Training Epoch: 185 [128/50000]	Loss: 0.9382	LR: 0.002183
Training Epoch: 185 [128/50000]	Loss: 0.8978	LR: 0.002183
Training Epoch: 185 [128/50000]	Loss: 0.6898	LR: 0.002183
Training Epoch: 185 [128/50000]	Loss: 0.9437	LR: 0.002183
Training Epoch: 185 [128/50000]	Loss: 0.8620	LR: 0.002183
Evaluating Network.....
Test set: Epoch: 185, Average loss: 0.0105, Top1Accuracy: 0.6284, Top3Accuracy: 0.8260, Top5Accuracy: 0.8845, Time consumed:1.09s

Training Epoch: 186 [128/50000]	Loss: 0.9861	LR: 0.002126
Training Epoch: 186 [128/50000]	Loss: 0.7612	LR: 0.002126
Training Epoch: 186 [128/50000]	Loss: 0.8441	LR: 0.002126
Training Epoch: 186 [128/50000]	Loss: 1.0537	LR: 0.002126
Training Epoch: 186 [128/50000]	Loss: 0.9585	LR: 0.002126
Training Epoch: 186 [128/50000]	Loss: 0.9783	LR: 0.002126
Training Epoch: 186 [128/50000]	Loss: 0.9176	LR: 0.002126
Training Epoch: 186 [128/50000]	Loss: 1.0345	LR: 0.002126
Training Epoch: 186 [128/50000]	Loss: 0.8203	LR: 0.002126
Training Epoch: 186 [128/50000]	Loss: 0.8971	LR: 0.002126
Evaluating Network.....
Test set: Epoch: 186, Average loss: 0.0106, Top1Accuracy: 0.6292, Top3Accuracy: 0.8256, Top5Accuracy: 0.8844, Time consumed:1.11s

Training Epoch: 187 [128/50000]	Loss: 0.7984	LR: 0.002070
Training Epoch: 187 [128/50000]	Loss: 0.9148	LR: 0.002070
Training Epoch: 187 [128/50000]	Loss: 0.8164	LR: 0.002070
Training Epoch: 187 [128/50000]	Loss: 0.7861	LR: 0.002070
Training Epoch: 187 [128/50000]	Loss: 0.8505	LR: 0.002070
Training Epoch: 187 [128/50000]	Loss: 0.8055	LR: 0.002070
Training Epoch: 187 [128/50000]	Loss: 0.9182	LR: 0.002070
Training Epoch: 187 [128/50000]	Loss: 0.9639	LR: 0.002070
Training Epoch: 187 [128/50000]	Loss: 0.7214	LR: 0.002070
Training Epoch: 187 [128/50000]	Loss: 1.1352	LR: 0.002070
Evaluating Network.....
Test set: Epoch: 187, Average loss: 0.0106, Top1Accuracy: 0.6290, Top3Accuracy: 0.8236, Top5Accuracy: 0.8842, Time consumed:1.10s

Training Epoch: 188 [128/50000]	Loss: 0.9573	LR: 0.002015
Training Epoch: 188 [128/50000]	Loss: 0.9767	LR: 0.002015
Training Epoch: 188 [128/50000]	Loss: 0.8952	LR: 0.002015
Training Epoch: 188 [128/50000]	Loss: 0.9560	LR: 0.002015
Training Epoch: 188 [128/50000]	Loss: 0.9743	LR: 0.002015
Training Epoch: 188 [128/50000]	Loss: 0.8674	LR: 0.002015
Training Epoch: 188 [128/50000]	Loss: 0.8600	LR: 0.002015
Training Epoch: 188 [128/50000]	Loss: 0.7420	LR: 0.002015
Training Epoch: 188 [128/50000]	Loss: 0.9009	LR: 0.002015
Training Epoch: 188 [128/50000]	Loss: 0.9691	LR: 0.002015
Evaluating Network.....
Test set: Epoch: 188, Average loss: 0.0106, Top1Accuracy: 0.6282, Top3Accuracy: 0.8242, Top5Accuracy: 0.8850, Time consumed:1.14s

Training Epoch: 189 [128/50000]	Loss: 0.8567	LR: 0.001962
Training Epoch: 189 [128/50000]	Loss: 0.7629	LR: 0.001962
Training Epoch: 189 [128/50000]	Loss: 0.9162	LR: 0.001962
Training Epoch: 189 [128/50000]	Loss: 0.8753	LR: 0.001962
Training Epoch: 189 [128/50000]	Loss: 1.0119	LR: 0.001962
Training Epoch: 189 [128/50000]	Loss: 0.7697	LR: 0.001962
Training Epoch: 189 [128/50000]	Loss: 1.2037	LR: 0.001962
Training Epoch: 189 [128/50000]	Loss: 0.8160	LR: 0.001962
Training Epoch: 189 [128/50000]	Loss: 0.9110	LR: 0.001962
Training Epoch: 189 [128/50000]	Loss: 0.9155	LR: 0.001962
Evaluating Network.....
Test set: Epoch: 189, Average loss: 0.0106, Top1Accuracy: 0.6272, Top3Accuracy: 0.8257, Top5Accuracy: 0.8847, Time consumed:1.12s

Training Epoch: 190 [128/50000]	Loss: 0.8738	LR: 0.001910
Training Epoch: 190 [128/50000]	Loss: 1.0076	LR: 0.001910
Training Epoch: 190 [128/50000]	Loss: 0.9072	LR: 0.001910
Training Epoch: 190 [128/50000]	Loss: 0.7532	LR: 0.001910
Training Epoch: 190 [128/50000]	Loss: 0.9797	LR: 0.001910
Training Epoch: 190 [128/50000]	Loss: 1.1093	LR: 0.001910
Training Epoch: 190 [128/50000]	Loss: 0.8580	LR: 0.001910
Training Epoch: 190 [128/50000]	Loss: 0.7797	LR: 0.001910
Training Epoch: 190 [128/50000]	Loss: 1.0383	LR: 0.001910
Training Epoch: 190 [128/50000]	Loss: 0.8366	LR: 0.001910
Evaluating Network.....
Test set: Epoch: 190, Average loss: 0.0105, Top1Accuracy: 0.6293, Top3Accuracy: 0.8264, Top5Accuracy: 0.8855, Time consumed:1.11s

Training Epoch: 191 [128/50000]	Loss: 0.8884	LR: 0.001860
Training Epoch: 191 [128/50000]	Loss: 0.8555	LR: 0.001860
Training Epoch: 191 [128/50000]	Loss: 0.7492	LR: 0.001860
Training Epoch: 191 [128/50000]	Loss: 0.8562	LR: 0.001860
Training Epoch: 191 [128/50000]	Loss: 0.9278	LR: 0.001860
Training Epoch: 191 [128/50000]	Loss: 0.9692	LR: 0.001860
Training Epoch: 191 [128/50000]	Loss: 0.9817	LR: 0.001860
Training Epoch: 191 [128/50000]	Loss: 0.7018	LR: 0.001860
Training Epoch: 191 [128/50000]	Loss: 0.9155	LR: 0.001860
Training Epoch: 191 [128/50000]	Loss: 0.6364	LR: 0.001860
Evaluating Network.....
Test set: Epoch: 191, Average loss: 0.0106, Top1Accuracy: 0.6279, Top3Accuracy: 0.8251, Top5Accuracy: 0.8846, Time consumed:1.10s

Training Epoch: 192 [128/50000]	Loss: 0.7276	LR: 0.001811
Training Epoch: 192 [128/50000]	Loss: 0.9724	LR: 0.001811
Training Epoch: 192 [128/50000]	Loss: 1.0478	LR: 0.001811
Training Epoch: 192 [128/50000]	Loss: 0.8888	LR: 0.001811
Training Epoch: 192 [128/50000]	Loss: 0.8590	LR: 0.001811
Training Epoch: 192 [128/50000]	Loss: 0.9158	LR: 0.001811
Training Epoch: 192 [128/50000]	Loss: 0.9094	LR: 0.001811
Training Epoch: 192 [128/50000]	Loss: 0.9918	LR: 0.001811
Training Epoch: 192 [128/50000]	Loss: 1.1105	LR: 0.001811
Training Epoch: 192 [128/50000]	Loss: 0.8003	LR: 0.001811
Evaluating Network.....
Test set: Epoch: 192, Average loss: 0.0106, Top1Accuracy: 0.6287, Top3Accuracy: 0.8254, Top5Accuracy: 0.8854, Time consumed:1.13s

Training Epoch: 193 [128/50000]	Loss: 0.9644	LR: 0.001763
Training Epoch: 193 [128/50000]	Loss: 0.7495	LR: 0.001763
Training Epoch: 193 [128/50000]	Loss: 0.7886	LR: 0.001763
Training Epoch: 193 [128/50000]	Loss: 0.9311	LR: 0.001763
Training Epoch: 193 [128/50000]	Loss: 0.8170	LR: 0.001763
Training Epoch: 193 [128/50000]	Loss: 0.7322	LR: 0.001763
Training Epoch: 193 [128/50000]	Loss: 0.8519	LR: 0.001763
Training Epoch: 193 [128/50000]	Loss: 0.8048	LR: 0.001763
Training Epoch: 193 [128/50000]	Loss: 0.8871	LR: 0.001763
Training Epoch: 193 [128/50000]	Loss: 0.7321	LR: 0.001763
Evaluating Network.....
Test set: Epoch: 193, Average loss: 0.0105, Top1Accuracy: 0.6282, Top3Accuracy: 0.8252, Top5Accuracy: 0.8868, Time consumed:1.12s

Training Epoch: 194 [128/50000]	Loss: 0.9447	LR: 0.001716
Training Epoch: 194 [128/50000]	Loss: 1.0564	LR: 0.001716
Training Epoch: 194 [128/50000]	Loss: 1.1360	LR: 0.001716
Training Epoch: 194 [128/50000]	Loss: 0.7560	LR: 0.001716
Training Epoch: 194 [128/50000]	Loss: 0.8730	LR: 0.001716
Training Epoch: 194 [128/50000]	Loss: 0.7473	LR: 0.001716
Training Epoch: 194 [128/50000]	Loss: 0.7908	LR: 0.001716
Training Epoch: 194 [128/50000]	Loss: 0.6895	LR: 0.001716
Training Epoch: 194 [128/50000]	Loss: 0.9282	LR: 0.001716
Training Epoch: 194 [128/50000]	Loss: 0.7620	LR: 0.001716
Evaluating Network.....
Test set: Epoch: 194, Average loss: 0.0106, Top1Accuracy: 0.6277, Top3Accuracy: 0.8259, Top5Accuracy: 0.8848, Time consumed:1.10s

Training Epoch: 195 [128/50000]	Loss: 0.8631	LR: 0.001671
Training Epoch: 195 [128/50000]	Loss: 0.8684	LR: 0.001671
Training Epoch: 195 [128/50000]	Loss: 0.9013	LR: 0.001671
Training Epoch: 195 [128/50000]	Loss: 0.8598	LR: 0.001671
Training Epoch: 195 [128/50000]	Loss: 0.7981	LR: 0.001671
Training Epoch: 195 [128/50000]	Loss: 0.9415	LR: 0.001671
Training Epoch: 195 [128/50000]	Loss: 0.8207	LR: 0.001671
Training Epoch: 195 [128/50000]	Loss: 0.7608	LR: 0.001671
Training Epoch: 195 [128/50000]	Loss: 0.9757	LR: 0.001671
Training Epoch: 195 [128/50000]	Loss: 0.8300	LR: 0.001671
Evaluating Network.....
Test set: Epoch: 195, Average loss: 0.0106, Top1Accuracy: 0.6310, Top3Accuracy: 0.8243, Top5Accuracy: 0.8848, Time consumed:1.12s

Training Epoch: 196 [128/50000]	Loss: 1.0614	LR: 0.001627
Training Epoch: 196 [128/50000]	Loss: 0.8360	LR: 0.001627
Training Epoch: 196 [128/50000]	Loss: 0.9018	LR: 0.001627
Training Epoch: 196 [128/50000]	Loss: 0.8379	LR: 0.001627
Training Epoch: 196 [128/50000]	Loss: 0.7112	LR: 0.001627
Training Epoch: 196 [128/50000]	Loss: 0.8122	LR: 0.001627
Training Epoch: 196 [128/50000]	Loss: 0.8585	LR: 0.001627
Training Epoch: 196 [128/50000]	Loss: 0.7296	LR: 0.001627
Training Epoch: 196 [128/50000]	Loss: 0.8598	LR: 0.001627
Training Epoch: 196 [128/50000]	Loss: 0.7151	LR: 0.001627
Evaluating Network.....
Test set: Epoch: 196, Average loss: 0.0106, Top1Accuracy: 0.6277, Top3Accuracy: 0.8261, Top5Accuracy: 0.8846, Time consumed:1.11s

Training Epoch: 197 [128/50000]	Loss: 0.7812	LR: 0.001584
Training Epoch: 197 [128/50000]	Loss: 0.8523	LR: 0.001584
Training Epoch: 197 [128/50000]	Loss: 0.8099	LR: 0.001584
Training Epoch: 197 [128/50000]	Loss: 0.7422	LR: 0.001584
Training Epoch: 197 [128/50000]	Loss: 0.9910	LR: 0.001584
Training Epoch: 197 [128/50000]	Loss: 0.7599	LR: 0.001584
Training Epoch: 197 [128/50000]	Loss: 0.8956	LR: 0.001584
Training Epoch: 197 [128/50000]	Loss: 1.0004	LR: 0.001584
Training Epoch: 197 [128/50000]	Loss: 0.8355	LR: 0.001584
Training Epoch: 197 [128/50000]	Loss: 0.7216	LR: 0.001584
Evaluating Network.....
Test set: Epoch: 197, Average loss: 0.0108, Top1Accuracy: 0.6277, Top3Accuracy: 0.8264, Top5Accuracy: 0.8836, Time consumed:1.12s

Training Epoch: 198 [128/50000]	Loss: 0.8349	LR: 0.001542
Training Epoch: 198 [128/50000]	Loss: 0.8067	LR: 0.001542
Training Epoch: 198 [128/50000]	Loss: 1.0023	LR: 0.001542
Training Epoch: 198 [128/50000]	Loss: 0.7438	LR: 0.001542
Training Epoch: 198 [128/50000]	Loss: 0.8093	LR: 0.001542
Training Epoch: 198 [128/50000]	Loss: 1.0098	LR: 0.001542
Training Epoch: 198 [128/50000]	Loss: 0.9534	LR: 0.001542
Training Epoch: 198 [128/50000]	Loss: 0.8955	LR: 0.001542
Training Epoch: 198 [128/50000]	Loss: 1.1541	LR: 0.001542
Training Epoch: 198 [128/50000]	Loss: 0.9168	LR: 0.001542
Evaluating Network.....
Test set: Epoch: 198, Average loss: 0.0106, Top1Accuracy: 0.6274, Top3Accuracy: 0.8263, Top5Accuracy: 0.8853, Time consumed:1.12s

Training Epoch: 199 [128/50000]	Loss: 0.6827	LR: 0.001501
Training Epoch: 199 [128/50000]	Loss: 0.8241	LR: 0.001501
Training Epoch: 199 [128/50000]	Loss: 0.9990	LR: 0.001501
Training Epoch: 199 [128/50000]	Loss: 0.9305	LR: 0.001501
Training Epoch: 199 [128/50000]	Loss: 0.9035	LR: 0.001501
Training Epoch: 199 [128/50000]	Loss: 0.7800	LR: 0.001501
Training Epoch: 199 [128/50000]	Loss: 0.7928	LR: 0.001501
Training Epoch: 199 [128/50000]	Loss: 0.9661	LR: 0.001501
Training Epoch: 199 [128/50000]	Loss: 1.0564	LR: 0.001501
Training Epoch: 199 [128/50000]	Loss: 0.7736	LR: 0.001501
Evaluating Network.....
Test set: Epoch: 199, Average loss: 0.0106, Top1Accuracy: 0.6289, Top3Accuracy: 0.8271, Top5Accuracy: 0.8839, Time consumed:1.11s

Training Epoch: 200 [128/50000]	Loss: 0.8376	LR: 0.001462
Training Epoch: 200 [128/50000]	Loss: 0.9479	LR: 0.001462
Training Epoch: 200 [128/50000]	Loss: 0.8091	LR: 0.001462
Training Epoch: 200 [128/50000]	Loss: 0.8912	LR: 0.001462
Training Epoch: 200 [128/50000]	Loss: 0.8801	LR: 0.001462
Training Epoch: 200 [128/50000]	Loss: 0.8887	LR: 0.001462
Training Epoch: 200 [128/50000]	Loss: 0.7798	LR: 0.001462
Training Epoch: 200 [128/50000]	Loss: 0.9753	LR: 0.001462
Training Epoch: 200 [128/50000]	Loss: 0.7811	LR: 0.001462
Training Epoch: 200 [128/50000]	Loss: 0.8369	LR: 0.001462
Evaluating Network.....
Test set: Epoch: 200, Average loss: 0.0106, Top1Accuracy: 0.6288, Top3Accuracy: 0.8260, Top5Accuracy: 0.8834, Time consumed:1.10s

Training Epoch: 201 [128/50000]	Loss: 0.8949	LR: 0.001423
Training Epoch: 201 [128/50000]	Loss: 0.8865	LR: 0.001423
Training Epoch: 201 [128/50000]	Loss: 0.7672	LR: 0.001423
Training Epoch: 201 [128/50000]	Loss: 0.9429	LR: 0.001423
Training Epoch: 201 [128/50000]	Loss: 0.8681	LR: 0.001423
Training Epoch: 201 [128/50000]	Loss: 0.8011	LR: 0.001423
Training Epoch: 201 [128/50000]	Loss: 0.9923	LR: 0.001423
Training Epoch: 201 [128/50000]	Loss: 0.9138	LR: 0.001423
Training Epoch: 201 [128/50000]	Loss: 0.8711	LR: 0.001423
Training Epoch: 201 [128/50000]	Loss: 0.9838	LR: 0.001423
Evaluating Network.....
Test set: Epoch: 201, Average loss: 0.0106, Top1Accuracy: 0.6273, Top3Accuracy: 0.8265, Top5Accuracy: 0.8842, Time consumed:1.11s

Training Epoch: 202 [128/50000]	Loss: 0.9399	LR: 0.001386
Training Epoch: 202 [128/50000]	Loss: 0.8989	LR: 0.001386
Training Epoch: 202 [128/50000]	Loss: 0.8911	LR: 0.001386
Training Epoch: 202 [128/50000]	Loss: 0.8437	LR: 0.001386
Training Epoch: 202 [128/50000]	Loss: 0.8005	LR: 0.001386
Training Epoch: 202 [128/50000]	Loss: 0.9183	LR: 0.001386
Training Epoch: 202 [128/50000]	Loss: 0.9563	LR: 0.001386
Training Epoch: 202 [128/50000]	Loss: 0.8076	LR: 0.001386
Training Epoch: 202 [128/50000]	Loss: 0.9036	LR: 0.001386
Training Epoch: 202 [128/50000]	Loss: 0.9868	LR: 0.001386
Evaluating Network.....
Test set: Epoch: 202, Average loss: 0.0106, Top1Accuracy: 0.6292, Top3Accuracy: 0.8265, Top5Accuracy: 0.8841, Time consumed:1.09s

Training Epoch: 203 [128/50000]	Loss: 0.8570	LR: 0.001349
Training Epoch: 203 [128/50000]	Loss: 0.7923	LR: 0.001349
Training Epoch: 203 [128/50000]	Loss: 1.0704	LR: 0.001349
Training Epoch: 203 [128/50000]	Loss: 0.7961	LR: 0.001349
Training Epoch: 203 [128/50000]	Loss: 0.9425	LR: 0.001349
Training Epoch: 203 [128/50000]	Loss: 0.7184	LR: 0.001349
Training Epoch: 203 [128/50000]	Loss: 0.8980	LR: 0.001349
Training Epoch: 203 [128/50000]	Loss: 0.8808	LR: 0.001349
Training Epoch: 203 [128/50000]	Loss: 0.8734	LR: 0.001349
Training Epoch: 203 [128/50000]	Loss: 0.9626	LR: 0.001349
Evaluating Network.....
Test set: Epoch: 203, Average loss: 0.0106, Top1Accuracy: 0.6304, Top3Accuracy: 0.8254, Top5Accuracy: 0.8841, Time consumed:1.12s

Training Epoch: 204 [128/50000]	Loss: 0.7824	LR: 0.001313
Training Epoch: 204 [128/50000]	Loss: 0.9025	LR: 0.001313
Training Epoch: 204 [128/50000]	Loss: 0.7255	LR: 0.001313
Training Epoch: 204 [128/50000]	Loss: 0.8548	LR: 0.001313
Training Epoch: 204 [128/50000]	Loss: 0.9023	LR: 0.001313
Training Epoch: 204 [128/50000]	Loss: 1.0002	LR: 0.001313
Training Epoch: 204 [128/50000]	Loss: 0.8001	LR: 0.001313
Training Epoch: 204 [128/50000]	Loss: 0.8050	LR: 0.001313
Training Epoch: 204 [128/50000]	Loss: 1.0156	LR: 0.001313
Training Epoch: 204 [128/50000]	Loss: 0.8574	LR: 0.001313
Evaluating Network.....
Test set: Epoch: 204, Average loss: 0.0107, Top1Accuracy: 0.6282, Top3Accuracy: 0.8263, Top5Accuracy: 0.8843, Time consumed:1.10s

Training Epoch: 205 [128/50000]	Loss: 0.8283	LR: 0.001279
Training Epoch: 205 [128/50000]	Loss: 0.8034	LR: 0.001279
Training Epoch: 205 [128/50000]	Loss: 0.7202	LR: 0.001279
Training Epoch: 205 [128/50000]	Loss: 1.0505	LR: 0.001279
Training Epoch: 205 [128/50000]	Loss: 0.9815	LR: 0.001279
Training Epoch: 205 [128/50000]	Loss: 0.8936	LR: 0.001279
Training Epoch: 205 [128/50000]	Loss: 0.8321	LR: 0.001279
Training Epoch: 205 [128/50000]	Loss: 0.9085	LR: 0.001279
Training Epoch: 205 [128/50000]	Loss: 1.0645	LR: 0.001279
Training Epoch: 205 [128/50000]	Loss: 0.9292	LR: 0.001279
Evaluating Network.....
Test set: Epoch: 205, Average loss: 0.0105, Top1Accuracy: 0.6295, Top3Accuracy: 0.8257, Top5Accuracy: 0.8843, Time consumed:1.11s

Training Epoch: 206 [128/50000]	Loss: 0.8944	LR: 0.001245
Training Epoch: 206 [128/50000]	Loss: 0.7542	LR: 0.001245
Training Epoch: 206 [128/50000]	Loss: 0.8261	LR: 0.001245
Training Epoch: 206 [128/50000]	Loss: 0.6320	LR: 0.001245
Training Epoch: 206 [128/50000]	Loss: 1.1313	LR: 0.001245
Training Epoch: 206 [128/50000]	Loss: 0.7533	LR: 0.001245
Training Epoch: 206 [128/50000]	Loss: 0.9795	LR: 0.001245
Training Epoch: 206 [128/50000]	Loss: 0.7885	LR: 0.001245
Training Epoch: 206 [128/50000]	Loss: 0.8365	LR: 0.001245
Training Epoch: 206 [128/50000]	Loss: 1.0259	LR: 0.001245
Evaluating Network.....
Test set: Epoch: 206, Average loss: 0.0106, Top1Accuracy: 0.6299, Top3Accuracy: 0.8259, Top5Accuracy: 0.8846, Time consumed:1.10s

Training Epoch: 207 [128/50000]	Loss: 1.0780	LR: 0.001212
Training Epoch: 207 [128/50000]	Loss: 0.7353	LR: 0.001212
Training Epoch: 207 [128/50000]	Loss: 0.7993	LR: 0.001212
Training Epoch: 207 [128/50000]	Loss: 0.8891	LR: 0.001212
Training Epoch: 207 [128/50000]	Loss: 0.9467	LR: 0.001212
Training Epoch: 207 [128/50000]	Loss: 0.9453	LR: 0.001212
Training Epoch: 207 [128/50000]	Loss: 0.9165	LR: 0.001212
Training Epoch: 207 [128/50000]	Loss: 0.7419	LR: 0.001212
Training Epoch: 207 [128/50000]	Loss: 0.8307	LR: 0.001212
Training Epoch: 207 [128/50000]	Loss: 0.8232	LR: 0.001212
Evaluating Network.....
Test set: Epoch: 207, Average loss: 0.0106, Top1Accuracy: 0.6295, Top3Accuracy: 0.8259, Top5Accuracy: 0.8848, Time consumed:1.10s

Training Epoch: 208 [128/50000]	Loss: 0.8240	LR: 0.001180
Training Epoch: 208 [128/50000]	Loss: 0.7471	LR: 0.001180
Training Epoch: 208 [128/50000]	Loss: 0.9581	LR: 0.001180
Training Epoch: 208 [128/50000]	Loss: 1.0516	LR: 0.001180
Training Epoch: 208 [128/50000]	Loss: 0.9479	LR: 0.001180
Training Epoch: 208 [128/50000]	Loss: 0.8860	LR: 0.001180
Training Epoch: 208 [128/50000]	Loss: 0.7920	LR: 0.001180
Training Epoch: 208 [128/50000]	Loss: 0.7851	LR: 0.001180
Training Epoch: 208 [128/50000]	Loss: 0.8907	LR: 0.001180
Training Epoch: 208 [128/50000]	Loss: 0.7679	LR: 0.001180
Evaluating Network.....
Test set: Epoch: 208, Average loss: 0.0106, Top1Accuracy: 0.6285, Top3Accuracy: 0.8253, Top5Accuracy: 0.8839, Time consumed:1.10s

Training Epoch: 209 [128/50000]	Loss: 0.8347	LR: 0.001149
Training Epoch: 209 [128/50000]	Loss: 0.8443	LR: 0.001149
Training Epoch: 209 [128/50000]	Loss: 0.8033	LR: 0.001149
Training Epoch: 209 [128/50000]	Loss: 0.7449	LR: 0.001149
Training Epoch: 209 [128/50000]	Loss: 0.8620	LR: 0.001149
Training Epoch: 209 [128/50000]	Loss: 1.0084	LR: 0.001149
Training Epoch: 209 [128/50000]	Loss: 0.8704	LR: 0.001149
Training Epoch: 209 [128/50000]	Loss: 0.9126	LR: 0.001149
Training Epoch: 209 [128/50000]	Loss: 0.7733	LR: 0.001149
Training Epoch: 209 [128/50000]	Loss: 0.9736	LR: 0.001149
Evaluating Network.....
Test set: Epoch: 209, Average loss: 0.0106, Top1Accuracy: 0.6293, Top3Accuracy: 0.8246, Top5Accuracy: 0.8829, Time consumed:1.10s

Training Epoch: 210 [128/50000]	Loss: 0.7219	LR: 0.001119
Training Epoch: 210 [128/50000]	Loss: 0.8539	LR: 0.001119
Training Epoch: 210 [128/50000]	Loss: 0.9532	LR: 0.001119
Training Epoch: 210 [128/50000]	Loss: 1.0818	LR: 0.001119
Training Epoch: 210 [128/50000]	Loss: 0.9418	LR: 0.001119
Training Epoch: 210 [128/50000]	Loss: 0.8786	LR: 0.001119
Training Epoch: 210 [128/50000]	Loss: 0.9395	LR: 0.001119
Training Epoch: 210 [128/50000]	Loss: 0.9217	LR: 0.001119
Training Epoch: 210 [128/50000]	Loss: 0.8265	LR: 0.001119
Training Epoch: 210 [128/50000]	Loss: 0.8006	LR: 0.001119
Evaluating Network.....
Test set: Epoch: 210, Average loss: 0.0106, Top1Accuracy: 0.6293, Top3Accuracy: 0.8259, Top5Accuracy: 0.8832, Time consumed:1.10s

Training Epoch: 211 [128/50000]	Loss: 0.9604	LR: 0.001089
Training Epoch: 211 [128/50000]	Loss: 0.6261	LR: 0.001089
Training Epoch: 211 [128/50000]	Loss: 0.8453	LR: 0.001089
Training Epoch: 211 [128/50000]	Loss: 0.8288	LR: 0.001089
Training Epoch: 211 [128/50000]	Loss: 0.9041	LR: 0.001089
Training Epoch: 211 [128/50000]	Loss: 0.9087	LR: 0.001089
Training Epoch: 211 [128/50000]	Loss: 0.9295	LR: 0.001089
Training Epoch: 211 [128/50000]	Loss: 0.8347	LR: 0.001089
Training Epoch: 211 [128/50000]	Loss: 0.9429	LR: 0.001089
Training Epoch: 211 [128/50000]	Loss: 0.8921	LR: 0.001089
Evaluating Network.....
Test set: Epoch: 211, Average loss: 0.0107, Top1Accuracy: 0.6269, Top3Accuracy: 0.8271, Top5Accuracy: 0.8830, Time consumed:1.11s

Training Epoch: 212 [128/50000]	Loss: 0.8541	LR: 0.001060
Training Epoch: 212 [128/50000]	Loss: 0.9540	LR: 0.001060
Training Epoch: 212 [128/50000]	Loss: 0.9228	LR: 0.001060
Training Epoch: 212 [128/50000]	Loss: 0.8830	LR: 0.001060
Training Epoch: 212 [128/50000]	Loss: 0.7734	LR: 0.001060
Training Epoch: 212 [128/50000]	Loss: 0.8093	LR: 0.001060
Training Epoch: 212 [128/50000]	Loss: 1.1024	LR: 0.001060
Training Epoch: 212 [128/50000]	Loss: 0.8409	LR: 0.001060
Training Epoch: 212 [128/50000]	Loss: 0.8412	LR: 0.001060
Training Epoch: 212 [128/50000]	Loss: 0.9333	LR: 0.001060
Evaluating Network.....
Test set: Epoch: 212, Average loss: 0.0106, Top1Accuracy: 0.6291, Top3Accuracy: 0.8257, Top5Accuracy: 0.8844, Time consumed:1.11s

Training Epoch: 213 [128/50000]	Loss: 0.8090	LR: 0.001032
Training Epoch: 213 [128/50000]	Loss: 0.9055	LR: 0.001032
Training Epoch: 213 [128/50000]	Loss: 0.8319	LR: 0.001032
Training Epoch: 213 [128/50000]	Loss: 1.0486	LR: 0.001032
Training Epoch: 213 [128/50000]	Loss: 0.7964	LR: 0.001032
Training Epoch: 213 [128/50000]	Loss: 0.9974	LR: 0.001032
Training Epoch: 213 [128/50000]	Loss: 0.9150	LR: 0.001032
Training Epoch: 213 [128/50000]	Loss: 0.8306	LR: 0.001032
Training Epoch: 213 [128/50000]	Loss: 0.8824	LR: 0.001032
Training Epoch: 213 [128/50000]	Loss: 0.8314	LR: 0.001032
Evaluating Network.....
Test set: Epoch: 213, Average loss: 0.0106, Top1Accuracy: 0.6290, Top3Accuracy: 0.8247, Top5Accuracy: 0.8838, Time consumed:1.10s

Training Epoch: 214 [128/50000]	Loss: 0.9277	LR: 0.001005
Training Epoch: 214 [128/50000]	Loss: 0.5618	LR: 0.001005
Training Epoch: 214 [128/50000]	Loss: 0.8904	LR: 0.001005
Training Epoch: 214 [128/50000]	Loss: 1.0210	LR: 0.001005
Training Epoch: 214 [128/50000]	Loss: 0.9422	LR: 0.001005
Training Epoch: 214 [128/50000]	Loss: 0.9144	LR: 0.001005
Training Epoch: 214 [128/50000]	Loss: 0.8021	LR: 0.001005
Training Epoch: 214 [128/50000]	Loss: 0.7587	LR: 0.001005
Training Epoch: 214 [128/50000]	Loss: 1.1108	LR: 0.001005
Training Epoch: 214 [128/50000]	Loss: 0.7913	LR: 0.001005
Evaluating Network.....
Test set: Epoch: 214, Average loss: 0.0106, Top1Accuracy: 0.6280, Top3Accuracy: 0.8253, Top5Accuracy: 0.8825, Time consumed:1.10s

Training Epoch: 215 [128/50000]	Loss: 0.8001	LR: 0.000979
Training Epoch: 215 [128/50000]	Loss: 0.9539	LR: 0.000979
Training Epoch: 215 [128/50000]	Loss: 0.8501	LR: 0.000979
Training Epoch: 215 [128/50000]	Loss: 0.7443	LR: 0.000979
Training Epoch: 215 [128/50000]	Loss: 0.8169	LR: 0.000979
Training Epoch: 215 [128/50000]	Loss: 0.8611	LR: 0.000979
Training Epoch: 215 [128/50000]	Loss: 1.0945	LR: 0.000979
Training Epoch: 215 [128/50000]	Loss: 0.7663	LR: 0.000979
Training Epoch: 215 [128/50000]	Loss: 0.8017	LR: 0.000979
Training Epoch: 215 [128/50000]	Loss: 0.9431	LR: 0.000979
Evaluating Network.....
Test set: Epoch: 215, Average loss: 0.0106, Top1Accuracy: 0.6294, Top3Accuracy: 0.8254, Top5Accuracy: 0.8841, Time consumed:1.09s

Training Epoch: 216 [128/50000]	Loss: 0.9343	LR: 0.000953
Training Epoch: 216 [128/50000]	Loss: 1.0104	LR: 0.000953
Training Epoch: 216 [128/50000]	Loss: 0.7313	LR: 0.000953
Training Epoch: 216 [128/50000]	Loss: 0.7477	LR: 0.000953
Training Epoch: 216 [128/50000]	Loss: 0.8435	LR: 0.000953
Training Epoch: 216 [128/50000]	Loss: 0.8144	LR: 0.000953
Training Epoch: 216 [128/50000]	Loss: 0.8119	LR: 0.000953
Training Epoch: 216 [128/50000]	Loss: 0.8470	LR: 0.000953
Training Epoch: 216 [128/50000]	Loss: 0.8820	LR: 0.000953
Training Epoch: 216 [128/50000]	Loss: 0.8375	LR: 0.000953
Evaluating Network.....
Test set: Epoch: 216, Average loss: 0.0106, Top1Accuracy: 0.6280, Top3Accuracy: 0.8260, Top5Accuracy: 0.8847, Time consumed:1.11s

Training Epoch: 217 [128/50000]	Loss: 0.8071	LR: 0.000928
Training Epoch: 217 [128/50000]	Loss: 0.8070	LR: 0.000928
Training Epoch: 217 [128/50000]	Loss: 0.8115	LR: 0.000928
Training Epoch: 217 [128/50000]	Loss: 1.0280	LR: 0.000928
Training Epoch: 217 [128/50000]	Loss: 0.8575	LR: 0.000928
Training Epoch: 217 [128/50000]	Loss: 0.7535	LR: 0.000928
Training Epoch: 217 [128/50000]	Loss: 0.7941	LR: 0.000928
Training Epoch: 217 [128/50000]	Loss: 0.7236	LR: 0.000928
Training Epoch: 217 [128/50000]	Loss: 0.8739	LR: 0.000928
Training Epoch: 217 [128/50000]	Loss: 0.7134	LR: 0.000928
Evaluating Network.....
Test set: Epoch: 217, Average loss: 0.0107, Top1Accuracy: 0.6287, Top3Accuracy: 0.8250, Top5Accuracy: 0.8848, Time consumed:1.09s

Training Epoch: 218 [128/50000]	Loss: 0.8917	LR: 0.000903
Training Epoch: 218 [128/50000]	Loss: 1.0390	LR: 0.000903
Training Epoch: 218 [128/50000]	Loss: 0.8614	LR: 0.000903
Training Epoch: 218 [128/50000]	Loss: 0.9954	LR: 0.000903
Training Epoch: 218 [128/50000]	Loss: 0.9371	LR: 0.000903
Training Epoch: 218 [128/50000]	Loss: 0.7409	LR: 0.000903
Training Epoch: 218 [128/50000]	Loss: 0.7307	LR: 0.000903
Training Epoch: 218 [128/50000]	Loss: 0.8766	LR: 0.000903
Training Epoch: 218 [128/50000]	Loss: 0.8895	LR: 0.000903
Training Epoch: 218 [128/50000]	Loss: 0.8145	LR: 0.000903
Evaluating Network.....
Test set: Epoch: 218, Average loss: 0.0106, Top1Accuracy: 0.6289, Top3Accuracy: 0.8259, Top5Accuracy: 0.8843, Time consumed:1.11s

Training Epoch: 219 [128/50000]	Loss: 0.8622	LR: 0.000879
Training Epoch: 219 [128/50000]	Loss: 0.7595	LR: 0.000879
Training Epoch: 219 [128/50000]	Loss: 0.8566	LR: 0.000879
Training Epoch: 219 [128/50000]	Loss: 0.8818	LR: 0.000879
Training Epoch: 219 [128/50000]	Loss: 0.6549	LR: 0.000879
Training Epoch: 219 [128/50000]	Loss: 0.9439	LR: 0.000879
Training Epoch: 219 [128/50000]	Loss: 0.8678	LR: 0.000879
Training Epoch: 219 [128/50000]	Loss: 0.8576	LR: 0.000879
Training Epoch: 219 [128/50000]	Loss: 0.8102	LR: 0.000879
Training Epoch: 219 [128/50000]	Loss: 0.9427	LR: 0.000879
Evaluating Network.....
Test set: Epoch: 219, Average loss: 0.0107, Top1Accuracy: 0.6288, Top3Accuracy: 0.8250, Top5Accuracy: 0.8845, Time consumed:1.10s

Training Epoch: 220 [128/50000]	Loss: 0.8162	LR: 0.000856
Training Epoch: 220 [128/50000]	Loss: 0.8190	LR: 0.000856
Training Epoch: 220 [128/50000]	Loss: 0.8279	LR: 0.000856
Training Epoch: 220 [128/50000]	Loss: 0.8538	LR: 0.000856
Training Epoch: 220 [128/50000]	Loss: 0.8264	LR: 0.000856
Training Epoch: 220 [128/50000]	Loss: 0.8554	LR: 0.000856
Training Epoch: 220 [128/50000]	Loss: 0.9703	LR: 0.000856
Training Epoch: 220 [128/50000]	Loss: 0.7827	LR: 0.000856
Training Epoch: 220 [128/50000]	Loss: 0.7800	LR: 0.000856
Training Epoch: 220 [128/50000]	Loss: 0.9461	LR: 0.000856
Evaluating Network.....
Test set: Epoch: 220, Average loss: 0.0106, Top1Accuracy: 0.6298, Top3Accuracy: 0.8257, Top5Accuracy: 0.8840, Time consumed:1.11s

Training Epoch: 221 [128/50000]	Loss: 0.8351	LR: 0.000833
Training Epoch: 221 [128/50000]	Loss: 0.6243	LR: 0.000833
Training Epoch: 221 [128/50000]	Loss: 0.8776	LR: 0.000833
Training Epoch: 221 [128/50000]	Loss: 0.7779	LR: 0.000833
Training Epoch: 221 [128/50000]	Loss: 1.0028	LR: 0.000833
Training Epoch: 221 [128/50000]	Loss: 0.8544	LR: 0.000833
Training Epoch: 221 [128/50000]	Loss: 0.7674	LR: 0.000833
Training Epoch: 221 [128/50000]	Loss: 0.9071	LR: 0.000833
Training Epoch: 221 [128/50000]	Loss: 1.0307	LR: 0.000833
Training Epoch: 221 [128/50000]	Loss: 0.8971	LR: 0.000833
Evaluating Network.....
Test set: Epoch: 221, Average loss: 0.0106, Top1Accuracy: 0.6291, Top3Accuracy: 0.8247, Top5Accuracy: 0.8843, Time consumed:1.10s

Training Epoch: 222 [128/50000]	Loss: 0.9141	LR: 0.000811
Training Epoch: 222 [128/50000]	Loss: 0.7789	LR: 0.000811
Training Epoch: 222 [128/50000]	Loss: 0.9212	LR: 0.000811
Training Epoch: 222 [128/50000]	Loss: 0.6579	LR: 0.000811
Training Epoch: 222 [128/50000]	Loss: 0.7381	LR: 0.000811
Training Epoch: 222 [128/50000]	Loss: 0.8946	LR: 0.000811
Training Epoch: 222 [128/50000]	Loss: 0.7885	LR: 0.000811
Training Epoch: 222 [128/50000]	Loss: 0.8575	LR: 0.000811
Training Epoch: 222 [128/50000]	Loss: 0.7366	LR: 0.000811
Training Epoch: 222 [128/50000]	Loss: 0.7469	LR: 0.000811
Evaluating Network.....
Test set: Epoch: 222, Average loss: 0.0106, Top1Accuracy: 0.6295, Top3Accuracy: 0.8258, Top5Accuracy: 0.8848, Time consumed:1.08s

Training Epoch: 223 [128/50000]	Loss: 0.9647	LR: 0.000790
Training Epoch: 223 [128/50000]	Loss: 0.8067	LR: 0.000790
Training Epoch: 223 [128/50000]	Loss: 0.9274	LR: 0.000790
Training Epoch: 223 [128/50000]	Loss: 0.8114	LR: 0.000790
Training Epoch: 223 [128/50000]	Loss: 0.8559	LR: 0.000790
Training Epoch: 223 [128/50000]	Loss: 0.8567	LR: 0.000790
Training Epoch: 223 [128/50000]	Loss: 0.9281	LR: 0.000790
Training Epoch: 223 [128/50000]	Loss: 0.7648	LR: 0.000790
Training Epoch: 223 [128/50000]	Loss: 0.7980	LR: 0.000790
Training Epoch: 223 [128/50000]	Loss: 0.7296	LR: 0.000790
Evaluating Network.....
Test set: Epoch: 223, Average loss: 0.0106, Top1Accuracy: 0.6285, Top3Accuracy: 0.8257, Top5Accuracy: 0.8843, Time consumed:1.12s

Training Epoch: 224 [128/50000]	Loss: 0.8604	LR: 0.000769
Training Epoch: 224 [128/50000]	Loss: 0.7159	LR: 0.000769
Training Epoch: 224 [128/50000]	Loss: 0.7028	LR: 0.000769
Training Epoch: 224 [128/50000]	Loss: 0.6121	LR: 0.000769
Training Epoch: 224 [128/50000]	Loss: 0.6451	LR: 0.000769
Training Epoch: 224 [128/50000]	Loss: 0.7917	LR: 0.000769
Training Epoch: 224 [128/50000]	Loss: 0.7713	LR: 0.000769
Training Epoch: 224 [128/50000]	Loss: 0.8688	LR: 0.000769
Training Epoch: 224 [128/50000]	Loss: 0.9004	LR: 0.000769
Training Epoch: 224 [128/50000]	Loss: 0.7172	LR: 0.000769
Evaluating Network.....
Test set: Epoch: 224, Average loss: 0.0106, Top1Accuracy: 0.6293, Top3Accuracy: 0.8254, Top5Accuracy: 0.8844, Time consumed:1.13s

Training Epoch: 225 [128/50000]	Loss: 0.7858	LR: 0.000749
Training Epoch: 225 [128/50000]	Loss: 0.9121	LR: 0.000749
Training Epoch: 225 [128/50000]	Loss: 0.7169	LR: 0.000749
Training Epoch: 225 [128/50000]	Loss: 0.9605	LR: 0.000749
Training Epoch: 225 [128/50000]	Loss: 0.7843	LR: 0.000749
Training Epoch: 225 [128/50000]	Loss: 0.8774	LR: 0.000749
Training Epoch: 225 [128/50000]	Loss: 0.8762	LR: 0.000749
Training Epoch: 225 [128/50000]	Loss: 0.7959	LR: 0.000749
Training Epoch: 225 [128/50000]	Loss: 0.9422	LR: 0.000749
Training Epoch: 225 [128/50000]	Loss: 0.8742	LR: 0.000749
Evaluating Network.....
Test set: Epoch: 225, Average loss: 0.0106, Top1Accuracy: 0.6287, Top3Accuracy: 0.8264, Top5Accuracy: 0.8854, Time consumed:1.10s

Training Epoch: 226 [128/50000]	Loss: 0.7764	LR: 0.000729
Training Epoch: 226 [128/50000]	Loss: 0.8863	LR: 0.000729
Training Epoch: 226 [128/50000]	Loss: 0.8301	LR: 0.000729
Training Epoch: 226 [128/50000]	Loss: 0.8382	LR: 0.000729
Training Epoch: 226 [128/50000]	Loss: 0.8742	LR: 0.000729
Training Epoch: 226 [128/50000]	Loss: 0.8398	LR: 0.000729
Training Epoch: 226 [128/50000]	Loss: 0.8444	LR: 0.000729
Training Epoch: 226 [128/50000]	Loss: 0.9220	LR: 0.000729
Training Epoch: 226 [128/50000]	Loss: 0.9227	LR: 0.000729
Training Epoch: 226 [128/50000]	Loss: 0.7189	LR: 0.000729
Evaluating Network.....
Test set: Epoch: 226, Average loss: 0.0106, Top1Accuracy: 0.6292, Top3Accuracy: 0.8256, Top5Accuracy: 0.8831, Time consumed:1.10s

Training Epoch: 227 [128/50000]	Loss: 0.8130	LR: 0.000710
Training Epoch: 227 [128/50000]	Loss: 0.8559	LR: 0.000710
Training Epoch: 227 [128/50000]	Loss: 0.8114	LR: 0.000710
Training Epoch: 227 [128/50000]	Loss: 0.8049	LR: 0.000710
Training Epoch: 227 [128/50000]	Loss: 0.7549	LR: 0.000710
Training Epoch: 227 [128/50000]	Loss: 0.8037	LR: 0.000710
Training Epoch: 227 [128/50000]	Loss: 0.6637	LR: 0.000710
Training Epoch: 227 [128/50000]	Loss: 0.8757	LR: 0.000710
Training Epoch: 227 [128/50000]	Loss: 0.8914	LR: 0.000710
Training Epoch: 227 [128/50000]	Loss: 0.8930	LR: 0.000710
Evaluating Network.....
Test set: Epoch: 227, Average loss: 0.0107, Top1Accuracy: 0.6301, Top3Accuracy: 0.8261, Top5Accuracy: 0.8834, Time consumed:1.09s

Training Epoch: 228 [128/50000]	Loss: 0.9033	LR: 0.000691
Training Epoch: 228 [128/50000]	Loss: 0.9044	LR: 0.000691
Training Epoch: 228 [128/50000]	Loss: 0.8705	LR: 0.000691
Training Epoch: 228 [128/50000]	Loss: 0.6353	LR: 0.000691
Training Epoch: 228 [128/50000]	Loss: 0.8646	LR: 0.000691
Training Epoch: 228 [128/50000]	Loss: 0.8242	LR: 0.000691
Training Epoch: 228 [128/50000]	Loss: 0.9713	LR: 0.000691
Training Epoch: 228 [128/50000]	Loss: 0.8042	LR: 0.000691
Training Epoch: 228 [128/50000]	Loss: 0.9379	LR: 0.000691
Training Epoch: 228 [128/50000]	Loss: 0.7219	LR: 0.000691
Evaluating Network.....
Test set: Epoch: 228, Average loss: 0.0107, Top1Accuracy: 0.6291, Top3Accuracy: 0.8258, Top5Accuracy: 0.8832, Time consumed:1.09s

Training Epoch: 229 [128/50000]	Loss: 0.6712	LR: 0.000673
Training Epoch: 229 [128/50000]	Loss: 0.7585	LR: 0.000673
Training Epoch: 229 [128/50000]	Loss: 0.8371	LR: 0.000673
Training Epoch: 229 [128/50000]	Loss: 0.7597	LR: 0.000673
Training Epoch: 229 [128/50000]	Loss: 0.8066	LR: 0.000673
Training Epoch: 229 [128/50000]	Loss: 1.0422	LR: 0.000673
Training Epoch: 229 [128/50000]	Loss: 0.8637	LR: 0.000673
Training Epoch: 229 [128/50000]	Loss: 0.7746	LR: 0.000673
Training Epoch: 229 [128/50000]	Loss: 0.7996	LR: 0.000673
Training Epoch: 229 [128/50000]	Loss: 0.7549	LR: 0.000673
Evaluating Network.....
Test set: Epoch: 229, Average loss: 0.0107, Top1Accuracy: 0.6290, Top3Accuracy: 0.8265, Top5Accuracy: 0.8827, Time consumed:1.11s

Training Epoch: 230 [128/50000]	Loss: 0.9118	LR: 0.000655
Training Epoch: 230 [128/50000]	Loss: 0.6610	LR: 0.000655
Training Epoch: 230 [128/50000]	Loss: 0.7167	LR: 0.000655
Training Epoch: 230 [128/50000]	Loss: 0.9747	LR: 0.000655
Training Epoch: 230 [128/50000]	Loss: 0.5703	LR: 0.000655
Training Epoch: 230 [128/50000]	Loss: 0.9207	LR: 0.000655
Training Epoch: 230 [128/50000]	Loss: 0.8421	LR: 0.000655
Training Epoch: 230 [128/50000]	Loss: 1.0921	LR: 0.000655
Training Epoch: 230 [128/50000]	Loss: 0.9118	LR: 0.000655
Training Epoch: 230 [128/50000]	Loss: 0.7684	LR: 0.000655
Evaluating Network.....
Test set: Epoch: 230, Average loss: 0.0106, Top1Accuracy: 0.6299, Top3Accuracy: 0.8257, Top5Accuracy: 0.8831, Time consumed:1.08s

Training Epoch: 231 [128/50000]	Loss: 0.7748	LR: 0.000638
Training Epoch: 231 [128/50000]	Loss: 0.9869	LR: 0.000638
Training Epoch: 231 [128/50000]	Loss: 0.8447	LR: 0.000638
Training Epoch: 231 [128/50000]	Loss: 0.9224	LR: 0.000638
Training Epoch: 231 [128/50000]	Loss: 0.7227	LR: 0.000638
Training Epoch: 231 [128/50000]	Loss: 0.9795	LR: 0.000638
Training Epoch: 231 [128/50000]	Loss: 0.7429	LR: 0.000638
Training Epoch: 231 [128/50000]	Loss: 0.8582	LR: 0.000638
Training Epoch: 231 [128/50000]	Loss: 0.8464	LR: 0.000638
Training Epoch: 231 [128/50000]	Loss: 0.8758	LR: 0.000638
Evaluating Network.....
Test set: Epoch: 231, Average loss: 0.0106, Top1Accuracy: 0.6308, Top3Accuracy: 0.8254, Top5Accuracy: 0.8839, Time consumed:1.11s

Training Epoch: 232 [128/50000]	Loss: 0.8503	LR: 0.000621
Training Epoch: 232 [128/50000]	Loss: 0.8213	LR: 0.000621
Training Epoch: 232 [128/50000]	Loss: 0.7894	LR: 0.000621
Training Epoch: 232 [128/50000]	Loss: 0.8568	LR: 0.000621
Training Epoch: 232 [128/50000]	Loss: 0.7398	LR: 0.000621
Training Epoch: 232 [128/50000]	Loss: 0.9230	LR: 0.000621
Training Epoch: 232 [128/50000]	Loss: 0.7800	LR: 0.000621
Training Epoch: 232 [128/50000]	Loss: 0.7264	LR: 0.000621
Training Epoch: 232 [128/50000]	Loss: 0.8340	LR: 0.000621
Training Epoch: 232 [128/50000]	Loss: 1.0631	LR: 0.000621
Evaluating Network.....
Test set: Epoch: 232, Average loss: 0.0107, Top1Accuracy: 0.6292, Top3Accuracy: 0.8263, Top5Accuracy: 0.8839, Time consumed:1.09s

Training Epoch: 233 [128/50000]	Loss: 0.8485	LR: 0.000605
Training Epoch: 233 [128/50000]	Loss: 0.8658	LR: 0.000605
Training Epoch: 233 [128/50000]	Loss: 0.7922	LR: 0.000605
Training Epoch: 233 [128/50000]	Loss: 0.9381	LR: 0.000605
Training Epoch: 233 [128/50000]	Loss: 0.9656	LR: 0.000605
Training Epoch: 233 [128/50000]	Loss: 0.7594	LR: 0.000605
Training Epoch: 233 [128/50000]	Loss: 0.8983	LR: 0.000605
Training Epoch: 233 [128/50000]	Loss: 0.7058	LR: 0.000605
Training Epoch: 233 [128/50000]	Loss: 0.8651	LR: 0.000605
Training Epoch: 233 [128/50000]	Loss: 0.8094	LR: 0.000605
Evaluating Network.....
Test set: Epoch: 233, Average loss: 0.0107, Top1Accuracy: 0.6306, Top3Accuracy: 0.8260, Top5Accuracy: 0.8838, Time consumed:1.10s

Training Epoch: 234 [128/50000]	Loss: 1.1669	LR: 0.000589
Training Epoch: 234 [128/50000]	Loss: 0.8841	LR: 0.000589
Training Epoch: 234 [128/50000]	Loss: 0.7480	LR: 0.000589
Training Epoch: 234 [128/50000]	Loss: 0.9736	LR: 0.000589
Training Epoch: 234 [128/50000]	Loss: 0.9448	LR: 0.000589
Training Epoch: 234 [128/50000]	Loss: 0.8168	LR: 0.000589
Training Epoch: 234 [128/50000]	Loss: 0.8381	LR: 0.000589
Training Epoch: 234 [128/50000]	Loss: 0.8235	LR: 0.000589
Training Epoch: 234 [128/50000]	Loss: 0.8350	LR: 0.000589
Training Epoch: 234 [128/50000]	Loss: 0.8013	LR: 0.000589
Evaluating Network.....
Test set: Epoch: 234, Average loss: 0.0107, Top1Accuracy: 0.6307, Top3Accuracy: 0.8265, Top5Accuracy: 0.8843, Time consumed:1.11s

Training Epoch: 235 [128/50000]	Loss: 0.7500	LR: 0.000573
Training Epoch: 235 [128/50000]	Loss: 0.8559	LR: 0.000573
Training Epoch: 235 [128/50000]	Loss: 0.9943	LR: 0.000573
Training Epoch: 235 [128/50000]	Loss: 0.9478	LR: 0.000573
Training Epoch: 235 [128/50000]	Loss: 1.0838	LR: 0.000573
Training Epoch: 235 [128/50000]	Loss: 0.9092	LR: 0.000573
Training Epoch: 235 [128/50000]	Loss: 0.8929	LR: 0.000573
Training Epoch: 235 [128/50000]	Loss: 0.6681	LR: 0.000573
Training Epoch: 235 [128/50000]	Loss: 0.8535	LR: 0.000573
Training Epoch: 235 [128/50000]	Loss: 0.7637	LR: 0.000573
Evaluating Network.....
Test set: Epoch: 235, Average loss: 0.0107, Top1Accuracy: 0.6286, Top3Accuracy: 0.8260, Top5Accuracy: 0.8836, Time consumed:1.08s

Training Epoch: 236 [128/50000]	Loss: 0.9152	LR: 0.000558
Training Epoch: 236 [128/50000]	Loss: 0.7895	LR: 0.000558
Training Epoch: 236 [128/50000]	Loss: 0.7505	LR: 0.000558
Training Epoch: 236 [128/50000]	Loss: 0.9044	LR: 0.000558
Training Epoch: 236 [128/50000]	Loss: 0.7517	LR: 0.000558
Training Epoch: 236 [128/50000]	Loss: 0.9740	LR: 0.000558
Training Epoch: 236 [128/50000]	Loss: 0.8464	LR: 0.000558
Training Epoch: 236 [128/50000]	Loss: 0.7734	LR: 0.000558
Training Epoch: 236 [128/50000]	Loss: 0.7921	LR: 0.000558
Training Epoch: 236 [128/50000]	Loss: 0.7754	LR: 0.000558
Evaluating Network.....
Test set: Epoch: 236, Average loss: 0.0106, Top1Accuracy: 0.6299, Top3Accuracy: 0.8278, Top5Accuracy: 0.8843, Time consumed:1.10s

Training Epoch: 237 [128/50000]	Loss: 0.7889	LR: 0.000543
Training Epoch: 237 [128/50000]	Loss: 0.9437	LR: 0.000543
Training Epoch: 237 [128/50000]	Loss: 0.9032	LR: 0.000543
Training Epoch: 237 [128/50000]	Loss: 0.8144	LR: 0.000543
Training Epoch: 237 [128/50000]	Loss: 0.7962	LR: 0.000543
Training Epoch: 237 [128/50000]	Loss: 0.9753	LR: 0.000543
Training Epoch: 237 [128/50000]	Loss: 0.8336	LR: 0.000543
Training Epoch: 237 [128/50000]	Loss: 1.2186	LR: 0.000543
Training Epoch: 237 [128/50000]	Loss: 1.0332	LR: 0.000543
Training Epoch: 237 [128/50000]	Loss: 0.8504	LR: 0.000543
Evaluating Network.....
Test set: Epoch: 237, Average loss: 0.0106, Top1Accuracy: 0.6306, Top3Accuracy: 0.8255, Top5Accuracy: 0.8828, Time consumed:1.11s

Training Epoch: 238 [128/50000]	Loss: 0.6969	LR: 0.000529
Training Epoch: 238 [128/50000]	Loss: 0.8399	LR: 0.000529
Training Epoch: 238 [128/50000]	Loss: 0.8180	LR: 0.000529
Training Epoch: 238 [128/50000]	Loss: 0.7504	LR: 0.000529
Training Epoch: 238 [128/50000]	Loss: 0.8643	LR: 0.000529
Training Epoch: 238 [128/50000]	Loss: 0.9826	LR: 0.000529
Training Epoch: 238 [128/50000]	Loss: 0.7745	LR: 0.000529
Training Epoch: 238 [128/50000]	Loss: 0.9786	LR: 0.000529
Training Epoch: 238 [128/50000]	Loss: 0.9975	LR: 0.000529
Training Epoch: 238 [128/50000]	Loss: 0.7288	LR: 0.000529
Evaluating Network.....
Test set: Epoch: 238, Average loss: 0.0107, Top1Accuracy: 0.6302, Top3Accuracy: 0.8267, Top5Accuracy: 0.8841, Time consumed:1.11s

Training Epoch: 239 [128/50000]	Loss: 0.8646	LR: 0.000515
Training Epoch: 239 [128/50000]	Loss: 0.8533	LR: 0.000515
Training Epoch: 239 [128/50000]	Loss: 1.0265	LR: 0.000515
Training Epoch: 239 [128/50000]	Loss: 0.9098	LR: 0.000515
Training Epoch: 239 [128/50000]	Loss: 0.7822	LR: 0.000515
Training Epoch: 239 [128/50000]	Loss: 1.0138	LR: 0.000515
Training Epoch: 239 [128/50000]	Loss: 0.6780	LR: 0.000515
Training Epoch: 239 [128/50000]	Loss: 0.8885	LR: 0.000515
Training Epoch: 239 [128/50000]	Loss: 0.9193	LR: 0.000515
Training Epoch: 239 [128/50000]	Loss: 1.0396	LR: 0.000515
Evaluating Network.....
Test set: Epoch: 239, Average loss: 0.0106, Top1Accuracy: 0.6299, Top3Accuracy: 0.8258, Top5Accuracy: 0.8833, Time consumed:1.12s

Training Epoch: 240 [128/50000]	Loss: 0.7164	LR: 0.000501
Training Epoch: 240 [128/50000]	Loss: 0.7817	LR: 0.000501
Training Epoch: 240 [128/50000]	Loss: 1.0340	LR: 0.000501
Training Epoch: 240 [128/50000]	Loss: 0.8716	LR: 0.000501
Training Epoch: 240 [128/50000]	Loss: 0.8375	LR: 0.000501
Training Epoch: 240 [128/50000]	Loss: 0.7095	LR: 0.000501
Training Epoch: 240 [128/50000]	Loss: 0.7035	LR: 0.000501
Training Epoch: 240 [128/50000]	Loss: 0.9099	LR: 0.000501
Training Epoch: 240 [128/50000]	Loss: 0.8158	LR: 0.000501
Training Epoch: 240 [128/50000]	Loss: 0.8358	LR: 0.000501
Evaluating Network.....
Test set: Epoch: 240, Average loss: 0.0106, Top1Accuracy: 0.6303, Top3Accuracy: 0.8274, Top5Accuracy: 0.8839, Time consumed:1.09s

Training Epoch: 241 [128/50000]	Loss: 0.7167	LR: 0.000488
Training Epoch: 241 [128/50000]	Loss: 0.9477	LR: 0.000488
Training Epoch: 241 [128/50000]	Loss: 0.7890	LR: 0.000488
Training Epoch: 241 [128/50000]	Loss: 0.7623	LR: 0.000488
Training Epoch: 241 [128/50000]	Loss: 0.7774	LR: 0.000488
Training Epoch: 241 [128/50000]	Loss: 0.9002	LR: 0.000488
Training Epoch: 241 [128/50000]	Loss: 0.8129	LR: 0.000488
Training Epoch: 241 [128/50000]	Loss: 0.8493	LR: 0.000488
Training Epoch: 241 [128/50000]	Loss: 0.7939	LR: 0.000488
Training Epoch: 241 [128/50000]	Loss: 0.8210	LR: 0.000488
Evaluating Network.....
Test set: Epoch: 241, Average loss: 0.0106, Top1Accuracy: 0.6316, Top3Accuracy: 0.8262, Top5Accuracy: 0.8841, Time consumed:1.11s

Training Epoch: 242 [128/50000]	Loss: 0.7643	LR: 0.000475
Training Epoch: 242 [128/50000]	Loss: 0.7539	LR: 0.000475
Training Epoch: 242 [128/50000]	Loss: 0.8215	LR: 0.000475
Training Epoch: 242 [128/50000]	Loss: 0.8665	LR: 0.000475
Training Epoch: 242 [128/50000]	Loss: 0.8017	LR: 0.000475
Training Epoch: 242 [128/50000]	Loss: 0.8941	LR: 0.000475
Training Epoch: 242 [128/50000]	Loss: 0.8720	LR: 0.000475
Training Epoch: 242 [128/50000]	Loss: 0.7890	LR: 0.000475
Training Epoch: 242 [128/50000]	Loss: 0.8973	LR: 0.000475
Training Epoch: 242 [128/50000]	Loss: 0.8306	LR: 0.000475
Evaluating Network.....
Test set: Epoch: 242, Average loss: 0.0107, Top1Accuracy: 0.6299, Top3Accuracy: 0.8258, Top5Accuracy: 0.8840, Time consumed:1.15s

Training Epoch: 243 [128/50000]	Loss: 0.9238	LR: 0.000463
Training Epoch: 243 [128/50000]	Loss: 0.6942	LR: 0.000463
Training Epoch: 243 [128/50000]	Loss: 0.6955	LR: 0.000463
Training Epoch: 243 [128/50000]	Loss: 0.7915	LR: 0.000463
Training Epoch: 243 [128/50000]	Loss: 0.9154	LR: 0.000463
Training Epoch: 243 [128/50000]	Loss: 0.6585	LR: 0.000463
Training Epoch: 243 [128/50000]	Loss: 0.8772	LR: 0.000463
Training Epoch: 243 [128/50000]	Loss: 0.8092	LR: 0.000463
Training Epoch: 243 [128/50000]	Loss: 0.8396	LR: 0.000463
Training Epoch: 243 [128/50000]	Loss: 0.7962	LR: 0.000463
Evaluating Network.....
Test set: Epoch: 243, Average loss: 0.0107, Top1Accuracy: 0.6294, Top3Accuracy: 0.8262, Top5Accuracy: 0.8837, Time consumed:1.12s

Training Epoch: 244 [128/50000]	Loss: 0.6504	LR: 0.000450
Training Epoch: 244 [128/50000]	Loss: 0.8115	LR: 0.000450
Training Epoch: 244 [128/50000]	Loss: 0.8575	LR: 0.000450
Training Epoch: 244 [128/50000]	Loss: 0.8346	LR: 0.000450
Training Epoch: 244 [128/50000]	Loss: 0.9042	LR: 0.000450
Training Epoch: 244 [128/50000]	Loss: 0.9769	LR: 0.000450
Training Epoch: 244 [128/50000]	Loss: 0.8706	LR: 0.000450
Training Epoch: 244 [128/50000]	Loss: 1.0737	LR: 0.000450
Training Epoch: 244 [128/50000]	Loss: 0.9594	LR: 0.000450
Training Epoch: 244 [128/50000]	Loss: 0.8964	LR: 0.000450
Evaluating Network.....
Test set: Epoch: 244, Average loss: 0.0107, Top1Accuracy: 0.6312, Top3Accuracy: 0.8262, Top5Accuracy: 0.8838, Time consumed:1.14s

Training Epoch: 245 [128/50000]	Loss: 0.8077	LR: 0.000439
Training Epoch: 245 [128/50000]	Loss: 0.8021	LR: 0.000439
Training Epoch: 245 [128/50000]	Loss: 0.8361	LR: 0.000439
Training Epoch: 245 [128/50000]	Loss: 0.8484	LR: 0.000439
Training Epoch: 245 [128/50000]	Loss: 0.9491	LR: 0.000439
Training Epoch: 245 [128/50000]	Loss: 0.8051	LR: 0.000439
Training Epoch: 245 [128/50000]	Loss: 0.8876	LR: 0.000439
Training Epoch: 245 [128/50000]	Loss: 0.8296	LR: 0.000439
Training Epoch: 245 [128/50000]	Loss: 1.1050	LR: 0.000439
Training Epoch: 245 [128/50000]	Loss: 0.8950	LR: 0.000439
Evaluating Network.....
Test set: Epoch: 245, Average loss: 0.0106, Top1Accuracy: 0.6297, Top3Accuracy: 0.8261, Top5Accuracy: 0.8834, Time consumed:1.11s

Training Epoch: 246 [128/50000]	Loss: 0.9717	LR: 0.000427
Training Epoch: 246 [128/50000]	Loss: 1.0156	LR: 0.000427
Training Epoch: 246 [128/50000]	Loss: 0.8865	LR: 0.000427
Training Epoch: 246 [128/50000]	Loss: 0.8733	LR: 0.000427
Training Epoch: 246 [128/50000]	Loss: 0.8394	LR: 0.000427
Training Epoch: 246 [128/50000]	Loss: 0.9291	LR: 0.000427
Training Epoch: 246 [128/50000]	Loss: 0.7180	LR: 0.000427
Training Epoch: 246 [128/50000]	Loss: 0.9525	LR: 0.000427
Training Epoch: 246 [128/50000]	Loss: 0.8918	LR: 0.000427
Training Epoch: 246 [128/50000]	Loss: 0.7748	LR: 0.000427
Evaluating Network.....
Test set: Epoch: 246, Average loss: 0.0107, Top1Accuracy: 0.6296, Top3Accuracy: 0.8251, Top5Accuracy: 0.8823, Time consumed:1.10s

Training Epoch: 247 [128/50000]	Loss: 0.8420	LR: 0.000416
Training Epoch: 247 [128/50000]	Loss: 0.8209	LR: 0.000416
Training Epoch: 247 [128/50000]	Loss: 0.8470	LR: 0.000416
Training Epoch: 247 [128/50000]	Loss: 0.8391	LR: 0.000416
Training Epoch: 247 [128/50000]	Loss: 0.8437	LR: 0.000416
Training Epoch: 247 [128/50000]	Loss: 0.8276	LR: 0.000416
Training Epoch: 247 [128/50000]	Loss: 0.8580	LR: 0.000416
Training Epoch: 247 [128/50000]	Loss: 0.8129	LR: 0.000416
Training Epoch: 247 [128/50000]	Loss: 0.9241	LR: 0.000416
Training Epoch: 247 [128/50000]	Loss: 0.8092	LR: 0.000416
Evaluating Network.....
Test set: Epoch: 247, Average loss: 0.0106, Top1Accuracy: 0.6287, Top3Accuracy: 0.8258, Top5Accuracy: 0.8835, Time consumed:1.12s

Training Epoch: 248 [128/50000]	Loss: 0.7386	LR: 0.000405
Training Epoch: 248 [128/50000]	Loss: 0.8108	LR: 0.000405
Training Epoch: 248 [128/50000]	Loss: 0.9559	LR: 0.000405
Training Epoch: 248 [128/50000]	Loss: 0.7154	LR: 0.000405
Training Epoch: 248 [128/50000]	Loss: 0.9771	LR: 0.000405
Training Epoch: 248 [128/50000]	Loss: 0.9582	LR: 0.000405
Training Epoch: 248 [128/50000]	Loss: 0.9123	LR: 0.000405
Training Epoch: 248 [128/50000]	Loss: 0.7990	LR: 0.000405
Training Epoch: 248 [128/50000]	Loss: 0.7715	LR: 0.000405
Training Epoch: 248 [128/50000]	Loss: 1.0154	LR: 0.000405
Evaluating Network.....
Test set: Epoch: 248, Average loss: 0.0106, Top1Accuracy: 0.6290, Top3Accuracy: 0.8254, Top5Accuracy: 0.8838, Time consumed:1.12s

Training Epoch: 249 [128/50000]	Loss: 0.8838	LR: 0.000394
Training Epoch: 249 [128/50000]	Loss: 0.8874	LR: 0.000394
Training Epoch: 249 [128/50000]	Loss: 0.7242	LR: 0.000394
Training Epoch: 249 [128/50000]	Loss: 0.7406	LR: 0.000394
Training Epoch: 249 [128/50000]	Loss: 0.7541	LR: 0.000394
Training Epoch: 249 [128/50000]	Loss: 0.8150	LR: 0.000394
Training Epoch: 249 [128/50000]	Loss: 0.9005	LR: 0.000394
Training Epoch: 249 [128/50000]	Loss: 0.7845	LR: 0.000394
Training Epoch: 249 [128/50000]	Loss: 0.9293	LR: 0.000394
Training Epoch: 249 [128/50000]	Loss: 0.8664	LR: 0.000394
Evaluating Network.....
Test set: Epoch: 249, Average loss: 0.0106, Top1Accuracy: 0.6298, Top3Accuracy: 0.8255, Top5Accuracy: 0.8841, Time consumed:1.12s

Training Epoch: 250 [128/50000]	Loss: 0.9805	LR: 0.000384
Training Epoch: 250 [128/50000]	Loss: 0.8758	LR: 0.000384
Training Epoch: 250 [128/50000]	Loss: 0.6639	LR: 0.000384
Training Epoch: 250 [128/50000]	Loss: 0.8461	LR: 0.000384
Training Epoch: 250 [128/50000]	Loss: 0.9047	LR: 0.000384
Training Epoch: 250 [128/50000]	Loss: 0.7808	LR: 0.000384
Training Epoch: 250 [128/50000]	Loss: 0.8174	LR: 0.000384
Training Epoch: 250 [128/50000]	Loss: 0.6532	LR: 0.000384
Training Epoch: 250 [128/50000]	Loss: 1.1169	LR: 0.000384
Training Epoch: 250 [128/50000]	Loss: 0.9772	LR: 0.000384
Evaluating Network.....
Test set: Epoch: 250, Average loss: 0.0107, Top1Accuracy: 0.6295, Top3Accuracy: 0.8253, Top5Accuracy: 0.8833, Time consumed:1.12s

Training Epoch: 251 [128/50000]	Loss: 0.8963	LR: 0.000373
Training Epoch: 251 [128/50000]	Loss: 0.8733	LR: 0.000373
Training Epoch: 251 [128/50000]	Loss: 0.8470	LR: 0.000373
Training Epoch: 251 [128/50000]	Loss: 0.6982	LR: 0.000373
Training Epoch: 251 [128/50000]	Loss: 0.7134	LR: 0.000373
Training Epoch: 251 [128/50000]	Loss: 0.7679	LR: 0.000373
Training Epoch: 251 [128/50000]	Loss: 0.6873	LR: 0.000373
Training Epoch: 251 [128/50000]	Loss: 0.8740	LR: 0.000373
Training Epoch: 251 [128/50000]	Loss: 0.7949	LR: 0.000373
Training Epoch: 251 [128/50000]	Loss: 0.7820	LR: 0.000373
Evaluating Network.....
Test set: Epoch: 251, Average loss: 0.0106, Top1Accuracy: 0.6293, Top3Accuracy: 0.8253, Top5Accuracy: 0.8834, Time consumed:1.10s

Training Epoch: 252 [128/50000]	Loss: 0.9546	LR: 0.000364
Training Epoch: 252 [128/50000]	Loss: 0.9204	LR: 0.000364
Training Epoch: 252 [128/50000]	Loss: 0.8836	LR: 0.000364
Training Epoch: 252 [128/50000]	Loss: 0.7087	LR: 0.000364
Training Epoch: 252 [128/50000]	Loss: 0.9058	LR: 0.000364
Training Epoch: 252 [128/50000]	Loss: 0.6780	LR: 0.000364
Training Epoch: 252 [128/50000]	Loss: 0.7122	LR: 0.000364
Training Epoch: 252 [128/50000]	Loss: 0.8190	LR: 0.000364
Training Epoch: 252 [128/50000]	Loss: 0.7834	LR: 0.000364
Training Epoch: 252 [128/50000]	Loss: 0.8793	LR: 0.000364
Evaluating Network.....
Test set: Epoch: 252, Average loss: 0.0106, Top1Accuracy: 0.6306, Top3Accuracy: 0.8258, Top5Accuracy: 0.8831, Time consumed:1.08s

Training Epoch: 253 [128/50000]	Loss: 0.7615	LR: 0.000354
Training Epoch: 253 [128/50000]	Loss: 0.9008	LR: 0.000354
Training Epoch: 253 [128/50000]	Loss: 0.6295	LR: 0.000354
Training Epoch: 253 [128/50000]	Loss: 0.8991	LR: 0.000354
Training Epoch: 253 [128/50000]	Loss: 0.9753	LR: 0.000354
Training Epoch: 253 [128/50000]	Loss: 0.8497	LR: 0.000354
Training Epoch: 253 [128/50000]	Loss: 0.7396	LR: 0.000354
Training Epoch: 253 [128/50000]	Loss: 1.0680	LR: 0.000354
Training Epoch: 253 [128/50000]	Loss: 0.8004	LR: 0.000354
Training Epoch: 253 [128/50000]	Loss: 0.9271	LR: 0.000354
Evaluating Network.....
Test set: Epoch: 253, Average loss: 0.0107, Top1Accuracy: 0.6315, Top3Accuracy: 0.8254, Top5Accuracy: 0.8845, Time consumed:1.10s

Training Epoch: 254 [128/50000]	Loss: 0.9332	LR: 0.000345
Training Epoch: 254 [128/50000]	Loss: 0.9729	LR: 0.000345
Training Epoch: 254 [128/50000]	Loss: 0.8817	LR: 0.000345
Training Epoch: 254 [128/50000]	Loss: 0.6779	LR: 0.000345
Training Epoch: 254 [128/50000]	Loss: 0.7803	LR: 0.000345
Training Epoch: 254 [128/50000]	Loss: 0.7813	LR: 0.000345
Training Epoch: 254 [128/50000]	Loss: 0.8854	LR: 0.000345
Training Epoch: 254 [128/50000]	Loss: 0.7683	LR: 0.000345
Training Epoch: 254 [128/50000]	Loss: 0.7209	LR: 0.000345
Training Epoch: 254 [128/50000]	Loss: 1.0423	LR: 0.000345
Evaluating Network.....
Test set: Epoch: 254, Average loss: 0.0106, Top1Accuracy: 0.6302, Top3Accuracy: 0.8257, Top5Accuracy: 0.8838, Time consumed:1.11s

Training Epoch: 255 [128/50000]	Loss: 0.8580	LR: 0.000336
Training Epoch: 255 [128/50000]	Loss: 0.9972	LR: 0.000336
Training Epoch: 255 [128/50000]	Loss: 0.8956	LR: 0.000336
Training Epoch: 255 [128/50000]	Loss: 0.7078	LR: 0.000336
Training Epoch: 255 [128/50000]	Loss: 0.6544	LR: 0.000336
Training Epoch: 255 [128/50000]	Loss: 0.8871	LR: 0.000336
Training Epoch: 255 [128/50000]	Loss: 0.8873	LR: 0.000336
Training Epoch: 255 [128/50000]	Loss: 0.8562	LR: 0.000336
Training Epoch: 255 [128/50000]	Loss: 0.8839	LR: 0.000336
Training Epoch: 255 [128/50000]	Loss: 1.0972	LR: 0.000336
Evaluating Network.....
Test set: Epoch: 255, Average loss: 0.0106, Top1Accuracy: 0.6293, Top3Accuracy: 0.8259, Top5Accuracy: 0.8831, Time consumed:1.10s

Training Epoch: 256 [128/50000]	Loss: 0.7160	LR: 0.000327
Training Epoch: 256 [128/50000]	Loss: 0.8205	LR: 0.000327
Training Epoch: 256 [128/50000]	Loss: 0.8787	LR: 0.000327
Training Epoch: 256 [128/50000]	Loss: 0.6017	LR: 0.000327
Training Epoch: 256 [128/50000]	Loss: 0.8376	LR: 0.000327
Training Epoch: 256 [128/50000]	Loss: 0.7948	LR: 0.000327
Training Epoch: 256 [128/50000]	Loss: 0.7486	LR: 0.000327
Training Epoch: 256 [128/50000]	Loss: 0.9056	LR: 0.000327
Training Epoch: 256 [128/50000]	Loss: 0.8245	LR: 0.000327
Training Epoch: 256 [128/50000]	Loss: 0.8227	LR: 0.000327
Evaluating Network.....
Test set: Epoch: 256, Average loss: 0.0107, Top1Accuracy: 0.6303, Top3Accuracy: 0.8252, Top5Accuracy: 0.8833, Time consumed:1.11s

Training Epoch: 257 [128/50000]	Loss: 0.8666	LR: 0.000318
Training Epoch: 257 [128/50000]	Loss: 0.8382	LR: 0.000318
Training Epoch: 257 [128/50000]	Loss: 0.8381	LR: 0.000318
Training Epoch: 257 [128/50000]	Loss: 0.9037	LR: 0.000318
Training Epoch: 257 [128/50000]	Loss: 0.7820	LR: 0.000318
Training Epoch: 257 [128/50000]	Loss: 0.8047	LR: 0.000318
Training Epoch: 257 [128/50000]	Loss: 0.7559	LR: 0.000318
Training Epoch: 257 [128/50000]	Loss: 0.7461	LR: 0.000318
Training Epoch: 257 [128/50000]	Loss: 0.8051	LR: 0.000318
Training Epoch: 257 [128/50000]	Loss: 0.8939	LR: 0.000318
Evaluating Network.....
Test set: Epoch: 257, Average loss: 0.0107, Top1Accuracy: 0.6299, Top3Accuracy: 0.8264, Top5Accuracy: 0.8827, Time consumed:1.10s

Training Epoch: 258 [128/50000]	Loss: 1.0082	LR: 0.000310
Training Epoch: 258 [128/50000]	Loss: 0.7287	LR: 0.000310
Training Epoch: 258 [128/50000]	Loss: 0.8606	LR: 0.000310
Training Epoch: 258 [128/50000]	Loss: 0.8517	LR: 0.000310
Training Epoch: 258 [128/50000]	Loss: 0.7671	LR: 0.000310
Training Epoch: 258 [128/50000]	Loss: 0.8513	LR: 0.000310
Training Epoch: 258 [128/50000]	Loss: 0.8518	LR: 0.000310
Training Epoch: 258 [128/50000]	Loss: 0.9758	LR: 0.000310
Training Epoch: 258 [128/50000]	Loss: 0.8880	LR: 0.000310
Training Epoch: 258 [128/50000]	Loss: 0.6477	LR: 0.000310
Evaluating Network.....
Test set: Epoch: 258, Average loss: 0.0107, Top1Accuracy: 0.6301, Top3Accuracy: 0.8255, Top5Accuracy: 0.8823, Time consumed:1.10s

Training Epoch: 259 [128/50000]	Loss: 0.6879	LR: 0.000302
Training Epoch: 259 [128/50000]	Loss: 0.9746	LR: 0.000302
Training Epoch: 259 [128/50000]	Loss: 0.9138	LR: 0.000302
Training Epoch: 259 [128/50000]	Loss: 0.8604	LR: 0.000302
Training Epoch: 259 [128/50000]	Loss: 0.8823	LR: 0.000302
Training Epoch: 259 [128/50000]	Loss: 0.7286	LR: 0.000302
Training Epoch: 259 [128/50000]	Loss: 1.1360	LR: 0.000302
Training Epoch: 259 [128/50000]	Loss: 0.7951	LR: 0.000302
Training Epoch: 259 [128/50000]	Loss: 0.8592	LR: 0.000302
Training Epoch: 259 [128/50000]	Loss: 0.7469	LR: 0.000302
Evaluating Network.....
Test set: Epoch: 259, Average loss: 0.0106, Top1Accuracy: 0.6303, Top3Accuracy: 0.8250, Top5Accuracy: 0.8836, Time consumed:1.11s

Training Epoch: 260 [128/50000]	Loss: 0.8243	LR: 0.000294
Training Epoch: 260 [128/50000]	Loss: 0.9179	LR: 0.000294
Training Epoch: 260 [128/50000]	Loss: 0.7304	LR: 0.000294
Training Epoch: 260 [128/50000]	Loss: 0.8671	LR: 0.000294
Training Epoch: 260 [128/50000]	Loss: 0.7717	LR: 0.000294
Training Epoch: 260 [128/50000]	Loss: 0.7166	LR: 0.000294
Training Epoch: 260 [128/50000]	Loss: 0.9258	LR: 0.000294
Training Epoch: 260 [128/50000]	Loss: 0.8701	LR: 0.000294
Training Epoch: 260 [128/50000]	Loss: 1.1098	LR: 0.000294
Training Epoch: 260 [128/50000]	Loss: 0.7573	LR: 0.000294
Evaluating Network.....
Test set: Epoch: 260, Average loss: 0.0107, Top1Accuracy: 0.6288, Top3Accuracy: 0.8262, Top5Accuracy: 0.8838, Time consumed:1.11s

Training Epoch: 261 [128/50000]	Loss: 0.8041	LR: 0.000286
Training Epoch: 261 [128/50000]	Loss: 0.8566	LR: 0.000286
Training Epoch: 261 [128/50000]	Loss: 0.8278	LR: 0.000286
Training Epoch: 261 [128/50000]	Loss: 0.6491	LR: 0.000286
Training Epoch: 261 [128/50000]	Loss: 0.8016	LR: 0.000286
Training Epoch: 261 [128/50000]	Loss: 0.7816	LR: 0.000286
Training Epoch: 261 [128/50000]	Loss: 0.7208	LR: 0.000286
Training Epoch: 261 [128/50000]	Loss: 0.7131	LR: 0.000286
Training Epoch: 261 [128/50000]	Loss: 0.8307	LR: 0.000286
Training Epoch: 261 [128/50000]	Loss: 0.8190	LR: 0.000286
Evaluating Network.....
Test set: Epoch: 261, Average loss: 0.0106, Top1Accuracy: 0.6297, Top3Accuracy: 0.8244, Top5Accuracy: 0.8847, Time consumed:1.09s

Training Epoch: 262 [128/50000]	Loss: 0.8258	LR: 0.000278
Training Epoch: 262 [128/50000]	Loss: 1.0190	LR: 0.000278
Training Epoch: 262 [128/50000]	Loss: 0.6538	LR: 0.000278
Training Epoch: 262 [128/50000]	Loss: 0.8333	LR: 0.000278
Training Epoch: 262 [128/50000]	Loss: 0.7957	LR: 0.000278
Training Epoch: 262 [128/50000]	Loss: 0.8877	LR: 0.000278
Training Epoch: 262 [128/50000]	Loss: 0.8369	LR: 0.000278
Training Epoch: 262 [128/50000]	Loss: 0.8050	LR: 0.000278
Training Epoch: 262 [128/50000]	Loss: 0.9006	LR: 0.000278
Training Epoch: 262 [128/50000]	Loss: 0.9221	LR: 0.000278
Evaluating Network.....
Test set: Epoch: 262, Average loss: 0.0107, Top1Accuracy: 0.6308, Top3Accuracy: 0.8256, Top5Accuracy: 0.8840, Time consumed:1.10s

Training Epoch: 263 [128/50000]	Loss: 0.7013	LR: 0.000271
Training Epoch: 263 [128/50000]	Loss: 0.8384	LR: 0.000271
Training Epoch: 263 [128/50000]	Loss: 0.7927	LR: 0.000271
Training Epoch: 263 [128/50000]	Loss: 0.9730	LR: 0.000271
Training Epoch: 263 [128/50000]	Loss: 0.9748	LR: 0.000271
Training Epoch: 263 [128/50000]	Loss: 0.7279	LR: 0.000271
Training Epoch: 263 [128/50000]	Loss: 0.8314	LR: 0.000271
Training Epoch: 263 [128/50000]	Loss: 0.7180	LR: 0.000271
Training Epoch: 263 [128/50000]	Loss: 0.7727	LR: 0.000271
Training Epoch: 263 [128/50000]	Loss: 0.9786	LR: 0.000271
Evaluating Network.....
Test set: Epoch: 263, Average loss: 0.0107, Top1Accuracy: 0.6298, Top3Accuracy: 0.8251, Top5Accuracy: 0.8834, Time consumed:1.11s

Training Epoch: 264 [128/50000]	Loss: 0.8041	LR: 0.000264
Training Epoch: 264 [128/50000]	Loss: 0.9207	LR: 0.000264
Training Epoch: 264 [128/50000]	Loss: 0.9231	LR: 0.000264
Training Epoch: 264 [128/50000]	Loss: 0.9620	LR: 0.000264
Training Epoch: 264 [128/50000]	Loss: 0.7259	LR: 0.000264
Training Epoch: 264 [128/50000]	Loss: 0.7412	LR: 0.000264
Training Epoch: 264 [128/50000]	Loss: 0.9889	LR: 0.000264
Training Epoch: 264 [128/50000]	Loss: 0.8972	LR: 0.000264
Training Epoch: 264 [128/50000]	Loss: 1.0028	LR: 0.000264
Training Epoch: 264 [128/50000]	Loss: 0.8728	LR: 0.000264
Evaluating Network.....
Test set: Epoch: 264, Average loss: 0.0107, Top1Accuracy: 0.6288, Top3Accuracy: 0.8244, Top5Accuracy: 0.8831, Time consumed:1.11s

Training Epoch: 265 [128/50000]	Loss: 0.9883	LR: 0.000257
Training Epoch: 265 [128/50000]	Loss: 0.7642	LR: 0.000257
Training Epoch: 265 [128/50000]	Loss: 0.9905	LR: 0.000257
Training Epoch: 265 [128/50000]	Loss: 0.9621	LR: 0.000257
Training Epoch: 265 [128/50000]	Loss: 0.7723	LR: 0.000257
Training Epoch: 265 [128/50000]	Loss: 0.7072	LR: 0.000257
Training Epoch: 265 [128/50000]	Loss: 0.9136	LR: 0.000257
Training Epoch: 265 [128/50000]	Loss: 0.9718	LR: 0.000257
Training Epoch: 265 [128/50000]	Loss: 0.8925	LR: 0.000257
Training Epoch: 265 [128/50000]	Loss: 0.9040	LR: 0.000257
Evaluating Network.....
Test set: Epoch: 265, Average loss: 0.0107, Top1Accuracy: 0.6277, Top3Accuracy: 0.8250, Top5Accuracy: 0.8832, Time consumed:1.09s

Training Epoch: 266 [128/50000]	Loss: 1.0643	LR: 0.000250
Training Epoch: 266 [128/50000]	Loss: 0.8103	LR: 0.000250
Training Epoch: 266 [128/50000]	Loss: 0.7725	LR: 0.000250
Training Epoch: 266 [128/50000]	Loss: 0.8411	LR: 0.000250
Training Epoch: 266 [128/50000]	Loss: 0.8129	LR: 0.000250
Training Epoch: 266 [128/50000]	Loss: 0.8413	LR: 0.000250
Training Epoch: 266 [128/50000]	Loss: 0.7660	LR: 0.000250
Training Epoch: 266 [128/50000]	Loss: 1.0851	LR: 0.000250
Training Epoch: 266 [128/50000]	Loss: 0.8165	LR: 0.000250
Training Epoch: 266 [128/50000]	Loss: 0.8902	LR: 0.000250
Evaluating Network.....
Test set: Epoch: 266, Average loss: 0.0107, Top1Accuracy: 0.6302, Top3Accuracy: 0.8249, Top5Accuracy: 0.8834, Time consumed:1.10s

Training Epoch: 267 [128/50000]	Loss: 0.8091	LR: 0.000243
Training Epoch: 267 [128/50000]	Loss: 0.9687	LR: 0.000243
Training Epoch: 267 [128/50000]	Loss: 0.8298	LR: 0.000243
Training Epoch: 267 [128/50000]	Loss: 1.0563	LR: 0.000243
Training Epoch: 267 [128/50000]	Loss: 0.7530	LR: 0.000243
Training Epoch: 267 [128/50000]	Loss: 0.8051	LR: 0.000243
Training Epoch: 267 [128/50000]	Loss: 0.7725	LR: 0.000243
Training Epoch: 267 [128/50000]	Loss: 0.8363	LR: 0.000243
Training Epoch: 267 [128/50000]	Loss: 0.9118	LR: 0.000243
Training Epoch: 267 [128/50000]	Loss: 0.8012	LR: 0.000243
Evaluating Network.....
Test set: Epoch: 267, Average loss: 0.0106, Top1Accuracy: 0.6289, Top3Accuracy: 0.8263, Top5Accuracy: 0.8827, Time consumed:1.12s

Training Epoch: 268 [128/50000]	Loss: 0.7300	LR: 0.000237
Training Epoch: 268 [128/50000]	Loss: 0.7471	LR: 0.000237
Training Epoch: 268 [128/50000]	Loss: 1.0052	LR: 0.000237
Training Epoch: 268 [128/50000]	Loss: 0.6005	LR: 0.000237
Training Epoch: 268 [128/50000]	Loss: 0.8809	LR: 0.000237
Training Epoch: 268 [128/50000]	Loss: 0.7857	LR: 0.000237
Training Epoch: 268 [128/50000]	Loss: 0.7661	LR: 0.000237
Training Epoch: 268 [128/50000]	Loss: 1.0418	LR: 0.000237
Training Epoch: 268 [128/50000]	Loss: 0.8486	LR: 0.000237
Training Epoch: 268 [128/50000]	Loss: 0.8813	LR: 0.000237
Evaluating Network.....
Test set: Epoch: 268, Average loss: 0.0106, Top1Accuracy: 0.6282, Top3Accuracy: 0.8255, Top5Accuracy: 0.8833, Time consumed:1.10s

Training Epoch: 269 [128/50000]	Loss: 0.8391	LR: 0.000231
Training Epoch: 269 [128/50000]	Loss: 0.8383	LR: 0.000231
Training Epoch: 269 [128/50000]	Loss: 0.8803	LR: 0.000231
Training Epoch: 269 [128/50000]	Loss: 0.7516	LR: 0.000231
Training Epoch: 269 [128/50000]	Loss: 0.7353	LR: 0.000231
Training Epoch: 269 [128/50000]	Loss: 0.7410	LR: 0.000231
Training Epoch: 269 [128/50000]	Loss: 0.9984	LR: 0.000231
Training Epoch: 269 [128/50000]	Loss: 0.7462	LR: 0.000231
Training Epoch: 269 [128/50000]	Loss: 0.8421	LR: 0.000231
Training Epoch: 269 [128/50000]	Loss: 0.7096	LR: 0.000231
Evaluating Network.....
Test set: Epoch: 269, Average loss: 0.0106, Top1Accuracy: 0.6299, Top3Accuracy: 0.8255, Top5Accuracy: 0.8829, Time consumed:1.11s

Training Epoch: 270 [128/50000]	Loss: 0.7955	LR: 0.000225
Training Epoch: 270 [128/50000]	Loss: 0.7109	LR: 0.000225
Training Epoch: 270 [128/50000]	Loss: 0.8242	LR: 0.000225
Training Epoch: 270 [128/50000]	Loss: 0.7316	LR: 0.000225
Training Epoch: 270 [128/50000]	Loss: 1.0534	LR: 0.000225
Training Epoch: 270 [128/50000]	Loss: 0.7596	LR: 0.000225
Training Epoch: 270 [128/50000]	Loss: 0.8110	LR: 0.000225
Training Epoch: 270 [128/50000]	Loss: 0.9383	LR: 0.000225
Training Epoch: 270 [128/50000]	Loss: 0.8642	LR: 0.000225
Training Epoch: 270 [128/50000]	Loss: 0.7445	LR: 0.000225
Evaluating Network.....
Test set: Epoch: 270, Average loss: 0.0106, Top1Accuracy: 0.6289, Top3Accuracy: 0.8252, Top5Accuracy: 0.8838, Time consumed:1.10s

Training Epoch: 271 [128/50000]	Loss: 0.8776	LR: 0.000219
Training Epoch: 271 [128/50000]	Loss: 0.9240	LR: 0.000219
Training Epoch: 271 [128/50000]	Loss: 0.6097	LR: 0.000219
Training Epoch: 271 [128/50000]	Loss: 0.8479	LR: 0.000219
Training Epoch: 271 [128/50000]	Loss: 0.8979	LR: 0.000219
Training Epoch: 271 [128/50000]	Loss: 1.0014	LR: 0.000219
Training Epoch: 271 [128/50000]	Loss: 0.7808	LR: 0.000219
Training Epoch: 271 [128/50000]	Loss: 0.9980	LR: 0.000219
Training Epoch: 271 [128/50000]	Loss: 0.7249	LR: 0.000219
Training Epoch: 271 [128/50000]	Loss: 0.6258	LR: 0.000219
Evaluating Network.....
Test set: Epoch: 271, Average loss: 0.0106, Top1Accuracy: 0.6295, Top3Accuracy: 0.8265, Top5Accuracy: 0.8838, Time consumed:1.11s

Training Epoch: 272 [128/50000]	Loss: 0.7730	LR: 0.000213
Training Epoch: 272 [128/50000]	Loss: 0.6768	LR: 0.000213
Training Epoch: 272 [128/50000]	Loss: 0.8514	LR: 0.000213
Training Epoch: 272 [128/50000]	Loss: 0.8140	LR: 0.000213
Training Epoch: 272 [128/50000]	Loss: 0.8628	LR: 0.000213
Training Epoch: 272 [128/50000]	Loss: 0.8781	LR: 0.000213
Training Epoch: 272 [128/50000]	Loss: 0.6485	LR: 0.000213
Training Epoch: 272 [128/50000]	Loss: 0.7993	LR: 0.000213
Training Epoch: 272 [128/50000]	Loss: 0.8789	LR: 0.000213
Training Epoch: 272 [128/50000]	Loss: 0.8496	LR: 0.000213
Evaluating Network.....
Test set: Epoch: 272, Average loss: 0.0106, Top1Accuracy: 0.6302, Top3Accuracy: 0.8253, Top5Accuracy: 0.8830, Time consumed:1.10s

Training Epoch: 273 [128/50000]	Loss: 0.8219	LR: 0.000207
Training Epoch: 273 [128/50000]	Loss: 0.6572	LR: 0.000207
Training Epoch: 273 [128/50000]	Loss: 0.8530	LR: 0.000207
Training Epoch: 273 [128/50000]	Loss: 0.9086	LR: 0.000207
Training Epoch: 273 [128/50000]	Loss: 0.8465	LR: 0.000207
Training Epoch: 273 [128/50000]	Loss: 0.7048	LR: 0.000207
Training Epoch: 273 [128/50000]	Loss: 0.8350	LR: 0.000207
Training Epoch: 273 [128/50000]	Loss: 0.7074	LR: 0.000207
Training Epoch: 273 [128/50000]	Loss: 0.7555	LR: 0.000207
Training Epoch: 273 [128/50000]	Loss: 0.6850	LR: 0.000207
Evaluating Network.....
Test set: Epoch: 273, Average loss: 0.0107, Top1Accuracy: 0.6293, Top3Accuracy: 0.8257, Top5Accuracy: 0.8837, Time consumed:1.10s

Training Epoch: 274 [128/50000]	Loss: 0.9216	LR: 0.000202
Training Epoch: 274 [128/50000]	Loss: 0.7270	LR: 0.000202
Training Epoch: 274 [128/50000]	Loss: 0.6435	LR: 0.000202
Training Epoch: 274 [128/50000]	Loss: 0.7342	LR: 0.000202
Training Epoch: 274 [128/50000]	Loss: 0.8399	LR: 0.000202
Training Epoch: 274 [128/50000]	Loss: 0.6304	LR: 0.000202
Training Epoch: 274 [128/50000]	Loss: 0.8465	LR: 0.000202
Training Epoch: 274 [128/50000]	Loss: 0.7753	LR: 0.000202
Training Epoch: 274 [128/50000]	Loss: 0.9370	LR: 0.000202
Training Epoch: 274 [128/50000]	Loss: 0.7247	LR: 0.000202
Evaluating Network.....
Test set: Epoch: 274, Average loss: 0.0107, Top1Accuracy: 0.6289, Top3Accuracy: 0.8259, Top5Accuracy: 0.8825, Time consumed:1.11s

Training Epoch: 275 [128/50000]	Loss: 0.7281	LR: 0.000197
Training Epoch: 275 [128/50000]	Loss: 0.9034	LR: 0.000197
Training Epoch: 275 [128/50000]	Loss: 0.8264	LR: 0.000197
Training Epoch: 275 [128/50000]	Loss: 1.1041	LR: 0.000197
Training Epoch: 275 [128/50000]	Loss: 1.0102	LR: 0.000197
Training Epoch: 275 [128/50000]	Loss: 0.8269	LR: 0.000197
Training Epoch: 275 [128/50000]	Loss: 0.8900	LR: 0.000197
Training Epoch: 275 [128/50000]	Loss: 0.8335	LR: 0.000197
Training Epoch: 275 [128/50000]	Loss: 0.9379	LR: 0.000197
Training Epoch: 275 [128/50000]	Loss: 0.8526	LR: 0.000197
Evaluating Network.....
Test set: Epoch: 275, Average loss: 0.0107, Top1Accuracy: 0.6289, Top3Accuracy: 0.8260, Top5Accuracy: 0.8837, Time consumed:1.11s

Training Epoch: 276 [128/50000]	Loss: 0.7914	LR: 0.000191
Training Epoch: 276 [128/50000]	Loss: 0.9213	LR: 0.000191
Training Epoch: 276 [128/50000]	Loss: 0.8608	LR: 0.000191
Training Epoch: 276 [128/50000]	Loss: 0.7385	LR: 0.000191
Training Epoch: 276 [128/50000]	Loss: 0.7106	LR: 0.000191
Training Epoch: 276 [128/50000]	Loss: 0.7154	LR: 0.000191
Training Epoch: 276 [128/50000]	Loss: 0.8690	LR: 0.000191
Training Epoch: 276 [128/50000]	Loss: 0.8777	LR: 0.000191
Training Epoch: 276 [128/50000]	Loss: 0.8418	LR: 0.000191
Training Epoch: 276 [128/50000]	Loss: 0.8123	LR: 0.000191
Evaluating Network.....
Test set: Epoch: 276, Average loss: 0.0107, Top1Accuracy: 0.6285, Top3Accuracy: 0.8263, Top5Accuracy: 0.8832, Time consumed:1.10s

Training Epoch: 277 [128/50000]	Loss: 0.9168	LR: 0.000186
Training Epoch: 277 [128/50000]	Loss: 0.9151	LR: 0.000186
Training Epoch: 277 [128/50000]	Loss: 0.9135	LR: 0.000186
Training Epoch: 277 [128/50000]	Loss: 0.7575	LR: 0.000186
Training Epoch: 277 [128/50000]	Loss: 0.9464	LR: 0.000186
Training Epoch: 277 [128/50000]	Loss: 0.7690	LR: 0.000186
Training Epoch: 277 [128/50000]	Loss: 0.7769	LR: 0.000186
Training Epoch: 277 [128/50000]	Loss: 0.7528	LR: 0.000186
Training Epoch: 277 [128/50000]	Loss: 0.7745	LR: 0.000186
Training Epoch: 277 [128/50000]	Loss: 0.8264	LR: 0.000186
Evaluating Network.....
Test set: Epoch: 277, Average loss: 0.0107, Top1Accuracy: 0.6305, Top3Accuracy: 0.8258, Top5Accuracy: 0.8835, Time consumed:1.08s

Training Epoch: 278 [128/50000]	Loss: 0.8868	LR: 0.000181
Training Epoch: 278 [128/50000]	Loss: 0.9458	LR: 0.000181
Training Epoch: 278 [128/50000]	Loss: 0.9524	LR: 0.000181
Training Epoch: 278 [128/50000]	Loss: 0.7835	LR: 0.000181
Training Epoch: 278 [128/50000]	Loss: 0.8595	LR: 0.000181
Training Epoch: 278 [128/50000]	Loss: 0.6910	LR: 0.000181
Training Epoch: 278 [128/50000]	Loss: 0.7919	LR: 0.000181
Training Epoch: 278 [128/50000]	Loss: 0.8239	LR: 0.000181
Training Epoch: 278 [128/50000]	Loss: 0.7394	LR: 0.000181
Training Epoch: 278 [128/50000]	Loss: 0.7643	LR: 0.000181
Evaluating Network.....
Test set: Epoch: 278, Average loss: 0.0107, Top1Accuracy: 0.6285, Top3Accuracy: 0.8254, Top5Accuracy: 0.8830, Time consumed:1.11s

Training Epoch: 279 [128/50000]	Loss: 0.7868	LR: 0.000177
Training Epoch: 279 [128/50000]	Loss: 0.6595	LR: 0.000177
Training Epoch: 279 [128/50000]	Loss: 0.8537	LR: 0.000177
Training Epoch: 279 [128/50000]	Loss: 0.8651	LR: 0.000177
Training Epoch: 279 [128/50000]	Loss: 0.6738	LR: 0.000177
Training Epoch: 279 [128/50000]	Loss: 0.8889	LR: 0.000177
Training Epoch: 279 [128/50000]	Loss: 1.0171	LR: 0.000177
Training Epoch: 279 [128/50000]	Loss: 0.8716	LR: 0.000177
Training Epoch: 279 [128/50000]	Loss: 0.7019	LR: 0.000177
Training Epoch: 279 [128/50000]	Loss: 0.6984	LR: 0.000177
Evaluating Network.....
Test set: Epoch: 279, Average loss: 0.0106, Top1Accuracy: 0.6284, Top3Accuracy: 0.8247, Top5Accuracy: 0.8828, Time consumed:1.08s

Training Epoch: 280 [128/50000]	Loss: 0.8946	LR: 0.000172
Training Epoch: 280 [128/50000]	Loss: 0.9023	LR: 0.000172
Training Epoch: 280 [128/50000]	Loss: 0.7467	LR: 0.000172
Training Epoch: 280 [128/50000]	Loss: 0.9047	LR: 0.000172
Training Epoch: 280 [128/50000]	Loss: 0.8117	LR: 0.000172
Training Epoch: 280 [128/50000]	Loss: 0.7977	LR: 0.000172
Training Epoch: 280 [128/50000]	Loss: 0.9503	LR: 0.000172
Training Epoch: 280 [128/50000]	Loss: 0.9414	LR: 0.000172
Training Epoch: 280 [128/50000]	Loss: 0.8900	LR: 0.000172
Training Epoch: 280 [128/50000]	Loss: 0.7357	LR: 0.000172
Evaluating Network.....
Test set: Epoch: 280, Average loss: 0.0106, Top1Accuracy: 0.6302, Top3Accuracy: 0.8258, Top5Accuracy: 0.8837, Time consumed:1.09s

Training Epoch: 281 [128/50000]	Loss: 0.7657	LR: 0.000167
Training Epoch: 281 [128/50000]	Loss: 0.8674	LR: 0.000167
Training Epoch: 281 [128/50000]	Loss: 0.7985	LR: 0.000167
Training Epoch: 281 [128/50000]	Loss: 0.7140	LR: 0.000167
Training Epoch: 281 [128/50000]	Loss: 0.8471	LR: 0.000167
Training Epoch: 281 [128/50000]	Loss: 0.7872	LR: 0.000167
Training Epoch: 281 [128/50000]	Loss: 0.8694	LR: 0.000167
Training Epoch: 281 [128/50000]	Loss: 0.7615	LR: 0.000167
Training Epoch: 281 [128/50000]	Loss: 0.8525	LR: 0.000167
Training Epoch: 281 [128/50000]	Loss: 0.9477	LR: 0.000167
Evaluating Network.....
Test set: Epoch: 281, Average loss: 0.0106, Top1Accuracy: 0.6304, Top3Accuracy: 0.8256, Top5Accuracy: 0.8838, Time consumed:1.09s

Training Epoch: 282 [128/50000]	Loss: 0.6804	LR: 0.000163
Training Epoch: 282 [128/50000]	Loss: 1.0177	LR: 0.000163
Training Epoch: 282 [128/50000]	Loss: 0.7826	LR: 0.000163
Training Epoch: 282 [128/50000]	Loss: 0.7130	LR: 0.000163
Training Epoch: 282 [128/50000]	Loss: 0.8169	LR: 0.000163
Training Epoch: 282 [128/50000]	Loss: 0.8134	LR: 0.000163
Training Epoch: 282 [128/50000]	Loss: 0.6577	LR: 0.000163
Training Epoch: 282 [128/50000]	Loss: 0.9180	LR: 0.000163
Training Epoch: 282 [128/50000]	Loss: 0.7528	LR: 0.000163
Training Epoch: 282 [128/50000]	Loss: 0.8738	LR: 0.000163
Evaluating Network.....
Test set: Epoch: 282, Average loss: 0.0107, Top1Accuracy: 0.6294, Top3Accuracy: 0.8259, Top5Accuracy: 0.8832, Time consumed:1.10s

Training Epoch: 283 [128/50000]	Loss: 0.9197	LR: 0.000159
Training Epoch: 283 [128/50000]	Loss: 0.9197	LR: 0.000159
Training Epoch: 283 [128/50000]	Loss: 1.0549	LR: 0.000159
Training Epoch: 283 [128/50000]	Loss: 0.7309	LR: 0.000159
Training Epoch: 283 [128/50000]	Loss: 0.9064	LR: 0.000159
Training Epoch: 283 [128/50000]	Loss: 0.9433	LR: 0.000159
Training Epoch: 283 [128/50000]	Loss: 0.7858	LR: 0.000159
Training Epoch: 283 [128/50000]	Loss: 0.7994	LR: 0.000159
Training Epoch: 283 [128/50000]	Loss: 0.7084	LR: 0.000159
Training Epoch: 283 [128/50000]	Loss: 0.7794	LR: 0.000159
Evaluating Network.....
Test set: Epoch: 283, Average loss: 0.0108, Top1Accuracy: 0.6285, Top3Accuracy: 0.8256, Top5Accuracy: 0.8824, Time consumed:1.11s

Training Epoch: 284 [128/50000]	Loss: 0.7250	LR: 0.000154
Training Epoch: 284 [128/50000]	Loss: 0.8068	LR: 0.000154
Training Epoch: 284 [128/50000]	Loss: 0.7391	LR: 0.000154
Training Epoch: 284 [128/50000]	Loss: 0.9071	LR: 0.000154
Training Epoch: 284 [128/50000]	Loss: 0.7940	LR: 0.000154
Training Epoch: 284 [128/50000]	Loss: 0.6821	LR: 0.000154
Training Epoch: 284 [128/50000]	Loss: 0.7701	LR: 0.000154
Training Epoch: 284 [128/50000]	Loss: 0.7700	LR: 0.000154
Training Epoch: 284 [128/50000]	Loss: 0.8384	LR: 0.000154
Training Epoch: 284 [128/50000]	Loss: 0.6984	LR: 0.000154
Evaluating Network.....
Test set: Epoch: 284, Average loss: 0.0106, Top1Accuracy: 0.6285, Top3Accuracy: 0.8252, Top5Accuracy: 0.8841, Time consumed:1.12s

Training Epoch: 285 [128/50000]	Loss: 0.6911	LR: 0.000150
Training Epoch: 285 [128/50000]	Loss: 0.8924	LR: 0.000150
Training Epoch: 285 [128/50000]	Loss: 0.7600	LR: 0.000150
Training Epoch: 285 [128/50000]	Loss: 0.8688	LR: 0.000150
Training Epoch: 285 [128/50000]	Loss: 0.8838	LR: 0.000150
Training Epoch: 285 [128/50000]	Loss: 0.8357	LR: 0.000150
Training Epoch: 285 [128/50000]	Loss: 0.9650	LR: 0.000150
Training Epoch: 285 [128/50000]	Loss: 0.7914	LR: 0.000150
Training Epoch: 285 [128/50000]	Loss: 0.9169	LR: 0.000150
Training Epoch: 285 [128/50000]	Loss: 0.9642	LR: 0.000150
Evaluating Network.....
Test set: Epoch: 285, Average loss: 0.0107, Top1Accuracy: 0.6291, Top3Accuracy: 0.8249, Top5Accuracy: 0.8836, Time consumed:1.10s

Training Epoch: 286 [128/50000]	Loss: 0.8324	LR: 0.000146
Training Epoch: 286 [128/50000]	Loss: 0.9810	LR: 0.000146
Training Epoch: 286 [128/50000]	Loss: 0.8826	LR: 0.000146
Training Epoch: 286 [128/50000]	Loss: 0.7446	LR: 0.000146
Training Epoch: 286 [128/50000]	Loss: 0.9640	LR: 0.000146
Training Epoch: 286 [128/50000]	Loss: 0.7268	LR: 0.000146
Training Epoch: 286 [128/50000]	Loss: 0.8160	LR: 0.000146
Training Epoch: 286 [128/50000]	Loss: 0.7083	LR: 0.000146
Training Epoch: 286 [128/50000]	Loss: 0.8022	LR: 0.000146
Training Epoch: 286 [128/50000]	Loss: 0.9098	LR: 0.000146
Evaluating Network.....
Test set: Epoch: 286, Average loss: 0.0106, Top1Accuracy: 0.6293, Top3Accuracy: 0.8252, Top5Accuracy: 0.8838, Time consumed:1.12s

Training Epoch: 287 [128/50000]	Loss: 0.8505	LR: 0.000143
Training Epoch: 287 [128/50000]	Loss: 0.9040	LR: 0.000143
Training Epoch: 287 [128/50000]	Loss: 0.8766	LR: 0.000143
Training Epoch: 287 [128/50000]	Loss: 0.9925	LR: 0.000143
Training Epoch: 287 [128/50000]	Loss: 0.9792	LR: 0.000143
Training Epoch: 287 [128/50000]	Loss: 0.7915	LR: 0.000143
Training Epoch: 287 [128/50000]	Loss: 0.8809	LR: 0.000143
Training Epoch: 287 [128/50000]	Loss: 0.8035	LR: 0.000143
Training Epoch: 287 [128/50000]	Loss: 0.7759	LR: 0.000143
Training Epoch: 287 [128/50000]	Loss: 0.8789	LR: 0.000143
Evaluating Network.....
Test set: Epoch: 287, Average loss: 0.0106, Top1Accuracy: 0.6291, Top3Accuracy: 0.8254, Top5Accuracy: 0.8821, Time consumed:1.11s

Training Epoch: 288 [128/50000]	Loss: 0.6653	LR: 0.000139
Training Epoch: 288 [128/50000]	Loss: 0.9010	LR: 0.000139
Training Epoch: 288 [128/50000]	Loss: 0.8266	LR: 0.000139
Training Epoch: 288 [128/50000]	Loss: 0.5934	LR: 0.000139
Training Epoch: 288 [128/50000]	Loss: 0.7565	LR: 0.000139
Training Epoch: 288 [128/50000]	Loss: 0.8510	LR: 0.000139
Training Epoch: 288 [128/50000]	Loss: 0.8767	LR: 0.000139
Training Epoch: 288 [128/50000]	Loss: 0.9874	LR: 0.000139
Training Epoch: 288 [128/50000]	Loss: 0.8685	LR: 0.000139
Training Epoch: 288 [128/50000]	Loss: 0.7983	LR: 0.000139
Evaluating Network.....
Test set: Epoch: 288, Average loss: 0.0107, Top1Accuracy: 0.6291, Top3Accuracy: 0.8266, Top5Accuracy: 0.8829, Time consumed:1.10s

Training Epoch: 289 [128/50000]	Loss: 0.9001	LR: 0.000135
Training Epoch: 289 [128/50000]	Loss: 1.0309	LR: 0.000135
Training Epoch: 289 [128/50000]	Loss: 0.8925	LR: 0.000135
Training Epoch: 289 [128/50000]	Loss: 0.8169	LR: 0.000135
Training Epoch: 289 [128/50000]	Loss: 0.7406	LR: 0.000135
Training Epoch: 289 [128/50000]	Loss: 0.7199	LR: 0.000135
Training Epoch: 289 [128/50000]	Loss: 0.9395	LR: 0.000135
Training Epoch: 289 [128/50000]	Loss: 0.8491	LR: 0.000135
Training Epoch: 289 [128/50000]	Loss: 0.9262	LR: 0.000135
Training Epoch: 289 [128/50000]	Loss: 0.8938	LR: 0.000135
Evaluating Network.....
Test set: Epoch: 289, Average loss: 0.0106, Top1Accuracy: 0.6295, Top3Accuracy: 0.8254, Top5Accuracy: 0.8828, Time consumed:1.10s

Training Epoch: 290 [128/50000]	Loss: 0.7565	LR: 0.000132
Training Epoch: 290 [128/50000]	Loss: 0.8560	LR: 0.000132
Training Epoch: 290 [128/50000]	Loss: 0.9227	LR: 0.000132
Training Epoch: 290 [128/50000]	Loss: 1.0938	LR: 0.000132
Training Epoch: 290 [128/50000]	Loss: 0.8848	LR: 0.000132
Training Epoch: 290 [128/50000]	Loss: 0.6623	LR: 0.000132
Training Epoch: 290 [128/50000]	Loss: 0.9705	LR: 0.000132
Training Epoch: 290 [128/50000]	Loss: 0.8247	LR: 0.000132
Training Epoch: 290 [128/50000]	Loss: 0.9320	LR: 0.000132
Training Epoch: 290 [128/50000]	Loss: 0.8642	LR: 0.000132
Evaluating Network.....
Test set: Epoch: 290, Average loss: 0.0106, Top1Accuracy: 0.6292, Top3Accuracy: 0.8262, Top5Accuracy: 0.8834, Time consumed:1.12s

Training Epoch: 291 [128/50000]	Loss: 0.6895	LR: 0.000128
Training Epoch: 291 [128/50000]	Loss: 0.7128	LR: 0.000128
Training Epoch: 291 [128/50000]	Loss: 0.8710	LR: 0.000128
Training Epoch: 291 [128/50000]	Loss: 0.8424	LR: 0.000128
Training Epoch: 291 [128/50000]	Loss: 0.6186	LR: 0.000128
Training Epoch: 291 [128/50000]	Loss: 0.8227	LR: 0.000128
Training Epoch: 291 [128/50000]	Loss: 0.8551	LR: 0.000128
Training Epoch: 291 [128/50000]	Loss: 0.8942	LR: 0.000128
Training Epoch: 291 [128/50000]	Loss: 0.9969	LR: 0.000128
Training Epoch: 291 [128/50000]	Loss: 0.6901	LR: 0.000128
Evaluating Network.....
Test set: Epoch: 291, Average loss: 0.0106, Top1Accuracy: 0.6287, Top3Accuracy: 0.8250, Top5Accuracy: 0.8827, Time consumed:1.10s

Training Epoch: 292 [128/50000]	Loss: 1.0118	LR: 0.000125
Training Epoch: 292 [128/50000]	Loss: 1.0070	LR: 0.000125
Training Epoch: 292 [128/50000]	Loss: 1.0477	LR: 0.000125
Training Epoch: 292 [128/50000]	Loss: 0.8507	LR: 0.000125
Training Epoch: 292 [128/50000]	Loss: 0.8063	LR: 0.000125
Training Epoch: 292 [128/50000]	Loss: 0.7707	LR: 0.000125
Training Epoch: 292 [128/50000]	Loss: 0.6964	LR: 0.000125
Training Epoch: 292 [128/50000]	Loss: 0.7562	LR: 0.000125
Training Epoch: 292 [128/50000]	Loss: 0.7959	LR: 0.000125
Training Epoch: 292 [128/50000]	Loss: 0.7822	LR: 0.000125
Evaluating Network.....
Test set: Epoch: 292, Average loss: 0.0106, Top1Accuracy: 0.6297, Top3Accuracy: 0.8246, Top5Accuracy: 0.8836, Time consumed:1.10s

Training Epoch: 293 [128/50000]	Loss: 0.7647	LR: 0.000121
Training Epoch: 293 [128/50000]	Loss: 0.8260	LR: 0.000121
Training Epoch: 293 [128/50000]	Loss: 0.8984	LR: 0.000121
Training Epoch: 293 [128/50000]	Loss: 0.8523	LR: 0.000121
Training Epoch: 293 [128/50000]	Loss: 0.6245	LR: 0.000121
Training Epoch: 293 [128/50000]	Loss: 0.7741	LR: 0.000121
Training Epoch: 293 [128/50000]	Loss: 0.8557	LR: 0.000121
Training Epoch: 293 [128/50000]	Loss: 0.8780	LR: 0.000121
Training Epoch: 293 [128/50000]	Loss: 1.0323	LR: 0.000121
Training Epoch: 293 [128/50000]	Loss: 0.7898	LR: 0.000121
Evaluating Network.....
Test set: Epoch: 293, Average loss: 0.0107, Top1Accuracy: 0.6296, Top3Accuracy: 0.8252, Top5Accuracy: 0.8829, Time consumed:1.10s

Training Epoch: 294 [128/50000]	Loss: 0.8250	LR: 0.000118
Training Epoch: 294 [128/50000]	Loss: 0.7717	LR: 0.000118
Training Epoch: 294 [128/50000]	Loss: 0.9060	LR: 0.000118
Training Epoch: 294 [128/50000]	Loss: 0.7505	LR: 0.000118
Training Epoch: 294 [128/50000]	Loss: 0.9362	LR: 0.000118
Training Epoch: 294 [128/50000]	Loss: 0.7480	LR: 0.000118
Training Epoch: 294 [128/50000]	Loss: 0.6666	LR: 0.000118
Training Epoch: 294 [128/50000]	Loss: 0.9130	LR: 0.000118
Training Epoch: 294 [128/50000]	Loss: 0.9018	LR: 0.000118
Training Epoch: 294 [128/50000]	Loss: 0.9274	LR: 0.000118
Evaluating Network.....
Test set: Epoch: 294, Average loss: 0.0107, Top1Accuracy: 0.6276, Top3Accuracy: 0.8254, Top5Accuracy: 0.8826, Time consumed:1.10s

Training Epoch: 295 [128/50000]	Loss: 0.7098	LR: 0.000115
Training Epoch: 295 [128/50000]	Loss: 0.9226	LR: 0.000115
Training Epoch: 295 [128/50000]	Loss: 0.6477	LR: 0.000115
Training Epoch: 295 [128/50000]	Loss: 0.8817	LR: 0.000115
Training Epoch: 295 [128/50000]	Loss: 0.8001	LR: 0.000115
Training Epoch: 295 [128/50000]	Loss: 0.8905	LR: 0.000115
Training Epoch: 295 [128/50000]	Loss: 0.8430	LR: 0.000115
Training Epoch: 295 [128/50000]	Loss: 0.8217	LR: 0.000115
Training Epoch: 295 [128/50000]	Loss: 0.8399	LR: 0.000115
Training Epoch: 295 [128/50000]	Loss: 0.8652	LR: 0.000115
Evaluating Network.....
Test set: Epoch: 295, Average loss: 0.0107, Top1Accuracy: 0.6293, Top3Accuracy: 0.8258, Top5Accuracy: 0.8824, Time consumed:1.10s

Training Epoch: 296 [128/50000]	Loss: 0.8689	LR: 0.000112
Training Epoch: 296 [128/50000]	Loss: 0.9608	LR: 0.000112
Training Epoch: 296 [128/50000]	Loss: 0.8884	LR: 0.000112
Training Epoch: 296 [128/50000]	Loss: 0.8643	LR: 0.000112
Training Epoch: 296 [128/50000]	Loss: 0.8522	LR: 0.000112
Training Epoch: 296 [128/50000]	Loss: 0.8510	LR: 0.000112
Training Epoch: 296 [128/50000]	Loss: 0.7967	LR: 0.000112
Training Epoch: 296 [128/50000]	Loss: 0.7951	LR: 0.000112
Training Epoch: 296 [128/50000]	Loss: 0.7864	LR: 0.000112
Training Epoch: 296 [128/50000]	Loss: 0.8157	LR: 0.000112
Evaluating Network.....
Test set: Epoch: 296, Average loss: 0.0106, Top1Accuracy: 0.6309, Top3Accuracy: 0.8255, Top5Accuracy: 0.8832, Time consumed:1.10s

Training Epoch: 297 [128/50000]	Loss: 0.8671	LR: 0.000109
Training Epoch: 297 [128/50000]	Loss: 0.9051	LR: 0.000109
Training Epoch: 297 [128/50000]	Loss: 0.8619	LR: 0.000109
Training Epoch: 297 [128/50000]	Loss: 0.8292	LR: 0.000109
Training Epoch: 297 [128/50000]	Loss: 0.9146	LR: 0.000109
Training Epoch: 297 [128/50000]	Loss: 0.7599	LR: 0.000109
Training Epoch: 297 [128/50000]	Loss: 0.7143	LR: 0.000109
Training Epoch: 297 [128/50000]	Loss: 0.6849	LR: 0.000109
Training Epoch: 297 [128/50000]	Loss: 0.8353	LR: 0.000109
Training Epoch: 297 [128/50000]	Loss: 0.6886	LR: 0.000109
Evaluating Network.....
Test set: Epoch: 297, Average loss: 0.0107, Top1Accuracy: 0.6301, Top3Accuracy: 0.8263, Top5Accuracy: 0.8828, Time consumed:1.10s

Training Epoch: 298 [128/50000]	Loss: 0.8982	LR: 0.000106
Training Epoch: 298 [128/50000]	Loss: 0.6605	LR: 0.000106
Training Epoch: 298 [128/50000]	Loss: 0.6924	LR: 0.000106
Training Epoch: 298 [128/50000]	Loss: 0.7842	LR: 0.000106
Training Epoch: 298 [128/50000]	Loss: 0.7739	LR: 0.000106
Training Epoch: 298 [128/50000]	Loss: 0.8410	LR: 0.000106
Training Epoch: 298 [128/50000]	Loss: 1.0130	LR: 0.000106
Training Epoch: 298 [128/50000]	Loss: 0.8809	LR: 0.000106
Training Epoch: 298 [128/50000]	Loss: 0.7322	LR: 0.000106
Training Epoch: 298 [128/50000]	Loss: 0.7840	LR: 0.000106
Evaluating Network.....
Test set: Epoch: 298, Average loss: 0.0107, Top1Accuracy: 0.6303, Top3Accuracy: 0.8262, Top5Accuracy: 0.8833, Time consumed:1.08s

Training Epoch: 299 [128/50000]	Loss: 1.0676	LR: 0.000103
Training Epoch: 299 [128/50000]	Loss: 0.8488	LR: 0.000103
Training Epoch: 299 [128/50000]	Loss: 0.8887	LR: 0.000103
Training Epoch: 299 [128/50000]	Loss: 0.8170	LR: 0.000103
Training Epoch: 299 [128/50000]	Loss: 0.8538	LR: 0.000103
Training Epoch: 299 [128/50000]	Loss: 0.8887	LR: 0.000103
Training Epoch: 299 [128/50000]	Loss: 0.8679	LR: 0.000103
Training Epoch: 299 [128/50000]	Loss: 0.9107	LR: 0.000103
Training Epoch: 299 [128/50000]	Loss: 0.7886	LR: 0.000103
Training Epoch: 299 [128/50000]	Loss: 0.7239	LR: 0.000103
Evaluating Network.....
Test set: Epoch: 299, Average loss: 0.0107, Top1Accuracy: 0.6309, Top3Accuracy: 0.8256, Top5Accuracy: 0.8833, Time consumed:1.12s

Training Epoch: 300 [128/50000]	Loss: 0.9033	LR: 0.000101
Training Epoch: 300 [128/50000]	Loss: 0.6838	LR: 0.000101
Training Epoch: 300 [128/50000]	Loss: 0.9223	LR: 0.000101
Training Epoch: 300 [128/50000]	Loss: 1.0121	LR: 0.000101
Training Epoch: 300 [128/50000]	Loss: 0.8939	LR: 0.000101
Training Epoch: 300 [128/50000]	Loss: 1.0452	LR: 0.000101
Training Epoch: 300 [128/50000]	Loss: 0.8856	LR: 0.000101
Training Epoch: 300 [128/50000]	Loss: 0.7990	LR: 0.000101
Training Epoch: 300 [128/50000]	Loss: 0.6647	LR: 0.000101
Training Epoch: 300 [128/50000]	Loss: 0.8320	LR: 0.000101
Evaluating Network.....
Test set: Epoch: 300, Average loss: 0.0106, Top1Accuracy: 0.6295, Top3Accuracy: 0.8259, Top5Accuracy: 0.8842, Time consumed:1.10s

Training Epoch: 301 [128/50000]	Loss: 0.8504	LR: 0.000098
Training Epoch: 301 [128/50000]	Loss: 0.9458	LR: 0.000098
Training Epoch: 301 [128/50000]	Loss: 0.7422	LR: 0.000098
Training Epoch: 301 [128/50000]	Loss: 0.7640	LR: 0.000098
Training Epoch: 301 [128/50000]	Loss: 0.8774	LR: 0.000098
Training Epoch: 301 [128/50000]	Loss: 0.9002	LR: 0.000098
Training Epoch: 301 [128/50000]	Loss: 0.8371	LR: 0.000098
Training Epoch: 301 [128/50000]	Loss: 0.8224	LR: 0.000098
Training Epoch: 301 [128/50000]	Loss: 0.7934	LR: 0.000098
Training Epoch: 301 [128/50000]	Loss: 0.8447	LR: 0.000098
Evaluating Network.....
Test set: Epoch: 301, Average loss: 0.0106, Top1Accuracy: 0.6316, Top3Accuracy: 0.8257, Top5Accuracy: 0.8827, Time consumed:1.10s

Training Epoch: 302 [128/50000]	Loss: 0.9689	LR: 0.000095
Training Epoch: 302 [128/50000]	Loss: 0.6259	LR: 0.000095
Training Epoch: 302 [128/50000]	Loss: 0.8811	LR: 0.000095
Training Epoch: 302 [128/50000]	Loss: 0.9037	LR: 0.000095
Training Epoch: 302 [128/50000]	Loss: 0.7996	LR: 0.000095
Training Epoch: 302 [128/50000]	Loss: 0.8030	LR: 0.000095
Training Epoch: 302 [128/50000]	Loss: 0.7276	LR: 0.000095
Training Epoch: 302 [128/50000]	Loss: 0.8733	LR: 0.000095
Training Epoch: 302 [128/50000]	Loss: 0.9317	LR: 0.000095
Training Epoch: 302 [128/50000]	Loss: 0.9051	LR: 0.000095
Evaluating Network.....
Test set: Epoch: 302, Average loss: 0.0106, Top1Accuracy: 0.6312, Top3Accuracy: 0.8254, Top5Accuracy: 0.8838, Time consumed:1.12s

Training Epoch: 303 [128/50000]	Loss: 0.8284	LR: 0.000093
Training Epoch: 303 [128/50000]	Loss: 0.7334	LR: 0.000093
Training Epoch: 303 [128/50000]	Loss: 0.8272	LR: 0.000093
Training Epoch: 303 [128/50000]	Loss: 0.6502	LR: 0.000093
Training Epoch: 303 [128/50000]	Loss: 0.7836	LR: 0.000093
Training Epoch: 303 [128/50000]	Loss: 0.6757	LR: 0.000093
Training Epoch: 303 [128/50000]	Loss: 0.9163	LR: 0.000093
Training Epoch: 303 [128/50000]	Loss: 0.9168	LR: 0.000093
Training Epoch: 303 [128/50000]	Loss: 0.8151	LR: 0.000093
Training Epoch: 303 [128/50000]	Loss: 1.0334	LR: 0.000093
Evaluating Network.....
Test set: Epoch: 303, Average loss: 0.0107, Top1Accuracy: 0.6304, Top3Accuracy: 0.8250, Top5Accuracy: 0.8828, Time consumed:1.11s

Training Epoch: 304 [128/50000]	Loss: 0.8368	LR: 0.000090
Training Epoch: 304 [128/50000]	Loss: 0.7004	LR: 0.000090
Training Epoch: 304 [128/50000]	Loss: 0.9430	LR: 0.000090
Training Epoch: 304 [128/50000]	Loss: 0.9226	LR: 0.000090
Training Epoch: 304 [128/50000]	Loss: 0.8722	LR: 0.000090
Training Epoch: 304 [128/50000]	Loss: 0.8820	LR: 0.000090
Training Epoch: 304 [128/50000]	Loss: 0.9117	LR: 0.000090
Training Epoch: 304 [128/50000]	Loss: 0.7416	LR: 0.000090
Training Epoch: 304 [128/50000]	Loss: 0.7102	LR: 0.000090
Training Epoch: 304 [128/50000]	Loss: 0.7890	LR: 0.000090
Evaluating Network.....
Test set: Epoch: 304, Average loss: 0.0106, Top1Accuracy: 0.6303, Top3Accuracy: 0.8263, Top5Accuracy: 0.8834, Time consumed:1.10s

Training Epoch: 305 [128/50000]	Loss: 0.8000	LR: 0.000088
Training Epoch: 305 [128/50000]	Loss: 0.9876	LR: 0.000088
Training Epoch: 305 [128/50000]	Loss: 0.9597	LR: 0.000088
Training Epoch: 305 [128/50000]	Loss: 0.9132	LR: 0.000088
Training Epoch: 305 [128/50000]	Loss: 0.7612	LR: 0.000088
Training Epoch: 305 [128/50000]	Loss: 0.8312	LR: 0.000088
Training Epoch: 305 [128/50000]	Loss: 0.8624	LR: 0.000088
Training Epoch: 305 [128/50000]	Loss: 0.8456	LR: 0.000088
Training Epoch: 305 [128/50000]	Loss: 0.8330	LR: 0.000088
Training Epoch: 305 [128/50000]	Loss: 0.8655	LR: 0.000088
Evaluating Network.....
Test set: Epoch: 305, Average loss: 0.0106, Top1Accuracy: 0.6303, Top3Accuracy: 0.8267, Top5Accuracy: 0.8833, Time consumed:1.10s

Training Epoch: 306 [128/50000]	Loss: 0.8746	LR: 0.000086
Training Epoch: 306 [128/50000]	Loss: 0.8905	LR: 0.000086
Training Epoch: 306 [128/50000]	Loss: 0.8363	LR: 0.000086
Training Epoch: 306 [128/50000]	Loss: 0.8370	LR: 0.000086
Training Epoch: 306 [128/50000]	Loss: 0.7932	LR: 0.000086
Training Epoch: 306 [128/50000]	Loss: 0.8573	LR: 0.000086
Training Epoch: 306 [128/50000]	Loss: 0.9286	LR: 0.000086
Training Epoch: 306 [128/50000]	Loss: 0.8416	LR: 0.000086
Training Epoch: 306 [128/50000]	Loss: 0.7594	LR: 0.000086
Training Epoch: 306 [128/50000]	Loss: 0.9502	LR: 0.000086
Evaluating Network.....
Test set: Epoch: 306, Average loss: 0.0107, Top1Accuracy: 0.6280, Top3Accuracy: 0.8255, Top5Accuracy: 0.8826, Time consumed:1.09s

Training Epoch: 307 [128/50000]	Loss: 0.8400	LR: 0.000083
Training Epoch: 307 [128/50000]	Loss: 0.9361	LR: 0.000083
Training Epoch: 307 [128/50000]	Loss: 0.9073	LR: 0.000083
Training Epoch: 307 [128/50000]	Loss: 0.7595	LR: 0.000083
Training Epoch: 307 [128/50000]	Loss: 0.8404	LR: 0.000083
Training Epoch: 307 [128/50000]	Loss: 0.6488	LR: 0.000083
Training Epoch: 307 [128/50000]	Loss: 0.7832	LR: 0.000083
Training Epoch: 307 [128/50000]	Loss: 0.7516	LR: 0.000083
Training Epoch: 307 [128/50000]	Loss: 0.7398	LR: 0.000083
Training Epoch: 307 [128/50000]	Loss: 0.8396	LR: 0.000083
Evaluating Network.....
Test set: Epoch: 307, Average loss: 0.0108, Top1Accuracy: 0.6286, Top3Accuracy: 0.8261, Top5Accuracy: 0.8834, Time consumed:1.11s

Training Epoch: 308 [128/50000]	Loss: 0.6337	LR: 0.000081
Training Epoch: 308 [128/50000]	Loss: 0.9113	LR: 0.000081
Training Epoch: 308 [128/50000]	Loss: 0.7898	LR: 0.000081
Training Epoch: 308 [128/50000]	Loss: 0.8595	LR: 0.000081
Training Epoch: 308 [128/50000]	Loss: 0.6448	LR: 0.000081
Training Epoch: 308 [128/50000]	Loss: 0.8573	LR: 0.000081
Training Epoch: 308 [128/50000]	Loss: 0.7509	LR: 0.000081
Training Epoch: 308 [128/50000]	Loss: 0.8232	LR: 0.000081
Training Epoch: 308 [128/50000]	Loss: 0.8322	LR: 0.000081
Training Epoch: 308 [128/50000]	Loss: 1.0364	LR: 0.000081
Evaluating Network.....
Test set: Epoch: 308, Average loss: 0.0107, Top1Accuracy: 0.6297, Top3Accuracy: 0.8265, Top5Accuracy: 0.8840, Time consumed:1.10s

Training Epoch: 309 [128/50000]	Loss: 1.0367	LR: 0.000079
Training Epoch: 309 [128/50000]	Loss: 0.9538	LR: 0.000079
Training Epoch: 309 [128/50000]	Loss: 0.7555	LR: 0.000079
Training Epoch: 309 [128/50000]	Loss: 0.8089	LR: 0.000079
Training Epoch: 309 [128/50000]	Loss: 0.7413	LR: 0.000079
Training Epoch: 309 [128/50000]	Loss: 0.7808	LR: 0.000079
Training Epoch: 309 [128/50000]	Loss: 0.9167	LR: 0.000079
Training Epoch: 309 [128/50000]	Loss: 0.8440	LR: 0.000079
Training Epoch: 309 [128/50000]	Loss: 0.7727	LR: 0.000079
Training Epoch: 309 [128/50000]	Loss: 0.9240	LR: 0.000079
Evaluating Network.....
Test set: Epoch: 309, Average loss: 0.0106, Top1Accuracy: 0.6294, Top3Accuracy: 0.8254, Top5Accuracy: 0.8838, Time consumed:1.11s

Training Epoch: 310 [128/50000]	Loss: 0.8266	LR: 0.000077
Training Epoch: 310 [128/50000]	Loss: 0.8795	LR: 0.000077
Training Epoch: 310 [128/50000]	Loss: 1.0128	LR: 0.000077
Training Epoch: 310 [128/50000]	Loss: 1.0250	LR: 0.000077
Training Epoch: 310 [128/50000]	Loss: 0.7969	LR: 0.000077
Training Epoch: 310 [128/50000]	Loss: 0.9279	LR: 0.000077
Training Epoch: 310 [128/50000]	Loss: 0.8505	LR: 0.000077
Training Epoch: 310 [128/50000]	Loss: 1.2061	LR: 0.000077
Training Epoch: 310 [128/50000]	Loss: 0.8171	LR: 0.000077
Training Epoch: 310 [128/50000]	Loss: 0.8560	LR: 0.000077
Evaluating Network.....
Test set: Epoch: 310, Average loss: 0.0106, Top1Accuracy: 0.6286, Top3Accuracy: 0.8261, Top5Accuracy: 0.8833, Time consumed:1.11s

Training Epoch: 311 [128/50000]	Loss: 0.8802	LR: 0.000075
Training Epoch: 311 [128/50000]	Loss: 0.9865	LR: 0.000075
Training Epoch: 311 [128/50000]	Loss: 0.8680	LR: 0.000075
Training Epoch: 311 [128/50000]	Loss: 0.8344	LR: 0.000075
Training Epoch: 311 [128/50000]	Loss: 0.7849	LR: 0.000075
Training Epoch: 311 [128/50000]	Loss: 0.7009	LR: 0.000075
Training Epoch: 311 [128/50000]	Loss: 0.8356	LR: 0.000075
Training Epoch: 311 [128/50000]	Loss: 0.7921	LR: 0.000075
Training Epoch: 311 [128/50000]	Loss: 0.7408	LR: 0.000075
Training Epoch: 311 [128/50000]	Loss: 0.8149	LR: 0.000075
Evaluating Network.....
Test set: Epoch: 311, Average loss: 0.0106, Top1Accuracy: 0.6301, Top3Accuracy: 0.8260, Top5Accuracy: 0.8831, Time consumed:1.10s

Training Epoch: 312 [128/50000]	Loss: 0.6781	LR: 0.000073
Training Epoch: 312 [128/50000]	Loss: 0.8366	LR: 0.000073
Training Epoch: 312 [128/50000]	Loss: 0.6995	LR: 0.000073
Training Epoch: 312 [128/50000]	Loss: 0.7778	LR: 0.000073
Training Epoch: 312 [128/50000]	Loss: 0.8140	LR: 0.000073
Training Epoch: 312 [128/50000]	Loss: 0.8572	LR: 0.000073
Training Epoch: 312 [128/50000]	Loss: 0.8498	LR: 0.000073
Training Epoch: 312 [128/50000]	Loss: 0.8574	LR: 0.000073
Training Epoch: 312 [128/50000]	Loss: 0.6972	LR: 0.000073
Training Epoch: 312 [128/50000]	Loss: 0.7764	LR: 0.000073
Evaluating Network.....
Test set: Epoch: 312, Average loss: 0.0107, Top1Accuracy: 0.6293, Top3Accuracy: 0.8253, Top5Accuracy: 0.8834, Time consumed:1.12s

Training Epoch: 313 [128/50000]	Loss: 0.6963	LR: 0.000071
Training Epoch: 313 [128/50000]	Loss: 0.7060	LR: 0.000071
Training Epoch: 313 [128/50000]	Loss: 0.8271	LR: 0.000071
Training Epoch: 313 [128/50000]	Loss: 0.7672	LR: 0.000071
Training Epoch: 313 [128/50000]	Loss: 0.6208	LR: 0.000071
Training Epoch: 313 [128/50000]	Loss: 0.7531	LR: 0.000071
Training Epoch: 313 [128/50000]	Loss: 0.7221	LR: 0.000071
Training Epoch: 313 [128/50000]	Loss: 0.9449	LR: 0.000071
Training Epoch: 313 [128/50000]	Loss: 0.9009	LR: 0.000071
Training Epoch: 313 [128/50000]	Loss: 0.8049	LR: 0.000071
Evaluating Network.....
Test set: Epoch: 313, Average loss: 0.0107, Top1Accuracy: 0.6294, Top3Accuracy: 0.8262, Top5Accuracy: 0.8842, Time consumed:1.13s

Training Epoch: 314 [128/50000]	Loss: 0.7761	LR: 0.000069
Training Epoch: 314 [128/50000]	Loss: 0.9509	LR: 0.000069
Training Epoch: 314 [128/50000]	Loss: 0.9369	LR: 0.000069
Training Epoch: 314 [128/50000]	Loss: 0.8989	LR: 0.000069
Training Epoch: 314 [128/50000]	Loss: 0.9639	LR: 0.000069
Training Epoch: 314 [128/50000]	Loss: 0.9863	LR: 0.000069
Training Epoch: 314 [128/50000]	Loss: 0.7833	LR: 0.000069
Training Epoch: 314 [128/50000]	Loss: 1.0486	LR: 0.000069
Training Epoch: 314 [128/50000]	Loss: 0.7974	LR: 0.000069
Training Epoch: 314 [128/50000]	Loss: 0.9209	LR: 0.000069
Evaluating Network.....
Test set: Epoch: 314, Average loss: 0.0106, Top1Accuracy: 0.6301, Top3Accuracy: 0.8261, Top5Accuracy: 0.8835, Time consumed:1.11s

Training Epoch: 315 [128/50000]	Loss: 0.8208	LR: 0.000067
Training Epoch: 315 [128/50000]	Loss: 0.8811	LR: 0.000067
Training Epoch: 315 [128/50000]	Loss: 0.7668	LR: 0.000067
Training Epoch: 315 [128/50000]	Loss: 0.7529	LR: 0.000067
Training Epoch: 315 [128/50000]	Loss: 0.7869	LR: 0.000067
Training Epoch: 315 [128/50000]	Loss: 0.7330	LR: 0.000067
Training Epoch: 315 [128/50000]	Loss: 0.8016	LR: 0.000067
Training Epoch: 315 [128/50000]	Loss: 0.8444	LR: 0.000067
Training Epoch: 315 [128/50000]	Loss: 0.8336	LR: 0.000067
Training Epoch: 315 [128/50000]	Loss: 0.9801	LR: 0.000067
Evaluating Network.....
Test set: Epoch: 315, Average loss: 0.0106, Top1Accuracy: 0.6320, Top3Accuracy: 0.8255, Top5Accuracy: 0.8836, Time consumed:1.11s

Training Epoch: 316 [128/50000]	Loss: 0.8859	LR: 0.000066
Training Epoch: 316 [128/50000]	Loss: 0.9645	LR: 0.000066
Training Epoch: 316 [128/50000]	Loss: 0.9197	LR: 0.000066
Training Epoch: 316 [128/50000]	Loss: 0.8498	LR: 0.000066
Training Epoch: 316 [128/50000]	Loss: 0.8193	LR: 0.000066
Training Epoch: 316 [128/50000]	Loss: 0.7218	LR: 0.000066
Training Epoch: 316 [128/50000]	Loss: 0.7554	LR: 0.000066
Training Epoch: 316 [128/50000]	Loss: 0.8248	LR: 0.000066
Training Epoch: 316 [128/50000]	Loss: 0.8442	LR: 0.000066
Training Epoch: 316 [128/50000]	Loss: 0.7569	LR: 0.000066
Evaluating Network.....
Test set: Epoch: 316, Average loss: 0.0106, Top1Accuracy: 0.6300, Top3Accuracy: 0.8263, Top5Accuracy: 0.8839, Time consumed:1.11s

Training Epoch: 317 [128/50000]	Loss: 0.6739	LR: 0.000064
Training Epoch: 317 [128/50000]	Loss: 0.9460	LR: 0.000064
Training Epoch: 317 [128/50000]	Loss: 0.7278	LR: 0.000064
Training Epoch: 317 [128/50000]	Loss: 0.8351	LR: 0.000064
Training Epoch: 317 [128/50000]	Loss: 0.8455	LR: 0.000064
Training Epoch: 317 [128/50000]	Loss: 0.7558	LR: 0.000064
Training Epoch: 317 [128/50000]	Loss: 0.9844	LR: 0.000064
Training Epoch: 317 [128/50000]	Loss: 0.9107	LR: 0.000064
Training Epoch: 317 [128/50000]	Loss: 0.7937	LR: 0.000064
Training Epoch: 317 [128/50000]	Loss: 0.8176	LR: 0.000064
Evaluating Network.....
Test set: Epoch: 317, Average loss: 0.0106, Top1Accuracy: 0.6310, Top3Accuracy: 0.8262, Top5Accuracy: 0.8829, Time consumed:1.11s

Training Epoch: 318 [128/50000]	Loss: 0.8264	LR: 0.000062
Training Epoch: 318 [128/50000]	Loss: 0.7541	LR: 0.000062
Training Epoch: 318 [128/50000]	Loss: 0.8175	LR: 0.000062
Training Epoch: 318 [128/50000]	Loss: 0.7597	LR: 0.000062
Training Epoch: 318 [128/50000]	Loss: 0.9788	LR: 0.000062
Training Epoch: 318 [128/50000]	Loss: 0.8831	LR: 0.000062
Training Epoch: 318 [128/50000]	Loss: 0.7874	LR: 0.000062
Training Epoch: 318 [128/50000]	Loss: 0.7925	LR: 0.000062
Training Epoch: 318 [128/50000]	Loss: 0.9733	LR: 0.000062
Training Epoch: 318 [128/50000]	Loss: 1.0679	LR: 0.000062
Evaluating Network.....
Test set: Epoch: 318, Average loss: 0.0106, Top1Accuracy: 0.6286, Top3Accuracy: 0.8266, Top5Accuracy: 0.8836, Time consumed:1.12s

Training Epoch: 319 [128/50000]	Loss: 0.7449	LR: 0.000061
Training Epoch: 319 [128/50000]	Loss: 0.7449	LR: 0.000061
Training Epoch: 319 [128/50000]	Loss: 0.9255	LR: 0.000061
Training Epoch: 319 [128/50000]	Loss: 0.7563	LR: 0.000061
Training Epoch: 319 [128/50000]	Loss: 0.7323	LR: 0.000061
Training Epoch: 319 [128/50000]	Loss: 0.8159	LR: 0.000061
Training Epoch: 319 [128/50000]	Loss: 0.7764	LR: 0.000061
Training Epoch: 319 [128/50000]	Loss: 0.9151	LR: 0.000061
Training Epoch: 319 [128/50000]	Loss: 0.7039	LR: 0.000061
Training Epoch: 319 [128/50000]	Loss: 0.7773	LR: 0.000061
Evaluating Network.....
Test set: Epoch: 319, Average loss: 0.0106, Top1Accuracy: 0.6306, Top3Accuracy: 0.8260, Top5Accuracy: 0.8834, Time consumed:1.11s

Training Epoch: 320 [128/50000]	Loss: 0.9301	LR: 0.000059
Training Epoch: 320 [128/50000]	Loss: 0.8170	LR: 0.000059
Training Epoch: 320 [128/50000]	Loss: 1.1730	LR: 0.000059
Training Epoch: 320 [128/50000]	Loss: 0.8642	LR: 0.000059
Training Epoch: 320 [128/50000]	Loss: 0.7445	LR: 0.000059
Training Epoch: 320 [128/50000]	Loss: 0.7373	LR: 0.000059
Training Epoch: 320 [128/50000]	Loss: 0.8418	LR: 0.000059
Training Epoch: 320 [128/50000]	Loss: 0.8624	LR: 0.000059
Training Epoch: 320 [128/50000]	Loss: 0.8402	LR: 0.000059
Training Epoch: 320 [128/50000]	Loss: 0.8410	LR: 0.000059
Evaluating Network.....
Test set: Epoch: 320, Average loss: 0.0106, Top1Accuracy: 0.6294, Top3Accuracy: 0.8251, Top5Accuracy: 0.8831, Time consumed:1.10s

Training Epoch: 321 [128/50000]	Loss: 0.8447	LR: 0.000057
Training Epoch: 321 [128/50000]	Loss: 0.8867	LR: 0.000057
Training Epoch: 321 [128/50000]	Loss: 0.7750	LR: 0.000057
Training Epoch: 321 [128/50000]	Loss: 0.8614	LR: 0.000057
Training Epoch: 321 [128/50000]	Loss: 0.8893	LR: 0.000057
Training Epoch: 321 [128/50000]	Loss: 0.8432	LR: 0.000057
Training Epoch: 321 [128/50000]	Loss: 0.8453	LR: 0.000057
Training Epoch: 321 [128/50000]	Loss: 0.8719	LR: 0.000057
Training Epoch: 321 [128/50000]	Loss: 0.6292	LR: 0.000057
Training Epoch: 321 [128/50000]	Loss: 0.8189	LR: 0.000057
Evaluating Network.....
Test set: Epoch: 321, Average loss: 0.0107, Top1Accuracy: 0.6305, Top3Accuracy: 0.8271, Top5Accuracy: 0.8824, Time consumed:1.13s

Training Epoch: 322 [128/50000]	Loss: 1.0332	LR: 0.000056
Training Epoch: 322 [128/50000]	Loss: 0.8138	LR: 0.000056
Training Epoch: 322 [128/50000]	Loss: 1.0077	LR: 0.000056
Training Epoch: 322 [128/50000]	Loss: 0.8993	LR: 0.000056
Training Epoch: 322 [128/50000]	Loss: 0.8098	LR: 0.000056
Training Epoch: 322 [128/50000]	Loss: 0.9393	LR: 0.000056
Training Epoch: 322 [128/50000]	Loss: 0.7328	LR: 0.000056
Training Epoch: 322 [128/50000]	Loss: 0.8455	LR: 0.000056
Training Epoch: 322 [128/50000]	Loss: 0.8214	LR: 0.000056
Training Epoch: 322 [128/50000]	Loss: 0.8693	LR: 0.000056
Evaluating Network.....
Test set: Epoch: 322, Average loss: 0.0107, Top1Accuracy: 0.6290, Top3Accuracy: 0.8261, Top5Accuracy: 0.8836, Time consumed:1.11s

Training Epoch: 323 [128/50000]	Loss: 0.7009	LR: 0.000054
Training Epoch: 323 [128/50000]	Loss: 0.7696	LR: 0.000054
Training Epoch: 323 [128/50000]	Loss: 0.9141	LR: 0.000054
Training Epoch: 323 [128/50000]	Loss: 1.0526	LR: 0.000054
Training Epoch: 323 [128/50000]	Loss: 0.8727	LR: 0.000054
Training Epoch: 323 [128/50000]	Loss: 0.8318	LR: 0.000054
Training Epoch: 323 [128/50000]	Loss: 0.6882	LR: 0.000054
Training Epoch: 323 [128/50000]	Loss: 0.8006	LR: 0.000054
Training Epoch: 323 [128/50000]	Loss: 0.9456	LR: 0.000054
Training Epoch: 323 [128/50000]	Loss: 0.8970	LR: 0.000054
Evaluating Network.....
Test set: Epoch: 323, Average loss: 0.0106, Top1Accuracy: 0.6305, Top3Accuracy: 0.8251, Top5Accuracy: 0.8839, Time consumed:1.10s

Training Epoch: 324 [128/50000]	Loss: 0.8252	LR: 0.000053
Training Epoch: 324 [128/50000]	Loss: 0.7879	LR: 0.000053
Training Epoch: 324 [128/50000]	Loss: 0.7223	LR: 0.000053
Training Epoch: 324 [128/50000]	Loss: 0.9053	LR: 0.000053
Training Epoch: 324 [128/50000]	Loss: 0.7974	LR: 0.000053
Training Epoch: 324 [128/50000]	Loss: 0.7974	LR: 0.000053
Training Epoch: 324 [128/50000]	Loss: 0.7088	LR: 0.000053
Training Epoch: 324 [128/50000]	Loss: 0.9834	LR: 0.000053
Training Epoch: 324 [128/50000]	Loss: 0.8473	LR: 0.000053
Training Epoch: 324 [128/50000]	Loss: 0.7897	LR: 0.000053
Evaluating Network.....
Test set: Epoch: 324, Average loss: 0.0106, Top1Accuracy: 0.6310, Top3Accuracy: 0.8262, Top5Accuracy: 0.8828, Time consumed:1.13s

Training Epoch: 325 [128/50000]	Loss: 0.8011	LR: 0.000052
Training Epoch: 325 [128/50000]	Loss: 0.8615	LR: 0.000052
Training Epoch: 325 [128/50000]	Loss: 0.7099	LR: 0.000052
Training Epoch: 325 [128/50000]	Loss: 0.6708	LR: 0.000052
Training Epoch: 325 [128/50000]	Loss: 0.7789	LR: 0.000052
Training Epoch: 325 [128/50000]	Loss: 0.9902	LR: 0.000052
Training Epoch: 325 [128/50000]	Loss: 0.9916	LR: 0.000052
Training Epoch: 325 [128/50000]	Loss: 0.7590	LR: 0.000052
Training Epoch: 325 [128/50000]	Loss: 0.8231	LR: 0.000052
Training Epoch: 325 [128/50000]	Loss: 0.7396	LR: 0.000052
Evaluating Network.....
Test set: Epoch: 325, Average loss: 0.0106, Top1Accuracy: 0.6295, Top3Accuracy: 0.8254, Top5Accuracy: 0.8833, Time consumed:1.13s

Training Epoch: 326 [128/50000]	Loss: 0.8536	LR: 0.000050
Training Epoch: 326 [128/50000]	Loss: 1.0743	LR: 0.000050
Training Epoch: 326 [128/50000]	Loss: 0.7586	LR: 0.000050
Training Epoch: 326 [128/50000]	Loss: 0.8794	LR: 0.000050
Training Epoch: 326 [128/50000]	Loss: 0.9729	LR: 0.000050
Training Epoch: 326 [128/50000]	Loss: 0.9263	LR: 0.000050
Training Epoch: 326 [128/50000]	Loss: 0.7155	LR: 0.000050
Training Epoch: 326 [128/50000]	Loss: 0.7489	LR: 0.000050
Training Epoch: 326 [128/50000]	Loss: 0.8629	LR: 0.000050
Training Epoch: 326 [128/50000]	Loss: 0.8444	LR: 0.000050
Evaluating Network.....
Test set: Epoch: 326, Average loss: 0.0107, Top1Accuracy: 0.6300, Top3Accuracy: 0.8255, Top5Accuracy: 0.8830, Time consumed:1.10s

Training Epoch: 327 [128/50000]	Loss: 0.8717	LR: 0.000049
Training Epoch: 327 [128/50000]	Loss: 1.0275	LR: 0.000049
Training Epoch: 327 [128/50000]	Loss: 0.8962	LR: 0.000049
Training Epoch: 327 [128/50000]	Loss: 0.8761	LR: 0.000049
Training Epoch: 327 [128/50000]	Loss: 0.7950	LR: 0.000049
Training Epoch: 327 [128/50000]	Loss: 0.7829	LR: 0.000049
Training Epoch: 327 [128/50000]	Loss: 0.9393	LR: 0.000049
Training Epoch: 327 [128/50000]	Loss: 0.9613	LR: 0.000049
Training Epoch: 327 [128/50000]	Loss: 1.0240	LR: 0.000049
Training Epoch: 327 [128/50000]	Loss: 0.8870	LR: 0.000049
Evaluating Network.....
Test set: Epoch: 327, Average loss: 0.0106, Top1Accuracy: 0.6325, Top3Accuracy: 0.8254, Top5Accuracy: 0.8838, Time consumed:1.11s

Training Epoch: 328 [128/50000]	Loss: 0.9049	LR: 0.000048
Training Epoch: 328 [128/50000]	Loss: 0.8110	LR: 0.000048
Training Epoch: 328 [128/50000]	Loss: 1.0108	LR: 0.000048
Training Epoch: 328 [128/50000]	Loss: 0.8937	LR: 0.000048
Training Epoch: 328 [128/50000]	Loss: 0.8308	LR: 0.000048
Training Epoch: 328 [128/50000]	Loss: 1.0480	LR: 0.000048
Training Epoch: 328 [128/50000]	Loss: 0.8529	LR: 0.000048
Training Epoch: 328 [128/50000]	Loss: 0.8239	LR: 0.000048
Training Epoch: 328 [128/50000]	Loss: 0.7716	LR: 0.000048
Training Epoch: 328 [128/50000]	Loss: 0.7771	LR: 0.000048
Evaluating Network.....
Test set: Epoch: 328, Average loss: 0.0107, Top1Accuracy: 0.6291, Top3Accuracy: 0.8260, Top5Accuracy: 0.8836, Time consumed:1.09s

Training Epoch: 329 [128/50000]	Loss: 0.7903	LR: 0.000046
Training Epoch: 329 [128/50000]	Loss: 0.8051	LR: 0.000046
Training Epoch: 329 [128/50000]	Loss: 0.8313	LR: 0.000046
Training Epoch: 329 [128/50000]	Loss: 0.8009	LR: 0.000046
Training Epoch: 329 [128/50000]	Loss: 0.7884	LR: 0.000046
Training Epoch: 329 [128/50000]	Loss: 0.9556	LR: 0.000046
Training Epoch: 329 [128/50000]	Loss: 0.9547	LR: 0.000046
Training Epoch: 329 [128/50000]	Loss: 0.8496	LR: 0.000046
Training Epoch: 329 [128/50000]	Loss: 0.7097	LR: 0.000046
Training Epoch: 329 [128/50000]	Loss: 0.7595	LR: 0.000046
Evaluating Network.....
Test set: Epoch: 329, Average loss: 0.0107, Top1Accuracy: 0.6296, Top3Accuracy: 0.8256, Top5Accuracy: 0.8827, Time consumed:1.12s

Training Epoch: 330 [128/50000]	Loss: 0.6636	LR: 0.000045
Training Epoch: 330 [128/50000]	Loss: 0.8506	LR: 0.000045
Training Epoch: 330 [128/50000]	Loss: 0.9737	LR: 0.000045
Training Epoch: 330 [128/50000]	Loss: 0.9980	LR: 0.000045
Training Epoch: 330 [128/50000]	Loss: 0.7458	LR: 0.000045
Training Epoch: 330 [128/50000]	Loss: 0.9170	LR: 0.000045
Training Epoch: 330 [128/50000]	Loss: 0.7611	LR: 0.000045
Training Epoch: 330 [128/50000]	Loss: 1.0224	LR: 0.000045
Training Epoch: 330 [128/50000]	Loss: 0.7490	LR: 0.000045
Training Epoch: 330 [128/50000]	Loss: 0.8188	LR: 0.000045
Evaluating Network.....
Test set: Epoch: 330, Average loss: 0.0107, Top1Accuracy: 0.6298, Top3Accuracy: 0.8271, Top5Accuracy: 0.8835, Time consumed:1.12s

Training Epoch: 331 [128/50000]	Loss: 0.9009	LR: 0.000044
Training Epoch: 331 [128/50000]	Loss: 0.8134	LR: 0.000044
Training Epoch: 331 [128/50000]	Loss: 0.9379	LR: 0.000044
Training Epoch: 331 [128/50000]	Loss: 0.6991	LR: 0.000044
Training Epoch: 331 [128/50000]	Loss: 1.0391	LR: 0.000044
Training Epoch: 331 [128/50000]	Loss: 0.7983	LR: 0.000044
Training Epoch: 331 [128/50000]	Loss: 0.7068	LR: 0.000044
Training Epoch: 331 [128/50000]	Loss: 0.9569	LR: 0.000044
Training Epoch: 331 [128/50000]	Loss: 0.8424	LR: 0.000044
Training Epoch: 331 [128/50000]	Loss: 0.7297	LR: 0.000044
Evaluating Network.....
Test set: Epoch: 331, Average loss: 0.0106, Top1Accuracy: 0.6297, Top3Accuracy: 0.8267, Top5Accuracy: 0.8828, Time consumed:1.11s

Training Epoch: 332 [128/50000]	Loss: 0.6967	LR: 0.000043
Training Epoch: 332 [128/50000]	Loss: 0.7975	LR: 0.000043
Training Epoch: 332 [128/50000]	Loss: 0.8150	LR: 0.000043
Training Epoch: 332 [128/50000]	Loss: 1.0166	LR: 0.000043
Training Epoch: 332 [128/50000]	Loss: 0.8433	LR: 0.000043
Training Epoch: 332 [128/50000]	Loss: 1.0040	LR: 0.000043
Training Epoch: 332 [128/50000]	Loss: 0.8015	LR: 0.000043
Training Epoch: 332 [128/50000]	Loss: 0.7711	LR: 0.000043
Training Epoch: 332 [128/50000]	Loss: 0.9899	LR: 0.000043
Training Epoch: 332 [128/50000]	Loss: 0.8936	LR: 0.000043
Evaluating Network.....
Test set: Epoch: 332, Average loss: 0.0106, Top1Accuracy: 0.6290, Top3Accuracy: 0.8261, Top5Accuracy: 0.8820, Time consumed:1.11s

Training Epoch: 333 [128/50000]	Loss: 0.7377	LR: 0.000042
Training Epoch: 333 [128/50000]	Loss: 0.9849	LR: 0.000042
Training Epoch: 333 [128/50000]	Loss: 0.9533	LR: 0.000042
Training Epoch: 333 [128/50000]	Loss: 0.7197	LR: 0.000042
Training Epoch: 333 [128/50000]	Loss: 0.8960	LR: 0.000042
Training Epoch: 333 [128/50000]	Loss: 0.7465	LR: 0.000042
Training Epoch: 333 [128/50000]	Loss: 0.8700	LR: 0.000042
Training Epoch: 333 [128/50000]	Loss: 0.6217	LR: 0.000042
Training Epoch: 333 [128/50000]	Loss: 0.7299	LR: 0.000042
Training Epoch: 333 [128/50000]	Loss: 0.8404	LR: 0.000042
Evaluating Network.....
Test set: Epoch: 333, Average loss: 0.0106, Top1Accuracy: 0.6301, Top3Accuracy: 0.8265, Top5Accuracy: 0.8829, Time consumed:1.11s

Training Epoch: 334 [128/50000]	Loss: 0.8457	LR: 0.000041
Training Epoch: 334 [128/50000]	Loss: 0.8245	LR: 0.000041
Training Epoch: 334 [128/50000]	Loss: 0.8288	LR: 0.000041
Training Epoch: 334 [128/50000]	Loss: 0.9576	LR: 0.000041
Training Epoch: 334 [128/50000]	Loss: 0.7584	LR: 0.000041
Training Epoch: 334 [128/50000]	Loss: 0.7410	LR: 0.000041
Training Epoch: 334 [128/50000]	Loss: 0.7566	LR: 0.000041
Training Epoch: 334 [128/50000]	Loss: 0.9134	LR: 0.000041
Training Epoch: 334 [128/50000]	Loss: 0.7393	LR: 0.000041
Training Epoch: 334 [128/50000]	Loss: 0.9018	LR: 0.000041
Evaluating Network.....
Test set: Epoch: 334, Average loss: 0.0107, Top1Accuracy: 0.6296, Top3Accuracy: 0.8268, Top5Accuracy: 0.8830, Time consumed:1.10s

Training Epoch: 335 [128/50000]	Loss: 0.8858	LR: 0.000039
Training Epoch: 335 [128/50000]	Loss: 0.7734	LR: 0.000039
Training Epoch: 335 [128/50000]	Loss: 0.8379	LR: 0.000039
Training Epoch: 335 [128/50000]	Loss: 0.6811	LR: 0.000039
Training Epoch: 335 [128/50000]	Loss: 0.8068	LR: 0.000039
Training Epoch: 335 [128/50000]	Loss: 1.0013	LR: 0.000039
Training Epoch: 335 [128/50000]	Loss: 0.8121	LR: 0.000039
Training Epoch: 335 [128/50000]	Loss: 0.8663	LR: 0.000039
Training Epoch: 335 [128/50000]	Loss: 0.8508	LR: 0.000039
Training Epoch: 335 [128/50000]	Loss: 0.7155	LR: 0.000039
Evaluating Network.....
Test set: Epoch: 335, Average loss: 0.0106, Top1Accuracy: 0.6309, Top3Accuracy: 0.8254, Top5Accuracy: 0.8840, Time consumed:1.12s

Training Epoch: 336 [128/50000]	Loss: 1.0521	LR: 0.000038
Training Epoch: 336 [128/50000]	Loss: 0.5602	LR: 0.000038
Training Epoch: 336 [128/50000]	Loss: 0.8107	LR: 0.000038
Training Epoch: 336 [128/50000]	Loss: 0.8133	LR: 0.000038
Training Epoch: 336 [128/50000]	Loss: 0.8441	LR: 0.000038
Training Epoch: 336 [128/50000]	Loss: 0.7789	LR: 0.000038
Training Epoch: 336 [128/50000]	Loss: 0.8235	LR: 0.000038
Training Epoch: 336 [128/50000]	Loss: 0.7474	LR: 0.000038
Training Epoch: 336 [128/50000]	Loss: 0.8812	LR: 0.000038
Training Epoch: 336 [128/50000]	Loss: 0.7371	LR: 0.000038
Evaluating Network.....
Test set: Epoch: 336, Average loss: 0.0106, Top1Accuracy: 0.6323, Top3Accuracy: 0.8257, Top5Accuracy: 0.8840, Time consumed:1.12s

Training Epoch: 337 [128/50000]	Loss: 0.7008	LR: 0.000037
Training Epoch: 337 [128/50000]	Loss: 0.7309	LR: 0.000037
Training Epoch: 337 [128/50000]	Loss: 0.7689	LR: 0.000037
Training Epoch: 337 [128/50000]	Loss: 0.7165	LR: 0.000037
Training Epoch: 337 [128/50000]	Loss: 0.9862	LR: 0.000037
Training Epoch: 337 [128/50000]	Loss: 0.8163	LR: 0.000037
Training Epoch: 337 [128/50000]	Loss: 0.7777	LR: 0.000037
Training Epoch: 337 [128/50000]	Loss: 0.9097	LR: 0.000037
Training Epoch: 337 [128/50000]	Loss: 0.7890	LR: 0.000037
Training Epoch: 337 [128/50000]	Loss: 0.8753	LR: 0.000037
Evaluating Network.....
Test set: Epoch: 337, Average loss: 0.0106, Top1Accuracy: 0.6302, Top3Accuracy: 0.8259, Top5Accuracy: 0.8843, Time consumed:1.12s

Training Epoch: 338 [128/50000]	Loss: 0.8839	LR: 0.000036
Training Epoch: 338 [128/50000]	Loss: 0.8193	LR: 0.000036
Training Epoch: 338 [128/50000]	Loss: 0.8324	LR: 0.000036
Training Epoch: 338 [128/50000]	Loss: 0.7674	LR: 0.000036
Training Epoch: 338 [128/50000]	Loss: 0.9263	LR: 0.000036
Training Epoch: 338 [128/50000]	Loss: 0.7920	LR: 0.000036
Training Epoch: 338 [128/50000]	Loss: 0.7679	LR: 0.000036
Training Epoch: 338 [128/50000]	Loss: 0.7641	LR: 0.000036
Training Epoch: 338 [128/50000]	Loss: 0.7947	LR: 0.000036
Training Epoch: 338 [128/50000]	Loss: 0.9243	LR: 0.000036
Evaluating Network.....
Test set: Epoch: 338, Average loss: 0.0106, Top1Accuracy: 0.6292, Top3Accuracy: 0.8257, Top5Accuracy: 0.8831, Time consumed:1.11s

Training Epoch: 339 [128/50000]	Loss: 0.8459	LR: 0.000035
Training Epoch: 339 [128/50000]	Loss: 0.7859	LR: 0.000035
Training Epoch: 339 [128/50000]	Loss: 0.6345	LR: 0.000035
Training Epoch: 339 [128/50000]	Loss: 0.9677	LR: 0.000035
Training Epoch: 339 [128/50000]	Loss: 0.7644	LR: 0.000035
Training Epoch: 339 [128/50000]	Loss: 1.0772	LR: 0.000035
Training Epoch: 339 [128/50000]	Loss: 0.7378	LR: 0.000035
Training Epoch: 339 [128/50000]	Loss: 0.7839	LR: 0.000035
Training Epoch: 339 [128/50000]	Loss: 0.9010	LR: 0.000035
Training Epoch: 339 [128/50000]	Loss: 0.8614	LR: 0.000035
Evaluating Network.....
Test set: Epoch: 339, Average loss: 0.0106, Top1Accuracy: 0.6303, Top3Accuracy: 0.8258, Top5Accuracy: 0.8837, Time consumed:1.11s

Training Epoch: 340 [128/50000]	Loss: 0.7856	LR: 0.000035
Training Epoch: 340 [128/50000]	Loss: 0.9000	LR: 0.000035
Training Epoch: 340 [128/50000]	Loss: 0.8842	LR: 0.000035
Training Epoch: 340 [128/50000]	Loss: 0.7363	LR: 0.000035
Training Epoch: 340 [128/50000]	Loss: 0.8933	LR: 0.000035
Training Epoch: 340 [128/50000]	Loss: 0.7235	LR: 0.000035
Training Epoch: 340 [128/50000]	Loss: 0.8731	LR: 0.000035
Training Epoch: 340 [128/50000]	Loss: 0.7126	LR: 0.000035
Training Epoch: 340 [128/50000]	Loss: 0.6792	LR: 0.000035
Training Epoch: 340 [128/50000]	Loss: 0.9568	LR: 0.000035
Evaluating Network.....
Test set: Epoch: 340, Average loss: 0.0106, Top1Accuracy: 0.6292, Top3Accuracy: 0.8261, Top5Accuracy: 0.8841, Time consumed:1.12s

Training Epoch: 341 [128/50000]	Loss: 0.8854	LR: 0.000034
Training Epoch: 341 [128/50000]	Loss: 0.9313	LR: 0.000034
Training Epoch: 341 [128/50000]	Loss: 0.9383	LR: 0.000034
Training Epoch: 341 [128/50000]	Loss: 0.7028	LR: 0.000034
Training Epoch: 341 [128/50000]	Loss: 0.7798	LR: 0.000034
Training Epoch: 341 [128/50000]	Loss: 0.8273	LR: 0.000034
Training Epoch: 341 [128/50000]	Loss: 0.8684	LR: 0.000034
Training Epoch: 341 [128/50000]	Loss: 0.8276	LR: 0.000034
Training Epoch: 341 [128/50000]	Loss: 0.7367	LR: 0.000034
Training Epoch: 341 [128/50000]	Loss: 0.8328	LR: 0.000034
Evaluating Network.....
Test set: Epoch: 341, Average loss: 0.0106, Top1Accuracy: 0.6306, Top3Accuracy: 0.8267, Top5Accuracy: 0.8825, Time consumed:1.13s

Training Epoch: 342 [128/50000]	Loss: 0.6761	LR: 0.000033
Training Epoch: 342 [128/50000]	Loss: 0.8790	LR: 0.000033
Training Epoch: 342 [128/50000]	Loss: 0.7649	LR: 0.000033
Training Epoch: 342 [128/50000]	Loss: 0.8074	LR: 0.000033
Training Epoch: 342 [128/50000]	Loss: 0.9624	LR: 0.000033
Training Epoch: 342 [128/50000]	Loss: 0.7923	LR: 0.000033
Training Epoch: 342 [128/50000]	Loss: 0.7919	LR: 0.000033
Training Epoch: 342 [128/50000]	Loss: 0.8277	LR: 0.000033
Training Epoch: 342 [128/50000]	Loss: 0.7852	LR: 0.000033
Training Epoch: 342 [128/50000]	Loss: 0.7658	LR: 0.000033
Evaluating Network.....
Test set: Epoch: 342, Average loss: 0.0107, Top1Accuracy: 0.6308, Top3Accuracy: 0.8260, Top5Accuracy: 0.8825, Time consumed:1.11s

Training Epoch: 343 [128/50000]	Loss: 0.7075	LR: 0.000032
Training Epoch: 343 [128/50000]	Loss: 0.5719	LR: 0.000032
Training Epoch: 343 [128/50000]	Loss: 0.7856	LR: 0.000032
Training Epoch: 343 [128/50000]	Loss: 0.8523	LR: 0.000032
Training Epoch: 343 [128/50000]	Loss: 0.8532	LR: 0.000032
Training Epoch: 343 [128/50000]	Loss: 0.8525	LR: 0.000032
Training Epoch: 343 [128/50000]	Loss: 0.8506	LR: 0.000032
Training Epoch: 343 [128/50000]	Loss: 0.8604	LR: 0.000032
Training Epoch: 343 [128/50000]	Loss: 0.8234	LR: 0.000032
Training Epoch: 343 [128/50000]	Loss: 1.0038	LR: 0.000032
Evaluating Network.....
Test set: Epoch: 343, Average loss: 0.0106, Top1Accuracy: 0.6300, Top3Accuracy: 0.8258, Top5Accuracy: 0.8837, Time consumed:1.13s

Training Epoch: 344 [128/50000]	Loss: 0.7604	LR: 0.000031
Training Epoch: 344 [128/50000]	Loss: 0.8676	LR: 0.000031
Training Epoch: 344 [128/50000]	Loss: 1.0205	LR: 0.000031
Training Epoch: 344 [128/50000]	Loss: 0.8368	LR: 0.000031
Training Epoch: 344 [128/50000]	Loss: 0.7367	LR: 0.000031
Training Epoch: 344 [128/50000]	Loss: 0.8020	LR: 0.000031
Training Epoch: 344 [128/50000]	Loss: 0.9632	LR: 0.000031
Training Epoch: 344 [128/50000]	Loss: 0.6650	LR: 0.000031
Training Epoch: 344 [128/50000]	Loss: 0.8879	LR: 0.000031
Training Epoch: 344 [128/50000]	Loss: 0.9509	LR: 0.000031
Evaluating Network.....
Test set: Epoch: 344, Average loss: 0.0107, Top1Accuracy: 0.6287, Top3Accuracy: 0.8267, Top5Accuracy: 0.8835, Time consumed:1.13s

Training Epoch: 345 [128/50000]	Loss: 0.9475	LR: 0.000030
Training Epoch: 345 [128/50000]	Loss: 0.8127	LR: 0.000030
Training Epoch: 345 [128/50000]	Loss: 0.8568	LR: 0.000030
Training Epoch: 345 [128/50000]	Loss: 0.9444	LR: 0.000030
Training Epoch: 345 [128/50000]	Loss: 0.8545	LR: 0.000030
Training Epoch: 345 [128/50000]	Loss: 0.7895	LR: 0.000030
Training Epoch: 345 [128/50000]	Loss: 0.8854	LR: 0.000030
Training Epoch: 345 [128/50000]	Loss: 0.8232	LR: 0.000030
Training Epoch: 345 [128/50000]	Loss: 0.9242	LR: 0.000030
Training Epoch: 345 [128/50000]	Loss: 0.6638	LR: 0.000030
Evaluating Network.....
Test set: Epoch: 345, Average loss: 0.0106, Top1Accuracy: 0.6291, Top3Accuracy: 0.8263, Top5Accuracy: 0.8842, Time consumed:1.13s

Training Epoch: 346 [128/50000]	Loss: 0.7728	LR: 0.000029
Training Epoch: 346 [128/50000]	Loss: 1.0344	LR: 0.000029
Training Epoch: 346 [128/50000]	Loss: 0.9127	LR: 0.000029
Training Epoch: 346 [128/50000]	Loss: 0.8319	LR: 0.000029
Training Epoch: 346 [128/50000]	Loss: 0.7409	LR: 0.000029
Training Epoch: 346 [128/50000]	Loss: 0.9319	LR: 0.000029
Training Epoch: 346 [128/50000]	Loss: 0.8609	LR: 0.000029
Training Epoch: 346 [128/50000]	Loss: 0.8462	LR: 0.000029
Training Epoch: 346 [128/50000]	Loss: 0.7873	LR: 0.000029
Training Epoch: 346 [128/50000]	Loss: 0.9631	LR: 0.000029
Evaluating Network.....
Test set: Epoch: 346, Average loss: 0.0106, Top1Accuracy: 0.6310, Top3Accuracy: 0.8253, Top5Accuracy: 0.8829, Time consumed:1.12s

Training Epoch: 347 [128/50000]	Loss: 0.9558	LR: 0.000029
Training Epoch: 347 [128/50000]	Loss: 0.9922	LR: 0.000029
Training Epoch: 347 [128/50000]	Loss: 0.9822	LR: 0.000029
Training Epoch: 347 [128/50000]	Loss: 0.7412	LR: 0.000029
Training Epoch: 347 [128/50000]	Loss: 0.7502	LR: 0.000029
Training Epoch: 347 [128/50000]	Loss: 0.8060	LR: 0.000029
Training Epoch: 347 [128/50000]	Loss: 0.8342	LR: 0.000029
Training Epoch: 347 [128/50000]	Loss: 0.8031	LR: 0.000029
Training Epoch: 347 [128/50000]	Loss: 0.8333	LR: 0.000029
Training Epoch: 347 [128/50000]	Loss: 0.7174	LR: 0.000029
Evaluating Network.....
Test set: Epoch: 347, Average loss: 0.0107, Top1Accuracy: 0.6286, Top3Accuracy: 0.8271, Top5Accuracy: 0.8831, Time consumed:1.10s

Training Epoch: 348 [128/50000]	Loss: 0.8495	LR: 0.000028
Training Epoch: 348 [128/50000]	Loss: 0.9614	LR: 0.000028
Training Epoch: 348 [128/50000]	Loss: 0.8296	LR: 0.000028
Training Epoch: 348 [128/50000]	Loss: 0.8485	LR: 0.000028
Training Epoch: 348 [128/50000]	Loss: 0.8886	LR: 0.000028
Training Epoch: 348 [128/50000]	Loss: 0.9494	LR: 0.000028
Training Epoch: 348 [128/50000]	Loss: 0.8608	LR: 0.000028
Training Epoch: 348 [128/50000]	Loss: 0.9964	LR: 0.000028
Training Epoch: 348 [128/50000]	Loss: 0.7041	LR: 0.000028
Training Epoch: 348 [128/50000]	Loss: 0.7732	LR: 0.000028
Evaluating Network.....
Test set: Epoch: 348, Average loss: 0.0107, Top1Accuracy: 0.6306, Top3Accuracy: 0.8266, Top5Accuracy: 0.8828, Time consumed:1.11s

Training Epoch: 349 [128/50000]	Loss: 0.7766	LR: 0.000027
Training Epoch: 349 [128/50000]	Loss: 0.7671	LR: 0.000027
Training Epoch: 349 [128/50000]	Loss: 0.8234	LR: 0.000027
Training Epoch: 349 [128/50000]	Loss: 0.7691	LR: 0.000027
Training Epoch: 349 [128/50000]	Loss: 0.7784	LR: 0.000027
Training Epoch: 349 [128/50000]	Loss: 0.8318	LR: 0.000027
Training Epoch: 349 [128/50000]	Loss: 0.7482	LR: 0.000027
Training Epoch: 349 [128/50000]	Loss: 0.7238	LR: 0.000027
Training Epoch: 349 [128/50000]	Loss: 0.9266	LR: 0.000027
Training Epoch: 349 [128/50000]	Loss: 0.7293	LR: 0.000027
Evaluating Network.....
Test set: Epoch: 349, Average loss: 0.0107, Top1Accuracy: 0.6303, Top3Accuracy: 0.8266, Top5Accuracy: 0.8824, Time consumed:1.11s

Training Epoch: 350 [128/50000]	Loss: 0.9121	LR: 0.000026
Training Epoch: 350 [128/50000]	Loss: 0.9037	LR: 0.000026
Training Epoch: 350 [128/50000]	Loss: 0.8309	LR: 0.000026
Training Epoch: 350 [128/50000]	Loss: 0.7924	LR: 0.000026
Training Epoch: 350 [128/50000]	Loss: 0.7554	LR: 0.000026
Training Epoch: 350 [128/50000]	Loss: 0.7745	LR: 0.000026
Training Epoch: 350 [128/50000]	Loss: 0.7519	LR: 0.000026
Training Epoch: 350 [128/50000]	Loss: 0.8760	LR: 0.000026
Training Epoch: 350 [128/50000]	Loss: 1.0277	LR: 0.000026
Training Epoch: 350 [128/50000]	Loss: 0.8456	LR: 0.000026
Evaluating Network.....
Test set: Epoch: 350, Average loss: 0.0107, Top1Accuracy: 0.6296, Top3Accuracy: 0.8261, Top5Accuracy: 0.8831, Time consumed:1.11s

Training Epoch: 351 [128/50000]	Loss: 0.9607	LR: 0.000026
Training Epoch: 351 [128/50000]	Loss: 0.7952	LR: 0.000026
Training Epoch: 351 [128/50000]	Loss: 0.8014	LR: 0.000026
Training Epoch: 351 [128/50000]	Loss: 0.9659	LR: 0.000026
Training Epoch: 351 [128/50000]	Loss: 0.7410	LR: 0.000026
Training Epoch: 351 [128/50000]	Loss: 0.7549	LR: 0.000026
Training Epoch: 351 [128/50000]	Loss: 0.6758	LR: 0.000026
Training Epoch: 351 [128/50000]	Loss: 0.9153	LR: 0.000026
Training Epoch: 351 [128/50000]	Loss: 0.7618	LR: 0.000026
Training Epoch: 351 [128/50000]	Loss: 1.0749	LR: 0.000026
Evaluating Network.....
Test set: Epoch: 351, Average loss: 0.0107, Top1Accuracy: 0.6301, Top3Accuracy: 0.8251, Top5Accuracy: 0.8836, Time consumed:1.11s

Training Epoch: 352 [128/50000]	Loss: 0.6969	LR: 0.000025
Training Epoch: 352 [128/50000]	Loss: 1.0971	LR: 0.000025
Training Epoch: 352 [128/50000]	Loss: 0.8167	LR: 0.000025
Training Epoch: 352 [128/50000]	Loss: 0.8531	LR: 0.000025
Training Epoch: 352 [128/50000]	Loss: 0.8415	LR: 0.000025
Training Epoch: 352 [128/50000]	Loss: 0.8128	LR: 0.000025
Training Epoch: 352 [128/50000]	Loss: 0.7510	LR: 0.000025
Training Epoch: 352 [128/50000]	Loss: 0.9080	LR: 0.000025
Training Epoch: 352 [128/50000]	Loss: 0.7601	LR: 0.000025
Training Epoch: 352 [128/50000]	Loss: 0.8706	LR: 0.000025
Evaluating Network.....
Test set: Epoch: 352, Average loss: 0.0106, Top1Accuracy: 0.6289, Top3Accuracy: 0.8259, Top5Accuracy: 0.8824, Time consumed:1.11s

Training Epoch: 353 [128/50000]	Loss: 0.7404	LR: 0.000024
Training Epoch: 353 [128/50000]	Loss: 0.7679	LR: 0.000024
Training Epoch: 353 [128/50000]	Loss: 0.8642	LR: 0.000024
Training Epoch: 353 [128/50000]	Loss: 0.7913	LR: 0.000024
Training Epoch: 353 [128/50000]	Loss: 0.7596	LR: 0.000024
Training Epoch: 353 [128/50000]	Loss: 0.8156	LR: 0.000024
Training Epoch: 353 [128/50000]	Loss: 0.7384	LR: 0.000024
Training Epoch: 353 [128/50000]	Loss: 0.8581	LR: 0.000024
Training Epoch: 353 [128/50000]	Loss: 0.8225	LR: 0.000024
Training Epoch: 353 [128/50000]	Loss: 0.7571	LR: 0.000024
Evaluating Network.....
Test set: Epoch: 353, Average loss: 0.0107, Top1Accuracy: 0.6300, Top3Accuracy: 0.8262, Top5Accuracy: 0.8830, Time consumed:1.11s

Training Epoch: 354 [128/50000]	Loss: 0.6580	LR: 0.000024
Training Epoch: 354 [128/50000]	Loss: 0.9555	LR: 0.000024
Training Epoch: 354 [128/50000]	Loss: 0.7419	LR: 0.000024
Training Epoch: 354 [128/50000]	Loss: 0.8572	LR: 0.000024
Training Epoch: 354 [128/50000]	Loss: 0.9237	LR: 0.000024
Training Epoch: 354 [128/50000]	Loss: 0.9117	LR: 0.000024
Training Epoch: 354 [128/50000]	Loss: 0.7140	LR: 0.000024
Training Epoch: 354 [128/50000]	Loss: 0.8721	LR: 0.000024
Training Epoch: 354 [128/50000]	Loss: 0.9450	LR: 0.000024
Training Epoch: 354 [128/50000]	Loss: 0.7586	LR: 0.000024
Evaluating Network.....
Test set: Epoch: 354, Average loss: 0.0106, Top1Accuracy: 0.6310, Top3Accuracy: 0.8262, Top5Accuracy: 0.8835, Time consumed:1.11s

Training Epoch: 355 [128/50000]	Loss: 0.7182	LR: 0.000023
Training Epoch: 355 [128/50000]	Loss: 0.8088	LR: 0.000023
Training Epoch: 355 [128/50000]	Loss: 0.8688	LR: 0.000023
Training Epoch: 355 [128/50000]	Loss: 0.7649	LR: 0.000023
Training Epoch: 355 [128/50000]	Loss: 0.8391	LR: 0.000023
Training Epoch: 355 [128/50000]	Loss: 0.8138	LR: 0.000023
Training Epoch: 355 [128/50000]	Loss: 0.8119	LR: 0.000023
Training Epoch: 355 [128/50000]	Loss: 0.9091	LR: 0.000023
Training Epoch: 355 [128/50000]	Loss: 0.7829	LR: 0.000023
Training Epoch: 355 [128/50000]	Loss: 0.8379	LR: 0.000023
Evaluating Network.....
Test set: Epoch: 355, Average loss: 0.0106, Top1Accuracy: 0.6295, Top3Accuracy: 0.8273, Top5Accuracy: 0.8829, Time consumed:1.12s

Training Epoch: 356 [128/50000]	Loss: 0.8871	LR: 0.000023
Training Epoch: 356 [128/50000]	Loss: 0.7712	LR: 0.000023
Training Epoch: 356 [128/50000]	Loss: 0.7200	LR: 0.000023
Training Epoch: 356 [128/50000]	Loss: 0.8320	LR: 0.000023
Training Epoch: 356 [128/50000]	Loss: 0.9315	LR: 0.000023
Training Epoch: 356 [128/50000]	Loss: 0.8209	LR: 0.000023
Training Epoch: 356 [128/50000]	Loss: 0.7739	LR: 0.000023
Training Epoch: 356 [128/50000]	Loss: 0.8581	LR: 0.000023
Training Epoch: 356 [128/50000]	Loss: 0.9045	LR: 0.000023
Training Epoch: 356 [128/50000]	Loss: 0.9236	LR: 0.000023
Evaluating Network.....
Test set: Epoch: 356, Average loss: 0.0107, Top1Accuracy: 0.6304, Top3Accuracy: 0.8261, Top5Accuracy: 0.8840, Time consumed:1.10s

Training Epoch: 357 [128/50000]	Loss: 0.8334	LR: 0.000022
Training Epoch: 357 [128/50000]	Loss: 0.6867	LR: 0.000022
Training Epoch: 357 [128/50000]	Loss: 0.8652	LR: 0.000022
Training Epoch: 357 [128/50000]	Loss: 0.8535	LR: 0.000022
Training Epoch: 357 [128/50000]	Loss: 0.8020	LR: 0.000022
Training Epoch: 357 [128/50000]	Loss: 0.7817	LR: 0.000022
Training Epoch: 357 [128/50000]	Loss: 0.9680	LR: 0.000022
Training Epoch: 357 [128/50000]	Loss: 0.7821	LR: 0.000022
Training Epoch: 357 [128/50000]	Loss: 0.7079	LR: 0.000022
Training Epoch: 357 [128/50000]	Loss: 0.8640	LR: 0.000022
Evaluating Network.....
Test set: Epoch: 357, Average loss: 0.0108, Top1Accuracy: 0.6297, Top3Accuracy: 0.8264, Top5Accuracy: 0.8829, Time consumed:1.11s

Training Epoch: 358 [128/50000]	Loss: 0.7881	LR: 0.000021
Training Epoch: 358 [128/50000]	Loss: 0.7836	LR: 0.000021
Training Epoch: 358 [128/50000]	Loss: 0.8801	LR: 0.000021
Training Epoch: 358 [128/50000]	Loss: 0.9491	LR: 0.000021
Training Epoch: 358 [128/50000]	Loss: 1.0165	LR: 0.000021
Training Epoch: 358 [128/50000]	Loss: 0.9717	LR: 0.000021
Training Epoch: 358 [128/50000]	Loss: 0.9111	LR: 0.000021
Training Epoch: 358 [128/50000]	Loss: 0.8863	LR: 0.000021
Training Epoch: 358 [128/50000]	Loss: 1.0116	LR: 0.000021
Training Epoch: 358 [128/50000]	Loss: 0.7922	LR: 0.000021
Evaluating Network.....
Test set: Epoch: 358, Average loss: 0.0107, Top1Accuracy: 0.6297, Top3Accuracy: 0.8266, Top5Accuracy: 0.8836, Time consumed:1.12s

Training Epoch: 359 [128/50000]	Loss: 0.6688	LR: 0.000021
Training Epoch: 359 [128/50000]	Loss: 0.8196	LR: 0.000021
Training Epoch: 359 [128/50000]	Loss: 0.8298	LR: 0.000021
Training Epoch: 359 [128/50000]	Loss: 0.8690	LR: 0.000021
Training Epoch: 359 [128/50000]	Loss: 0.7765	LR: 0.000021
Training Epoch: 359 [128/50000]	Loss: 0.8242	LR: 0.000021
Training Epoch: 359 [128/50000]	Loss: 0.7655	LR: 0.000021
Training Epoch: 359 [128/50000]	Loss: 0.8022	LR: 0.000021
Training Epoch: 359 [128/50000]	Loss: 0.9959	LR: 0.000021
Training Epoch: 359 [128/50000]	Loss: 0.8416	LR: 0.000021
Evaluating Network.....
Test set: Epoch: 359, Average loss: 0.0107, Top1Accuracy: 0.6297, Top3Accuracy: 0.8256, Top5Accuracy: 0.8830, Time consumed:1.14s

Training Epoch: 360 [128/50000]	Loss: 0.9050	LR: 0.000020
Training Epoch: 360 [128/50000]	Loss: 0.7653	LR: 0.000020
Training Epoch: 360 [128/50000]	Loss: 0.8499	LR: 0.000020
Training Epoch: 360 [128/50000]	Loss: 0.7457	LR: 0.000020
Training Epoch: 360 [128/50000]	Loss: 0.6921	LR: 0.000020
Training Epoch: 360 [128/50000]	Loss: 0.8780	LR: 0.000020
Training Epoch: 360 [128/50000]	Loss: 0.8100	LR: 0.000020
Training Epoch: 360 [128/50000]	Loss: 0.8511	LR: 0.000020
Training Epoch: 360 [128/50000]	Loss: 0.8987	LR: 0.000020
Training Epoch: 360 [128/50000]	Loss: 0.7557	LR: 0.000020
Evaluating Network.....
Test set: Epoch: 360, Average loss: 0.0107, Top1Accuracy: 0.6288, Top3Accuracy: 0.8252, Top5Accuracy: 0.8844, Time consumed:1.11s

Training Epoch: 361 [128/50000]	Loss: 0.8218	LR: 0.000020
Training Epoch: 361 [128/50000]	Loss: 0.9488	LR: 0.000020
Training Epoch: 361 [128/50000]	Loss: 0.7362	LR: 0.000020
Training Epoch: 361 [128/50000]	Loss: 0.7135	LR: 0.000020
Training Epoch: 361 [128/50000]	Loss: 0.8210	LR: 0.000020
Training Epoch: 361 [128/50000]	Loss: 0.7625	LR: 0.000020
Training Epoch: 361 [128/50000]	Loss: 0.8227	LR: 0.000020
Training Epoch: 361 [128/50000]	Loss: 0.9082	LR: 0.000020
Training Epoch: 361 [128/50000]	Loss: 0.8370	LR: 0.000020
Training Epoch: 361 [128/50000]	Loss: 0.7418	LR: 0.000020
Evaluating Network.....
Test set: Epoch: 361, Average loss: 0.0106, Top1Accuracy: 0.6295, Top3Accuracy: 0.8270, Top5Accuracy: 0.8825, Time consumed:1.12s

Training Epoch: 362 [128/50000]	Loss: 0.8716	LR: 0.000019
Training Epoch: 362 [128/50000]	Loss: 0.6534	LR: 0.000019
Training Epoch: 362 [128/50000]	Loss: 0.7384	LR: 0.000019
Training Epoch: 362 [128/50000]	Loss: 0.7301	LR: 0.000019
Training Epoch: 362 [128/50000]	Loss: 0.7255	LR: 0.000019
Training Epoch: 362 [128/50000]	Loss: 0.7495	LR: 0.000019
Training Epoch: 362 [128/50000]	Loss: 0.9096	LR: 0.000019
Training Epoch: 362 [128/50000]	Loss: 0.7849	LR: 0.000019
Training Epoch: 362 [128/50000]	Loss: 0.7161	LR: 0.000019
Training Epoch: 362 [128/50000]	Loss: 0.9267	LR: 0.000019
Evaluating Network.....
Test set: Epoch: 362, Average loss: 0.0107, Top1Accuracy: 0.6306, Top3Accuracy: 0.8267, Top5Accuracy: 0.8824, Time consumed:1.11s

Training Epoch: 363 [128/50000]	Loss: 0.9468	LR: 0.000019
Training Epoch: 363 [128/50000]	Loss: 0.8720	LR: 0.000019
Training Epoch: 363 [128/50000]	Loss: 0.7705	LR: 0.000019
Training Epoch: 363 [128/50000]	Loss: 0.8194	LR: 0.000019
Training Epoch: 363 [128/50000]	Loss: 0.9724	LR: 0.000019
Training Epoch: 363 [128/50000]	Loss: 0.6698	LR: 0.000019
Training Epoch: 363 [128/50000]	Loss: 0.7574	LR: 0.000019
Training Epoch: 363 [128/50000]	Loss: 0.7719	LR: 0.000019
Training Epoch: 363 [128/50000]	Loss: 0.7534	LR: 0.000019
Training Epoch: 363 [128/50000]	Loss: 0.7509	LR: 0.000019
Evaluating Network.....
Test set: Epoch: 363, Average loss: 0.0107, Top1Accuracy: 0.6302, Top3Accuracy: 0.8266, Top5Accuracy: 0.8823, Time consumed:1.10s

Training Epoch: 364 [128/50000]	Loss: 0.7323	LR: 0.000018
Training Epoch: 364 [128/50000]	Loss: 0.9346	LR: 0.000018
Training Epoch: 364 [128/50000]	Loss: 0.7520	LR: 0.000018
Training Epoch: 364 [128/50000]	Loss: 0.7595	LR: 0.000018
Training Epoch: 364 [128/50000]	Loss: 0.9251	LR: 0.000018
Training Epoch: 364 [128/50000]	Loss: 0.7421	LR: 0.000018
Training Epoch: 364 [128/50000]	Loss: 0.8648	LR: 0.000018
Training Epoch: 364 [128/50000]	Loss: 0.8722	LR: 0.000018
Training Epoch: 364 [128/50000]	Loss: 0.8905	LR: 0.000018
Training Epoch: 364 [128/50000]	Loss: 0.8067	LR: 0.000018
Evaluating Network.....
Test set: Epoch: 364, Average loss: 0.0107, Top1Accuracy: 0.6306, Top3Accuracy: 0.8265, Top5Accuracy: 0.8823, Time consumed:1.10s

Training Epoch: 365 [128/50000]	Loss: 0.6594	LR: 0.000018
Training Epoch: 365 [128/50000]	Loss: 0.9769	LR: 0.000018
Training Epoch: 365 [128/50000]	Loss: 0.9654	LR: 0.000018
Training Epoch: 365 [128/50000]	Loss: 0.6282	LR: 0.000018
Training Epoch: 365 [128/50000]	Loss: 0.7152	LR: 0.000018
Training Epoch: 365 [128/50000]	Loss: 0.7594	LR: 0.000018
Training Epoch: 365 [128/50000]	Loss: 0.8397	LR: 0.000018
Training Epoch: 365 [128/50000]	Loss: 0.8879	LR: 0.000018
Training Epoch: 365 [128/50000]	Loss: 0.8261	LR: 0.000018
Training Epoch: 365 [128/50000]	Loss: 0.8865	LR: 0.000018
Evaluating Network.....
Test set: Epoch: 365, Average loss: 0.0107, Top1Accuracy: 0.6289, Top3Accuracy: 0.8260, Top5Accuracy: 0.8840, Time consumed:1.13s

Training Epoch: 366 [128/50000]	Loss: 0.8274	LR: 0.000017
Training Epoch: 366 [128/50000]	Loss: 0.8151	LR: 0.000017
Training Epoch: 366 [128/50000]	Loss: 0.8951	LR: 0.000017
Training Epoch: 366 [128/50000]	Loss: 0.7265	LR: 0.000017
Training Epoch: 366 [128/50000]	Loss: 0.9489	LR: 0.000017
Training Epoch: 366 [128/50000]	Loss: 0.7594	LR: 0.000017
Training Epoch: 366 [128/50000]	Loss: 0.8064	LR: 0.000017
Training Epoch: 366 [128/50000]	Loss: 0.6648	LR: 0.000017
Training Epoch: 366 [128/50000]	Loss: 0.9090	LR: 0.000017
Training Epoch: 366 [128/50000]	Loss: 0.9172	LR: 0.000017
Evaluating Network.....
Test set: Epoch: 366, Average loss: 0.0106, Top1Accuracy: 0.6305, Top3Accuracy: 0.8263, Top5Accuracy: 0.8839, Time consumed:1.14s

Training Epoch: 367 [128/50000]	Loss: 0.6670	LR: 0.000017
Training Epoch: 367 [128/50000]	Loss: 0.7779	LR: 0.000017
Training Epoch: 367 [128/50000]	Loss: 0.7806	LR: 0.000017
Training Epoch: 367 [128/50000]	Loss: 0.8184	LR: 0.000017
Training Epoch: 367 [128/50000]	Loss: 0.8068	LR: 0.000017
Training Epoch: 367 [128/50000]	Loss: 0.7315	LR: 0.000017
Training Epoch: 367 [128/50000]	Loss: 0.7224	LR: 0.000017
Training Epoch: 367 [128/50000]	Loss: 0.8544	LR: 0.000017
Training Epoch: 367 [128/50000]	Loss: 0.9844	LR: 0.000017
Training Epoch: 367 [128/50000]	Loss: 0.8535	LR: 0.000017
Evaluating Network.....
Test set: Epoch: 367, Average loss: 0.0107, Top1Accuracy: 0.6292, Top3Accuracy: 0.8257, Top5Accuracy: 0.8834, Time consumed:1.11s

Training Epoch: 368 [128/50000]	Loss: 1.0444	LR: 0.000016
Training Epoch: 368 [128/50000]	Loss: 0.8251	LR: 0.000016
Training Epoch: 368 [128/50000]	Loss: 0.9511	LR: 0.000016
Training Epoch: 368 [128/50000]	Loss: 0.7919	LR: 0.000016
Training Epoch: 368 [128/50000]	Loss: 0.8684	LR: 0.000016
Training Epoch: 368 [128/50000]	Loss: 0.8143	LR: 0.000016
Training Epoch: 368 [128/50000]	Loss: 0.9613	LR: 0.000016
Training Epoch: 368 [128/50000]	Loss: 0.9250	LR: 0.000016
Training Epoch: 368 [128/50000]	Loss: 0.9527	LR: 0.000016
Training Epoch: 368 [128/50000]	Loss: 0.6609	LR: 0.000016
Evaluating Network.....
Test set: Epoch: 368, Average loss: 0.0106, Top1Accuracy: 0.6307, Top3Accuracy: 0.8254, Top5Accuracy: 0.8829, Time consumed:1.11s

Training Epoch: 369 [128/50000]	Loss: 0.8962	LR: 0.000016
Training Epoch: 369 [128/50000]	Loss: 0.9536	LR: 0.000016
Training Epoch: 369 [128/50000]	Loss: 0.7925	LR: 0.000016
Training Epoch: 369 [128/50000]	Loss: 0.7854	LR: 0.000016
Training Epoch: 369 [128/50000]	Loss: 0.8656	LR: 0.000016
Training Epoch: 369 [128/50000]	Loss: 0.7810	LR: 0.000016
Training Epoch: 369 [128/50000]	Loss: 0.6996	LR: 0.000016
Training Epoch: 369 [128/50000]	Loss: 0.7956	LR: 0.000016
Training Epoch: 369 [128/50000]	Loss: 0.7345	LR: 0.000016
Training Epoch: 369 [128/50000]	Loss: 1.0620	LR: 0.000016
Evaluating Network.....
Test set: Epoch: 369, Average loss: 0.0107, Top1Accuracy: 0.6290, Top3Accuracy: 0.8262, Top5Accuracy: 0.8832, Time consumed:1.11s

Training Epoch: 370 [128/50000]	Loss: 0.7599	LR: 0.000015
Training Epoch: 370 [128/50000]	Loss: 0.8650	LR: 0.000015
Training Epoch: 370 [128/50000]	Loss: 0.6933	LR: 0.000015
Training Epoch: 370 [128/50000]	Loss: 0.8788	LR: 0.000015
Training Epoch: 370 [128/50000]	Loss: 0.7269	LR: 0.000015
Training Epoch: 370 [128/50000]	Loss: 0.9270	LR: 0.000015
Training Epoch: 370 [128/50000]	Loss: 0.9404	LR: 0.000015
Training Epoch: 370 [128/50000]	Loss: 0.9043	LR: 0.000015
Training Epoch: 370 [128/50000]	Loss: 0.8236	LR: 0.000015
Training Epoch: 370 [128/50000]	Loss: 1.1219	LR: 0.000015
Evaluating Network.....
Test set: Epoch: 370, Average loss: 0.0106, Top1Accuracy: 0.6305, Top3Accuracy: 0.8266, Top5Accuracy: 0.8843, Time consumed:1.11s

Training Epoch: 371 [128/50000]	Loss: 0.7178	LR: 0.000015
Training Epoch: 371 [128/50000]	Loss: 0.7389	LR: 0.000015
Training Epoch: 371 [128/50000]	Loss: 0.6796	LR: 0.000015
Training Epoch: 371 [128/50000]	Loss: 0.7008	LR: 0.000015
Training Epoch: 371 [128/50000]	Loss: 0.8362	LR: 0.000015
Training Epoch: 371 [128/50000]	Loss: 0.9064	LR: 0.000015
Training Epoch: 371 [128/50000]	Loss: 0.7774	LR: 0.000015
Training Epoch: 371 [128/50000]	Loss: 0.8485	LR: 0.000015
Training Epoch: 371 [128/50000]	Loss: 0.7811	LR: 0.000015
Training Epoch: 371 [128/50000]	Loss: 0.8968	LR: 0.000015
Evaluating Network.....
Test set: Epoch: 371, Average loss: 0.0106, Top1Accuracy: 0.6306, Top3Accuracy: 0.8258, Top5Accuracy: 0.8824, Time consumed:1.11s

Training Epoch: 372 [128/50000]	Loss: 0.7643	LR: 0.000015
Training Epoch: 372 [128/50000]	Loss: 0.8837	LR: 0.000015
Training Epoch: 372 [128/50000]	Loss: 0.8998	LR: 0.000015
Training Epoch: 372 [128/50000]	Loss: 0.8849	LR: 0.000015
Training Epoch: 372 [128/50000]	Loss: 1.0093	LR: 0.000015
Training Epoch: 372 [128/50000]	Loss: 0.8917	LR: 0.000015
Training Epoch: 372 [128/50000]	Loss: 0.6514	LR: 0.000015
Training Epoch: 372 [128/50000]	Loss: 0.9364	LR: 0.000015
Training Epoch: 372 [128/50000]	Loss: 0.8121	LR: 0.000015
Training Epoch: 372 [128/50000]	Loss: 0.7001	LR: 0.000015
Evaluating Network.....
Test set: Epoch: 372, Average loss: 0.0106, Top1Accuracy: 0.6300, Top3Accuracy: 0.8256, Top5Accuracy: 0.8840, Time consumed:1.10s

Training Epoch: 373 [128/50000]	Loss: 0.7097	LR: 0.000014
Training Epoch: 373 [128/50000]	Loss: 0.8080	LR: 0.000014
Training Epoch: 373 [128/50000]	Loss: 1.0190	LR: 0.000014
Training Epoch: 373 [128/50000]	Loss: 0.8195	LR: 0.000014
Training Epoch: 373 [128/50000]	Loss: 0.8379	LR: 0.000014
Training Epoch: 373 [128/50000]	Loss: 0.7060	LR: 0.000014
Training Epoch: 373 [128/50000]	Loss: 0.8379	LR: 0.000014
Training Epoch: 373 [128/50000]	Loss: 0.7293	LR: 0.000014
Training Epoch: 373 [128/50000]	Loss: 0.7463	LR: 0.000014
Training Epoch: 373 [128/50000]	Loss: 0.8443	LR: 0.000014
Evaluating Network.....
Test set: Epoch: 373, Average loss: 0.0107, Top1Accuracy: 0.6289, Top3Accuracy: 0.8254, Top5Accuracy: 0.8830, Time consumed:1.12s

Training Epoch: 374 [128/50000]	Loss: 0.7859	LR: 0.000014
Training Epoch: 374 [128/50000]	Loss: 0.8542	LR: 0.000014
Training Epoch: 374 [128/50000]	Loss: 0.6455	LR: 0.000014
Training Epoch: 374 [128/50000]	Loss: 0.7342	LR: 0.000014
Training Epoch: 374 [128/50000]	Loss: 0.8241	LR: 0.000014
Training Epoch: 374 [128/50000]	Loss: 0.9405	LR: 0.000014
Training Epoch: 374 [128/50000]	Loss: 0.8478	LR: 0.000014
Training Epoch: 374 [128/50000]	Loss: 0.7441	LR: 0.000014
Training Epoch: 374 [128/50000]	Loss: 0.9422	LR: 0.000014
Training Epoch: 374 [128/50000]	Loss: 0.9252	LR: 0.000014
Evaluating Network.....
Test set: Epoch: 374, Average loss: 0.0106, Top1Accuracy: 0.6303, Top3Accuracy: 0.8263, Top5Accuracy: 0.8829, Time consumed:1.10s

Training Epoch: 375 [128/50000]	Loss: 0.8528	LR: 0.000014
Training Epoch: 375 [128/50000]	Loss: 0.8134	LR: 0.000014
Training Epoch: 375 [128/50000]	Loss: 0.9345	LR: 0.000014
Training Epoch: 375 [128/50000]	Loss: 0.7112	LR: 0.000014
Training Epoch: 375 [128/50000]	Loss: 0.8666	LR: 0.000014
Training Epoch: 375 [128/50000]	Loss: 0.9709	LR: 0.000014
Training Epoch: 375 [128/50000]	Loss: 0.9083	LR: 0.000014
Training Epoch: 375 [128/50000]	Loss: 0.8087	LR: 0.000014
Training Epoch: 375 [128/50000]	Loss: 0.7909	LR: 0.000014
Training Epoch: 375 [128/50000]	Loss: 0.9686	LR: 0.000014
Evaluating Network.....
Test set: Epoch: 375, Average loss: 0.0107, Top1Accuracy: 0.6307, Top3Accuracy: 0.8251, Top5Accuracy: 0.8813, Time consumed:1.11s

Training Epoch: 376 [128/50000]	Loss: 0.9080	LR: 0.000013
Training Epoch: 376 [128/50000]	Loss: 0.9014	LR: 0.000013
Training Epoch: 376 [128/50000]	Loss: 0.8753	LR: 0.000013
Training Epoch: 376 [128/50000]	Loss: 0.7780	LR: 0.000013
Training Epoch: 376 [128/50000]	Loss: 0.9090	LR: 0.000013
Training Epoch: 376 [128/50000]	Loss: 0.8595	LR: 0.000013
Training Epoch: 376 [128/50000]	Loss: 0.7114	LR: 0.000013
Training Epoch: 376 [128/50000]	Loss: 0.7925	LR: 0.000013
Training Epoch: 376 [128/50000]	Loss: 0.8271	LR: 0.000013
Training Epoch: 376 [128/50000]	Loss: 0.8004	LR: 0.000013
Evaluating Network.....
Test set: Epoch: 376, Average loss: 0.0106, Top1Accuracy: 0.6298, Top3Accuracy: 0.8261, Top5Accuracy: 0.8826, Time consumed:1.24s

Training Epoch: 377 [128/50000]	Loss: 0.7453	LR: 0.000013
Training Epoch: 377 [128/50000]	Loss: 0.8476	LR: 0.000013
Training Epoch: 377 [128/50000]	Loss: 0.7115	LR: 0.000013
Training Epoch: 377 [128/50000]	Loss: 0.7635	LR: 0.000013
Training Epoch: 377 [128/50000]	Loss: 0.8172	LR: 0.000013
Training Epoch: 377 [128/50000]	Loss: 0.8438	LR: 0.000013
Training Epoch: 377 [128/50000]	Loss: 0.7438	LR: 0.000013
Training Epoch: 377 [128/50000]	Loss: 0.9365	LR: 0.000013
Training Epoch: 377 [128/50000]	Loss: 0.8673	LR: 0.000013
Training Epoch: 377 [128/50000]	Loss: 0.6909	LR: 0.000013
Evaluating Network.....
Test set: Epoch: 377, Average loss: 0.0107, Top1Accuracy: 0.6300, Top3Accuracy: 0.8263, Top5Accuracy: 0.8835, Time consumed:1.11s

Training Epoch: 378 [128/50000]	Loss: 0.9095	LR: 0.000012
Training Epoch: 378 [128/50000]	Loss: 0.8529	LR: 0.000012
Training Epoch: 378 [128/50000]	Loss: 0.8476	LR: 0.000012
Training Epoch: 378 [128/50000]	Loss: 0.8199	LR: 0.000012
Training Epoch: 378 [128/50000]	Loss: 0.9752	LR: 0.000012
Training Epoch: 378 [128/50000]	Loss: 0.8432	LR: 0.000012
Training Epoch: 378 [128/50000]	Loss: 0.7954	LR: 0.000012
Training Epoch: 378 [128/50000]	Loss: 0.7615	LR: 0.000012
Training Epoch: 378 [128/50000]	Loss: 0.9061	LR: 0.000012
Training Epoch: 378 [128/50000]	Loss: 0.6953	LR: 0.000012
Evaluating Network.....
Test set: Epoch: 378, Average loss: 0.0107, Top1Accuracy: 0.6298, Top3Accuracy: 0.8263, Top5Accuracy: 0.8831, Time consumed:1.11s

Training Epoch: 379 [128/50000]	Loss: 0.8032	LR: 0.000012
Training Epoch: 379 [128/50000]	Loss: 0.8130	LR: 0.000012
Training Epoch: 379 [128/50000]	Loss: 0.8462	LR: 0.000012
Training Epoch: 379 [128/50000]	Loss: 0.9273	LR: 0.000012
Training Epoch: 379 [128/50000]	Loss: 0.8373	LR: 0.000012
Training Epoch: 379 [128/50000]	Loss: 0.9692	LR: 0.000012
Training Epoch: 379 [128/50000]	Loss: 0.7865	LR: 0.000012
Training Epoch: 379 [128/50000]	Loss: 0.8869	LR: 0.000012
Training Epoch: 379 [128/50000]	Loss: 0.8118	LR: 0.000012
Training Epoch: 379 [128/50000]	Loss: 0.7300	LR: 0.000012
Evaluating Network.....
Test set: Epoch: 379, Average loss: 0.0108, Top1Accuracy: 0.6294, Top3Accuracy: 0.8251, Top5Accuracy: 0.8829, Time consumed:1.11s

Training Epoch: 380 [128/50000]	Loss: 0.6605	LR: 0.000012
Training Epoch: 380 [128/50000]	Loss: 0.7939	LR: 0.000012
Training Epoch: 380 [128/50000]	Loss: 0.8092	LR: 0.000012
Training Epoch: 380 [128/50000]	Loss: 0.8742	LR: 0.000012
Training Epoch: 380 [128/50000]	Loss: 0.9281	LR: 0.000012
Training Epoch: 380 [128/50000]	Loss: 0.7837	LR: 0.000012
Training Epoch: 380 [128/50000]	Loss: 0.6629	LR: 0.000012
Training Epoch: 380 [128/50000]	Loss: 0.7612	LR: 0.000012
Training Epoch: 380 [128/50000]	Loss: 0.8977	LR: 0.000012
Training Epoch: 380 [128/50000]	Loss: 0.8694	LR: 0.000012
Evaluating Network.....
Test set: Epoch: 380, Average loss: 0.0107, Top1Accuracy: 0.6297, Top3Accuracy: 0.8253, Top5Accuracy: 0.8831, Time consumed:1.10s

Training Epoch: 381 [128/50000]	Loss: 0.9318	LR: 0.000012
Training Epoch: 381 [128/50000]	Loss: 0.8327	LR: 0.000012
Training Epoch: 381 [128/50000]	Loss: 0.7371	LR: 0.000012
Training Epoch: 381 [128/50000]	Loss: 0.8118	LR: 0.000012
Training Epoch: 381 [128/50000]	Loss: 0.7160	LR: 0.000012
Training Epoch: 381 [128/50000]	Loss: 0.7856	LR: 0.000012
Training Epoch: 381 [128/50000]	Loss: 0.6696	LR: 0.000012
Training Epoch: 381 [128/50000]	Loss: 0.7556	LR: 0.000012
Training Epoch: 381 [128/50000]	Loss: 0.8751	LR: 0.000012
Training Epoch: 381 [128/50000]	Loss: 1.0534	LR: 0.000012
Evaluating Network.....
Test set: Epoch: 381, Average loss: 0.0106, Top1Accuracy: 0.6293, Top3Accuracy: 0.8252, Top5Accuracy: 0.8839, Time consumed:1.12s

Training Epoch: 382 [128/50000]	Loss: 0.8987	LR: 0.000011
Training Epoch: 382 [128/50000]	Loss: 0.8461	LR: 0.000011
Training Epoch: 382 [128/50000]	Loss: 0.7976	LR: 0.000011
Training Epoch: 382 [128/50000]	Loss: 0.8405	LR: 0.000011
Training Epoch: 382 [128/50000]	Loss: 0.9077	LR: 0.000011
Training Epoch: 382 [128/50000]	Loss: 0.8185	LR: 0.000011
Training Epoch: 382 [128/50000]	Loss: 1.0534	LR: 0.000011
Training Epoch: 382 [128/50000]	Loss: 0.9399	LR: 0.000011
Training Epoch: 382 [128/50000]	Loss: 0.8544	LR: 0.000011
Training Epoch: 382 [128/50000]	Loss: 0.8897	LR: 0.000011
Evaluating Network.....
Test set: Epoch: 382, Average loss: 0.0107, Top1Accuracy: 0.6290, Top3Accuracy: 0.8250, Top5Accuracy: 0.8836, Time consumed:1.12s

Training Epoch: 383 [128/50000]	Loss: 0.8422	LR: 0.000011
Training Epoch: 383 [128/50000]	Loss: 0.7783	LR: 0.000011
Training Epoch: 383 [128/50000]	Loss: 0.8030	LR: 0.000011
Training Epoch: 383 [128/50000]	Loss: 0.6258	LR: 0.000011
Training Epoch: 383 [128/50000]	Loss: 0.8839	LR: 0.000011
Training Epoch: 383 [128/50000]	Loss: 0.8377	LR: 0.000011
Training Epoch: 383 [128/50000]	Loss: 0.7950	LR: 0.000011
Training Epoch: 383 [128/50000]	Loss: 0.8511	LR: 0.000011
Training Epoch: 383 [128/50000]	Loss: 0.8644	LR: 0.000011
Training Epoch: 383 [128/50000]	Loss: 0.8805	LR: 0.000011
Evaluating Network.....
Test set: Epoch: 383, Average loss: 0.0106, Top1Accuracy: 0.6300, Top3Accuracy: 0.8251, Top5Accuracy: 0.8826, Time consumed:1.10s

Training Epoch: 384 [128/50000]	Loss: 0.8931	LR: 0.000011
Training Epoch: 384 [128/50000]	Loss: 0.9347	LR: 0.000011
Training Epoch: 384 [128/50000]	Loss: 0.7830	LR: 0.000011
Training Epoch: 384 [128/50000]	Loss: 0.7467	LR: 0.000011
Training Epoch: 384 [128/50000]	Loss: 0.8309	LR: 0.000011
Training Epoch: 384 [128/50000]	Loss: 0.8444	LR: 0.000011
Training Epoch: 384 [128/50000]	Loss: 0.7545	LR: 0.000011
Training Epoch: 384 [128/50000]	Loss: 0.6103	LR: 0.000011
Training Epoch: 384 [128/50000]	Loss: 0.7207	LR: 0.000011
Training Epoch: 384 [128/50000]	Loss: 1.0637	LR: 0.000011
Evaluating Network.....
Test set: Epoch: 384, Average loss: 0.0107, Top1Accuracy: 0.6305, Top3Accuracy: 0.8260, Top5Accuracy: 0.8832, Time consumed:1.12s

Training Epoch: 385 [128/50000]	Loss: 0.9736	LR: 0.000010
Training Epoch: 385 [128/50000]	Loss: 0.8802	LR: 0.000010
Training Epoch: 385 [128/50000]	Loss: 0.9678	LR: 0.000010
Training Epoch: 385 [128/50000]	Loss: 0.8109	LR: 0.000010
Training Epoch: 385 [128/50000]	Loss: 0.7558	LR: 0.000010
Training Epoch: 385 [128/50000]	Loss: 0.7404	LR: 0.000010
Training Epoch: 385 [128/50000]	Loss: 0.8845	LR: 0.000010
Training Epoch: 385 [128/50000]	Loss: 0.6619	LR: 0.000010
Training Epoch: 385 [128/50000]	Loss: 1.0112	LR: 0.000010
Training Epoch: 385 [128/50000]	Loss: 0.8727	LR: 0.000010
Evaluating Network.....
Test set: Epoch: 385, Average loss: 0.0107, Top1Accuracy: 0.6300, Top3Accuracy: 0.8256, Top5Accuracy: 0.8842, Time consumed:1.11s

Training Epoch: 386 [128/50000]	Loss: 0.9121	LR: 0.000010
Training Epoch: 386 [128/50000]	Loss: 0.9061	LR: 0.000010
Training Epoch: 386 [128/50000]	Loss: 0.8428	LR: 0.000010
Training Epoch: 386 [128/50000]	Loss: 0.7739	LR: 0.000010
Training Epoch: 386 [128/50000]	Loss: 0.6602	LR: 0.000010
Training Epoch: 386 [128/50000]	Loss: 0.9586	LR: 0.000010
Training Epoch: 386 [128/50000]	Loss: 0.7109	LR: 0.000010
Training Epoch: 386 [128/50000]	Loss: 0.9103	LR: 0.000010
Training Epoch: 386 [128/50000]	Loss: 0.8246	LR: 0.000010
Training Epoch: 386 [128/50000]	Loss: 0.7926	LR: 0.000010
Evaluating Network.....
Test set: Epoch: 386, Average loss: 0.0107, Top1Accuracy: 0.6301, Top3Accuracy: 0.8263, Top5Accuracy: 0.8829, Time consumed:1.12s

Training Epoch: 387 [128/50000]	Loss: 0.8543	LR: 0.000010
Training Epoch: 387 [128/50000]	Loss: 0.8685	LR: 0.000010
Training Epoch: 387 [128/50000]	Loss: 0.8419	LR: 0.000010
Training Epoch: 387 [128/50000]	Loss: 0.8048	LR: 0.000010
Training Epoch: 387 [128/50000]	Loss: 0.9434	LR: 0.000010
Training Epoch: 387 [128/50000]	Loss: 0.7322	LR: 0.000010
Training Epoch: 387 [128/50000]	Loss: 0.9380	LR: 0.000010
Training Epoch: 387 [128/50000]	Loss: 0.8259	LR: 0.000010
Training Epoch: 387 [128/50000]	Loss: 0.9537	LR: 0.000010
Training Epoch: 387 [128/50000]	Loss: 1.0022	LR: 0.000010
Evaluating Network.....
Test set: Epoch: 387, Average loss: 0.0106, Top1Accuracy: 0.6304, Top3Accuracy: 0.8271, Top5Accuracy: 0.8820, Time consumed:1.13s

Training Epoch: 388 [128/50000]	Loss: 0.8439	LR: 0.000010
Training Epoch: 388 [128/50000]	Loss: 0.8471	LR: 0.000010
Training Epoch: 388 [128/50000]	Loss: 0.8935	LR: 0.000010
Training Epoch: 388 [128/50000]	Loss: 0.9882	LR: 0.000010
Training Epoch: 388 [128/50000]	Loss: 1.0181	LR: 0.000010
Training Epoch: 388 [128/50000]	Loss: 0.8214	LR: 0.000010
Training Epoch: 388 [128/50000]	Loss: 0.8879	LR: 0.000010
Training Epoch: 388 [128/50000]	Loss: 0.8414	LR: 0.000010
Training Epoch: 388 [128/50000]	Loss: 0.8351	LR: 0.000010
Training Epoch: 388 [128/50000]	Loss: 0.8448	LR: 0.000010
Evaluating Network.....
Test set: Epoch: 388, Average loss: 0.0107, Top1Accuracy: 0.6294, Top3Accuracy: 0.8246, Top5Accuracy: 0.8844, Time consumed:1.12s

Training Epoch: 389 [128/50000]	Loss: 0.9314	LR: 0.000009
Training Epoch: 389 [128/50000]	Loss: 0.8018	LR: 0.000009
Training Epoch: 389 [128/50000]	Loss: 0.8166	LR: 0.000009
Training Epoch: 389 [128/50000]	Loss: 0.9001	LR: 0.000009
Training Epoch: 389 [128/50000]	Loss: 0.8477	LR: 0.000009
Training Epoch: 389 [128/50000]	Loss: 0.9153	LR: 0.000009
Training Epoch: 389 [128/50000]	Loss: 0.8522	LR: 0.000009
Training Epoch: 389 [128/50000]	Loss: 0.8562	LR: 0.000009
Training Epoch: 389 [128/50000]	Loss: 0.7021	LR: 0.000009
Training Epoch: 389 [128/50000]	Loss: 0.7340	LR: 0.000009
Evaluating Network.....
Test set: Epoch: 389, Average loss: 0.0106, Top1Accuracy: 0.6298, Top3Accuracy: 0.8253, Top5Accuracy: 0.8828, Time consumed:1.13s

Training Epoch: 390 [128/50000]	Loss: 0.8036	LR: 0.000009
Training Epoch: 390 [128/50000]	Loss: 0.7688	LR: 0.000009
Training Epoch: 390 [128/50000]	Loss: 0.9569	LR: 0.000009
Training Epoch: 390 [128/50000]	Loss: 0.9614	LR: 0.000009
Training Epoch: 390 [128/50000]	Loss: 0.8554	LR: 0.000009
Training Epoch: 390 [128/50000]	Loss: 0.7883	LR: 0.000009
Training Epoch: 390 [128/50000]	Loss: 0.8855	LR: 0.000009
Training Epoch: 390 [128/50000]	Loss: 0.9106	LR: 0.000009
Training Epoch: 390 [128/50000]	Loss: 0.7084	LR: 0.000009
Training Epoch: 390 [128/50000]	Loss: 0.9497	LR: 0.000009
Evaluating Network.....
Test set: Epoch: 390, Average loss: 0.0107, Top1Accuracy: 0.6288, Top3Accuracy: 0.8269, Top5Accuracy: 0.8823, Time consumed:1.11s

Training Epoch: 391 [128/50000]	Loss: 1.0215	LR: 0.000009
Training Epoch: 391 [128/50000]	Loss: 0.9437	LR: 0.000009
Training Epoch: 391 [128/50000]	Loss: 0.7752	LR: 0.000009
Training Epoch: 391 [128/50000]	Loss: 0.8295	LR: 0.000009
Training Epoch: 391 [128/50000]	Loss: 0.8150	LR: 0.000009
Training Epoch: 391 [128/50000]	Loss: 0.8241	LR: 0.000009
Training Epoch: 391 [128/50000]	Loss: 0.8207	LR: 0.000009
Training Epoch: 391 [128/50000]	Loss: 0.8608	LR: 0.000009
Training Epoch: 391 [128/50000]	Loss: 0.7719	LR: 0.000009
Training Epoch: 391 [128/50000]	Loss: 0.8678	LR: 0.000009
Evaluating Network.....
Test set: Epoch: 391, Average loss: 0.0107, Top1Accuracy: 0.6301, Top3Accuracy: 0.8264, Top5Accuracy: 0.8837, Time consumed:1.12s

Training Epoch: 392 [128/50000]	Loss: 0.8812	LR: 0.000009
Training Epoch: 392 [128/50000]	Loss: 0.9589	LR: 0.000009
Training Epoch: 392 [128/50000]	Loss: 0.7775	LR: 0.000009
Training Epoch: 392 [128/50000]	Loss: 0.7974	LR: 0.000009
Training Epoch: 392 [128/50000]	Loss: 0.7681	LR: 0.000009
Training Epoch: 392 [128/50000]	Loss: 0.8534	LR: 0.000009
Training Epoch: 392 [128/50000]	Loss: 0.9922	LR: 0.000009
Training Epoch: 392 [128/50000]	Loss: 0.8642	LR: 0.000009
Training Epoch: 392 [128/50000]	Loss: 0.7674	LR: 0.000009
Training Epoch: 392 [128/50000]	Loss: 1.0533	LR: 0.000009
Evaluating Network.....
Test set: Epoch: 392, Average loss: 0.0106, Top1Accuracy: 0.6290, Top3Accuracy: 0.8259, Top5Accuracy: 0.8837, Time consumed:1.11s

Training Epoch: 393 [128/50000]	Loss: 0.9253	LR: 0.000008
Training Epoch: 393 [128/50000]	Loss: 0.6353	LR: 0.000008
Training Epoch: 393 [128/50000]	Loss: 0.7173	LR: 0.000008
Training Epoch: 393 [128/50000]	Loss: 0.9183	LR: 0.000008
Training Epoch: 393 [128/50000]	Loss: 0.8455	LR: 0.000008
Training Epoch: 393 [128/50000]	Loss: 0.6703	LR: 0.000008
Training Epoch: 393 [128/50000]	Loss: 0.8967	LR: 0.000008
Training Epoch: 393 [128/50000]	Loss: 0.9896	LR: 0.000008
Training Epoch: 393 [128/50000]	Loss: 0.9415	LR: 0.000008
Training Epoch: 393 [128/50000]	Loss: 0.8053	LR: 0.000008
Evaluating Network.....
Test set: Epoch: 393, Average loss: 0.0106, Top1Accuracy: 0.6294, Top3Accuracy: 0.8258, Top5Accuracy: 0.8826, Time consumed:1.13s

Training Epoch: 394 [128/50000]	Loss: 0.8951	LR: 0.000008
Training Epoch: 394 [128/50000]	Loss: 0.7416	LR: 0.000008
Training Epoch: 394 [128/50000]	Loss: 0.7578	LR: 0.000008
Training Epoch: 394 [128/50000]	Loss: 0.7080	LR: 0.000008
Training Epoch: 394 [128/50000]	Loss: 1.0314	LR: 0.000008
Training Epoch: 394 [128/50000]	Loss: 0.8513	LR: 0.000008
Training Epoch: 394 [128/50000]	Loss: 0.8081	LR: 0.000008
Training Epoch: 394 [128/50000]	Loss: 0.7732	LR: 0.000008
Training Epoch: 394 [128/50000]	Loss: 0.9274	LR: 0.000008
Training Epoch: 394 [128/50000]	Loss: 1.0613	LR: 0.000008
Evaluating Network.....
Test set: Epoch: 394, Average loss: 0.0106, Top1Accuracy: 0.6305, Top3Accuracy: 0.8262, Top5Accuracy: 0.8834, Time consumed:1.11s

Training Epoch: 395 [128/50000]	Loss: 0.7853	LR: 0.000008
Training Epoch: 395 [128/50000]	Loss: 0.8886	LR: 0.000008
Training Epoch: 395 [128/50000]	Loss: 0.6660	LR: 0.000008
Training Epoch: 395 [128/50000]	Loss: 0.6195	LR: 0.000008
Training Epoch: 395 [128/50000]	Loss: 0.6894	LR: 0.000008
Training Epoch: 395 [128/50000]	Loss: 0.7882	LR: 0.000008
Training Epoch: 395 [128/50000]	Loss: 0.8525	LR: 0.000008
Training Epoch: 395 [128/50000]	Loss: 0.8483	LR: 0.000008
Training Epoch: 395 [128/50000]	Loss: 0.7026	LR: 0.000008
Training Epoch: 395 [128/50000]	Loss: 0.7626	LR: 0.000008
Evaluating Network.....
Test set: Epoch: 395, Average loss: 0.0106, Top1Accuracy: 0.6307, Top3Accuracy: 0.8257, Top5Accuracy: 0.8837, Time consumed:1.12s

Training Epoch: 396 [128/50000]	Loss: 0.7342	LR: 0.000008
Training Epoch: 396 [128/50000]	Loss: 0.6709	LR: 0.000008
Training Epoch: 396 [128/50000]	Loss: 0.7344	LR: 0.000008
Training Epoch: 396 [128/50000]	Loss: 0.8215	LR: 0.000008
Training Epoch: 396 [128/50000]	Loss: 0.7952	LR: 0.000008
Training Epoch: 396 [128/50000]	Loss: 0.8943	LR: 0.000008
Training Epoch: 396 [128/50000]	Loss: 0.7447	LR: 0.000008
Training Epoch: 396 [128/50000]	Loss: 0.8948	LR: 0.000008
Training Epoch: 396 [128/50000]	Loss: 0.8618	LR: 0.000008
Training Epoch: 396 [128/50000]	Loss: 0.7460	LR: 0.000008
Evaluating Network.....
Test set: Epoch: 396, Average loss: 0.0106, Top1Accuracy: 0.6294, Top3Accuracy: 0.8268, Top5Accuracy: 0.8837, Time consumed:1.12s

Training Epoch: 397 [128/50000]	Loss: 0.8915	LR: 0.000008
Training Epoch: 397 [128/50000]	Loss: 0.8415	LR: 0.000008
Training Epoch: 397 [128/50000]	Loss: 0.8456	LR: 0.000008
Training Epoch: 397 [128/50000]	Loss: 0.8220	LR: 0.000008
Training Epoch: 397 [128/50000]	Loss: 0.7813	LR: 0.000008
Training Epoch: 397 [128/50000]	Loss: 0.6911	LR: 0.000008
Training Epoch: 397 [128/50000]	Loss: 0.9197	LR: 0.000008
Training Epoch: 397 [128/50000]	Loss: 1.0083	LR: 0.000008
Training Epoch: 397 [128/50000]	Loss: 0.7546	LR: 0.000008
Training Epoch: 397 [128/50000]	Loss: 1.0244	LR: 0.000008
Evaluating Network.....
Test set: Epoch: 397, Average loss: 0.0108, Top1Accuracy: 0.6303, Top3Accuracy: 0.8254, Top5Accuracy: 0.8836, Time consumed:1.12s

Training Epoch: 398 [128/50000]	Loss: 0.8433	LR: 0.000007
Training Epoch: 398 [128/50000]	Loss: 0.7964	LR: 0.000007
Training Epoch: 398 [128/50000]	Loss: 0.7217	LR: 0.000007
Training Epoch: 398 [128/50000]	Loss: 0.7953	LR: 0.000007
Training Epoch: 398 [128/50000]	Loss: 0.8590	LR: 0.000007
Training Epoch: 398 [128/50000]	Loss: 0.8985	LR: 0.000007
Training Epoch: 398 [128/50000]	Loss: 0.8769	LR: 0.000007
Training Epoch: 398 [128/50000]	Loss: 0.8884	LR: 0.000007
Training Epoch: 398 [128/50000]	Loss: 0.8220	LR: 0.000007
Training Epoch: 398 [128/50000]	Loss: 0.8680	LR: 0.000007
Evaluating Network.....
Test set: Epoch: 398, Average loss: 0.0106, Top1Accuracy: 0.6305, Top3Accuracy: 0.8265, Top5Accuracy: 0.8840, Time consumed:1.12s

Training Epoch: 399 [128/50000]	Loss: 0.6427	LR: 0.000007
Training Epoch: 399 [128/50000]	Loss: 0.9291	LR: 0.000007
Training Epoch: 399 [128/50000]	Loss: 0.8166	LR: 0.000007
Training Epoch: 399 [128/50000]	Loss: 0.7711	LR: 0.000007
Training Epoch: 399 [128/50000]	Loss: 0.9371	LR: 0.000007
Training Epoch: 399 [128/50000]	Loss: 0.6470	LR: 0.000007
Training Epoch: 399 [128/50000]	Loss: 0.7845	LR: 0.000007
Training Epoch: 399 [128/50000]	Loss: 0.8290	LR: 0.000007
Training Epoch: 399 [128/50000]	Loss: 0.8335	LR: 0.000007
Training Epoch: 399 [128/50000]	Loss: 0.9234	LR: 0.000007
Evaluating Network.....
Test set: Epoch: 399, Average loss: 0.0107, Top1Accuracy: 0.6301, Top3Accuracy: 0.8256, Top5Accuracy: 0.8828, Time consumed:1.13s

Training Epoch: 400 [128/50000]	Loss: 0.8580	LR: 0.000007
Training Epoch: 400 [128/50000]	Loss: 0.7515	LR: 0.000007
Training Epoch: 400 [128/50000]	Loss: 0.8339	LR: 0.000007
Training Epoch: 400 [128/50000]	Loss: 0.8046	LR: 0.000007
Training Epoch: 400 [128/50000]	Loss: 0.8370	LR: 0.000007
Training Epoch: 400 [128/50000]	Loss: 0.9224	LR: 0.000007
Training Epoch: 400 [128/50000]	Loss: 0.8014	LR: 0.000007
Training Epoch: 400 [128/50000]	Loss: 0.8410	LR: 0.000007
Training Epoch: 400 [128/50000]	Loss: 0.8542	LR: 0.000007
Training Epoch: 400 [128/50000]	Loss: 1.0379	LR: 0.000007
Evaluating Network.....
Test set: Epoch: 400, Average loss: 0.0106, Top1Accuracy: 0.6298, Top3Accuracy: 0.8259, Top5Accuracy: 0.8839, Time consumed:1.09s

